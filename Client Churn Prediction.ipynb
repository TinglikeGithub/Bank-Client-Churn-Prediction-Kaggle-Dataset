{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "Our top priority in this business problem is to identify customers who are getting churned. \n",
    "Even if we predict non-churning customers as churned, it won't harm our business. \n",
    "But predicting churning customers as Non-churning will do. So recall (TP/TP+FN) need to be higher.\n",
    "\n",
    "Metric: recall rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.99991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.99994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.99987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0  768805383  Existing Customer            45      M                3   \n",
       "1  818770008  Existing Customer            49      F                5   \n",
       "2  713982108  Existing Customer            51      M                3   \n",
       "3  769911858  Existing Customer            40      F                4   \n",
       "4  709106358  Existing Customer            40      M                3   \n",
       "\n",
       "  Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0     High School        Married     $60K - $80K          Blue   \n",
       "1        Graduate         Single  Less than $40K          Blue   \n",
       "2        Graduate        Married    $80K - $120K          Blue   \n",
       "3     High School        Unknown  Less than $40K          Blue   \n",
       "4      Uneducated        Married     $60K - $80K          Blue   \n",
       "\n",
       "   Months_on_book  ...  Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "0              39  ...       12691.0                  777          11914.0   \n",
       "1              44  ...        8256.0                  864           7392.0   \n",
       "2              36  ...        3418.0                    0           3418.0   \n",
       "3              34  ...        3313.0                 2517            796.0   \n",
       "4              21  ...        4716.0                    0           4716.0   \n",
       "\n",
       "   Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0                 1.335             1144              42                1.625   \n",
       "1                 1.541             1291              33                3.714   \n",
       "2                 2.594             1887              20                2.333   \n",
       "3                 1.405             1171              20                2.333   \n",
       "4                 2.175              816              28                2.500   \n",
       "\n",
       "   Avg_Utilization_Ratio  \\\n",
       "0                  0.061   \n",
       "1                  0.105   \n",
       "2                  0.000   \n",
       "3                  0.760   \n",
       "4                  0.000   \n",
       "\n",
       "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  \\\n",
       "0                                           0.000093                                                                                    \n",
       "1                                           0.000057                                                                                    \n",
       "2                                           0.000021                                                                                    \n",
       "3                                           0.000134                                                                                    \n",
       "4                                           0.000022                                                                                    \n",
       "\n",
       "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  \n",
       "0                                            0.99991                                                                                   \n",
       "1                                            0.99994                                                                                   \n",
       "2                                            0.99998                                                                                   \n",
       "3                                            0.99987                                                                                   \n",
       "4                                            0.99998                                                                                   \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('BankChurners.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['CLIENTNUM',\n",
    "                'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
    "                'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2']\n",
    "\n",
    "# Remove CLIENTNUM and the Naive_Bayes_Classifiers\n",
    "data_raw = df.drop(drop_columns,errors='ignore',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Attrition_Flag            10127 non-null  object \n",
      " 1   Customer_Age              10127 non-null  int64  \n",
      " 2   Gender                    10127 non-null  object \n",
      " 3   Dependent_count           10127 non-null  int64  \n",
      " 4   Education_Level           10127 non-null  object \n",
      " 5   Marital_Status            10127 non-null  object \n",
      " 6   Income_Category           10127 non-null  object \n",
      " 7   Card_Category             10127 non-null  object \n",
      " 8   Months_on_book            10127 non-null  int64  \n",
      " 9   Total_Relationship_Count  10127 non-null  int64  \n",
      " 10  Months_Inactive_12_mon    10127 non-null  int64  \n",
      " 11  Contacts_Count_12_mon     10127 non-null  int64  \n",
      " 12  Credit_Limit              10127 non-null  float64\n",
      " 13  Total_Revolving_Bal       10127 non-null  int64  \n",
      " 14  Avg_Open_To_Buy           10127 non-null  float64\n",
      " 15  Total_Amt_Chng_Q4_Q1      10127 non-null  float64\n",
      " 16  Total_Trans_Amt           10127 non-null  int64  \n",
      " 17  Total_Trans_Ct            10127 non-null  int64  \n",
      " 18  Total_Ct_Chng_Q4_Q1       10127 non-null  float64\n",
      " 19  Avg_Utilization_Ratio     10127 non-null  float64\n",
      "dtypes: float64(5), int64(9), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Attrition_Flag', 'Customer_Age', 'Gender', 'Dependent_count',\n",
       "       'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category',\n",
       "       'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
       "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
       "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
       "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attrition_Flag              0\n",
       "Customer_Age                0\n",
       "Gender                      0\n",
       "Dependent_count             0\n",
       "Education_Level             0\n",
       "Marital_Status              0\n",
       "Income_Category             0\n",
       "Card_Category               0\n",
       "Months_on_book              0\n",
       "Total_Relationship_Count    0\n",
       "Months_Inactive_12_mon      0\n",
       "Contacts_Count_12_mon       0\n",
       "Credit_Limit                0\n",
       "Total_Revolving_Bal         0\n",
       "Avg_Open_To_Buy             0\n",
       "Total_Amt_Chng_Q4_Q1        0\n",
       "Total_Trans_Amt             0\n",
       "Total_Trans_Ct              0\n",
       "Total_Ct_Chng_Q4_Q1         0\n",
       "Avg_Utilization_Ratio       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAAHQCAYAAAC4H45lAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4eklEQVR4nO3deVxU5eI/8M+ZlWEbQHZBpNwFV1xQEzVTyaXFUrNMzax7y8qbtljfrtqtvG1mV8vbr9Q0LbtWmqWZS66J5r7njqKCIMKwMzDz/P7AOTEyAwwz7J/363VeyjnPOec5hwPz4TnPeY4khBAgIiIiokpR1HYFiIiIiOoThiciIiIiBzA8ERERETmA4YmIiIjIAQxPRERERA5geCIiIiJyAMMTERERkQMYnoiIiIgcwPBERERE5ACGJ6pT+vXrB0mSsG3bttquCgCgefPmkCQJiYmJVvPrWj2BulknV/r+++/Rs2dPeHh4QJIkSJJU21UiokaK4YlcxhI0LJNCoYC3tzfCw8Nxzz334P/+7/9w8uTJGqnLvHnzMGvWLGRmZtbI/qrbtm3bMGvWrAYbjCqyadMmPPTQQ9i7dy+aNWuG3r17o3fv3g5v5/r161Cr1ZAkqUrr1zU//fQTRo8ejWbNmsHNzQ1+fn7o2rUr3njjDVy/fr22q1cjLH80ODpVJ1v7UygU0Ov16NatG+bMmYO8vLxqrQNVL1VtV4AanpYtWyIwMBAAUFBQgBs3bmDz5s3YvHkz3n77bYwcORKfffYZmjRpUmbdZs2aoXXr1nB3d3eqDvPmzcOlS5cwYcIE+Pj4VHk7d955J9zc3KBWq52qj7O2bduG2bNnAyj5sLDFVeeuLlq4cCEA4IMPPsC0adOqvJ1vvvkGxcXFAIDdu3fj/PnzuPPOO11Sx5pkMBgwevRo/PrrrwCAgIAAREdHIysrC4cOHcLBgwfx8ccf44svvsCoUaNqubbVKzo6Wv6elvb7778DAKKioqDX62u6WmX2XVxcjCtXrmD//v3Yv38/VqxYgZ07d8LX17dW6kZOEkQuEhERIQCIJUuWlFmWlpYm5s2bJ/z9/QUA0aZNG5GZmVntdbl48WK1bD8uLk4AEFu3bq2W7d9u5syZAoCYOXNmjeyvrmnbtq0AIE6ePOnUdrp06SIACB8fHwFAzJo1y0U1rDmFhYWiW7duAoBo3ry5WL9+vTCbzfLyy5cvizFjxggAQqFQiO+++64Wa1t7ANToz2hl971lyxbh6ekpAIiXXnqpxutGrsHbdlQj/P398cILL2D//v0ICQnBn3/+ialTp9Z2taieyM/PBwDodLoqb+PkyZM4ePAgdDodPvzwQwDAV1995ZL61aSZM2di3759CAkJwc6dOxEfH291Gyo8PBzffPMNJk6cCLPZjCeffLLR3MKrDwYMGIC///3vAIDNmzfXcm2oqhieqEZFRETg008/BQAsX74cSUlJVsvtdXouLi7Gxx9/jO7du8PLywtarRahoaHo1asXZs6cKfdt+vLLLyFJEi5dugQAiIyMtOp3YNnutm3bIEkS+vXrh+LiYrz33nuIjo6Gu7s7mjdvLu/XXofx0v744w8MHToUfn5+8PDwQK9evbBmzRqbZSvq1D1hwgRIkoQvv/xSnidJknzLbvbs2VbHM2HChEptWwiB5cuXIy4uDj4+PtDpdGjTpg1eeeUV3Lx502ZdSvcN+eWXX9C3b194eXlBr9cjPj4ehw4dsntOypObm4u33noLHTp0gIeHB7y9vdGjRw988sknZW6/WI7Jcv5Lfz9nzZrl0H4tQWnYsGEYO3YsvL29cf78eSQkJFiVW7BgASRJwrBhw+xu6+bNm9BoNFCr1UhPT7dadujQIQwfPhy+vr7w9PREz5498d133wGA0/1tMjMzsWDBAgAltzDDwsLslv3444/h7+9vtY7FrFmz5HOYkpKCSZMmITQ0FG5ubmjbti0++OADm7fCLK5cuYLnn38erVq1gk6ng4+PD/r37y8f5+1KX5t//vknHn74Yfj7+0On06Fr16743//+V4WzUXVFRUWYP38+unfvDm9vb3h4eKBjx454++23a6QvUkREBADAaDSWWVbRNXL776TMzEzodDqo1epyQ/KwYcMgSRI++eQT5ypPJWq76YsajvJu25VmMplEaGioACC++OILq2X2boeNHDlSbgq/8847Rbdu3UR4eLhQKpUCgDh06JAQQoj169eL3r17C61WKwCImJgY0bt3b3k6ePCgEEKIrVu3CgCib9++YujQofJ2u3btKtq3b1/mmG6//Wep55tvvik0Go3w9PQUMTExIiQkRK7nhx9+WObYK7rdN378+DLnsHfv3iI8PFwAEOHh4VbH8/bbb1e4bbPZLMaOHSvX64477hBdunQRGo1GABARERHi/PnzZepiKb9w4UIhSZIICQkRXbp0ER4eHgKA8PT0FKdOnbJ5HPakpqaK6Oho+ZZShw4d5FtyAMQ999wj8vPz5fJTpkyx+/1ctGhRpfdrMpnkc7h69WohhBATJkwQAMTf//73MnVUqVRCrVaL9PR0m9v77LPPBABx7733Ws3ftGmTXFdvb2+ra2Lu3LnycVbVihUrBADh7+8vjEZjheVfeOEFAUC0atXKar7lNvCUKVPkn6NOnTqJVq1ayXW8//77hclkKrPNbdu2Cb1eLwAInU4noqOj5XMLQEybNq3MOpZr84MPPhCenp7Cy8tLdO3aVQQEBMjrffXVV1U+L7ZYtnv7z0NeXp4YMGCAvLxt27aiQ4cOQqFQCACiU6dO4saNG9WybwvLtTdy5Ei769pj63fSI488Yvd3jhBCpKSkCJVKJTQajd1rmhzD8EQuU9nwJMRfYejpp5+2mm8rAOzfv18ODrf3eTEYDOLzzz8Xly9ftlkXe32eLOFJqVSKwMBAsXv3bnlZ6Q/visKTSqUSY8aMETk5OUKIkqDyn//8R152+PDhCo+vNFvhSYjK9Xmyt+358+cLAMLLy0ts3LhRnp+cnCx69+4tAIgePXqU2Z7ll7i7u7tVfbKyssTdd98tAIjRo0fbrY8tlu97+/btxblz5+T5+/btE0FBQQKAePnll8us52wfti1btggAwtfXVxQWFgohSoIOAOHn5yfPsxg8eLAAID777DOb2+vXr58AIJYvXy7Py8rKEsHBwQKAmDhxosjLyxNClFwTCxYskEOVM+Hp2WefFQDEiBEjKlX++++/l/dZOhBYrieVSiWio6Otzuv27dvlcLRgwQKr7V29elX4+fkJSZLEO++8IwoKCuRlv//+u2jatKkAIH766Ser9SzXplqtFlOmTJF/xsxms3jllVcEABEaGiqKi4sdPSV22Qsw06ZNk/d34MABef7Zs2dFmzZtBAAxatQol++7uLhYJCYmirfeektIkiQ0Go3V753b17XH1s+C5Vru0KGDzXU+/PBDAUA89NBDVT4mssbwRC7jSHiaOnWqACAeeOABq/m2AsA333wjAIh//OMfDtelovAEQHz//fcOb8dSz8DAQKuwZfHggw8KAOLxxx+v8PhKc3V4MpvNcqvARx99VGadK1euyC1QW7ZssVpmOT/PPfdcmfWOHj0qAAi9Xm+3Prc7c+aMkCRJAJBbAEv73//+JwAIDw8PkZWVZbXM2fBk+Uv/ySeflOeZTCY57FhaoyyWLl0qAIh+/fqV2dbVq1eFQqEQ7u7uIjs7W57/3//+VwAlD0MUFRWVWc/yvXUmPN1///0O/SwcPnxY3ueRI0fk+ZbrCYBVgLCw/AHQvHlzq87oL774Yrn7/+mnnwQAMWDAAKv5lmuzY8eOZVqzjEaj/H2wdV1Ula0AYzAYhLu7u83vuRBC/PHHHwKAkCTJKtxXdd/2pnvuuUfs3bu33HXtsfWzYDabRfPmzQXwVyt8aR06dBAAxM8//1zlYyJr7PNEtcLDwwMAkJ2dXWHZ8PBwAMCWLVvs9s+pKr1ej/vuu6/K60+aNAlubm5l5j/zzDMAID9KXltOnTqFpKQkuLm5YfLkyWWWN23aFCNHjgQAbNy40eY2nnzyyTLzoqOj4ebmBoPBUKbPjz2bNm2CEAJ9+vRB586dyywfOXIkwsLCkJubKz9m7gr5+fn4/vvvAQBjx46V5ysUCowZMwZA2Y7jDzzwAHQ6HXbs2IFr165ZLfv2229hNpsxfPhweHp6Wh0fAIwbNw4qVdlRYCZOnOj0sVh+Xiw/PxUpXc7Wz1psbCy6dOlSZv4TTzwBNzc3JCYm4vTp0/L8H374AYDtawIAhgwZAo1Gg927d9vsM/XEE09AobD+2FGr1ejYsSMA4MKFC5U4qqrbtWsX8vLy0KxZM5s/9926dUNsbCyEEPL30xlRUVHymGS9e/fGnXfeCbVaje3bt+Ozzz5DYWGh0/sASvpJjR8/HgCwdOlSq2WHDx/G0aNHERwcjCFDhrhkf8QO41RLcnJyAADe3t4Vlo2NjUWPHj1w9OhRhIeH4/7778fcuXNx4MABCCGcqkfLli2hVCqrvH7btm3LnX/9+nVkZWVVefvOOnPmDICSMaDsfeC2b9/equzt7I2DFBAQAOCv72Vl69KuXTubyxUKBdq0aVNuXapizZo1yM7ORmhoKOLi4qyWPfroowCAn3/+GRkZGfJ8Ly8vDBs2DGazGd9++63VOt988w0A4JFHHrGaf/bsWQBAhw4dbNbD3nxHeHl5ASjpdF8ZpctZ1i3N3vXr4eEh/9Fi+V7k5OTInZSfeuop9OnTp8xkGYOsoKDAZqi2dy1ZxoWr7LVUVZZjadOmjd1O2RX9PDhi/vz52LVrlzydO3cOiYmJGDBgABYvXmwV5p01ceJESJKEr7/+2iq4WsLUY4895tTvOrLG8ES14vLlywD++qVZHoVCgV9++QUvvPACdDodfvzxR0ybNg0xMTGIjIy0ejLNUZX9C94ee/UvPb8yrWvVxfJhVN55DgoKAmC/nvbOkaUFobIB1hV1qQpLq9KYMWPKtHrExMSgVatWMBqNZZ74snywWcISAJw/fx779u2Dj48P4uPjrcpbgoqtkFLefEc0bdpUrkdllC5nWbc0R74XBoNBXvb777/bnSxPkFmGlyjNVddSVdXWNVhaaGgovvrqK7i5ueGHH37A4cOHXbLdiIgIDBgwAKmpqfjll18AlDyl/PXXXwOA1ZO55DyGJ6pxZrNZfjy8e/fulVrH19cX8+bNQ1paGg4dOoSPP/4Y/fv3x6VLlzBx4kS7j0hXt7S0tArnl/7QtPy1a+9DorItCpVlua2Umppqt4zl8WZXfLjXtbpcv35dvh05d+5cm6/NsLQw3H7rLj4+Hj4+Pti3bx/OnTsH4K8gNXLkSGg0GqvylmBgr/XEFR/GvXr1AgC7t8Vut2PHDgAlLay2RvS3d/0Cf32fLN+L0rcojUYjREmfWbtT6SE/6oq68vPg7++Pli1bAigZ6sSWqvyOeOKJJwD81dr0yy+/IDU1FTExMXKLGrkGwxPVuDVr1iAlJQVqtRqDBg1yaF1JktCpUyc8//zz+O233/Dqq68CAD7//PMy5WrCqVOnyp0fFBRkdWvS8gFr70PL8iF9u6oeT6tWrQCUtPTZ+1A/ceKEVdnqYtm+vfcbms1m/Pnnny6ty9dffw2TyQStVougoCC7E1DSmlK6z41Wq8WDDz4I4K/QZPnX1u0WS52PHj1qsy7Hjh1z+njuvfdeeHh44MaNG1i1alW5ZbOzs7FixQoAwOjRo22WsXf95uXlya3DluPS6/UIDQ0F8Nc1U99YjuXUqVN2w0lN/TyYzWYAKNOPs7zfEQaDATdu3LC7zQcffBA+Pj746aefcPPmTblVnq1OrsfwRDXq0qVLmDJlCgDg8ccft3krwRE9e/YEgDKdei0jUdu6deBKixYtstnp0zIQ6O3h8I477gAA7Nu3r8w6+/fvx5EjR2zup6rH07ZtWzRr1gwFBQX44osvyiy/du2a3Jl68ODBDm3bUYMGDYIkSdi1a5fNATZ/+OEHXLlyBR4eHi57aa+lNenVV19FSkqK3Sk2NhZAycCtpZW+dXfkyBGcPHkSISEhNt8veM8998jbMJlMZZY7c3vZwsfHB88++ywAYNq0abhy5Yrdsi+88AJu3LgBvV4vr3O73bt327xttHjxYhQUFCAiIgKtW7eW51vC5Lx586p+ELWoT58+cHd3R1JSEn788ccyy/fv34+EhARIkiR/P6tDWlqa/IeS5XeCRXm/I2z9DJfm5uaGRx55BEajEQsWLMDPP/8MjUZTpn8euUDNP+BHDVVF77b7+OOP5XfbtWvXThgMhjLlbD1uv3z5cvHmm2+WeUz9xo0b8mB3tw8JYBn4cuHChTbrahmqIC4urlLHVN44T48++qjVOE+ffPKJkCRJKJXKMo8Nr1+/Xn7Ev/SjymfOnBHt2rUTarXa5jlctWqVACD69Olj8zH40nWyN86Tt7e32Lx5szw/JSVF3HXXXQKA6NmzZ5ntoQqPTFfEMs5TVFSU1cCcBw4ckAeTfOWVV1yyr+PHj8vHcPbs2XLLfvLJJwKAaNmypdV8k8kk12vIkCECgJg6darNbZQe5+nJJ5+0Gsvo008/dck4T0IIUVBQIL+jLzIyUvzyyy9WwwkkJSXJgyZKkiS+/fbbMtsoPc5Tx44dRWJiorxs586dwtfXVwAQ8+fPt1ovKSlJ+Pn5ycMVZGRkWC1PT08XixYtEv/617+s5ld1iA5nWM61vXGemjZtajU0wrlz50S7du0EqjB+WWX3LUTJ8CCDBg0SQMlgp7cPy/Hyyy8LoGSwzpSUFHn+L7/8Iry9vYVKpSr3Z2Hfvn3y9xYc26naMDyRy1g+4Fq2bCmPAh0TEyOPP2KZHn74Ybuj3Nr6JfvRRx/J6zZt2lR069ZNREVFyeMTNW3aVFy6dMlqO8uWLZPXiYqKEnFxcSIuLk4OM64KT5YRxr28vERMTIw8cjoA8d5775XZntlsFgMHDhRAyQjbrVu3FlFRUUKhUIi+ffvKI4Hf/iFiMBjkD7SQkBDRu3dvERcXJ+bMmVPuubPss/QI4y1atLAaYbxZs2bljjDu6LkpT+kRxpVKpejYsaP8gQVADBw40Oa4WVXZl2XwxdjY2ArL3rhxQw6uCQkJVsssY5JZJnvj8whRMlih5bzq9XrRrVs3+ZqwDFSoUCgqfQz2ZGRkyNcRABEQECBiYmJE69at5bG0PD09xddff21zfUt4evbZZ0V4eLhQqVSiU6dOonXr1vI2hw8fbnOE8V27dsl/BKnVahEdHS169Ogh7rjjDnnft4ePuhSe8vLyRP/+/eXl7dq1Ex07dpTfVtCxY0eXjTAeFRVl9UaAFi1ayKHG3d1d/Prrr2XWTU1NlUO4VqsVnTp1kn+Hvvrqq5X6WbCM6wSO7VRtGJ7IZSw/1KUnT09PERYWJgYOHChef/31MiOE387WL9nLly+Ld999V9xzzz2iWbNmws3NTTRp0kR06dJFvPXWW2X++rX4+OOPRYcOHYROpyvzi9RV4Wnr1q1i7969Ij4+Xvj4+AidTid69uwpfvjhB7vbzM7OFi+++KIICwsTGo1GREZGitdff10UFBSU+yGyb98+ER8fL/z8/ORXSYwfP77cc2dhNpvFsmXLxF133SW8vb2FVqsVLVu2FC+99JLdD4rqCE9CCJGTkyPefPNNERUVJXQ6nfDw8BDdunUT8+fPt/vKEUf3ZTKZRFhYmAAgPvnkk0qtM3z4cAFAPPPMM1bzLQMnAiWv8KnIgQMHxNChQ4Ver5eP7ZtvvhE5OTlyqHKVNWvWiIceeki+lvR6vejUqZN47bXXRHJyst31Sg+6mpycLJ544gkREhIiNBqNaN26tXj33XfttnAKUfIB//rrr4uOHTsKT09PodPpRIsWLUR8fLz49NNPrVpMhKhb4UmIkoE5P/74YxETEyM8PDzk18y89dZbIjc312X7vn3S6XSiTZs2YsqUKTb/YLE4f/68ePjhh4Wvr6/Q6XSic+fO8rmpzM+C5VVAwcHBLh21nf4iCVHNz4YSEREOHDiAmJgYdOzY0WWPp1fVrFmzMHv2bMycOdPhFyxT3ffqq6/i3XffxfTp0/H+++/XdnUaJHYYJyKqAUuWLAEAl3WGJ7KlqKgIy5YtA+CaUe3JNoYnIiIX2bp1K1auXGn1BGZRURHmzp2LhQsXQqFQ2HxNDpGr/Oc//0FycjLi4uLsjuZPziv7AiYiIqoSy6CtarUakZGR8Pb2xpkzZ+RX9MyZMwedOnUCABw6dAjPPfdcpbc9f/58m+8EbIj69OlT6bJPPPGEPDikq/3yyy94++23K13+u+++Q3BwcLXUpTwpKSkYM2YM0tPTcfz4cSgUCofqTY5jeCIicpG77roLU6ZMwdatW3Ht2jVcuHABfn5+iIuLw5QpU6zG/TIYDA69ALn061EaOkfOy8CBA6utHtevX3eoLgUFBdVWl4r2u337dqjVarRv3x6zZ8/m7eFqxg7jRERERA5gnyciIiIiB/C2nRPMZjOuXbsGLy+vGnuXGhERETlHCIHs7GyEhoZCoXC8HYnhyQnXrl1DeHh4bVeDiIiIqiApKQlhYWEOr8fw5AQvLy8AJSff29u7lmtDRERElZGVlYXw8HD5c9xRDE9OsNyq8/b2ZngiIiKqZ6ra5YYdxomIiIgcwPBERERE5ACGJyIiIiIHMDwREREROYDhiYiIiMgBDE9EREREDmB4IiIiInIAwxMRERGRAxieiIiIiBzA8ERERETkAIYnIiIiIgcwPBERERE5gOGJiIiIyAEMT0REREQOUNV2Bch5ZrMZQogKy0mSBIWCeZmIiMgZ/CSt58xmM8KbRUClUlU4hTeLgNlsru0qExER1WtsearnhBC4dvUK3lt3DAqF0m45s9mEl4dGV6qFioiIiOxjeGogFAolFEr74YmIiIhcg7ftiIiIiBzA8ERERETkAIYnIiIiIgcwPBERERE5gOGJiIiIyAEMT0REREQOYHgiIiIicgDDExEREZEDGJ6IiIiIHMDwREREROQAhiciIiIiBzA8ERERETmgzoWnHTt2YPjw4QgNDYUkSVizZo3VckmSbE7vv/++XKZfv35llo8ZM8ZqOxkZGRg3bhz0ej30ej3GjRuHzMzMGjhCIiIiqs/qXHjKzc1Fx44dsWDBApvLk5OTrabFixdDkiSMHDnSqtzkyZOtyn322WdWy8eOHYvDhw9jw4YN2LBhAw4fPoxx48ZV23ERERFRw6Cq7QrcLj4+HvHx8XaXBwcHW339448/on///rjjjjus5ru7u5cpa3Hq1Cls2LABe/bsQY8ePQAAn3/+OWJjY3H69Gm0bt3ayaMgIiKihqrOtTw54vr161i3bh0mTZpUZtmKFSvg7++P9u3bY/r06cjOzpaXJSQkQK/Xy8EJAHr27Am9Xo/du3fb3V9hYSGysrKsJiIiImpc6lzLkyOWLl0KLy8vPPjgg1bzH330UURGRiI4OBjHjx/HjBkzcOTIEWzatAkAkJKSgsDAwDLbCwwMREpKit39zZkzB7Nnz3btQRAREVG9Uq/D0+LFi/Hoo4/Czc3Nav7kyZPl/0dFRaFly5aIiYnBwYMH0aVLFwAlHc9vJ4SwOd9ixowZePHFF+Wvs7KyEB4e7uxhEBERUT1Sb8PTzp07cfr0aXz77bcVlu3SpQvUajXOnj2LLl26IDg4GNevXy9TLi0tDUFBQXa3o9VqodVqnao3ERER1W/1ts/TokWL0LVrV3Ts2LHCsidOnEBRURFCQkIAALGxsTAYDPjjjz/kMnv37oXBYECvXr2qrc5ERERU/9W5lqecnBycO3dO/vrixYs4fPgw/Pz80KxZMwAlt8tWrVqFDz/8sMz658+fx4oVK3DvvffC398fJ0+exLRp09C5c2f07t0bANC2bVsMGTIEkydPlocweOqppzBs2DA+aUdERETlqnMtT/v370fnzp3RuXNnAMCLL76Izp0745///KdcZuXKlRBC4JFHHimzvkajwZYtWzB48GC0bt0azz//PAYNGoTNmzdDqVTK5VasWIHo6GgMGjQIgwYNQocOHfDVV19V/wESERFRvSYJIURtV6K+ysrKgl6vh8FggLe3d63UwWQyQaVS4YNfTkJRKhzezmwyYXp8OxQXF1uFSCIiosbG2c/vOtfyRERERFSXMTwREREROYDhiYiIiMgBDE9EREREDmB4IiIiInIAwxMRERGRAxieiIiIiBzA8ERERETkAIYnIiIiIgcwPBERERE5gOGJiIiIyAEMT0REREQOYHgiIiIicgDDExEREZEDGJ6IiIiIHMDwREREROQAhiciIiIiBzA8ERERETmA4YmIiIjIAQxPRERERA5geCIiIiJyAMMTERERkQMYnoiIiIgcwPBERERE5ACGJyIiIiIHMDwREREROYDhiYiIiMgBDE9EREREDmB4IiIiInIAwxMRERGRAxieiIiIiBzA8ERERETkAIYnIiIiIgcwPBERERE5gOGJiIiIyAEMT0REREQOqHPhaceOHRg+fDhCQ0MhSRLWrFljtXzChAmQJMlq6tmzp1WZwsJCPPfcc/D394eHhwdGjBiBK1euWJXJyMjAuHHjoNfrodfrMW7cOGRmZlbz0REREVF9V+fCU25uLjp27IgFCxbYLTNkyBAkJyfL0/r1662WT506FatXr8bKlSuxa9cu5OTkYNiwYTCZTHKZsWPH4vDhw9iwYQM2bNiAw4cPY9y4cdV2XERERNQwqGq7AreLj49HfHx8uWW0Wi2Cg4NtLjMYDFi0aBG++uorDBw4EACwfPlyhIeHY/PmzRg8eDBOnTqFDRs2YM+ePejRowcA4PPPP0dsbCxOnz6N1q1bu/agiIiIqMGocy1PlbFt2zYEBgaiVatWmDx5MlJTU+VlBw4cQFFREQYNGiTPCw0NRVRUFHbv3g0ASEhIgF6vl4MTAPTs2RN6vV4uY0thYSGysrKsJiIiImpc6l14io+Px4oVK/Dbb7/hww8/xL59+zBgwAAUFhYCAFJSUqDRaODr62u1XlBQEFJSUuQygYGBZbYdGBgol7Flzpw5ch8pvV6P8PBwFx4ZERER1Qd17rZdRUaPHi3/PyoqCjExMYiIiMC6devw4IMP2l1PCAFJkuSvS//fXpnbzZgxAy+++KL8dVZWFgMUERFRI1PvWp5uFxISgoiICJw9exYAEBwcDKPRiIyMDKtyqampCAoKkstcv369zLbS0tLkMrZotVp4e3tbTURERNS41PvwlJ6ejqSkJISEhAAAunbtCrVajU2bNsllkpOTcfz4cfTq1QsAEBsbC4PBgD/++EMus3fvXhgMBrkMERERkS117rZdTk4Ozp07J3998eJFHD58GH5+fvDz88OsWbMwcuRIhISEIDExEa+99hr8/f3xwAMPAAD0ej0mTZqEadOmoUmTJvDz88P06dMRHR0tP33Xtm1bDBkyBJMnT8Znn30GAHjqqacwbNgwPmlHRERE5apz4Wn//v3o37+//LWlj9H48eOxcOFCHDt2DMuWLUNmZiZCQkLQv39/fPvtt/Dy8pLX+eijj6BSqTBq1Cjk5+fj7rvvxpdffgmlUimXWbFiBZ5//nn5qbwRI0aUO7YUEREREQBIQghR25Wor7KysqDX62EwGGqt/5PJZIJKpcIHv5yEolQ4vJ3ZZML0+HYoLi62CpFERESNjbOf3/W+zxMRERFRTWJ4IiIiInIAwxMRERGRAxieiIiIiBzA8ERERETkAIYnIiIiIgcwPBERERE5gOGJiIiIyAEMT0REREQOYHgiIiIicgDDExEREZEDGJ6IiIiIHMDwREREROQAhiciIiIiBzA8ERERETmA4YmIiIjIAQxPRERERA5geCIiIiJyAMMTERERkQMYnoiIiIgcoKrtCpBtZrMZQogKy5lMphqoDREREVkwPNVBZrMZ4c0icO3qlUqvU5mgRURERM5jeKqDhBC4dvUK3lt3DAqFstyyxUVGvDqiEwCGJyIioprA8FSHKRRKKJTlhyeFqfzlRERE5FrsME5ERETkAIYnIiIiIgcwPBERERE5gOGJiIiIyAEMT0REREQOYHgiIiIicgDDExEREZEDGJ6IiIiIHMDwREREROQAhiciIiIiBzA8ERERETmA4YmIiIjIAQxPRERERA6oc+Fpx44dGD58OEJDQyFJEtasWSMvKyoqwiuvvILo6Gh4eHggNDQUjz/+OK5du2a1jX79+kGSJKtpzJgxVmUyMjIwbtw46PV66PV6jBs3DpmZmTVwhERERFSf1bnwlJubi44dO2LBggVlluXl5eHgwYN44403cPDgQfzwww84c+YMRowYUabs5MmTkZycLE+fffaZ1fKxY8fi8OHD2LBhAzZs2IDDhw9j3Lhx1XZcRERE1DCoarsCt4uPj0d8fLzNZXq9Hps2bbKaN3/+fHTv3h2XL19Gs2bN5Pnu7u4IDg62uZ1Tp05hw4YN2LNnD3r06AEA+PzzzxEbG4vTp0+jdevWLjoaIiIiamjqXMuTowwGAyRJgo+Pj9X8FStWwN/fH+3bt8f06dORnZ0tL0tISIBer5eDEwD07NkTer0eu3fvtruvwsJCZGVlWU1ERETUuNS5lidHFBQU4NVXX8XYsWPh7e0tz3/00UcRGRmJ4OBgHD9+HDNmzMCRI0fkVquUlBQEBgaW2V5gYCBSUlLs7m/OnDmYPXu26w+EiIiI6o16G56KioowZswYmM1mfPrpp1bLJk+eLP8/KioKLVu2RExMDA4ePIguXboAACRJKrNNIYTN+RYzZszAiy++KH+dlZWF8PBwZw+FiIiI6pF6GZ6KioowatQoXLx4Eb/99ptVq5MtXbp0gVqtxtmzZ9GlSxcEBwfj+vXrZcqlpaUhKCjI7na0Wi20Wq3T9SciIqL6q971ebIEp7Nnz2Lz5s1o0qRJheucOHECRUVFCAkJAQDExsbCYDDgjz/+kMvs3bsXBoMBvXr1qra6ExERUf1X51qecnJycO7cOfnrixcv4vDhw/Dz80NoaCgeeughHDx4ED///DNMJpPcR8nPzw8ajQbnz5/HihUrcO+998Lf3x8nT57EtGnT0LlzZ/Tu3RsA0LZtWwwZMgSTJ0+WhzB46qmnMGzYMD5pR0REROWqc+Fp//796N+/v/y1pY/R+PHjMWvWLKxduxYA0KlTJ6v1tm7din79+kGj0WDLli34+OOPkZOTg/DwcAwdOhQzZ86EUqmUy69YsQLPP/88Bg0aBAAYMWKEzbGliIiIiEpzKjx17twZTz31FB599NEK+x1VVr9+/SCEsLu8vGUAEB4eju3bt1e4Hz8/Pyxfvtzh+hEREVHj5lSfp1OnTmHKlCkICQnBhAkTsGvXLlfVi4iIiKhOcio8paSk4KOPPkKLFi2wbNkyxMXFoW3btpg7dy5u3LjhqjoSERER1RlOhScfHx88//zzOHLkCP744w/5fXLTp09HWFgYRo8ejY0bN7qqrkRERES1zmVDFcTExOC///0vkpOTsXjxYnTv3h2rVq1CfHw8IiMj8fbbbyM5OdlVuyMiIiKqFS4f50mn02HEiBF44IEHEBoaCiEELl26hDfeeAPNmzfHlClTkJeX5+rdEhEREdUIl4anzZs3Y8yYMWjatCmmT58Os9mM1157DadPn8bKlSvRuXNnLFy4EFOmTHHlbomIiIhqjNPjPF27dg2LFy/GkiVLkJiYCAC455578NRTT+G+++6Tx1Zq2bIlRo0aheHDh+PHH390drdEREREtcKp8DR8+HBs2LABJpMJQUFBePXVVzF58mQ0b97c7jq9evXC+vXrndktERERUa1xKjytX78eAwcOlFuZVKqKNzd8+HCEhoY6s1siIiKiWuNUeDp37hwiIyMdWicqKgpRUVHO7JaIiIio1jjVYdzR4ERERERU3zkVnubOnQt/f39cu3bN5vJr164hICAA//nPf5zZDREREVGd4VR4WrVqFTp06GC3D1NoaCg6deqElStXOrMbIiIiojrDqfB05syZCvsvtW/fHmfPnnVmN0RERER1hlPhKS8vDx4eHuWWcXNzQ05OjjO7ISIiIqoznApPERER2L17d7llEhISEBYW5sxuiIiIiOoMp8LTsGHDsGvXLixevNjm8i+++AK7du3C8OHDndkNERERUZ3h1DhPr7zyClauXInJkydj+fLluOeee9C0aVNcvXoVGzduxI4dOxAaGooZM2a4qr5EREREtcqp8BQQEICtW7fisccew7Zt27Bt2zZIkgQhBACge/fuWL58OQICAlxSWSIiIqLa5vSLgVu2bIm9e/di//79+OOPP5CZmQkfHx90794dMTExrqgjERERUZ3hdHiyiImJYVgiIiKiBs+pDuNEREREjY3TLU9paWlYsmQJ9u3bh8zMTJhMpjJlJEnCli1bnN0VERERUa1zKjwdPXoUAwYMQEZGhtxJ3BZJkpzZDREREVGd4dRtu2nTpuHmzZt4/fXXcfHiRRQVFcFsNpeZbLVGEREREdVHTrU8JSQk4P7778ebb77pqvoQERER1WlOtTxpNBrceeedrqoLERERUZ3nVHgaMGAA9u/f76q6EBEREdV5ToWn999/HydOnMAHH3zgqvoQERER1WlO9Xn617/+hfbt2+OVV17Bf//7X3Ts2BF6vb5MOUmSsGjRImd2RURERFQnOBWevvzyS/n/Fy5cwIULF2yWY3giIiKihsKp8HTx4kVX1YOIiIioXnAqPEVERLiqHkRERET1gkvfbXfz5k0kJSW5cpNEREREdYrT4clgMOCFF15AUFAQAgICEBkZKS/bu3cv7r33Xhw4cMDZ3RARERHVCU6Fp5s3b6JHjx6YP38+wsPD0bZtW6t33HXo0AG///47VqxY4XRFiYiIiOoCp8LTrFmzcObMGXzzzTfYv38/Hn74YavlOp0OcXFx+O233yq9zR07dmD48OEIDQ2FJElYs2aN1XIhBGbNmoXQ0FDodDr069cPJ06csCpTWFiI5557Dv7+/vDw8MCIESNw5coVqzIZGRkYN24c9Ho99Ho9xo0bh8zMTIeOn4iIiBofp8LT2rVrMWzYMIwePdpumYiIiDLBpTy5ubno2LEjFixYYHP5e++9h7lz52LBggXYt28fgoODcc899yA7O1suM3XqVKxevRorV67Erl27kJOTg2HDhlm9oHjs2LE4fPgwNmzYgA0bNuDw4cMYN25cpetJREREjZNTT9slJydjzJgx5ZZxc3NDbm5upbcZHx+P+Ph4m8uEEJg3bx5ef/11PPjggwCApUuXIigoCF9//TWefvppGAwGLFq0CF999RUGDhwIAFi+fDnCw8OxefNmDB48GKdOncKGDRuwZ88e9OjRAwDw+eefIzY2FqdPn0br1q0rXV8iIiJqXJxqeWrSpEmFT9f9+eefCAkJcWY3sosXLyIlJQWDBg2S52m1WsTFxWH37t0AgAMHDqCoqMiqTGhoKKKiouQyCQkJ0Ov1cnACgJ49e0Kv18tliIiIiGxxKjz17dsXa9euxdWrV20uP3nyJDZs2CC3ADkrJSUFABAUFGQ1PygoSF6WkpICjUYDX1/fcssEBgaW2X5gYKBcxpbCwkJkZWVZTURERNS4OBWeXn/9dRQXF6N37974+uuvcePGDQDAqVOnsGjRIgwYMABarRYvvfSSSyprIUmS1ddCiDLzbnd7GVvlK9rOnDlz5A7mer0e4eHhDtaciIiI6junwlN0dDS+/fZbZGZmYty4cfj0008hhEBUVBQmT56M/Px8/O9//0PLli1dUtng4GAAKNM6lJqaKrdGBQcHw2g0IiMjo9wy169fL7P9tLS0Mq1apc2YMQMGg0Ge6sOAoMZiMzLzjEjNLoSk0tR2dYiIiOo9pzqMA8CIESNw4cIFLF26FHv37sXNmzfh7e2NHj16YOLEifD393dFPQEAkZGRCA4OxqZNm9C5c2cAgNFoxPbt2/Huu+8CALp27Qq1Wo1NmzZh1KhRAEo6th8/fhzvvfceACA2NhYGgwF//PEHunfvDqBkQE+DwYBevXrZ3b9Wq4VWq3XZ8VQnk1lg59k0HL1igGXkrdDJ/8Uvx5IxJCq43BY2SZKgULh08HkiIqIGw+nwBAB+fn74xz/+4YpNIScnB+fOnZO/vnjxIg4fPgw/Pz80a9YMU6dOxTvvvIOWLVuiZcuWeOedd+Du7o6xY8cCAPR6PSZNmoRp06ahSZMm8PPzw/Tp0xEdHS33vWrbti2GDBmCyZMn47PPPgMAPPXUUxg2bFiDeNIuz1iM9cdScDUzHwCgVkqQAMA7EFNWHkHu6U9xY+17gNlkc/3QpmFIunyJAYqIiMgGl4QnV9q/fz/69+8vf/3iiy8CAMaPH48vv/wSL7/8MvLz8/HMM88gIyMDPXr0wMaNG+Hl5SWv89FHH0GlUmHUqFHIz8/H3XffjS+//BJKpVIus2LFCjz//PPyU3kjRoywO7ZUfWIyC6w+dBU3cozQKBUY3D4IdwR4Ij+/AO998D78eo+BR+ve6DVvK/q2LNsqaDab8PLQaKuR4omIiOgvknDiU3LZsmWVLvv4449XdTd1VlZWFvR6PQwGA7y9vV22XZPJBJVKhQ9+OQlFqcBnS7HRiJeHReP99cehVKnxx8WbSLiQDp1aiZFdmqKJp9aq3N+X7cX6E2kAgHvaBaFdiHW9zSYTpse3Q3FxsVXYJCIiaiic/fx2quVpwoQJlX7KrSGGp7rmZq4Rf1y8CQDo28pfDk6l3eHvgR6RJuy9eBO//ZmKIC+tzXJERERkm1PhacmSJTbnGwwGHDx4EF9//TVGjBiB4cOHO7MbqgQhBLb8eR0mIRDRxB2tg7zslu0R6YeUrAJcSs/DznM3cH+npjVYUyIiovrNqfA0fvz4cpc//fTTuPvuu/H3v//dmd1QJVzOKMC1zAKolRIGtA6s8Gm6fq0C8NWeS7iUnodL6bmIaOJRg7UlIiKqv6r1carY2FgMHz4c//znP6tzNwTgyJWS0c7bh+rhrVNXWN7HXYOOYT4AgJ3nbsDMDuJERESVUu3PokdERODIkSPVvZtGTeUXhssZJcMSdAr3qfR63SP9oFUpkJ5jxKlkvmqGiIioMqo1PAkhsGPHDuh0uurcTaPn3XUYgJLO4PpKtDpZuKmV6N7cDwBw4FIGhycgIiKqBKf6PO3YscPm/OLiYly9ehXLli3Dvn37MG7cOGd2Q+UoKDLBI6pk8E9HWp0soprqsffiTWTkFSExPQ8Rvm4uriEREVHD4lR46tevX7kdk4UQiI2Nxdy5c53ZDZXjTFouFBo3NPFQI8zX8RY+jUqBqKbeOHg5E4eSMhDhG1INtSQiImo4nApP//znP22GJ4VCAV9fX8TExKBnz57O7IIqcC4tDwDQNtizwjG37OkY5oNDSZlIupmPGzmFrqweERFRg+NUeJo1a5aLqkFVkVNYjOSskrDTIqDqQw1469RoEeCJs6k5OHzF4KrqERERNUh882s9di41BwBQcPUUPLXOvaawczMfAMCZ1FxIGndnq0ZERNRgOfWJe/ny5Sqv26xZM2d2TQDOpmYDAPL+3Akg3qltBXu7oYmHBum5Rni0vcsFtSMiImqYnApPzZs3r1I/G0mSUFxc7MyuG72cwmJcyywAAOSd/t3p7UmShHYh3th57gY8O9zj9PaIiIgaKqfC0+OPP46LFy9i586d8PHxQadOnRAUFITr16/j8OHDyMzMRN++fREZGemq+tItllt2wV5aXMpOd8k2Wwd74ffzN6ANbYOzqTloE6J3yXaJiIgaEqfC00svvYTevXvjtddew4wZM+Dh8Ven5dzcXLz99ttYuHAhPv30U7Rr187pytJfLtwoCU93+rtjr4u26aFVoXkTd1y4kYfvDlzB/w1jeCIiIrqdUx3GX375ZXTv3h1vvfWWVXACAA8PD7zzzjvo1q0bXnnlFacqSdaKTGb5ll2En2tHb28b7AUAWH3oGopMZpdum4iIqCFwKjz9/vvv6N69e7llunXrhp07dzqzG7rN1cx8mMwCXm4q+Oice8rudhF+7jDlZiA914jfz91w6baJiIgaAqfCk9lsxrlz58otc/bsWb4zzcUup5cMjBnh517lgTHtUSok5P5Z0gF97ZFrLt02ERFRQ+BUeOrbty++//57rFy50ubyb775Bj/88AP69u3rzG7oNpduloSnZn7VMx5T3qntAICNJ66joMhULfsgIiKqr5y65/Pee+9h586dePTRR/Huu++iT58+CAwMRGpqKnbt2oWjR4/Cy8sL7777rqvq2+hlFxThZq4REoBwP3dAuD7cFF79E6E+briWWYCtf6YiPprvuyMiIrJwKjy1a9cOv//+O6ZMmYIdO3bgyJEjVsv79u2LTz75hE/audDlW61OQd5ucFMrUWysjpYhgaHRIfh850X8dPQawxMREVEpTvc2joqKwrZt25CUlIQjR47AYDBAr9ejY8eOCA8Pd0UdqRRLf6dmTar3FSrDO5SEpy2nUpFdUAQvN3W17o+IiKi+cNmjWuHh4QxL1UwIgaSMfAAlncWrU7sQL9wR4IELabnYfOo6HugcVq37IyIiqi9c8mJgo9GI9evXY+7cufjXv/4lzy8oKEBqairMZo4X5Ao3c43ILzJBpZAQ5O1WrfuSJAlDb92u23A8pVr3RUREVJ84HZ7Wrl2LZs2aYfjw4Zg+fTpmzZolLzt69ChCQkLsPo1HjrEMjBmsd4NS4dohCmwZ3D4YALD9TBryjHwXIREREeCCQTIfeughaLVafPzxxxg7dqzV8u7du6NFixb4/vvvnaoklbhqKLll19THtaOK29M+1BvhfjoUFJmx40xajeyTiIiornMqPL311lvw8fHB/v37MWXKFLRs2bJMma5du5Z5Co+q5lpmSXgKraHwJEkShtxqfeKtOyIiohJOhac9e/bgvvvuQ0BAgN0y4eHhSEnhB6+zsvKLkF1QDIUEhOirt79TaUOiSsLTllOpMBaz7xoREZFT4amwsBB6vb7cMgaDAQqFS/qlN2qWVqcALy3Uypo7n53DfRHopUV2YTF+P8933RERETn1KXzHHXdg//795ZZJSEhAmzZtnNkNoeRlwEDN9XeyUCgkueP4r7x1R0RE5Fx4GjlyJHbu3Illy5bZXP7BBx/g+PHjGD16tDO7Ifz1pF1N9XcqzXLrbuPJ6zCZ+ZJnIiJq3JwaJPOll17C999/j4kTJ2L58uUoKCj5gH/55ZeRkJCA3bt3o1OnTpgyZYpLKttY5RtNuJlnBFA74al7pB983NW4mWvEvsSb6HlHkxqvAxERUV3hVMuTp6cndu7ciTFjxmDr1q3YtWsXhBD44IMPsHv3bowaNQqbN2+GVqt1VX0bpeSsklt2vu5q6NTKGt+/WqnAwLZBAPjUHRERkdM9j319fbFixQqkpKRg/fr1WL58OdauXYtr167hm2++ga+vryvq2ahdNxQCKBkcs7aUHrLAzFt3RETUiDl1227AgAHo06cP3nzzTTRp0gRDhgxxVb2olJSsWyOLV/MrWcrTp6U/PDRKpGQV4OhVAzqF+9RaXYiIiGqTUy1Pe/fuRXExX9tRnYQQSDH89VqW2uKmVqJ/m0AAvHVHRESNm1PhqW3btkhMTHRRVciWjLwiGE1mqBQS/D1qt++Y5am7DceTIQRv3RERUePkVHh67rnnsHbtWpw8edJV9amU5s2bQ5KkMtOzzz4LAJgwYUKZZT179rTaRmFhIZ577jn4+/vDw8MDI0aMwJUrV2r0OCrD0uoU6K2FogZeBlye/q0DoVEpkJiehzPXc2q1LkRERLXFqT5PkZGR6NevH3r27Imnn34a3bp1Q1BQECSp7Id83759ndmVlX379sFkMslfHz9+HPfccw8efvhhed6QIUOwZMkS+WuNRmO1jalTp+Knn37CypUr0aRJE0ybNg3Dhg3DgQMHoFTW/BNt9tSF/k4WHloV7mrhjy1/puLXEyloHexV21UiIiKqcU6Fp379+kGSJAgh8OGHH9oMTRalw46zbn+X3r///W/ceeediIuLk+dptVoEBwfbXN9gMGDRokX46quvMHDgQADA8uXLER4ejs2bN2Pw4MEuq6uz6lJ4AoDB7YPl8PT83WVfBE1ERNTQORWe/vnPf5YbmGqC0WjE8uXL8eKLL1rVZdu2bQgMDISPjw/i4uLw9ttvIzCwpMPzgQMHUFRUhEGDBsnlQ0NDERUVhd27d9sNT4WFhSgsLJS/zsrKqqajKlFkMuNGTu0PU1Da3W0DoZCAE9eykHQzD+F+7rVdJSIiohrlcHhSKpWYNWsW3njjDcyaNQtAyVN3e/fuxfPPP+/q+lVozZo1yMzMxIQJE+R58fHxePjhhxEREYGLFy/ijTfewIABA3DgwAFotVqkpKRAo9GUGYMqKCgIKSn2nySbM2cOZs+eXV2HUkZqdiGEADw0Snhqncq5LtPEU4tuzf2w9+JNbDx5HZP6RNZ2lYiIiGqUwx3GhRBlnrTasGED/vGPf7isUo5YtGgR4uPjERoaKs8bPXo0hg4diqioKAwfPhy//PILzpw5g3Xr1pW7LSFEuS1pM2bMgMFgkKekpCSXHYct17P/anWq7Ra+0uQXBZ/gkAVERNT4OD3CeG26dOkSNm/ejCeffLLcciEhIYiIiMDZs2cBAMHBwTAajcjIyLAql5qaiqCgILvb0Wq18Pb2tpqqU+qt8BRYR/o7WQxqX3KO9ifeRHpOYQWliYiIGpZ6HZ6WLFmCwMBADB06tNxy6enpSEpKQkhICACga9euUKvV2LRpk1wmOTkZx48fR69evaq1zo5Iyy55GXCQV916N2CYrzuimnrDLIDNp67XdnWIiIhqVL0NT2azGUuWLMH48eOhUv3VHygnJwfTp09HQkICEhMTsW3bNgwfPhz+/v544IEHAAB6vR6TJk3CtGnTsGXLFhw6dAiPPfYYoqOj5afvapukcUdmfhGAutfyBACD2/31rjsiIqLGpN6Gp82bN+Py5ct44oknrOYrlUocO3YM9913H1q1aoXx48ejVatWSEhIgJfXX+MSffTRR7j//vsxatQo9O7dG+7u7vjpp5/qzBhPmuA7AQBebiro1HWjTqUNvjXa+O/n0pFdUFTLtSEiIqo5VXqEa/ny5dizZ4/89blz5wAA9957r83ykiRV2FnbUYMGDbL5ihCdTodff/21wvXd3Nwwf/58zJ8/36X1chVtcAsAQJBX3Wt1AoCWgZ6I9PfAxRu52HY6DcM7hla8EhERUQNQpfB07tw5OTCVtmHDBpvl69KTYvWFJrhkAMpA77rV38lCkiQMbh+M/24/j19PpDA8ERFRo+FweLp48WJ11INuowkqaXkKrGOdxUsb3D4I/91+HttOp6Gw2AStqu7dXiQiInI1h8NTREREddSDSsnKL4Lar6Qlpy52FrfoGOaDIG8trmcVYve5dPRvE1jbVSIiIqp29bbDeEN2/FrJa1+862hncQuFQpIHzFx3LLmWa0NERFQzGJ7qoGNXDQDq9i07i6HRJWNn/XoiBcZicy3XhoiIqPoxPNVBlpanAM+6H55imvsh0EuL7IJi7DqXVtvVISIiqnYMT3VQsUlAmIoQ6KWp7apUSKmQcO+t1qefj/LWHRERNXwMT3XQwkc74/JHD6Opj662q1IpQzuUhKdNJ66jsNhUy7UhIiKqXgxPdZWpGEpF/Rgfq2szXwR5a5FdWIydZ27UdnWIiIiqFcMTOU1R6tYdn7ojIqKGjuGJXGJYh5JxqTadvI6CIt66IyKihovhiVyic7gPQvVuyCksxvYzfOqOiIgaLoYncgmrW3d86o6IiBowhidyGctTd5tP8dYdERE1XAxP5DKdwn3Q1EeHPKMJ206n1nZ1iIiIqgXDE9lkMpkqnMxm69exSJIktz5xwEwiImqoGJ7IitlsBiQFtFotVCpVuVN4s4gyAcryrrstp1KRU1hcG4dARERUrVS1XQGqY4QAhBnv/nwESqXabjGz2YSXh0ZDCGE1v0OYHpH+Hrh4Ixe/Hk/ByK5h1V1jIiKiGsWWJ7JJoVBCoSxnUihtridJEu7v1BQAsPrQ1ZqsMhERUY1geCKXe6BzSXj6/fwNpBgKark2RERErsXwRC7XrIk7YiJ8IQTw42G2PhERUcPC8ETV4oEuvHVHREQNE8MTVYth0aHQKBX4MyUbx68aars6RERELsPwRNVC767GPe2CAACr9ifVcm2IiIhch+GJqs2obuEASm7d8XUtRETUUDA8UbXp08IfoXo3ZBUU49cTKbVdHSIiIpdgeKJqo1RIeDimpPXp2328dUdERA0DwxNVq4djwiBJwO7z6bicnlfb1SEiInIawxNVqzBfd/Rp4Q8AWLnvci3XhoiIyHkMT+QUk8lU4fRIt5L32327LwmFxew4TkRE9RvDE1WJ2WwGJAW0Wi1UKlW509BOzSByM5Cea8SG4+w4TkRE9ZuqtitA9ZQQgDDj3Z+PQKlUl1vUbDbh7bffhs9dj2FZwiXcd+vFwURERPURW57IKQqFEgplBZNCiZwjv0KlkHDgUgZOXOOI40REVH8xPFGNMOVmYHD7khHHv0q4VMu1ISIiqjqGJ6oxj/eMAFAy4nh6TmEt14aIiKhqGJ6oxnSN8EHHMD0Ki834ag9bn4iIqH6qd+Fp1qxZkCTJagoODpaXCyEwa9YshIaGQqfToV+/fjhx4oTVNgoLC/Hcc8/B398fHh4eGDFiBK5cuVLTh9LoSJKEJ++6A0DJrTu+746IiOqjeheeAKB9+/ZITk6Wp2PHjsnL3nvvPcydOxcLFizAvn37EBwcjHvuuQfZ2dlymalTp2L16tVYuXIldu3ahZycHAwbNgwmEz/Mq1t8VDCa+uiQnmvE6kNXa7s6REREDquX4UmlUiE4OFieAgICAJS0Os2bNw+vv/46HnzwQURFRWHp0qXIy8vD119/DQAwGAxYtGgRPvzwQwwcOBCdO3fG8uXLcezYMWzevLk2D6tRUCkVmNi7OQDgi50XYDaL2q0QERGRg+pleDp79ixCQ0MRGRmJMWPG4MKFCwCAixcvIiUlBYMGDZLLarVaxMXFYffu3QCAAwcOoKioyKpMaGgooqKi5DJUvUZ3C4eXmwrn03Lx6wkOmklERPVLvQtPPXr0wLJly/Drr7/i888/R0pKCnr16oX09HSkpJR8EAcFBVmtExQUJC9LSUmBRqOBr6+v3TL2FBYWIisry2oix3m5qTGxV3MAwPzfzkEItj4REVH9Ue/CU3x8PEaOHIno6GgMHDgQ69atAwAsXbpULiNJktU6Qogy825XmTJz5syBXq+Xp/Dw8CoeBU3sHQkPjRInk7Pw25+ptV0dIiKiSqt34el2Hh4eiI6OxtmzZ+Wn7m5vQUpNTZVbo4KDg2E0GpGRkWG3jD0zZsyAwWCQp6SkJBceSePi66HBY7El4z6x9YmIiOqTeh+eCgsLcerUKYSEhCAyMhLBwcHYtGmTvNxoNGL79u3o1asXAKBr165Qq9VWZZKTk3H8+HG5jD1arRbe3t5WE1Xd5LvugJtagcNJmdh+Jq22q0NERFQp9S48TZ8+Hdu3b8fFixexd+9ePPTQQ8jKysL48eMhSRKmTp2Kd955B6tXr8bx48cxYcIEuLu7Y+zYsQAAvV6PSZMmYdq0adiyZQsOHTqExx57TL4NSDXH31OLx3qUtD69/+tpPnlHRET1gqq2K+CoK1eu4JFHHsGNGzcQEBCAnj17Ys+ePYiIKPkQfvnll5Gfn49nnnkGGRkZ6NGjBzZu3AgvLy95Gx999BFUKhVGjRqF/Px83H333fjyyy+hVCpr67AarWf6t8DKfUk4cS0L648nY1iH0NquEhERUbnqXXhauXJlucslScKsWbMwa9Ysu2Xc3Nwwf/58zJ8/38W1I0f5eWjw5F2RmLf5LD7ceAaD2wdDrax3DaJERNSI8FOKat2Td90BPw8NLt7Ixar9fE0OERHVbQxPVGNMJpPNSaeS8Ey/knfefbjxNLILimq5pkRERPYxPFG1M5vNgKSAVquFSqWyOU3u1wZF6VeQnmvE/C1na7vKREREdtW7Pk9UDwkBCDPe/fkIlEq13WIX0rKx7kQaluxOxNgeEWju71GDlSQiIqoctjxRjVEolFAo7U+R/p7Iv3AARSaBt9adrO3qEhER2cTwRHWGJEm4+dvnUCslbD6VypcGExFRncTwRHVKcfoVPNknEgAw88cTyCksruUaERERWWN4ojpnSv870czPHSlZBfhw4+narg4REZEVhieqc9zUSrx1fxQAYOnuRBy4lFHBGkRERDWH4YnqpL6tAvBgl6YwC2D6qiPIN5pqu0pEREQAGJ6oDps5vD2Cvd1w8UYu3t3wZ21Xh4iICADDE9Vhep0a7z7UAQDw5e5E7Dp7o5ZrRERExPBEdVxcqwA82qMZAOAf/zuMtOzCWq4RERE1dgxPVOf939B2aBXkibTsQkxbdQRms6jtKhERUSPG8ER1nk6jxIKxXeCmVmDHmTQs3H6+tqtERESNGMMT1Qutgrwwe0R7AMAHG09j+5m0Wq4RERE1VgxPVOeYTCab08jOoRgVEwYhgOe/OYTL6Xm1XVUiImqEGJ6ozjCbzYCkgFarhUqlKjOp1Wq8PyYGhdf+hCG/CE8u24fsgqLarjYRETUyqtquAJFMCECY8e7PR6BUqu0Wy8ovxKItx3AGwDMrDmLxhG5QK/l3ABER1Qx+4lCdo1AooVDan7x1WqR9Nxs6tRI7z97AP388DiH4BB4REdUMhieql4zXz2Pe6I6QJOCbP5Lw0aYztV0lIiJqJBieqN4a2DYQb95X8gLh//x2Dl/svFDLNSIiosaA4YnqtXE9IzB9UCsAwFvrTuHrvZdruUZERNTQMTxRvfds/xaYfFckAOC11ccYoIiIqFoxPFG9J0kSXru3LSb1+StALUtIrN1KERFRg8XwRA2CJEn4v6Ft8eStAPXPH0/gg19P8yk8IiJyOYYnqrduH4HcbDbj1SGtMPXuFgCABVvP4eXvjqLIZK7lmhIRUUPCQTKp3ik9Erk9nh0GwW/ws1h14ArScgrx6aNd4K7h5U5ERM7jpwnVP5Ucifx8WjZ+PpyEbafT8Mjne/H/xnVFkLdbDVaUiIgaIt62o3qropHI7wzwwvWVr8PXXY0jSZkY+p9d2HshvbarTURE9RzDEzVoxmun8d3feqJNsBdu5BRi7Bd7sWjXRXYkJyKiKmN4ogaveRMP/PBML9zXKRQms8C/fj6JF1YeRp6xuLarRkRE9RDDEzUK7hoV5o3uhJnD20GlkLD2yDUM+88uHEnKrO2qERFRPcPwRI2GJEmY2DsS3zzVE0HeWly4kYuRC3fjP1vOopjDGRARUSUxPFGj0625H36d2hdDO4Sg2Cwwd9MZPPxZAi6kZZcZO8rWZDYzaBERNWYMT9Qo+bhrsOCRzpg3uhO83FQ4dDkT/d/dBN/Yh6BSa6BSqexO4c0iGKCIiBoxjvNEjZYkSbi/c1N0i/TDtP8dxp4LN+E34Em0HvEMBrQOQKBX2UE4zWYTXh4azaf1iIgasXrX8jRnzhx069YNXl5eCAwMxP3334/Tp09blZkwYQIkSbKaevbsaVWmsLAQzz33HPz9/eHh4YERI0bgypUrNXkoVEc09dHhq4ndkP7Lx9CqFEjLMeJ/B65i1/mbKBaS9fhRCmVtV5eIiGpZvQtP27dvx7PPPos9e/Zg06ZNKC4uxqBBg5Cbm2tVbsiQIUhOTpan9evXWy2fOnUqVq9ejZUrV2LXrl3IycnBsGHDYDKZavJwqAZUph+TEGbkHN2Ex7qHoVWQJwSAQ0mZ+GrPJfyZksWWJiIiktW723YbNmyw+nrJkiUIDAzEgQMH0LdvX3m+VqtFcHCwzW0YDAYsWrQIX331FQYOHAgAWL58OcLDw7F582YMHjy4+g6Aakxl3oF3O51aifioELQNycXWP1ORVVCMX09cx9ErBsS1CkCAh/3XwRARUeNQ78LT7QwGAwDAz8/Pav62bdsQGBgIHx8fxMXF4e2330ZgYCAA4MCBAygqKsKgQYPk8qGhoYiKisLu3bvthqfCwkIUFhbKX2dlZbn6cMiVKvkOPAAoLjLi1RGdAJS0MDVv4oFxPSNwMCkT+y7eRLKhACv3JaFdsBeUHr7VX3ciIqqz6t1tu9KEEHjxxRfRp08fREVFyfPj4+OxYsUK/Pbbb/jwww+xb98+DBgwQA4+KSkp0Gg08PW1/hAMCgpCSkqK3f3NmTMHer1ensLDw6vnwMilKnoHnr2+TCqlAt2b+2F8bHO0DvYCAJxMyUbo05/jg41nYMgvqulDISKiOqBeh6cpU6bg6NGj+Oabb6zmjx49GkOHDkVUVBSGDx+OX375BWfOnMG6devK3Z4QApIk2V0+Y8YMGAwGeUpKSnLJcVDd5ummwpD2wXi4axhCvLVQqN2wcPsFxL2/FZ/vuICCIvaTIyJqTOpteHruueewdu1abN26FWFhYeWWDQkJQUREBM6ePQsACA4OhtFoREZGhlW51NRUBAUF2d2OVquFt7e31USNR6iPDiM7hyL1+zfRMtATmXlFeHv9KQz4YBtW7U+CycxO5UREjUG9C09CCEyZMgU//PADfvvtN0RGRla4Tnp6OpKSkhASEgIA6Nq1K9RqNTZt2iSXSU5OxvHjx9GrV69qqzvVf5IkIf/cH1j3XG+891AHhOjdcM1QgJe+O4oh83Zg7ZFrDFFERA1cvQtPzz77LJYvX46vv/4aXl5eSElJQUpKCvLz8wEAOTk5mD59OhISEpCYmIht27Zh+PDh8Pf3xwMPPAAA0Ov1mDRpEqZNm4YtW7bg0KFDeOyxxxAdHS0/fUdUHqVCwqiYcGyd3g+v3dsGep0aZ1Nz8Pw3hzDoo+1Yc+gq35dHRNRA1bvwtHDhQhgMBvTr1w8hISHy9O233wIAlEoljh07hvvuuw+tWrXC+PHj0apVKyQkJMDLy0vezkcffYT7778fo0aNQu/eveHu7o6ffvoJSiUHQaSKWcaHUiuASb2bY/v0vvjHwJbQ69Q4n5aLqd8exsC52/HdgSsMUUREDUy9G6qgosEKdTodfv311wq34+bmhvnz52P+/Pmuqho1AhWNHSVpdPDqMgze3e5HIoDpq47gP1vO4m9xd+LBLk3hpmY4JyKq7+pdeCKqVZUcO6rAWIT33n4Tdw57Gpdv5uG11ccwd9NpPB7bHI/1jICfh6YGK01ERK5U727bEdUFFY0d5aZRI+uP7/HbP/rgtfjWCNG74UaOEXM3nUGvf2/B6z8cxbnrWTCZTCWtWUREVG+w5YmoGlhu7/l6uZfMUCjh3ro3vLs/CAS3wIo/krB87yXkn90LzaUEXPpjI/vbERHVEwxPRNXBzu09IQSuZhbgUJIBiTfz4N4qFmgVi3s+2omxPZrhoa5h8HHnLT0iqp/MZnOlXqQuSRIUivp784vhiagaWW7vldbM3xPN/D1xM9eIQ5du4mjidVy4Aby17hTe+/U0hkWH4NGezdClmW+5I94TEdUlZrMZ4c0icO3qlQrLhjYNQ9LlS/U2QDE8EdUSPw8N+rcOwPqXh+DL347jm31XcColGz8cuoofDl1FqyBPjOzSFMM7hCDI2w1A/f9rjYgaLiEErl29gvfWHbP5vlALs9mEl4dGV6qFqq5ieCKqRWazGaKoEOP73AkA0IS0gleneLi3vQtnrgNzfjmNd9afQsGlI8g9sQ36nEtIOn+aAYqI6ixbLe4NDcMTUW2y0zeqoMiEM6k5OHM9B8lZhdA17wxd884wFxXiuW8O4f7OYbirpT/HjSKialfZfkwmU+N5STrDE1EdcPtfau5KJTo180OnZn4w5BfhdEo2TiVnIRPAumMpWHcsBR4aJfq1CcTg9sHo3zoAXm72x50iIqoKR/oxWdTn23GVxfBEVMfpdWp0j/RD13BvvP7EfZjx2WpsOH4dKVkFWHc0GeuOJkOjVKBXiyYY3D4YA9sGIcDL9gjoRESOqGw/JgAoLjLi1RGdADA8EVEdIUkSjCnn8MbQtvjnsPY4etWADcdTsPFECi7cyMW202nYdjoNM3AMUU29EdcyAH1b+aNTmB4qpe0+UuyATkSVUZl+TApT4+lGwPBEVA8pFBI6hfugU7gPXhnSGudSc/DriRT8euI6jl014PjVLBy/moVPtp2HqSAHBYmHkH/hIAoSD8KUnS5vp74/LkxEVBsYnojqGVudMu/wd8ff4+7A3+PuQEpmHlr3ux+xE/4PSRkFKHDzhEebu+DR5i4AgN5Nhaa+OjTVa7HkuXsbRf8EIqp7KtPBvK62jjM8EdUTlle+aLWV6880uN18SEolrmcV4FJ6Hi6l5+F6VgEMBcUwJGfjZHI2wp5dhoFzd6DnHU3Q4w4/9Iz0s9lfqq7+AiOi+seR32V1tXWc4YmovrAzrMHtSnfaVEgSQvQ6hOh16HlHExQWm3AtswBXMvKQdDMPqVn5uJieh4vpefhmXxIAoCj9CgqvnUbhtT9ReO00itISERoaWid/gRFRPVTJ32V1eTBNhieieqaijpvlddrUqpSI9PdApL8Hio1GvDKyJ/72/7bgWlYRrmTm40aOEeomYVA3CYNn9N0AAJVCQk7iUby74U90ifBD52Y+CPRyc/lxEVHjUp8H02R4ImrERGEu7gjwRMuQkr/+CopMSDEUIDmrACmGAqRkFcBYbIZbs2h8tuMigIsAgBC9G9qHeqNdqL7k3xBvhPnq+C4+ImoUGJ6ISOamVqK5vwea+3sAKBnjJT27AB/PfgnP/vN9HLliwOnr2Ug2FCDZUIDNp1LldfU6NdqFeKN1kCfuDPRAiwBPtAj0hJ+Hxua+2I+KiOorhiciskuSJPh5aJB7bBPeeSAKSqUS2QVFOJWcjRPXDDhxLQsnr2XhbGo2DPlFSLiQjoQL6VbbMOVmoig96a/pxmUU3byKIG8dki4nMkAR1WNCCBQUmZFrLEZ2bgF0d8QgMT0ParUaOrUSHloldGplg2uVZngiIod4uZWMeN490k+eV1hswtnrOThxNRN/e/VNdBjyKDLyipBVUAylhw+UHj5waxZttR1RbMSgj3agub8HIpp4oHkTd0Q08UBEE3c09dHZHdiTiGpPYbEJVzPzcS2j5LZ+em4hCorM8vLAh2fh5+OpVuu4qRTw89QgRK9DmK8OQe71s59TaQxPRFQp5Y3JopKAtsGeaBWgw5itizHi5elQKJUoMpmRkWvEzVwj0m/9ezPPiKz8IphVGpxLy8W5tNyy21NICPPVyWEq3NcdYb46hPuV/F/vzvf4EdUUhc4bR68acCE9D1cz8mG28fCbTq2Em1qBlPMnEN4qCiYzkGc0Ib/IhIJiM65lFuBaZgEOXMqASiHB//4ZOJOag5ZB9t+AUJcxPBFRuRwdXwr468WgaqUCgd5uCPS2fjqvuKgYr40dgF93H8KVzL/Gobp0Mw+Xb+ahsNiMxPQ8JKbn2dy+l5sKYT66W4FKh6Y+OjTzc0ezJp4I89XBQ8tfbUTOMJsFtp1JxVcJlxA25StsP/vX7Xi9To0wXx1C9Tr4e2ng566BSqlAsdGIl2cOxrT1x6FUlfyBU2wyIyOvCGk5hbiakY+kjDxkFxTDo3VvbDx1AzvO3kSbEG90CveBXld//ijibxgiKl8lx2QBHHkxqEBxVhrubh9qY5kEpZcfVD4hUPuGQO3XFEovf6j0wVDpg6D09EV2QTFOpWTjVEq2za37uasR5uuOMD8dwnx0CPfVIcxPh3Bfd4Tq3eCmUbGvFZENuYXF+P7gFSz5PREXb5S0CksKJQK9tGgV5IU7Ajzg6277IRBbVEoFAry0CPDSol2IN4QQSMnIxeefzEPT/mORU2jC4aRMHLmSiVZBXoiJ8IW/Z91/sTnDExFViktfDOrggJ+lyxWZzMguKEZWQTGyCkr6VRnyjDh14lhJuNJ54WZeEW7mGXD0qsH27vMyEdM2EmG+JQOINvVxQ4heh1CfklYsb52qwXVwJSrPlYw8LEu4hG/+uIzsgmIAgJdWhVExYXhzwhA8t2KjS8ZkkiQJAZ4aZO78CjNefRlXDUU4lJSJyzfzcDolG6dTsnGHvwe6Rfoh0KPutkQxPBFRransgJ+ly2mVSmg1avh7/1Wu2GjE1pen4t2fj6BYKEtCVX5JuLIKWvnFKDILSO4+OHApAwcuZdjcr7tGiVAfHUL0bmjqo7sVrNwQ6qOT57up63+nV2rchBA4cCkDi3+/iA3HU+S+TM2buGNi70iM7BoGnUrCP29eqZb9KyRJHhrlelYB9idm4FxaDi7cyMWFG7m4098dqiZh1bJvZzE8EVGDoVAooVOpodOqEaQvu1wIgbyCIvzr6Qfx7brNSMkyItlQgGuZ+SX/GgpwM9eIPKMJ51JzcC41x+6+mnhoEOTthkBvLQK9rKcgbzcEeGnh76mBulRnWI5tRXWBsdiM9ceSsfj3izh65a/W2d4tmuCJ3pHo3zoQCkVJy2tlXt7rCkHebhjaIQQ3c43Yn3gTf6Zk4/yNPIQ+8Qm+O3AFo7tH1Eg9KovhiYgaDUmSoFVJMF4/jwe62v5lLKk0JX2svAPQJLwlXnzjX0jJKkRyqYCVZzQh/dYThCeT7e9PCDPMeQaYcm6iOOcm3EQhnp88Hk08tfDz0MDPQwNfdw2aeJb8W52tWWazuVLvCGPAa7hSswuw8o8kLN9zCanZhQAAjUqBBzo1xcQ+zdEm2LuCLVQ/Pw8NBrUPRtcIX+w+fwPnUzLR684mtV2tMhieiKhxqWx/q+IivDqiM6YN/q7MMoXWA0rvQCi9/KD08IPK0w+9R/8d+UVm5BaakGssRp7RBDMUUHr4QunhC03QnQCABVvP292nh0YpByo/z5Jw5e2mhpebCl5uKnhq1fC89X8vrQpebiVfe2pLJqXCdj8ts9mM8GYRuHa14tsvdfUt9lQ1QgjsS8zAsoREbDieguJb9+YCvbR4PDYCj3RvhiZ1sIN2E08thkYF45U3H0bou9druzplMDwRUaNUcX8rk0Od2vu/8Yb8eDZQ8qGVX2QqCVOFxcjKK8TqxR9D6eEDhc4bSnc9FDpvKNz1UOq8ISlVyDWakGvMR1JGfpWOyUOjhMetIOWhVd76VwUPjRIF7YbhgRljoVEpoVEqoFEpoFEqoFZK8v9VCoF/jekFk8nM8FTPpRgKsPbIVfxw8Cr+LPVUapdmPng8tjnujQ6BSlFynZZ3a66mbtvZ3X92esWFagHDExFROSrbqf12kiTBXaOCu0aFAC8tio1qfLl7pc0wJoSAsdiM/CIz8otMyDMWYdn7/4f3Pv4EuUYTsguKkXOr43tOYUkn+JzCknk3snIh3dpeSfgyybdkSvPqMgwHk7IqPN5m/1iFNjM3wkenvtUKpoavR8lYPr4e6lv/auDnoYafhxZNPLXw99SyA30dkJlnxK8nUrDm0DXsuZgOy11aN7UC93dqisd6RiCqaUlnQEdaIwFU6pZvY8LwRERUg+yFMZ0K0N0aS9RsMiH32CY82TsCynKCm8lkglarxZyfjqLILMFYbEaRyQyjyQxjsRlGk0CRyYz8wiJs+Pq/iBv1VEk5kxlFxaXL3fq32AwBwGQWcp+uyvLUqtDEU4MmHppbgUqDJh4l//rdCluWZT46tc1bjOxv5RiTWeBwUiZ2nEnDjrNpOJKUaTX6d7fmvrivU1MM7xBaZlR+IQSuXb2C99Ydg0Jh/xqr/NhtjQvDExFRHePoqO4qpRLackZVLzYa8e2uFbjrtRlWtxZvV1RYiFcfiMEb3+6B0Swhv8iMgqKSV2yU/n9BkRl5xmJcT0mGu08AjCZR0hJWWIxLdkaFL02YTTDnZ8GUmwlTngHmvJJ/PZQC7735fwjwckMTTw38PbVo4qmBu4YfVUIIXDMU4NiVTBy9YsCxqwYcScpE1q0xmSzaBHtheMdQjOgYinA/9wq3W9WW1caOVyQRUV3j4CCirmoVkCQJotgIL52m3JAFlLSOTY8fjIKCAuQXC9zIKWmpSs8xIj23sOTfHCNu5BRi9S+bEdKmC/KNJe85kxRKuSP97WasPl5mnptaAW83Nbx1ani7lXSUt/zfW2fpUK+Gu1oJd40Sbhrlrf+roNMooNOo4K5Wwk2thEalsNuxvraYzQLZBcVIzy3EzVwjbtw6b0kZebicXvLKosvpecguLC6zrrebCn1a+iOuVQDuahmAUB9dLRxB48PwRERUR9XlVgFL65ibm1vFhQFMX38CSpUKJrNAQZEJeUYT8ozFt/p4mZBbUIQd677DsIcewc3cIqTnFuJGjhGFxWYUFJlRUFRosy9XVUhSyXsX1QoJaqUCKmXJv+pb/6oUElRKBZSSBEkCFFLJShJKBnZUSBJwa74ES5mSf3GrjOUcFZsFTGaBYrNAsank/0VmM/KNlnNQ0ppXGSqFhNbBXugQpkd0Ux9EN9WjbYhXvXyxbn3H8ERERI6rYuuYUiGVPAGoVQHQlipXhNUb5mPpLx9brS9pdCVPI2o9oHDzgELrCb+gpvjnW3OQU1gsjyCfXVCMfGNxSad7owl5RcXIN5qQnHYTUKohqf56H5sQJQNFlvToqt2nyUrz1Crl8b+aeGjQ1PfWC6993dGsiTvCfUrey2it7NNy7DtW/RieiIioylzWOubg+FtP9ys7/pY97/58FJKkLGkFEgJms4BZAGZxqyWoyIiPpz6CZz/6BpCUMN1abnnCTNyqnslUjK/mTJdbmCBJgGQJKVLJ+xAlCUDJv6NffAsqhbKkhUqSoLjVQqVQSFArJEgw4aO/jYDZmAdzYS5gKntbrjSlSg1TcVGFxxsS2hSXEi+WG6BqewiC+q7Rh6dPP/0U77//PpKTk9G+fXvMmzcPd911V21Xi4ioUXLV+FvAX61eCoUCSpXK7gdesVEJ4/XzCPVxL7evV7HRiPwzv1e6ta1t8McVbq84M9mhY6lsuNRoNHbLlMYhCKqmUYenb7/9FlOnTsWnn36K3r1747PPPkN8fDxOnjyJZs2a1Xb1iIjIjopCFlB9fcJc3RfNkWNx9eCuHIKgahr1TdG5c+di0qRJePLJJ9G2bVvMmzcP4eHhWLhwYW1XjYiIqMosIcvuVM7YTlSxRhuejEYjDhw4gEGDBlnNHzRoEHbv3l1LtSIiIqK6rtHetrtx4wZMJhOCgoKs5gcFBSElJcXmOoWFhSgs/OtRWYPBAADIyqr4lQeOsHTky8sxQCGV/9dBcbFRLqtUlHcfvHbKsY6sY10qxzqyjvWxXGOto1mUfBZmZWWVO9J+VVg+t6vc50s0UlevXhUAxO7du63mv/XWW6J169Y215k5c6bArQcvOHHixIkTJ071e0pKSqpShmi0LU/+/v5QKpVlWplSU1PLtEZZzJgxAy+++KL8tdlsxs2bN9GkSZOSR1RdJCsrC+Hh4UhKSoK3t7fLtlvf8DzwHAA8BxY8DzwHAM+BhbPnQQiB7OxshIaGVmn/jTY8aTQadO3aFZs2bcIDDzwgz9+0aRPuu+8+m+totdoy75ry8fGptjp6e3s36h8OC54HngOA58CC54HnAOA5sHDmPOj1+irvt9GGJwB48cUXMW7cOMTExCA2Nhb/7//9P1y+fBl/+9vfartqREREVEc16vA0evRopKen480330RycjKioqKwfv16RERE1HbViIiIqI5q1OEJAJ555hk888wztV0NK1qtFjNnzixzi7Cx4XngOQB4Dix4HngOAJ4Di9o+D5IQHJudiIiIqLIa7SCZRERERFXB8ERERETkAIYnIiIiIgcwPBERERE5gOGpDvr0008RGRkJNzc3dO3aFTt37qztKlXJrFmzIEmS1RQcHCwvF0Jg1qxZCA0NhU6nQ79+/XDixAmrbRQWFuK5556Dv78/PDw8MGLECFy5csWqTEZGBsaNGwe9Xg+9Xo9x48YhMzOzJg6xjB07dmD48OEIDQ2FJElYs2aN1fKaPObLly9j+PDh8PDwgL+/P55//nkYjcbqOOwyKjoPEyZMKHNt9OzZ06pMfT4Pc+bMQbdu3eDl5YXAwEDcf//9OH36tFWZxnAtVOY8NPRrYeHChejQoYM8mGNsbCx++eUXeXljuA4qOgf18hqo0ktdqNqsXLlSqNVq8fnnn4uTJ0+KF154QXh4eIhLly7VdtUcNnPmTNG+fXuRnJwsT6mpqfLyf//738LLy0t8//334tixY2L06NEiJCREZGVlyWX+9re/iaZNm4pNmzaJgwcPiv79+4uOHTuK4uJiucyQIUNEVFSU2L17t9i9e7eIiooSw4YNq9FjtVi/fr14/fXXxffffy8AiNWrV1str6ljLi4uFlFRUaJ///7i4MGDYtOmTSI0NFRMmTKl2s+BEBWfh/Hjx4shQ4ZYXRvp6elWZerzeRg8eLBYsmSJOH78uDh8+LAYOnSoaNasmcjJyZHLNIZroTLnoaFfC2vXrhXr1q0Tp0+fFqdPnxavvfaaUKvV4vjx40KIxnEdVHQO6uM1wPBUx3Tv3l387W9/s5rXpk0b8eqrr9ZSjapu5syZomPHjjaXmc1mERwcLP7973/L8woKCoRerxf//e9/hRBCZGZmCrVaLVauXCmXuXr1qlAoFGLDhg1CCCFOnjwpAIg9e/bIZRISEgQA8eeff1bDUVXe7aGhJo95/fr1QqFQiKtXr8plvvnmG6HVaoXBYKiW47XHXni677777K7T0M5DamqqACC2b98uhGi818Lt50GIxnctCCGEr6+v+OKLLxrtdSDEX+dAiPp5DfC2XR1iNBpx4MABDBo0yGr+oEGDsHv37lqqlXPOnj2L0NBQREZGYsyYMbhw4QIA4OLFi0hJSbE6Vq1Wi7i4OPlYDxw4gKKiIqsyoaGhiIqKksskJCRAr9ejR48ecpmePXtCr9fXuXNWk8eckJCAqKgoq5deDh48GIWFhThw4EC1Hmdlbdu2DYGBgWjVqhUmT56M1NRUeVlDOw8GgwEA4OfnB6DxXgu3nweLxnItmEwmrFy5Erm5uYiNjW2U18Ht58Civl0DjX6E8brkxo0bMJlMCAoKspofFBSElJSUWqpV1fXo0QPLli1Dq1atcP36dbz11lvo1asXTpw4IR+PrWO9dOkSACAlJQUajQa+vr5lyljWT0lJQWBgYJl9BwYG1rlzVpPHnJKSUmY/vr6+0Gg0deK8xMfH4+GHH0ZERAQuXryIN954AwMGDMCBAweg1Wob1HkQQuDFF19Enz59EBUVJdcLaFzXgq3zADSOa+HYsWOIjY1FQUEBPD09sXr1arRr107+UG8M14G9cwDUz2uA4akOkiTJ6mshRJl59UF8fLz8/+joaMTGxuLOO+/E0qVL5c6AVTnW28vYKl+Xz1lNHXNdPi+jR4+W/x8VFYWYmBhERERg3bp1ePDBB+2uVx/Pw5QpU3D06FHs2rWrzLLGdC3YOw+N4Vpo3bo1Dh8+jMzMTHz//fcYP348tm/fbrdeDfE6sHcO2rVrVy+vAd62q0P8/f2hVCrLJODU1NQyabk+8vDwQHR0NM6ePSs/dVfesQYHB8NoNCIjI6PcMtevXy+zr7S0tDp3zmrymIODg8vsJyMjA0VFRXXuvABASEgIIiIicPbsWQAN5zw899xzWLt2LbZu3YqwsDB5fmO7FuydB1sa4rWg0WjQokULxMTEYM6cOejYsSM+/vjjRnUd2DsHttSHa4DhqQ7RaDTo2rUrNm3aZDV/06ZN6NWrVy3VynUKCwtx6tQphISEIDIyEsHBwVbHajQasX37dvlYu3btCrVabVUmOTkZx48fl8vExsbCYDDgjz/+kMvs3bsXBoOhzp2zmjzm2NhYHD9+HMnJyXKZjRs3QqvVomvXrtV6nFWRnp6OpKQkhISEAKj/50EIgSlTpuCHH37Ab7/9hsjISKvljeVaqOg82NLQrgVbhBAoLCxsNNeBLZZzYEu9uAYc6l5O1c4yVMGiRYvEyZMnxdSpU4WHh4dITEys7ao5bNq0aWLbtm3iwoULYs+ePWLYsGHCy8tLPpZ///vfQq/Xix9++EEcO3ZMPPLIIzYf0Q0LCxObN28WBw8eFAMGDLD5eGqHDh1EQkKCSEhIENHR0bU2VEF2drY4dOiQOHTokAAg5s6dKw4dOiQPNVFTx2x5JPfuu+8WBw8eFJs3bxZhYWE1NlRBeechOztbTJs2TezevVtcvHhRbN26VcTGxoqmTZs2mPPw97//Xej1erFt2zarx6/z8vLkMo3hWqjoPDSGa2HGjBlix44d4uLFi+Lo0aPitddeEwqFQmzcuFEI0Tiug/LOQX29Bhie6qBPPvlERERECI1GI7p06WL1WG99YhmvRK1Wi9DQUPHggw+KEydOyMvNZrOYOXOmCA4OFlqtVvTt21ccO3bMahv5+fliypQpws/PT+h0OjFs2DBx+fJlqzLp6eni0UcfFV5eXsLLy0s8+uijIiMjoyYOsYytW7cKAGWm8ePHCyFq9pgvXbokhg4dKnQ6nfDz8xNTpkwRBQUF1Xn4svLOQ15enhg0aJAICAgQarVaNGvWTIwfP77MMdbn82Dr2AGIJUuWyGUaw7VQ0XloDNfCE088If8+DwgIEHfffbccnIRoHNdBeeegvl4DkhBCONZWRURERNR4sc8TERERkQMYnoiIiIgcwPBERERE5ACGJyIiIiIHMDwREREROYDhiYiIiMgBDE9EREREDmB4ImpgHn/8cUiShODgYBQXF9d2dSq0evVqjBgxAiEhIdBoNAgICMDAgQOxePFimEym2q6eS2zbtg2SJFV66tevn8vr0K9fvzL7UavVCA8Px9ixY3Hs2DGX75OooeIgmUQNSFZWFkJCQpCfnw8hBNasWYP77ruvtqtlU25uLsaOHYu1a9fC19cXQ4cORXh4ONLS0rB+/Xpcu3YNPXv2xNq1axEQEFDb1XVKYmIivvzyyzLzli5dio4dO+L++++3Wta8eXNMmDDBpXXo168ftm/fjmnTpsHT0xMAkJOTg8OHD+O3336Dm5sbdu7cWSfffUhU5zg8JjkR1Vn//e9/BQAxffp0IUmSGD58eG1Xya6HH35YABBDhw4t8wqF/Px88eSTTwoAolevXqKoqKh2KlmNLK+wsby6p7rFxcUJACI5ObnMsvfee08AEI8//niN1IWovuNtO6IGZNGiRdBoNJgxYwZ69+6N9evXy28Qv3TpEhQKBe6++26b6xYUFECv16NFixZW8xMTEzF69Gj4+fnB09MTcXFx2LFjB2bNmgVJkrBt2zaH67llyxasWrUKLVu2xKpVq+Dj42O13M3NDf/v//0/9OnTB7t378ayZcuslltubSUlJWH06NFo0qQJPDw80K9fP+zevdvmPo1GI+bOnYsuXbrAw8MDXl5euOuuu7B27doyZSdMmABJkpCYmIhPP/0Ubdu2hZubGyIiIjB79myYzWaHj9kRly9fxqRJk9C0aVNoNBqEhYVh0qRJSEpKqpb9DRkyBACQlpZmNd9yq8+W0ucIAJYsWQJJkvD+++/bLL9+/XpIkoQXXnjBdRUnqiUMT0QNxLFjx7Bv3z4MHToUfn5+ePzxx2EymbB06VIAQEREBO666y5s27YNV69eLbP+jz/+iKysLDz22GPyvKtXr6JXr1743//+h9jYWDz//PPw9/fHoEGDsHfv3irXdfHixQCAadOmQafT2SwjSRJef/11q/KlZWRkoHfv3khMTMRTTz2FkSNHIiEhAf379y8T6AoLCzF48GBMmzYNADBp0iQ89thjuHTpEu677z4sWLDAZh1eeuklzJw5Ez179sTTTz8NAJg1axbeeOONKh13ZZw9exbdunXD4sWL0bVrV0ybNg1dunTB4sWLERMTg3Pnzrl8nxs3bgQAdOnSpcrbGD16NPR6Pb744gubyy3zn3zyySrvg6jOqO2mLyJyjRdeeEEAED/88IMQQojMzEzh5uYmWrZsKZf5/PPPBQDx3nvvlVl/2LBhAoA4e/asPO+xxx4TAMT7779vVXbJkiUCgAAgtm7d6nBdmzdvXmZftuTl5QmVSiU0Go0oLi6W51v2PW7cOGE2m+X527ZtE5IkiRYtWgiTySTPf+211wQAMWvWLKvyWVlZIiYmRmg0GnH16lV5/vjx4wUAERkZKa5duybPT0tLEz4+PsLLy0sUFhY6fNyl2bttN2DAAAFAfPbZZ1bzP/vsMwFA3H333VXan+W23bRp08TMmTPFzJkzxfTp08WgQYOEQqEQd999d5nbp5Z1bLGco4sXL8rznn32WQFAbN++3ars9evXhVqtFj169KhS3YnqGoYnogagsLBQNGnSRPj6+lp9qI8ePdrqwywzM1NotVrRoUMHq/XT0tKEWq0WPXv2lOcVFBQIrVYrgoKCygQFs9ks2rRpU+Xw5ObmJgCIgoKCCssGBQUJAOL69evyPABCqVSKy5cvlyk/dOhQAUDs3LlTCCGEyWQSvr6+okWLFlbByWLt2rUCgJg/f748zxIMFi9eXKa8ZdnRo0crdaz22ApPly9fFgBEu3btytTVbDaLtm3bCgA2j7siliBka4qMjBRfffWV3XVssRWejh49Kofa0ix9qr744guH601UF/G2HVEDsGbNGqSnp2P06NHQaDTy/McffxzAX7e99Ho9hg8fjqNHj1o9mr5y5UoUFRVh3Lhx8rzTp0+jsLAQMTExVtsESm6pxcbGVuchycStB4Jv73sTERGB8PDwMuXvuusuAMDhw4cBlBxHRkYGtFotZs+ejVmzZllNGzZsAAD8+eefZbZl6zZWWFgYACAzM7PKx2TPoUOHAABxcXFljleSJPTt2xcAcOTIkSrvIzk5GaLkD2fk5uZi3759uOOOOzBu3Di7/ZUqKzo6GrGxsfjuu+9gMBjk+YsXL4anpydGjx7t1PaJ6gqGJ6IGwBKOSocfABg8eDCCg4OxatUqZGVlWZVZsWKFXG758uVQq9VWH26W8vaGCQgKCqpyfYODgwGgwg7Q+fn5uHnzJjQaDfz8/KyWBQYGllsvy4f3zZs3AQAnTpzA7Nmzy0yffvopgJKhE26n1+vLzFOpVABQLWNQWc65vXNrOW+lg4kz3N3dERMTg++//x5eXl548803bZ4HRzz11FPIz8+Xr69du3bhzz//xCOPPCIPkUBU3zE8EdVzSUlJ2LRpEwCgd+/eVoMgqlQqpKSkIC8vDytXrgQAxMfHw9/fH19//TWEEDh37hz27t2Le++9F02aNJG36+3tDaDsE1gW169fr3Kde/XqBaDkqbvybN++HcXFxejWrRuUSqXVstTU1HLrZQk+luMYOXKk3OJia1qyZEmVj8dVLHW1d24t8y3lXEWv16NVq1bIycnB2bNn5fkKRclHhK3BVu0FuNGjR8PHx0fuIG75d/LkyS6tM1FtYngiqueWLFkCs9mMPn36YNKkSWUmS0vTokWLAABqtRqjRo1CUlIStm/fjuXLlwOA1VN2ANC6dWtotVocOHAARqPRapkQAnv27KlynS0DQM6dOxcFBQU2ywghMGfOHADAE088UWb5pUuXbLZc7dy5EwDQqVMnAEDbtm3h7e2N/fv3o6ioqMp1rgmWOu/YsUO+XWkhhChzbK5kaaErPQyDr68vAJR5OtNsNtu9dajT6fDYY4/h0KFD2L59O1atWoUOHTqgW7duLq8zUa2phX5WROQiZrNZNG/eXEiSJC5cuGC3XOfOnQUAcezYMSGEEAkJCQKAmDRpkmjRooXw8fGx2Xn70Ucftfm03ZdffunU03ZCCPHggw8KAGL48OEiMzPTallBQYF4+umn7Q6Sadl3ZZ+2e+WVVwQA8fzzzwuj0VimLseOHbPqkG6rM7TFzJkznTpuC3tP2/Xv399m5+ovvvhCABADBgyo0v7KGyTzxx9/FADKPHDwzjvvyE8plvb+++/L3wNb5+jYsWMCgAgNDS3TGZ+oIVDVZFAjItfasmULEhMT0b9/f0RGRtotN3HiRBw6dAiLFi3CRx99hJ49e6Jly5ZYtmwZioqKMHnyZGi12jLrzZkzB5s3b8ZLL72ErVu3olOnTjh9+jR+/vlnDBkyBBs2bJBv7Thq6dKlKCgowE8//YQ77rijzOtZrl69ih49emD16tVyP6PSOnTogG3btqFnz54YMGAArl27hpUrV0KtVuPzzz+3qtfs2bNx8OBB/Oc//8G6desQFxeHgIAAXL16FceOHcORI0eQkJBgtx9VTVq4cCH69OmDyZMn46effkK7du1w8uRJ+TU1CxcudGr7H3zwgdz3KC8vD6dOnZIHsJw3b57VwwETJ07Ee++9h1mzZuHw4cO48847sX//fhw/fhxxcXHYvn27zX1ERUWhV69e2L17N9zc3Mq0ahLVe7Wd3oio6saMGSMA2HzMvLQbN24IjUYj/P395ZaF2bNny60Ht4/LU9qFCxfEww8/LPR6vXB3dxd33XWX2L59u5gyZYoAIA4dOlTl+pvNZrFq1SoxdOhQERQUJNRqtWjSpIkYMGCA+OKLL+y+lgWAiIuLE5cuXRIPP/yw8PX1FTqdTvTt21fs2rXL5jrFxcXis88+E7179xbe3t5Cq9WKZs2aiSFDhoiFCxeKnJwcuWxttjwJIURiYqKYOHGiCAkJESqVSoSEhIiJEyeKxMTEKu/P1lAFSqVSBAUFifvvv1/s2LHD5noHDx4Ud999t3B3dxfe3t7ivvvuE2fPni33HAnx17hUjz32WJXrTFRX8cXARFQlffr0QUJCAgwGQ40/RSVJEuLi4qr0ahiqGc888wwWLlyI7du3y0MsEDUU7DBOROWyvBuvtBUrVuD333/HwIED+fg5lZGWloZly5ahbdu2DE7UILHPExGVKyoqCp07d0a7du2gVCpx+PBhbNu2DV5eXvjggw9qu3pUh6xbtw4HDx7Ed999h9zcXMycObO2q0RULRieiKhcf/vb3/DTTz9h//79yM3NRUBAAMaOHYs33ngDbdq0AVAy2va8efMqtb1Zs2ZVX2VrWGJiIr788ssKy/n4+GDq1Kku3feaNWvkUdTL069fP/Tr18+l+7Zn1apVWLp0KUJDQ/HOO+9wRHFqsNjniYiclpiYWO7TfqU1pF8527ZtQ//+/SssFxERgcTERJfue8KECVi6dGmF5WbOnNmgAitRXcDwREREROQAdhgnIiIicgDDExEREZEDGJ6IiIiIHMDwREREROQAhiciIiIiBzA8ERERETmA4YmIiIjIAQxPRERERA5geCIiIiJywP8HVPxjmUSmSU0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHRCAYAAACCSAZNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACH+klEQVR4nOzdd3wUdfrA8c+WZNM3vUEIAUINvUkRkKYgoKKiYgFFj7Mg+aFi4dToISingILl9DhAEVFPUBRFQOmd0HsLIYSEFFI3m03Z+f0RshLSSdlN9nm/XvtSZr4z88wku3n2W1WKoigIIYQQQtgRtbUDEEIIIYSob5IACSGEEMLuSAIkhBBCCLsjCZAQQggh7I4kQEIIIYSwO5IACSGEEMLuSAIkhBBCCLsjCZAQQggh7I4kQEIIIYSwO5IAiQZt0KBBqFQqNm3aZO1QAGjevDkqlYoLFy6U2G5rcYJtxlSbfvjhB2655RZcXV1RqVSoVCprh1RnLly4gEqlonnz5tYORYgGQxIgYTXFyULxS61W4+HhQUhICMOGDeMf//gHx48fr5dY5s+fT1RUFOnp6fVyvbq2adMmoqKiGm1yU5n169dz3333sXv3bpo1a0a/fv3o169fueU3bdpU4nexqq+oqKhqxWWrP5ebufdBgwZZO2yr2L59O3/7299o27Yter0enU5HkyZNGDVqFP/5z38wGAwlyh88eJCoqCh+/PFH6wQsyqW1dgBChIeH4+/vD0Bubi4pKSls2LCBDRs28M4773Dvvffy73//Gx8fn1LHNmvWjDZt2uDi4lKjGObPn09sbCwTJ07E09Pzps/TsmVLnJyccHBwqFE8NbVp0ybeeustgHL/UNXWs7NFn376KQDvv/8+L7zwQqXl9Xp9mQnSxYsXiYuLw8PDg44dO5ba36xZs2rFVZWfizWUde8ZGRkcPXq03P1lPY/GLCcnh8cff5zvvvsOACcnJ1q2bImzszPx8fGsWbOGNWvW8MYbb/D7779bns/Bgwd56623mDBhAnfffbcV70DcSBIgYXWvvfYaEydOLLEtJSWFr7/+mpkzZ/LDDz9w7Ngxdu3ahV6vL1Huyy+/rMdIK/fHH39YO4Qqs7VnV5tOnjwJwMiRI6tUvmvXrmzbtq3U9qioKN566y26du1qc7U2tamse9+0aRO33XZbufvtSX5+PsOHD2f79u0EBgby3nvvcf/99+Ps7Gwpc/z4cT766CMWLVrEuXPn7C5BbIikCUzYJF9fX6ZOncq+ffsICgri5MmTREZGWjss0UAYjUaAEn+ghLhZb731Ftu3bycgIICdO3fy2GOPlfrdat++PZ999hkbN2601GgLG6cIYSWhoaEKoCxevLjCcqtWrVIARavVKhcvXiyxb+DAgQqgbNy4scT2/Px8Zf78+UrPnj0VNzc3xdHRUQkKClL69OmjvPHGG0paWpqiKIqyePFiBSj3VXzejRs3KoAycOBAJT8/X3nvvfeUiIgIxdnZWQkNDS11TzExMeXGuXv3bmXkyJGKl5eX4uLiovTp00dZtWpVmfde3v0VmzBhQqlnWNH9TJgwoUrnNpvNyldffaUMGDBA0ev1ipOTk9KmTRtl+vTpSmpqapmxFF9DURTl119/VW699VbFzc1N8fDwUO644w5l//79ZR5XmezsbOWf//yn0rFjR8XFxUVxd3dXevXqpSxcuFDJz88vUbb4nsp6vfnmm9W+9ptvvmn5uZfl6NGjyiOPPKI0adJEcXBwUPz9/ZWxY8cqO3fuLFW2qj+Xc+fOKe+++64ycOBApWnTpoqjo6Pi6+ur3H777covv/xSZhwxMTEKUOJ3saaKf+fL+jNR/FzefPNNJSkpSXn22WeV0NBQRavVlriXdevWKc8++6zSqVMnxcvLS9HpdEqLFi2Uv//970psbGyZ173+dzo+Pl55/PHHlcDAQEWn0ynt27dXFi5cWOZxVX3PV1d6erri7u6uAMo333xTrWOLPw/KepX3OyXqjzSBCZs3ZswYgoODuXz5MuvWrWPSpEmVHvPggw/yww8/AEX9cry9vUlMTGTPnj3s3LmTe+65hy5duhAQEEC/fv3Yt28fJpOJHj16oNPpLOe5sclNURTuvvtu1qxZQ8uWLWnfvj25ublVvpetW7cyc+ZMHB0dadu2LfHx8ZZ4PvjgA6ZNm1blc5WnX79+lr4rISEhJfqptG7dutLjFUXhkUceYfny5QC0aNECT09Pjh49ypw5c/j222/5888/adGiRZnHf/bZZzzzzDMEBgbSunVrTp06xdq1a9m2bRt79+6lbdu2Vb6X5ORkhgwZwpEjR1Cr1URERJCfn8+ePXvYs2cPP/30E6tXr8bJyQko6pdSUFBQ5s+zuv11KrN69WrGjRuHyWTC09OTzp07Exsby8qVK/nxxx/57LPPeOqppyzlq/pzmTVrFosWLcLNzY3g4GA6depEfHw8v//+O7///jvvvvsuL7/8cq3ey81KTk6mR48exMfH06FDB/R6PRqNxrJ/xIgRmM1m/Pz8CA0NpaCggJiYGD777DO+//57tmzZQvv27cs8d2xsLN27dyc9PZ327dujVqs5fvw4zz33HOnp6cyYMaNE+aq+56trzZo1ZGVl4efnx3333VetY3v27ImjoyNnzpzB39+f8PBwyz5pIrMB1s7AhP2qag2QoijKvffeqwDK5MmTS2wvqxZj3759CqCEhIQox48fL1E+IyND+eKLL0rVJJVXc1Os+NuwRqNR/P39lR07dlj2GY3GSs9THKdWq1UefPBBJTs7W1GUopqWjz76yLLv4MGDld7f9cqqAVKUkt/Qy1PeuRcsWKAAiru7u7Ju3TrL9oSEBKVfv34KoPTu3bvU+bj2zdbFxaVEPJmZmcqQIUMUQHnggQfKjacsxT/3Dh06KGfPnrVs37t3rxIQEKAAyvTp00sdV9nPs6rKqwGKj49XPDw8FECZOnWqYjKZFEVRlMLCQuWdd95RAMXBwUE5dOhQmeer6Ofy66+/Krt27VLMZnOJ7Vu2bFGCgoIUjUZT4lkoivVqgDQajdKnTx8lLi7Osu/698O///1vJT4+vsSxOTk5lmc0aNCgUucu/p12cHBQ7rvvvhI1N5988okCKE5OTiW238x7vqqeffZZBVDuvvvumzq+uJb5+poxYRukD5BoEEJCQgBISkqqtOyZM2cAuO+++2jXrl2JfR4eHjz55JOW81VXYWEhn376KX369LFsK659qApvb28WL16Mq6srUDT8eMqUKYwdO5aCggLmzp17U3HVFkVRmDNnDgBvv/02w4YNs+wLDAzk22+/xdHRkd27d/Pnn3+WeY5JkyaV6NTu7u7OvHnzAFi7dm2VYzlz5gwrV64E4KuvvqJly5aWfT169GDBggUAfPzxx2RlZVX5vLXhk08+ITMzky5dujB//nwcHR0BUKvVvPbaa4wcOZL8/Hzef//9ap97xIgR9O7du9S8Rbfeeiv//Oc/KSws5Ntvv62V+6gprVbL//73P5o2bWrZdv374W9/+xvBwcEljnF2dua1116jf//+bNq0ifj4+DLP7ePjw5IlS0qMynz66afp1q0bubm5bNy40bK9Lt/zxfGFhYXd1PHCdkkTmGgQihOGqvyhK/6g++OPP7h69Sre3t61Foder+euu+666eMnTZpUZsL0zDPPsHLlSn7//feahFdjJ06cIC4uDicnpxLNN8WaNGnCvffeyzfffMO6desYPHhwqTJPPvlkqW0dO3bEycmJjIwMUlNTy5zS4Ebr169HURT69+9P165dS+2/9957adq0KZcuXWL79u3ccccdVbzLmlu3bh0Azz33XJn7p06dyq+//mopV13JycksX76c3bt3k5SUZGlmzcjIAODQoUM3dd7aNnTo0FIJzo327dvH//73P44fP05GRgaFhYXAX0nL4cOHadKkSanjHnroIcv7/no9e/Zk//79nD9/3rKtLt/zxZ85ZcUiGjZJgESDkJ2dDRR9m6tMnz596N27N7t377ZMqjhgwAAGDhxIt27dajQjcHh4eIk+DtV147fTG7dfuXKFzMzMKt1nXTh9+jRQ1F+mvA/8Dh06lCh7o+traq7n5+dHXFwc2dnZVUqAis9fXh8RtVpN27ZtuXTpEqdPn67XBKiy2Iqf0c38PNetW8e4ceMsyU5Zrl69Wo1o6055v89QVJv43HPP8cknn1R4jvLupbzfo+IRVsWfCVC373l3d3eAUhMcioZPmsBEg3Dx4kWAKg0vVavV/Pbbb0ydOhVnZ2d++uknXnjhBXr06EFYWBhLliy56Thq+i2wvPiv317fzTnXK/6jUtFzDggIAMqPs7xnpFYXfdwoilJvsdSVymIrjguqF1t6ejoPPvggGRkZPPbYY+zatYu0tDQKCwtRFIX169cDRfPS2IKK3g9fffUVn3zyCa6urnzyySecOXOGnJwcFEVBURQefvhhoPx7qc7vUV2+54trp2JiYm76HMI2SQIkbJ7ZbGbnzp0A9OrVq0rHeHl5MX/+fJKTkzlw4AAffvght912G7GxsTz++OP873//q8uQy5WcnFzp9uJvnIDlm2t5SUNtfyt1c3MDKu5rdeXKFaBknHXBlmK5UWWxFccF1Yvtt99+Iy0tjT59+rBkyRJ69+6Np6en5Y9+XFxcDaKuX19//TUAH3zwAU8//TStWrUqMXdObd9LXb3n+/btC8COHTsoKCiozZCFlUkCJGzejz/+SGJiIg4ODgwfPrxax6pUKrp06cLzzz/Pn3/+ySuvvALAF198UapcfThx4kSF2wMCAko0lxR/Cy4vcTp79myZ22/2foqHY1+8eLFEE8P1jh07VqJsXSk+f3nrwZnNZsuMz3Udy40qi634Gd3486zs51K8iG6fPn3KLGsrfX+qovheihOI6+Xn55f7Xqipqr7nq2rkyJG4ubmRlJR0U0lUY16Et6GTBEjYtNjYWEtH08cee6zMzpLVccsttwBw+fLlEtuLv5kWzyBcVxYtWoTJZCq1vbifxI0JXvFcO3v37i11zL59+8r9g3iz99OuXTuaNWtGbm4u//nPf0rtv3z5smWuldtvv71a566u4cOHo1Kp2LZtGwcOHCi1f+XKlVy6dAlXV9cKFzqtC8X3vnDhwjL3f/TRRyXKFavs51K8//oapGKpqaksWrTo5gK2goruZfHixeUm9bWtvPd8VXl6ejJlyhQAIiMjLYldebZv386OHTss/66vzxZRfZIACZuUkpLCRx99RI8ePUhISKB9+/ZVHiL+9ddf889//rPUB1VqaqrlD1O3bt1K7CtONDZv3lzz4CuQmprKpEmTLE1XiqLwySefsHLlSjQaTamJEEeMGAEUfXvds2ePZfuZM2eYMGECWm3Z4xiK76e61fYqlYqXXnoJgDfffLPE2mZXrlzhwQcfJC8vj1tuucWyTlRdadWqFWPHjgWKkt/rR/3s37+f559/HigaiVXfTWBPP/00Hh4eHDx4kP/7v/8jLy8PKKqVmjNnDmvWrMHBwaHUQqyV/VxuvfVWAL777js2bNhg2Z6QkMC9997boJpg+vfvD8A//vGPEsnO2rVreemll6o1fURlbuY9Xx1RUVH06dOHK1eu0KdPH7766qtSE6CePn2aZ599lkGDBpVoGr3+S0xOTs5NxyDqgLUmIBKieLK68PBwpV+/fkq/fv2UHj16KM2bNy8xZfz9999f7vILZU3mN2/ePMuxTZo0UXr27KlEREQojo6Olm03TsP/5ZdfWo6JiIhQBg4cqAwcOFA5cOCAoigll8Koyj2VNxHi22+/rTg6Oiru7u5Kjx49lODgYMt158yZU+p8ZrNZGTp0qAIoarVaadOmjRIREaGo1WplwIAByvjx48ucCDEjI0Px8vJSACUoKEjp16+fMnDgQGX27NkVPrviaxafF1BatWqldOvWzfL8mjVrppw7d65UrMXlq/tsKpKUlKR07NjRMule586dlfbt21uuNXTo0BIT79XkWmWpaCmMn376yfJMvLy8lJ49eyr+/v6Wn9W///3vUsdU5edy3333lXj2Xbp0UbRareLu7q7Mnz+/zHisuRRGeWJjYxVvb28FUJydnZUuXbpY3tu33Xab8vDDD5f5u1ve5J4VXftm3vPVlZWVZZmYs/ieIiIilJ49eypNmjSxbG/atKly5MgRy3GFhYVKeHi4Aig+Pj5Knz59lIEDBypTp06tUTyi5qQGSFjdmTNn2L59O9u3b+fkyZMUFBQwdOhQZsyYwfHjx/nuu++qNa/Hvffey3vvvcewYcPQaDQcOXKEhIQEIiIimDlzJkePHi21LMKjjz7Khx9+SKdOnTh37hybN29m8+bNpKen1+q93nrrrWzdupX+/ftz9uxZ0tLSuOWWW1i5cqWl5uV6KpWKVatWMW3aNIKDg4mJicFgMPDqq6+ybt06HBwcyryOh4cH69atY8SIEZhMJnbu3MnmzZstfWYqolKpWLZsGV9++SW33norSUlJHDt2jNDQUF566SX2799f7jIYtc3Pz4+dO3fy9ttv065dO06fPk1sbCw9e/ZkwYIF/Prrr7Vak1AdY8aMITo6mocffhgnJycOHjyIoijcc889bNu2jb/97W+ljqnKz+Xrr7/m9ddfp3nz5sTGxpKYmMh9993H3r176dy5c33eYo00a9aMnTt3MnbsWBwdHTl58iROTk689dZbrF27ttzay5txM+/56nJzc+N///sfW7ZsYdKkSYSEhHDhwgUOHTqEoijceeedLFq0iNOnTxMREWE5Tq1Ws2bNGu677z40Gg179uxh8+bNHDx4sIZ3LWpKpShVHJMqhBBCCNFISA2QEEIIIeyOJEBCCCGEsDuyFIYQQjQyBw4csAzdrooFCxaUud5aYyPPRVxPEiAhhGhkMjIy2L59e7XK2wN5LuJ60glaCCGEEHZH+gAJIYQQwu5IE1g5zGYzly9fxt3dXdZyEUIIIRoIRVHIysoiODjYspBwWSQBKsfly5cJCQmxdhhCCCGEuAlxcXE0bdq03P2SAJWjeG2huLi4Eqs5CyGEEMJ2ZWZmEhISUukagTaXABUUFBAVFcXXX39NYmIiQUFBTJw4kX/84x+WqixFUXjrrbf4/PPPSUtLo3fv3nz88cd06NDBch6TycSLL77IN998g9FoZMiQIXzyyScVZoPXK2728vDwkARICCGEaGAq675ic52g33vvPT777DMWLlzIiRMnmDNnDv/6179YsGCBpcycOXOYO3cuCxcuZO/evQQGBjJs2DCysrIsZSIjI1m1ahUrVqxg27ZtZGdnM2rUKAoLC61xW0IIIYSwITY3DH7UqFEEBASwaNEiy7Z7770XFxcXvvrqKxRFITg4mMjISF5++WWgqLYnICCA9957j8mTJ5ORkYGfnx9fffUVDzzwAPBXn55ff/2V22+/vdI4MjMz0ev1ZGRkSA2QEEII0UBU9e+3zdUA9e/fnz/++IPTp08DcOjQIbZt28bIkSMBiImJITExkeHDh1uO0el0DBw4kB07dgAQHR1Nfn5+iTLBwcFERERYytzIZDKRmZlZ4iWEEEKIxsnm+gC9/PLLZGRk0LZtWzQaDYWFhbzzzjs89NBDACQmJgIQEBBQ4riAgABiY2MtZRwdHfHy8ipVpvj4G82ePZu33nqrtm9HCCGEEDbI5mqAvv32W5YtW8by5cvZv38/S5cu5f3332fp0qUlyt3YuUlRlEo7PFVU5tVXXyUjI8PyiouLq9mNCCGEEMJm2VwN0EsvvcQrr7zCgw8+CEDHjh2JjY1l9uzZTJgwgcDAQADLCLFiSUlJllqhwMBA8vLySEtLK1ELlJSURN++fcu8rk6nQ6fT1dVtCSGEEMKG2FwNUE5OTqmZGzUaDWazGYCwsDACAwNZv369ZX9eXh6bN2+2JDfdu3fHwcGhRJmEhASOHj1abgIkhBBCCPthczVAo0eP5p133qFZs2Z06NCBAwcOMHfuXJ544gmgqOkrMjKSWbNmER4eTnh4OLNmzcLFxYXx48cDoNfrmTRpEi+88AI+Pj54e3vz4osv0rFjR4YOHWrN2xNCCCGEDbC5BGjBggW8/vrrPPPMMyQlJREcHMzkyZN54403LGWmT5+O0WjkmWeesUyEuG7duhKzPs6bNw+tVsu4ceMsEyEuWbIEjUZjjdsSQgghhA2xuXmAbIXMAySEEEI0PA12HiAhhBBCiLomCZAQQggh7I4kQEIIIYSwO5IACSGEEMLu2NwoMCGEqE0GgwGj0Vjl8s7Ozri6utZhREIIWyAJkBCi0TIYDIQ2b05qSkqVj/Hx9SX2wgVJgoRo5CQBEkI0WkajkdSUFF5Z9BsuHp6Vls/JTOfdSSMwGo2SAAnRyEkCJIRo9Fw8PHHTe1s7DCGEDZFO0EIIIYSwO5IACSGEEMLuSAIkhBBCCLsjCZAQQggh7I4kQEIIIYSwO5IACSGEEMLuSAIkhBBCCLsjCZAQQggh7I4kQEIIIYSwO5IACSGEEMLuSAIkhBBCCLsjCZAQQggh7I4kQEIIIYSwO5IACSGEEMLuSAIkhBBCCLsjCZAQQggh7I4kQEIIIYSwO5IACSGEEMLuSAIkhBBCCLsjCZAQQggh7I4kQEIIIYSwO5IACSGEEMLuSAIkhBBCCLsjCZAQQggh7I4kQEIIIYSwO5IACSGEEMLu2FwC1Lx5c1QqVanXs88+C4CiKERFRREcHIyzszODBg3i2LFjJc5hMpmYMmUKvr6+uLq6MmbMGC5dumSN2xFCCCGEDbK5BGjv3r0kJCRYXuvXrwfg/vvvB2DOnDnMnTuXhQsXsnfvXgIDAxk2bBhZWVmWc0RGRrJq1SpWrFjBtm3byM7OZtSoURQWFlrlnoQQQghhW2wuAfLz8yMwMNDy+uWXX2jZsiUDBw5EURTmz5/PjBkzGDt2LBERESxdupScnByWL18OQEZGBosWLeKDDz5g6NChdO3alWXLlnHkyBE2bNhg5bsTQgghhC2wuQToenl5eSxbtownnngClUpFTEwMiYmJDB8+3FJGp9MxcOBAduzYAUB0dDT5+fklygQHBxMREWEpUxaTyURmZmaJlxBCCCEaJ5tOgH788UfS09OZOHEiAImJiQAEBASUKBcQEGDZl5iYiKOjI15eXuWWKcvs2bPR6/WWV0hISC3eiRBCCCFsiU0nQIsWLWLEiBEEBweX2K5SqUr8W1GUUttuVFmZV199lYyMDMsrLi7u5gMXQgghhE2z2QQoNjaWDRs28OSTT1q2BQYGApSqyUlKSrLUCgUGBpKXl0daWlq5Zcqi0+nw8PAo8RJCCCFE42SzCdDixYvx9/fnzjvvtGwLCwsjMDDQMjIMivoJbd68mb59+wLQvXt3HBwcSpRJSEjg6NGjljJCCCGEsG9aawdQFrPZzOLFi5kwYQJa7V8hqlQqIiMjmTVrFuHh4YSHhzNr1ixcXFwYP348AHq9nkmTJvHCCy/g4+ODt7c3L774Ih07dmTo0KHWuiUhhBBC2BCbTIA2bNjAxYsXeeKJJ0rtmz59OkajkWeeeYa0tDR69+7NunXrcHd3t5SZN28eWq2WcePGYTQaGTJkCEuWLEGj0dTnbQghhBDCRqkURVGsHYQtyszMRK/Xk5GRIf2BhGigUlJS8PPz4+3vd+Km9660fHbGVd64vw/Jycn4+vrWQ4RCiNpW1b/fNtsHSAghhBCirkgCJIQQQgi7IwmQEEIIIeyOJEBCCCGEsDuSAAkhhBDC7kgCJIQQQgi7IwmQEEIIIeyOJEBCCCGEsDuSAAkhhBDC7kgCJIQQQgi7IwmQEEIIIeyOJEBCCCGEsDuSAAkhhBDC7kgCJIQQQgi7IwmQEEIIIeyOJEBCCCGEsDuSAAkhhBDC7kgCJIQQQgi7IwmQEEIIIeyOJEBCCCGEsDuSAAkhhBDC7mitHYAQovExGAwYjcYql3d2dsbV1bUOIxJCiJIkARJC1CqDwUBo8+akpqRU+RgfX19iL1yQJEgIUW8kARJC1Cqj0UhqSgqvLPoNFw/PSsvnZKbz7qQRGI1GSYCEEPVGEiAhRJ1w8fDETe9t7TDKVWA2Y8o3owAalQonB+kSKYQ9kQRICGEX0gx5XEg1EJdmJDXbRFZuAcp1+x21avQ6NZ63PsLpJAM+Pj6oVCqrxSuEqFuSAAkhGq3c/ELcOg3jp+PppOSklllGpQJFgbwCM8kFZvR9H2T8l0fp1DSO6be3pX+4bz1HLYSoD5IACSEanfxCMyv2XGT++tP4jJhKSk4hahU08XIm1NuVQA8nPF0ccHHUoFKpKCg0k2HM52LSVdauXYdXh34cvpTBI4t2M7C1H/+6vxP+7k7Wvi0hRC2SBEgI0ahEx6bx0v8OcT7ZAEBBeiJ9IlrQJSwAF8eyP/K0GjU+bjp0hTq++nEW2z+8zPJDV1m2K5bNp5O586NtfDy+G73CbLdPkxCieqTXnxCiUcgvNPPubye5/7MdnE824OvmyEuDQ4n/4u90CnQuN/kpi5eLA2+O7sBvUwcQ7u9GcpaJh77YxU8H4+vwDoQQ9UkSICFEg5dmyOPRRbv5bPM5zAqM7daEP6YN4oFugWAuuOnztvJ348dn+zG6czCFZoVp3x1i7dHEWoxcCGEtkgAJIRq088nZ3P3Jdnadv4qbTstnj3Rj7rgu6F0cauX8rjotHz7QhbFdm1BoVpjyzX62nE6ulXMLIaxHEiAhRIN1PjmbBz/fRWxqDk29nPnh6b7cERFU69dRq1XMua8Td3YMIr9Q4fkVB7icXvWlPoQQtkcSICFEg3QhxcBDX+wiKctE20B3fny2H20C3evselqNmrkPdKZTUz3pOflM+eYA+YXmOrueEKJuSQIkhGhw0gx5PPrf3VzJNBHu78ayJ3vj66ar8+vqtBoWPtQNdyct0bFpvL/uVJ1fUwhRN2wyAYqPj+eRRx7Bx8cHFxcXunTpQnR0tGW/oihERUURHByMs7MzgwYN4tixYyXOYTKZmDJlCr6+vri6ujJmzBguXbpU37cihKhl+YVmnvl6P3FXjTTzdmH5U7fUS/JTrJmPC/+6rxMAX2w5z9H4jHq7thCi9thcApSWlka/fv1wcHDgt99+4/jx43zwwQd4enpaysyZM4e5c+eycOFC9u7dS2BgIMOGDSMrK8tSJjIyklWrVrFixQq2bdtGdnY2o0aNorCw0Ap3JYSoLTN/Oc7O86m4Omr4z4Qe+LnXX/JT7I6IIMZ0DsaswOs/HcVsVio/SAhhU2xuIsT33nuPkJAQFi9ebNnWvHlzy/8risL8+fOZMWMGY8eOBWDp0qUEBASwfPlyJk+eTEZGBosWLeKrr75i6NChACxbtoyQkBA2bNjA7bffXq/3JISoHWuPJrB0ZywA8x7oQuuAuuvzU5kZd7bjjxNXOHAxne+j43igZzOrxSKEqD6bqwFavXo1PXr04P7778ff35+uXbvyxRdfWPbHxMSQmJjI8OHDLdt0Oh0DBw5kx44dAERHR5Ofn1+iTHBwMBEREZYyNzKZTGRmZpZ4CSFsR3KWiddWHQXg7wNbMrxDoFXjCfBw4v+GtQbg3d9OkpGTb9V4hBDVY3MJ0Pnz5/n0008JDw/n999/5+9//zvPP/88X375JQCJiUWTkAUEBJQ4LiAgwLIvMTERR0dHvLy8yi1zo9mzZ6PX6y2vkJCQ2r41IcRNUhSFV1ce5qohj3ZBHky7lnhY24S+zQn3dyMtJ5//bo+ptLzBYCAlJaVKL4PBUA93IIT9srkmMLPZTI8ePZg1axYAXbt25dixY3z66ac89thjlnIqlarEcYqilNp2o4rKvPrqq0ybNs3y78zMTEmChLARPx28zIYTSThq1Mwd1xlHrW18d3PQqIkc2ppnl+/nv9tjeKJ/GHrnsidgNBgMhDZvTmpKSpXO7ePrS+yFC7i6utZmyEKIa2wuAQoKCqJ9+/YltrVr144ffvgBgMDAomrvxMREgoL+mvAsKSnJUisUGBhIXl4eaWlpJWqBkpKS6Nu3b5nX1el06HT135lSCFGxbFMBs349AcDzQ1rRLsjDyhGVNCIikNYBbpy+ks3i7TFEDi27dspoNJKaksIri37DxcOzwnPmZKbz7qQRGI1GSYCEqCO28TXqOv369ePUqZJza5w+fZrQ0FAAwsLCCAwMZP369Zb9eXl5bN682ZLcdO/eHQcHhxJlEhISOHr0aLkJkBDCNi348wxJWSZCfVx4akALa4dTilqt4vkh4QD8d1sMmbkV9wVy8fDETe9d4auyBEkIUXM2lwD93//9H7t27WLWrFmcPXuW5cuX8/nnn/Pss88CRU1fkZGRzJo1i1WrVnH06FEmTpyIi4sL48ePB0Cv1zNp0iReeOEF/vjjDw4cOMAjjzxCx44dLaPChBC273xyNv/dVtS35o1R7dFpNVaOqGwjI4II93cjM7eAZbtirR2OEKIKbC4B6tmzJ6tWreKbb74hIiKCf/7zn8yfP5+HH37YUmb69OlERkbyzDPP0KNHD+Lj41m3bh3u7n8NiZ03bx53330348aNo1+/fri4uPDzzz+j0djmB6gQorR3fztJfqHCoDZ+DG7rb+1wyqVWq5g8sCUAX++6SIEskSGEzbO5PkAAo0aNYtSoUeXuV6lUREVFERUVVW4ZJycnFixYwIIFC+ogQiFEXTtyKYN1x6+gVsE/7mxX6SAHaxvVKYhZv54gPt3IHyeTuN3Kw/SFEBWzyQRICCHmbTgNwF1dmtDK33oTHlbEYDBgNP61KvyYDj4s2ZPAos1n6B5Q8uM1NTW1vsMTQlRAEiAhhM05cDGNP08mobmug7GtKWtYu8bDjyaT/8Oei5kEte1KQWrp9QcL8mXCRCFsgSRAQgibM2/DGQDGdm1CmK9tDgMvb1j7+rOZXEzPZ+iri+kb6mbZnhIfy0eRD5JfUGCFaIUQN7K5TtBCCPt27HIGW04no1GrmDLYNmt/rnfjsPZuzf0AOJ+Wj5P7X/uc3fVWjlQIcT1JgIQQNmXR1qJh7yM7BtHMx8XK0VRfiLcLrjoNpgIzF1JyrB2OEKIc0gQmhLAZiRm5rD50GYCnbg2zWhxV6bBcXhm1SkXbAA+iL6ZxMjGTVv5uZZYTQliXJEBCCJuxZMcFCswKvcK86dTUs96vn5drBJWKtm3bVvmYsjo1tw1yJ/piGjEpBoz5hTg7yPxjQtgaSYCEEDYhJ6+Q5buLZlF+sr91an/y80ygKEz9eBU+/hXP41NRp2ZfNx1+bjqSs02cuZJllWROCFExSYCEEDbh95OpZOYW0NzHhaHtAiose+P8O+W52bl3XNz1uOm9K44hM73C/W2D3Ek+Y+JEgiRAQtgiSYCEEDZh5aEkAB7uHYpaXf6sz2XNv1MZa8y90ybAnW1nUkjMzCXTKHP/CGFrJAESQlidY0BLTlwx4KhRc2/3phWWLW/+nbJYc+4dV52WYE9n4tONnEvOJti2V/IQwu5IAiSEsDq3LiMAuC3cC7Mxk5QKWreKm7WK59+pSGXNVHWtlb8b8elGziZnE2y7a7kKYZckARJCWFW2IQfX9gMBWPrGU3z++NEqHdcQlpRo6efK5tPJXE7PJddbpl0TwpZIAiREGarayRbA2dkZV1fbXK6hITiXmova0Rk3rcJrH3xe6arvDWlJCXcnBwI8dFzJNHEpW7F2OEKI60gCJMQNqtvJ1sfXl9gLFyQJukkXMosSg3AfR9w9fSotb+1mrepq5ecmCZAQNkgSICFuUJ1OtjmZ6bw7aQRGo1ESoJuQnpNHSi4o5kKa652tHU6daOnvxvZzqVzJAbVOfkeEsBWSAAlRjqp0shU1czIxC4DcCwdx7nirlaOpG14ujvi4OpJqyMO5ZU9rhyOEuEZ65QkhrEJRFEsCZDi20crR1K3mvkU1P04tuls5EiFEMUmAhBBWkZCRS4YxH60Kcs7stHY4dSrMpygBcg7rhlmRvkBC2AJJgIQQVnEiIROAEHcVSr7JytHUrUC9Ew5q0LjouWo0WzscIQSSAAkhrKDQrHA2KRuAUPfGP0WyRq0i0KXoPi9nF1o5GiEESAIkhLCCS2k55BaYcXbQ4O9i7WjqR9C1AWCXs6QGSAhbIAmQEKLenb5SVPsT7u+GupKJDxuLINei+7yaa8Zgsv1JHIVo7CQBEkLUq0KzwrnkawlQgJuVo6k/zloVpoQzAMSm5lg5GiGEJEBCiHp18WoOpgIzro4agj0b5+SH5THGRANFz0AIYV2SAAkh6tXpK0Vz/7Syo+avYrkXDgIQl5aDIsPhhbAqSYCEEPWmwGzmfLIBgNYB7laOpv6ZLp9Eo4KcvEJSDXnWDkcIuyYJkBCi3sRdNZJXWNT8FaR3snY49a+wAH/Xoo/dOGkGE8KqJAESQtSb4s7PLf3cUNlZ81exAFcNAHFpRitHIoR9kwRICFEvzIpiaf5q6W8/o79uFHgtAbqUlkOhWfoBCWEtkgAJIepFQnouxvxCdFo1Texs9Nf1vJxUODmoyS9UuJKZa+1whLBbkgAJIerF2WvNXy18XdGo7bP5C0ClUhHiVTT9dVya9AMSwlokARJC1DlF+WvyQ3tu/ioW4n0tAboq/YCEsBZJgIQQdS45y0RWbgFatYpQbztZ/KsCTb2KmgATM3MpKJS1wYSwhholQF27duXTTz8lMzOztuIhKioKlUpV4hUYGGjZrygKUVFRBAcH4+zszKBBgzh27FiJc5hMJqZMmYKvry+urq6MGTOGS5cu1VqMQojqOZ9S1Pk51McFrUa+d3k6O+DqqKHQrJAo/YCEsIoafRKdOHGC5557jqCgICZOnMi2bdtqJagOHTqQkJBgeR05csSyb86cOcydO5eFCxeyd+9eAgMDGTZsGFlZWZYykZGRrFq1ihUrVrBt2zays7MZNWoUhYWFtRKfEKJ6LqQWJUDNfV2tHIltUKlUlo7g8TIcXgirqFEClJiYyLx582jVqhVffvklAwcOpF27dsydO5eUlJSbPq9WqyUwMNDy8vPzA4pqf+bPn8+MGTMYO3YsERERLF26lJycHJYvXw5ARkYGixYt4oMPPmDo0KF07dqVZcuWceTIETZs2FCT2xVC3ASDqYArmSYAwnwkASrW5FozWHy6JEBCWEONEiBPT0+ef/55Dh06xJ49e3jqqadISEjgxRdfpGnTpjzwwAOsW7eu2uc9c+YMwcHBhIWF8eCDD3L+/HkAYmJiSExMZPjw4ZayOp2OgQMHsmPHDgCio6PJz88vUSY4OJiIiAhLmbKYTCYyMzNLvIQQNVdc++PvrsNVp7VyNLajuAYoISNX5gMSwgpqrTG+R48efPbZZyQkJPDf//6XXr168f333zNixAjCwsJ45513SEhIqPQ8vXv35ssvv+T333/niy++IDExkb59+5KamkpiYiIAAQEBJY4JCAiw7EtMTMTR0REvL69yy5Rl9uzZ6PV6yyskJKS6j0AIUYYLKUVDvcOk+asEb1dHnB00FJhlPiAhrKHWeyM6OzszZswY7rnnHoKDg1EUhdjYWF5//XWaN2/Oc889R05O+XNfjBgxgnvvvZeOHTsydOhQ1qxZA8DSpUstZW6cQl9RlEqn1a+szKuvvkpGRoblFRcXV5XbFUJUoNCscPHamlfS/6cklUpFsGfRemjSDCZE/avVBGjDhg08+OCDNGnShBdffBGz2cxrr73GqVOnWLFihWXU2HPPPVflc7q6utKxY0fOnDljGQ12Y01OUlKSpVYoMDCQvLw80tLSyi1TFp1Oh4eHR4mXEKJm4tOLFj91cdQQ4K6zdjg2p+m1CRElARKi/tU4Abp8+TIzZ86kZcuW3H777Xz//fcMHDiQ77//nri4OGbOnEl4eDjjxo1j165djBw5kp9++qnK5zeZTJw4cYKgoCDCwsIIDAxk/fr1lv15eXls3ryZvn37AtC9e3ccHBxKlElISODo0aOWMkKI+hFzbfh7cx9Xu138tCLF/YAupxsxSz8gIepVjXokjh49mrVr11JYWEhAQACvvPIKTz31FM2bNy/3mL59+/Lrr7+Wu//FF19k9OjRNGvWjKSkJGbOnElmZiYTJkxApVIRGRnJrFmzCA8PJzw8nFmzZuHi4sL48eMB0Ov1TJo0iRdeeAEfHx+8vb158cUXLU1qQoj6c+FaAiT9f8rm6+aIo1ZNXoGZFIMJf3cna4ckhN2oUQL066+/MnToUP72t79x1113odVWfrrRo0cTHBxc7v5Lly7x0EMPkZKSgp+fH7fccgu7du0iNDQUgOnTp2M0GnnmmWdIS0ujd+/erFu3Dnd3d8s55s2bh1arZdy4cRiNRoYMGcKSJUvQaDQ1uV0hRDVk5BaSbsxHrYJmMvtzmVQqFUEeTsRezSEhPVcSICHqUY0SoLNnzxIWFlatYyIiIoiIiCh3/4oVKyo8XqVSERUVRVRUVLllnJycWLBgAQsWLKhWbEKI2hOXngcUzXfjqJXZn8sTpL+WAGXk0lkGnwpRb2r0qVTd5EcIYT8uZhQlQDL5YcWCLPMBSUdoIepTjRKguXPn4uvry+XLl8vcf/nyZfz8/Pjoo49qchkhRAOjcnQmMbsAkP4/lQnwKBodl5lbgMFUYOVohLAfNUqAvv/+ezp16lRun57g4GC6dOlSabOWEKJxcQ7rhqKAp4sDni6O1g7Hpum0Gnzdip5RQoZMiChEfalRAnT69OkK+/NA0cKmZ86cqcllhBANjHPLHoDU/lRVkF6awYSobzVKgHJycnB1rfgDzsnJiezs7JpcRgjRgJgVBecW1xIg6f9TJUH6otFfUgMkRP2pUQIUGhpa4QKjADt37qRp06Y1uYwQogE5nmhA4+qFg1pF8LUOvqJixQlQUqaJArPZytEIYR9qlACNGjWKbdu28d///rfM/f/5z3/Ytm0bo0ePrsllhBANyLZz6QA00TugUcvsz1Whd3bA2UFDoaKQnGWydjhC2IUazQP08ssvs2LFCp566imWLVvGsGHDaNKkCfHx8axbt44tW7YQHBzMq6++WlvxCiFs3LaYonX4QvQOVo6k4VCpVATpnTifYiAhPRd3T2tHJETjV6MEyM/Pj40bN/LII4+wadMmNm3ahEqlQlGK1rTp1asXy5Ytw8/Pr1aCFULYtiuZuZy8koOimAnRy+iv6gjyLEqALmcYae0pM0ILUddqlAABhIeHs3v3bvbt28eePXtIT0/H09OTXr160aNHj9qIUQjRQGw8mQRAXsIZnHvKF5/q+GskWC6KorNyNEI0fjVOgIr16NFDEh4h7Nyf1xIg47m9QF/rBtPABLjrUKsgJ6+Q7DzpCC1EXZMFeoQQtcJUUMi2sylAcQIkqkOrUePnXlTzk5QtM0ILUddqXAOUnJzM4sWL2bt3L+np6RQWFpYqo1Kp+OOPP2p6KSGEDdt9/io5eYX4uTkQe+WctcNpkIL0zlzJNHElO9/aoQjR6NUoATp8+DCDBw8mLS3N0vG5LCqVDIUVorErbv7qF+bJPivH0lAF6504GAdJBqkBEqKu1agJ7IUXXuDq1avMmDGDmJgY8vPzMZvNpV5l1QoJIRoPRVH44+QVAPq39LRuMA1Y4LUJEa/mFKJykJFgQtSlGtUA7dy5k7vvvpu33367tuIRQjRA55KzibtqxFGjplczvbXDabDcnRxw02nJNhXgGBRu7XCEaNRqVAPk6OhIy5YtaysWIUQDVdz8dUtLH1wcNVaOpmELvlYL5NSkvZUjEaJxq1ECNHjwYPbtk9Z+IezdHyeKEqDBbWTun5oqbgZzDG5j5UiEaNxqlAD961//4tixY7z//vu1FY8QooHJMOazL7Zo+YvBbQOsHE3DV5wA6YLCKxxcIoSomRr1AfrnP/9Jhw4dePnll/nss8/o3Lkzen3p9n+VSsWiRYtqcikhhI3acjqZQrNCK383mvm4kJKSY+2QGjQ/Nx0qFWhcvUjMzENWEhKibtQoAVqyZInl/8+fP8/58+fLLCcJkBCNV/HyF0Pa+ls5ksZBq1Hj46whJaeQY4nZdJRulkLUiRolQDExMbUVhxCiASo0K2w8VZQA3SYJUK3xddVeS4AM1g5FiEarRglQaGhobcUhhFVdNeSx/WwK8elGYpPS8eh9H7FpeTR3KsBVV2tL5jU6B+PSScvJx8NJS/dQL2uH02j4uWo5mWziWEK2tUMRotGq1U/2q1evYjAYCAkJqc3TClFnDlxM4z/bYlh3LJH8wr86nHoNmsiGc1moz2fRyt+NriFels6p4i9/Xpv8cEBrPxw0srRgbfFzLfpoPnHFQKFZQaOW2fSFqG01/sTKyMhg6tSpBAQE4OfnR1hYmGXf7t27GTlyJNHR0TW9jBC1Kje/kH/+cpyxn+5gzeEE8gsV2ga6c3eXYB7tEYTh2Ca8nDWYFTh9JZtv98Xxx8kr5BXIKt3X+/NkMgBD2knzV23SO2kwm3Iw5ps5myS1QELUhRrVAF29epW+ffty+vRpunXrhp+fHydOnLDs79SpE9u3b+frr7+me/fuNQ5WiNpwKS2HiYv3Wv6w3NO1CZP6hxHRpGgEY0pKCjPvf5/nJ9xLjtqFg3HpnEjI4mh8JhdTc7izUxD+7lIblJBh5ERCJioVDGwtCVBtUqtU5CWewSm0M4fi0mkT6G7tkIRodGpUAxQVFcXp06f55ptv2LdvH/fff3+J/c7OzgwcOJA///yzRkEKUVtiUgyM+2wnZ5Oy8XfX8d+JPZj3QBdL8nMjf3cnhrcPZGzXJrg7acnMLeCH6Hji04z1HLntKZ79uVszL7xdHa0cTeNjSjgNwMFL6dYNRIhGqkYJ0OrVqxk1ahQPPPBAuWVCQ0O5dOlSTS4jRK04n5zNuH/v5HJGLi39XFn9XP8qT9wX4u3Cw72b0cTTmbxCM6sOxhOTYt8jdCyzP8vorzpRnAAdiku3biBCNFI1SoASEhJo377i9WqcnJwwGOz7D4WwvszcfJ78ch/JWSbaBrrz7eQ+1e7UrNNquLtLMGG+rhSaFX49kkBydn4dRWzbsk0FbDubAsDw9jL7c13Iu5YAnUzMIje/0MrRCNH41CgB8vHxIS4ursIyJ0+eJCgoqCaXEaJGzGaFad8e5HyygSC9E19N6o2vm+6mzqXVqLmzYxDNfVwoMCusO5uFxsP+akC2nE4mr8BMmK8rrfzdrB1Oo1SYlYqvqwOFZoVjlzOsHY4QjU6NEqABAwawevVq4uPjy9x//Phx1q5dy9ChQ2tyGSFqZOHGs2w4kYSjVs2/H+2On/vNJT/FNGoVIyKC8HVzJLdAwf++NzHm2dc39HXHEoGi2h+VSoZo15UOQUXJ5cE4SYCEqG01SoBmzJhBQUEB/fr1Y/ny5aSkFFWJnzhxgkWLFjF48GB0Oh0vvfRSrQQrRHUdu5zBR3+cAWDWPR3p1NSzVs7rqFUzpnMwLg4qHP1C+defsbVy3oYgv9DMH9c6QA/vIM1fdalDoCsg/YCEqAs1GgbfsWNHvv32Wx577DEeffRRABRFISIiAkVRcHd357vvviM8PLxWghWiOvILzbz0/WEKzAojIgK5r3vTWj2/u5MDA8Pc+fVUOquPJjP00GXGdA6u1WvYot3nr5KVW4Cvm44uITL7c10qrgE6JCPBhKh1NZ4JesyYMZw/f56lS5eye/durl69ioeHB7179+bxxx/H19e3NuIUoto+3XSO4wmZeLo48PZdEXVyjWAPBzJ2fodn3wd5beURuoZ4EuLtUifXshXrjhc1fw1r7y8zFNex9gFFNUCxqTmkGfLwkukGhKg1tbIUhre3N//3f/9XG6cSolbEXc1h4Z9nAYga3aHG/X4qkrFtOQPue5LDl7N5bdURvnyiV6PtF6MoCuuOFS1/MUxGf9U5dyctLfxcOZ9s4NCldAa1sb8O90LUFZtevGf27NmoVCoiIyMt2xRFISoqiuDgYJydnRk0aBDHjh0rcZzJZGLKlCn4+vri6urKmDFjZC4iO/Pe2pPkFZrp29KHu7oEYzAYSElJqdIrNTW1ehdTzLx5RwsctWq2nklh5f6yBwU0BkfiM0jMzMXFUUPfllK7Wx+6XOu3dkg6QgtRq2pUA/Tll19Wuexjjz1WrXPv3buXzz//nE6dOpXYPmfOHObOncuSJUto3bo1M2fOZNiwYZw6dQp396Lp4iMjI/n5559ZsWIFPj4+vPDCC4waNYro6Gg0Gk214hD1x2AwYDRWbYZlZ2dnXF1dy9wXHZvGL4cTUKngH3e2Jycnh9DmzUm91km/qgryqz7HT6i3M5FDw5mz9hT/XHOcgW38bnqovS0rrv0Z1MYPJwd5L9WHziGerDwQL/2AhKhlNUqAJk6cWGlVv6IoqFSqaiVA2dnZPPzww3zxxRfMnDmzxLnmz5/PjBkzGDt2LABLly4lICCA5cuXM3nyZDIyMli0aBFfffWVZfj9smXLCAkJYcOGDdx+++03caeirhkMhmolKT6+vsReuFAqCVIUhZlrjgNwf/emtA/2KKrVSUnhlUW/4eLhWem5U+Jj+SjyQfILCqp1D0/d2oJfDiVwPCGTd9acYN4DXap1fENQ3P9nePtAK0diPzqHeAJFI8GKP0+FEDVXowRo8eLFZW7PyMhg//79LF++nDFjxjB69OhqnffZZ5/lzjvvZOjQoSUSoJiYGBITExk+fLhlm06nY+DAgezYsYPJkycTHR1Nfn5+iTLBwcFERESwY8eOchMgk8mEyWSy/DszM7NaMYuaMRqNVU5ScjLTeXfSCIxGY6kEaP3xKxy4mI6Lo4YXhrcpsc/FwxM3vXelsRgy06sbPgAOGjXv3tuRuz7ezqoD8Tzcuxk9mld+vYYiJsXA6SvZaNUqbpO+KPWmXZA7DhoVqYY8LqUZG30neyHqS40SoAkTJlS4f/LkyQwZMoSnn366yudcsWIF+/fvZ+/evaX2JSYWffsMCCjZ+TIgIIDY2FhLGUdHR7y8vEqVKT6+LLNnz+att96qcpyiblQ1SSmLoih89GfRnD8T+zYnwKP+V2zv1NSTB3qEsGJvHG+uPsbq5/o3mpFS66/V/tzSwge9i4OVo7EfOq2G9kEeHLqUwaFL6ZIACVFL6rQTdJ8+fRg9ejRvvPFGlcrHxcUxdepUli1bhpNT+X+8bqwCrkq1cGVlXn31VTIyMiyvypb4ELZn46kkjsZn4uKo4clbW1gtjhdvb4O7k5ZjlzNZsfei1eKobcX9f2Tyw/p3fTOYEKJ21PkosNDQUA4dOlSlstHR0SQlJdG9e3e0Wi1arZbNmzfz0UcfodVqLTU/N9bkJCUlWfYFBgaSl5dHWlpauWXKotPp8PDwKPESDYeiKHz4R9Gw90f7hOJtxflSfN10TBvWGoAP1p0mK7fhL5ianGUi+mLRe2poO0mA6ltnGQkmRK2r0wRIURS2bNmCs7NzlcoPGTKEI0eOcPDgQcurR48ePPzwwxw8eJAWLVoQGBjI+vXrLcfk5eWxefNm+vbtC0D37t1xcHAoUSYhIYGjR49ayojGZ8uZFA7FpePkoOYpK9b+FHvkllBa+Lpy1ZDHF1tjrB1Ojf12NAFFKaqJCPas2vtZ1J7iGqAj8RkUFJqtG4wQjUSN+gBt2bKlzO0FBQXEx8fz5ZdfsnfvXssyGZVxd3cnIqLkjL2urq74+PhYtkdGRjJr1izCw8MJDw9n1qxZuLi4MH78eAD0ej2TJk3ihRdewMfHB29vb1588UU6duwoi7I2Yp9vOQfAw71DbWL4uYNGzUu3t+Hpr/fzn63neeSWZvi713+fpNryy6EEAEZ3CrJyJPapha8r7jotWaYCziRl0y5IaqiFqKkaJUCDBg2qsF+Noij06dOHuXPn1uQyJUyfPh2j0cgzzzxDWloavXv3Zt26dZY5gADmzZuHVqtl3LhxGI1GhgwZwpIlS2QOoEbq+OVMtp9NRaNW8UT/MGuHY3FHRCCdQzw5FJfOgj/O8s+762Y5jrqWkGFkb+xVAEZ2lATIGtRqFZ1C9Gw/m8qhuHRJgISoBTVKgN54440yEyC1Wo2Xlxc9evTglltuqckl2LRpU4l/q1QqoqKiiIqKKvcYJycnFixYwIIFC2p0bdEwLNpW1MQ0IiKQJjbUPKNSqXh1RFse/HwX3+y5yBP9wwjzLXvyRlu25nBR81ePUC9p/rKizk09ixKgS+k82KuZtcMRosGrUQJUURIiRH1Iysxl9aGipSesOfKrPLe08OG2Nn5sPJXM++tO8fH4btYOqdp+OVzU/DVKmr+sqrgf0EHpCC1ErbDptcCEqMxXu2LJL1ToEepFl2t/IGzN9DvaolIV1aQ0tGHMcVdzOBiXjkolzV/WVvz7ffpKFjl51ZulXAhRWo1qgC5evPk5Tpo1kypcUTOJSSl8vatoAsz7O/uSUs4yGtVe3LSWtQvy4J6uTVi5P553fzvJ8qd6N5jlDH4+fBmA3mHe+FthYknxlwAPJwI9nEjMzOXY5Ux6NqJZxoWwhholQM2bN7+pD3KVSkVBNddZEqJYXq4RVCp63zcZvzHTKchK5cH+Y0CpeHhwdRY3rW3ThrXml0MJ7DyfyubTyQxqAEtJKIrCD9GXABjbtamVoxEAnUP0JB7L5eDFdEmAhKihGiVAjz32GDExMWzduhVPT0+6dOlCQEAAV65c4eDBg6SnpzNgwADCwmxnZI5o+PLzTKAotL3/RVJN0LN1UyZ/t73c8je7uGltaurlwqN9Qlm0LYZ//X6KAeF+qG18iYzDlzI4l2xAp1UzoqMsfmoLOod48vuxK7IyvBC1oEYJ0EsvvUS/fv147bXXePXVV0ssTGkwGHjnnXf49NNP+eSTT2jfvn2NgxWimINPCKkmNSoVdGsRiJtT+b/KN7u4aW17ZlBLVuy5yLHLmfx2NJE7bbxT8cr9RbU/t3cIxN1J1v6yBV2uzQh9sIH1JRPCFtWoE/T06dPp1asXM2fOLLUqt6urK7NmzaJnz568/PLLNQpSiBu5dRkBFE0QV1HyY0t83HSWkWofrD9l0zP65hWYWX2oqP/Pvd2l+ctWdGyqR6WCS2lGUrJN1g5HiAatRgnQ9u3b6dWrV4VlevbsydatW2tyGSFKKDAruEUMBqBjE72Vo6meJ28Nw8vFgfPJBn64VsNiizadSiItJx9/dx39WvpYOxxxjbuTA6383AA4LM1gQtRIjRIgs9nM2bNnKyxz5swZFEWpyWWEKCE+W0Ht5Iarg4pm3i7WDqda3J0cePa2VgDM33CG3PxCK0dUtu+vdX6+u2sTtBqZLcOWWOYDuphu1TiEaOhq9Mk2YMAAfvjhB1asWFHm/m+++YaVK1cyYMCAmlxGiBJiMosS6jBPTYMZTn69R24JJUjvREJGLsuuDeO3JQkZRv44cQWAcT3+av4yGAykpKRU+rL2tAONnSUBuiQTIgpREzXqPDFnzhy2bt3Kww8/zHvvvUf//v3x9/cnKSmJbdu2cfjwYdzd3XnvvfdqK15h57Jy80nMKfr/Fp4No+/PjZwcNEwdEs4rK4/wyaZzPNirGW4627mXb/fGYVaK5v5p5V+0xp7BYCC0eXNSy5lrqSzWnHagMSvuCH0oLh1FURrklwAhbEGNPnXbt2/P9u3bee6559iyZQuHDh0qsX/AgAF8/PHHMgJM1JqTiVkA5F48gluH3laO5ubd170pn285z/kUA4u2xjB1aHitnNdgMGA0GqtU1tnZudTghYJCMyv2xAEwvvdfk5UajUZSU1J4ZdFvuHh4VnheW5h2oDFrG+SOo1ZNhjGf2NQcmjfA9eWEsAU1/toZERHBpk2biIuL49ChQ2RkZKDX6+ncuTMhISG1EaMQQNHEfMcTMgHIPrIBRthOAlSdZp/ixGPa8NY8t/wAX2w9z6N9QvF2daxRDNWtpfHx9SX2woUSSdCfJ5NIzMzF29WROyJKz/3j4uGJm77iCfhsZdqBxspBoyYi2IP9F9M5GJcuCZAQN6nW6t1DQkIk4RF1KjEzl/ScfDQqyDm9w9rhAH/NSt22bdsqH1OceIyMCKJD8DmOXc7k001nmXFnzWpKq1NLk5OZzruTRmA0GkskQF/vLlre5v7uTdFpNTWKR9SdziGelgTo7q5NrB2OEA1SrSRAeXl5bNiwgZMnT2IwGHj99dcByM3NJTMzE19fX9RqGUkiaub45aLanxB3FefzqtbMU9eKZ6We+vEqfPwrny35xsTjpdvbMHHxXpbujOWJ/mEE6Z1rHFNVamnKcjYpi82nk1Gp4KFeslafLSteGFVmhBbi5tU4K1m9ejXNmjVj9OjRvPjii0RFRVn2HT58mKCgoHJHiQlRVQWFZk5fyQYgzMP2On26uOtx03tX+rqxZmZgaz96hXmTV2Dmoz/OWCf4a/6zNQaAYe0CpFnFxhUnQMcuZ5JXYLsTagphy2o8EeJ9992HTqfjww8/ZPz48SX29+rVi1atWvHDDz/UKEghziUbyCs04+6kxb/mlSQ2Q6VS8fIdbQD4bt8lziZlWyWOpKxcVu6PB+BvA1pYJQZRdc28XfB0cSCvwMzJxExrhyNEg1SjJrCZM2fi6enJvn378PPzK7MjaPfu3dmzZ09NLiMEJ651fm4X5IFK1bjmP+ke6s3QdgFsOHGFWb+e4L8Te9Z7DF/tjCWv0EzXZp50D/Wq9+uLslXUub69vws7LmSw/UQ8wU4FZY7qE0KUr0Y1QLt27eKuu+7Cz8+v3DIhISEkJibW5DLCzmXnFnDxatHkP+0C3a0cTd14bWRbtGoVf55MYsvp5Hq9dk5eAV9dm5Bx8oAWMq+MDbi+c72fn1+Zr1+//hSA1+f/Bz8/P0KbN8dgMFg5ciEajhrVAJlMJvT6itdiysjIkA7QokZOJGaiAMGeTni6OHKlEU403MLPjQl9m7NoWwwz1xzn15a31tsSFEt2XCA9J5/mPi4Ma195R25R96rSuT4uPY91Z7No0vN2nrr39jJH9QkhylejT9gWLVqwb9++Csvs3LmzWkOEhbjRqStFkx+2C/SwciR16/nB4Xi5OHD6Sna9LZGRlVvAZ5vOARA5tDUatdT+2JKKOteHBvkCkJFbiNalcb83hKgLNUqA7r33XrZu3cqXX35Z5v7333+fo0eP8sADD9TkMsKOpWabSM3OQ62CVv5u1g6nTuldHJg2vKhD9PvrTnMlM7fOr7lsXwKZuQW0DnBjdOfgOr+eqD0ujlo8nIoq8VNybHNRXSFsWY0SoJdeeol27drx+OOPM3z4cP744w8Apk+fzq233srLL79Mly5deO6552olWGF/ioe+h/q44uTQ+CfmG9+rGZ1DPMk2FfD2z8fr9FpqFz3Lo4v6500b1kZqfxqgQA8nAJIMsu6aENVVowTIzc2NrVu38uCDD7Jx40a2bduGoii8//777Nixg3HjxrFhwwZ0Ol1txSvsiKIoluavNgGNs/PzjTRqFbPuiUCjVrHmSAIbTyXV2bU8b30EY76ZTk313N4hoM6uI+pOgL4oAUo2yLprQlRXjXtZenl58fXXX5OYmMivv/7KsmXLWL16NZcvX+abb77By0uG1IqbcyXLRIYxH61aRQs/++nY2SFYz+N9mwPw2sojZOTU/rf7K9n5uHcZAcA/7mwvI78aqOIaIEmAhKi+Go0CGzx4MP379+ftt9/Gx8eHO+64o7biEoLT11Z+b+HrikM9jYiqL5Utnjqhmw/rjiVwMS2XGT8eYcFDXWstSTGbFXbEFg2XHh1RNBO1aJj83XWoVWDMV9B4+Fs7HCEalBolQLt37+aWW26prViEsFAUhdNJRQlQ60Y09091Fk91DGpN4CP/4pfDCQxtF1Bri14eiEvnqrGQQmMmUwd0q5VzCuvQatT4ueu4kmlC16SdtcMRokGpUQLUrl07Lly4UEuhCPGX+HQjBlMhOq2aUB8Xa4dTa6qzeGpOZjqfLlqK562PMGPVEdoFedCmhslgYkYuO86lAJC+aTGerw+r0fmE9QXpna8lQDLdiBDVUaN2hSlTprB69WqOH6/b0SrC/hR3fm7p54a2EU6kWZXFU108PMnY+R3dQ9wx5BUyaeleUrNNN33N3PxCfj2agFmB5p6OZB9eX4t3JKwl6FpHaKkBEqJ6alQDFBYWxqBBg7jllluYPHkyPXv2JCAgoMy+CgMGDKjJpYQdKTQrlkVBa1rj0eApZt4bE86kFSeJTc3h78ui+WpS72pPCVBoVlh7LJGs3AL0zg7c2tyVzXUUsqhfxQmQo38YxjyZD0iIqqpRAjRo0CBUKhWKovDBBx9U2EmzsFDemKJqLl7NITffjLODhqaejWjp95vk6ezAogk9uOfjHey9kMZj/93Dogk9cHdyqNLxhWaF344mEJuag0atYmTHQBzNOXUctagv7k4OuDqoMeTDsUQDITKfpRBVUqME6I033pDhs6LWnb7W/NU6wA21TM4HQCt/d/77eE+eWLyXPTFXGf/FbhZN6IH/tWHQ5ckrMPP7sUTOpxjQqFWM6hSEv7sT2RmSADUm/m5aYtLyOHw5izukX7sQVVLtBEij0RAVFcXrr79OVFQUUDQabPfu3Tz//PO1HZ+wMwVmhXPJRc1fre1k8sOq6tncm2/+dguP/XcPR+IzGDp3MzPubMe4HiFlfhGJu5rDhhNXyMwtQKNWMbpTEKE+9jOfkj35KwHKtnYoQjQY1e5dqigKiqKU2LZ27Vr+7//+r9aCEvYrLj2P/EIFdyetpW+D+EtEEz3/+3sfOjXVk5lbwMs/HGHIB5t5//dTbDmXhnOLHhy9YuS7fXGsPBBPZm4B7k5a7unSRJKfRizAtei77JHL2aU+n4UQZbO54TWffvopnTp1wsPDAw8PD/r06cNvv/1m2a8oClFRUQQHB+Ps7MygQYM4duxYiXOYTCamTJmCr68vrq6ujBkzhkuXLtX3rYibcP5qHlBU+yPNq2Vr4efGyqf7MmNkO5wdNJxPMbBw41mmrTqN//1R7I7LISGjaCHViCYePNI7lCZe0peqMfN20WLON5GRW8D5FIO1wxGiQbC5BKhp06a8++677Nu3j3379jF48GDuuusuS5IzZ84c5s6dy8KFC9m7dy+BgYEMGzaMrKwsyzkiIyNZtWoVK1asYNu2bWRnZzNq1CjpiG3jVI4uxGUUJUD2svbXzdJq1Dw1oAV7Zgzhwwe7MCIikPaBrpgunybY3YEB4b480a85Q9oG4Ki1ube5qGUatYq8xDMARMemWTkaIRoGm/tkHD16NCNHjqR169a0bt2ad955Bzc3N3bt2oWiKMyfP58ZM2YwduxYIiIiWLp0KTk5OSxfvhyAjIwMFi1axAcffMDQoUPp2rUry5Yt48iRI2zYsMHKdycq4hJ+C4UKeLk44OvmaO1wGgR3Jwfu6tKETx/pzpePRJD41TRGtPGgazOvKo8SE42DKf4kAAcuSgIkRFXYXAJ0vcLCQlasWIHBYKBPnz7ExMSQmJjI8OHDLWV0Oh0DBw5kx44dAERHR5Ofn1+iTHBwMBEREZYyZTGZTGRmZpZ4ifrl2r5orqg20vwlRLWZ4k8AUgMkRFXd1DD4ZcuWsWvXLsu/z549C8DIkSPLLK9SqVizZk2Vz3/kyBH69OlDbm4ubm5urFq1ivbt21sSmICAgBLlAwICiI2NBSAxMRFHR8dSq9AHBASQmJhY7jVnz57NW2+9VeUYRe1Ky8nHqXlXoHGt/SVEfTFdLqoBOn0lmwxjPnpnqQEUoiI3lQCdPXvWkvRcb+3atWWWr+63+TZt2nDw4EHS09P54YcfmDBhAps3/zVv7Y3nUxSl0mtUVubVV19l2rRpln9nZmYSEhJSrbjFzfvj9FVUag2+Lhq8XKT5S4jqMudk0NRTx6V0Ewfj0hnY2s/aIQlh06qdAMXExNRFHCU4OjrSqlUrAHr06MHevXv58MMPefnll4GiWp6goCBL+aSkJEutUGBgIHl5eaSlpZWoBUpKSqJv377lXlOn06HT6eridkQVrD+VCkALb/kZ1KfU1NRaLSesq1OwO5fSTUTHpkkCJEQlqp0AhYaG1kUcFVIUBZPJRFhYGIGBgaxfv56uXYuaS/Ly8ti8eTPvvfceAN27d8fBwYH169czbtw4ABISEjh69Chz5syp99hF5a5k5rI/rmgUX5iX1P7Uh7xcI6hUtG1bvRXEC/Lz6ygiURs6Bbvx6/EU9ks/ICEqVaOlMOrCa6+9xogRIwgJCSErK4sVK1awadMm1q5di0qlIjIyklmzZhEeHk54eDizZs3CxcWF8ePHA6DX65k0aRIvvPACPj4+eHt78+KLL9KxY0eGDh1q5bsTZfn1SAIKkBt/Arce/a0djl3IzzOBojD141X4+AdWWj4lPpaPIh8kv6CgHqITN6tTsBsAB+PSKTQraGQpGSHKZXMJ0JUrV3j00UdJSEhAr9fTqVMn1q5dy7BhwwCYPn06RqORZ555hrS0NHr37s26detwd/+r4+y8efPQarWMGzcOo9HIkCFDWLJkCRpN9VbQFvXjl8MJAOSc2AJ3SQJUn1zc9bjpvSstZ8hMr/tgRI219HXB1VFDtqmA01eyaBfkYe2QhLBZNpcALVq0qML9KpWKqKgoyzpkZXFycmLBggUsWLCglqMTtS0+3Uh0bBoqIOfUdmuHI0SDplGr6NrMi21nU9gXmyYJkBAVsOl5gETjt+bwZQC6NnWnMPuqlaMRouHrHlo0+GPfBXk/CVERSYCEVRU3fw1v62PlSIRoHHq3KGrS3H3+qiyMKkQFJAESVnMhxcDhSxlo1CqGtK68H4oQonJdQ7xw0KhIzMwl7qrR2uEIYbMkARJWs+ZIUe1P35Y+eLnIrLVC1AZnRw2dmnoCsDtG5m8SojySAAmr+flQUf+f0Z2CrRyJEI1Lr7CiGtU9MdIPSIjySAIkrOJsUhYnE7Nw0Ki4vUPl89AIIaqud3ECJB2hhSiXJEDCKn4+VNT8dWu4H3pp/hKiVnUP9UKtgtjUHBIzcq0djhA2SRIgUe8UReGXa8PfR3cOqqS0EKK63J0c6BCsB6QfkBDlkQRI1LsTCVmcSzbgqFUztF2AtcMRolEq7ge0W/oBCVEmSYBEvSuu/bmtjR/uTtL8JURdKO4HtOu81AAJURZJgES9Kmr+Kur/M7qzjP4Soq70buGDWgXnkw3SD0iIMkgCJOrV4UsZXLyag7ODhsFt/a0djhCNlt7ZgY5NivoB7TiXYuVohLA9kgCJelXc/DWknT8ujja3Fq8QjUqflr4AbD8rzWBC3EgSIFFvzGaFNdL8JUS96deqaI29nedSZF0wIW4gCZCoN/svpnE5Ixd3nZaBrf2sHY4QjV6PUG8cNWouZ+RyITXH2uEIYVMkARL1prjz87D2ATg5aKwcjRCNn7Ojhq7NPAHpByTEjaQThqgXhWbFsvjpKJn8sFpSU6vWf6Oq5YR96dvSl90xV9lxNpWHe4daOxwhbIYkQKJe7I5JJTnLhN7Zgf6tpPmrKvJyjaBS0bZt22odV5CfX0cRiYaoXysf5m0oqgEymxXUapW1QxLCJkgCJOpFcfPXHR0CcdRKy2tV5OeZQFGY+vEqfPwrXzA2JT6WjyIfJL+goB6iEw1F5xBP3HRa0nLyOXY5k45N9dYOSQibIAmQqHP5hWbWHk0EpPnrZri463HTe1dazpCZXvfBiAbHQaOmb0sf1h2/wubTSZIACXGNfBUXdW7HuVSuGvLwcXWkTwsfa4cjhN0Z2Kao2Xnz6WQrRyKE7ZAESNS5Xw4VTX44omMgWo38yglR3waEFyVA+y+mk2GUPmJCgCRAoo6ZCgr5/di15q9OMvmhENYQ4u1CSz9XCs0KO87KcHghQBIgUce2nk4hM7eAAA8dPZtX3o9FCFE3BrYuWntPmsGEKCKdoEWdMRgM/LA3BoDBrbxIu1r+PDUyh40QdWtgGz/+uz2GzaeTURQFlUqGwwv7JgmQqBMGg4HQluG4PPQhap0Lc//vEd69fLLS42QOGyHqRu8wb3RaNQkZuZy+kk2bQHdrhySEVUkCJOqE0WjEqA/DTeeCm6OaGfP/W+E3TpnDRoi65eSgoW9LHzaeSmbDiSuSAAm7J32ARJ1xaXcrAG0C9bh7+uCm9y735ewuc5MIUdeGtg8AYMOJK1aORAjrkwRI1IlsUwHOLXsB0DrAzcrRCCEAhrYrSoAOxqWTlJVr5WiEsC5JgESd2HQmDbWDDr2TBj93nbXDEUIAAR5OdG6qR1HgzxNJ1g5HCKuSBEjUibUni0Z1tfR2lNEmQtiQ4lqg9celGUzYN0mARK1LzjKxJzYDgJbeUvsjhC0Z1qEoAdp2NoWcPBl0IOyXJECi1v1y+DJmBUyXT+LhpLF2OEKI67QJcKeplzOmAjNbz8is0MJ+yTB4Uet+Oli09pfh+GYY08/K0QhhP6o6oeigcG+W7Yln7dFEbu8QWMdRCWGbbK4GaPbs2fTs2RN3d3f8/f25++67OXXqVIkyiqIQFRVFcHAwzs7ODBo0iGPHjpUoYzKZmDJlCr6+vri6ujJmzBguXbpUn7dil2JTDRyMS0etAsPJrdYORwi7kJdrBJWKtm3b4ufnV+nr89efBor6AeXmF1o5eiGsw+ZqgDZv3syzzz5Lz549KSgoYMaMGQwfPpzjx4/j6uoKwJw5c5g7dy5LliyhdevWzJw5k2HDhnHq1Cnc3Ysm94qMjOTnn39mxYoV+Pj48MILLzBq1Ciio6PRaKRZpq4U1/70CtUTY0i3bjBC2In8PBMoClM/XoWPf8U1OjmZ6bw7aSS9xjtyJSuPLaeTGS61QMIO2VwCtHbt2hL/Xrx4Mf7+/kRHRzNgwAAURWH+/PnMmDGDsWPHArB06VICAgJYvnw5kydPJiMjg0WLFvHVV18xdOhQAJYtW0ZISAgbNmzg9ttvr/f7sgeKovDjwXgA7mjrw7dWjkcIe+PirsdNX5VFhxWGtPZmeXQivxxOkARI2CWbawK7UUZG0Wgib++iN3VMTAyJiYkMHz7cUkan0zFw4EB27NgBQHR0NPn5+SXKBAcHExERYSkjat+xy5mcTzag06oZFO5l7XCEEBUY3tYHKJoVWprBhD2y6QRIURSmTZtG//79iYiIACAxMRGAgICAEmUDAgIs+xITE3F0dMTLy6vcMjcymUxkZmaWeInqWX2oqPlraLsA3HQ2V7kohLhOh0BXmng6k5NXyMaTMimisD82nQA999xzHD58mG+++abUvhsn11MUpdIJ9yoqM3v2bPR6veUVEhJy84HboUKzwupr/X/GdAm2cjRCiMqoVCpGdQoC4OfDl60cjRD1z2YToClTprB69Wo2btxI06ZNLdsDA4vaqm+syUlKSrLUCgUGBpKXl0daWlq5ZW706quvkpGRYXnFxcXV5u00entirpKYmYu7k5ZBbfysHY4QogpGdy76srLhRBIZOflWjkaI+mVzCZCiKDz33HOsXLmSP//8k7CwsBL7w8LCCAwMZP369ZZteXl5bN68mb59+wLQvXt3HBwcSpRJSEjg6NGjljI30ul0eHh4lHiJqlt9qKjz88iIIHRaGWUnREPQIdiDtoHu5BWYpRZI2B2bS4CeffZZli1bxvLly3F3dycxMZHExESMRiNQVG0bGRnJrFmzWLVqFUePHmXixIm4uLgwfvx4APR6PZMmTeKFF17gjz/+4MCBAzzyyCN07NjRMipM1B5TQSFrDicAcFdXaf4SoqFQqVTc172ohv37aJknTdgXm+up+umnnwIwaNCgEtsXL17MxIkTAZg+fTpGo5FnnnmGtLQ0evfuzbp16yxzAAHMmzcPrVbLuHHjMBqNDBkyhCVLlsgcQHVg86lkMnMLCPDQ0TvMx9rhCCGq4e6uTXj3t5McikvnzJUswgPcKz9IiEbA5hIgRVEqLaNSqYiKiiIqKqrcMk5OTixYsIAFCxbUYnSiLD9dG/01ulMwGrWs/C5EQ+LrpmNQG382nLjC/6Iv8erIdtYOSYh6YXNNYKJhycrNZ8PxK0DRN0khRMNT3Ay28kA8+YVmK0cjRP2QBEjUyLpjVzAVmGnh50qHYOk4LkRDNLitP75ujiRnmVh/7QuNEI2dJECiRn7YX9Rx8q7OTSqdh0kIYZsctWoe7NkMgKU7Llg3GCHqiSRA4qbFpxvZeT4VgLHdpPlLiIbs4VuaoVGr2B1zlZOJMhO+aPwkARI37ccD8SgK9A7zJsTbxdrhCCFqIEjvzO0diiaK/XJnrJWjEaLuSQIkboqiKPxwbd6Qe7s3raS0EKIheKxPcwBW7Y8nwygzQ4vGTRIgcVMOxKVzPsWAs4OGkR2DrB2OEKIW9A7zpk2AO8b8QpbvvmjtcISoU5IAiZtSXPtzR0SgrPwuRCOhUql4akALABZtiyE3v9DKEQlRdyQBEtWWm1/Iz9cmP7y3mzR/CdGY3NUlmCaezqRkm/h+nywKLRovSYBEtf1xIonM3AKC9E70aSlLXwjRmDho1PztWi3Qv7ecl4kRRaMlCZCoFoPBwDe7zgNwR1tv0q6mkpKSUuqVmppq5UiFEDfrgZ4h+Lo5cinNyOqDskq8aJwkARJVZjAYaN62E1vPFiU3M58cjZ+fX5mvtm3bAlCQLyNJhGhonBw0PNE/DID5f5wmr0BqgUTjI71XRZUZjUZMQZ1wVWvwc9Uy6d//K7dsSnwsH0U+SH5BQT1GKISoLRP7Nmfx9gvEXTWyfHcsE/uFWTskIWqVJECiyhRFwS1iCAARTb1w03uWW9aQmV4/QQkh6oSLo5apQ8L5x49H+eiPM9wW5oKro6ZKxzo7O+Pq6lrHEQpRM5IAiSo7ccWAo38YGhW0DnC3djhCiDr2QM8QvthyjtirRjo/MI2MbcurdJyPry+xFy5IEiRsmiRAospWHU4CoLmXI04OVfsmKIRouBw0ap7u14RXfj6LT//x/O3vz+Cuq/i9n5OZzruTRmA0GiUBEjZNEiBRJdmmAtaeKOr83MbPycrRCCHqy5DW3uTGHsYptBN7E/IZ09nP2iEJUSskARJVsvrgZYz5ZvJT4wh062ztcIQQNVTVqSquXr1K6vpPaPrUZ8SkGDifnE0LP7c6jk6IuicJkKiSb/YUrQuUdeh3VLd3sW4wQoiblpdrBJXKMlVFVXXwc+RoUh6bTifT1MsFR63MoiIaNkmARKWOXMrgSHwGDhoVhqN/Ai9bOyQhxE3KzzOBojD141X4+AdWWr54Sov2PhouZmrJzC1gy5lkhrYLqIdohag7kgCJSn2zt6j2Z3C4N2eNmVaORghRG1zc9bjpvSstVzylhVatYlj7AH7YH8+xy5m08HWVpjDRoEkdpqiQwVTATwfiAbink7+VoxFCWFNTLxe6NfMEYMOJJHLyZKJT0XBJAiQq9POhyxjyCgnzdaV7iMz9I4S969PCBx9XR4z5hfx2NBGzWbF2SELcFEmARIWKOz8/1CsElUpl5WiEENam1agZERGIg0bFpTQjO87JwseiYZIESJTraHwGhy5l4KhRc1/3EGuHI4SwET5uOoZd6wQdfTGN01eyrByRENUnCZAo19e7i2p/hncIwNvV0crRCCFsSXiAO92beQGw7vgV4tOMVo5IiOqRBEiUKT0nj1UHLgHwWJ/m1g1GCGGT+rbyoaWfK4VmhdWHL5OSbbJ2SEJUmSRAokzf7o0jN99M+yAPejb3snY4QggbpFapuKNDIEF6J/IKzPx4IJ6M3EJrhyVElUgCJEopKDTz5c5YACb2ay6dn4UQ5dJq1IzpHIyPqyOGvEJ+PZWB1ruJtcMSolIyEaKdMxgMGI0l2+43nrlKfLoRT2ct/ZrqSElJAaq+dpAQwr44OWgY260JK/fHk2rII+Ch2ZxOMuDr62vt0IQol9QA2TGDwUBo8+b4+fmVeE1ZsBKA2D++pmlQgGV78dpBBfn51gxbCGGDXBy1jO3WBG9nDVo3b55acZztZ1OsHZYQ5ZIaIDtmNBpJTUnhlUW/4eLhCUBydj6rT2aiUsHkv0/G9flnLOWL1wTKL5DZX4UQpbk4ahnZxoP/rN4CzToycfEe/nlXBA/2ambt0IQoRWqABC4enrjpvXHTe3P8qhmAtgHuBPj5Wba76b1xdtdbOVIhhK3TadVc+e51hrf1Ib9Q4ZWVR5ix6gh5BWZrhyZECZIACYv0nDzOJWUD0C1URn4JIW5SYQEz72zJi8Nbo1IVzSl232c7OJecbe3IhLCQBEhYHLiYjgKE+rjg66azdjhCiAZMrVLx3OBw/juhJ3pnBw5fyuDOj7by1a5YFEXWDxPWZ3MJ0JYtWxg9ejTBwcGoVCp+/PHHEvsVRSEqKorg4GCcnZ0ZNGgQx44dK1HGZDIxZcoUfH19cXV1ZcyYMVy6dKke76Lhyckr4HhCJoBldlchhKip29r683vkAPq38iU338zrPx5l0tJ9JGfJpInCumwuATIYDHTu3JmFCxeWuX/OnDnMnTuXhQsXsnfvXgIDAxk2bBhZWX+tRRMZGcmqVatYsWIF27ZtIzs7m1GjRlFYKBN0lWf/xXQKzAoBHjqaejlbOxwhRCMSqHfiyyd68cao9jhq1fx5Monb52/hf9GXpDZIWI3NJUAjRoxg5syZjB07ttQ+RVGYP38+M2bMYOzYsURERLB06VJycnJYvnw5ABkZGSxatIgPPviAoUOH0rVrV5YtW8aRI0fYsGFDfd9Og5Cbb+bwpXQAeoV5y8SHQohap1areKJ/GD8/1592QR5cNeTx4veHeODzXbKYqrAKm0uAKhITE0NiYiLDhw+3bNPpdAwcOJAdO3YAEB0dTX5+fokywcHBREREWMqUxWQykZmZWeJlL45eySW/UMHPXUeYj6u1wxFCNGJtAt1Z/Vw/XhnRFmcHDXtirjLyw628+9tJcvJkig1RfxpUApSYmAhAQEBAie0BAQGWfYmJiTg6OuLl5VVumbLMnj0bvV5veYWEhNRy9LZJrXPleFIuAL2l9kcIUQ8cNGr+PrAl66cNYFj7AArMCp9tPsdt72/iu31xFJqlWUzUvQaVABW78Y+0oiiV/uGurMyrr75KRkaG5RUXF1crsdo6j973km9W8HFzpIWv1P4IIepPUy8XvnisB/95rAch3s5cyTQx/X+HufOjrWw5nWzt8EQj16Bmgg4MDASKanmCgoIs25OSkiy1QoGBgeTl5ZGWllaiFigpKYm+ffuWe26dTodOZ19Dv1Oy83DvMQaAvi18pPZHCFFrqrp2oNlspou/hm8fi+C7A1dYtCuek4lZPPbfPdzSXM/f+zUlIsjNUt7Z2RlXV/myJmquQSVAYWFhBAYGsn79erp27QpAXl4emzdv5r333gOge/fuODg4sH79esaNGwdAQkICR48eZc6cOVaL3Rb9Z2c8agcn/F21hEntjxCiFuTlGkGlsqwdWBmVWoNi/muErtrJDX3fB3Hvdie7LmSw60IGxvPRpG//hrzLJ/Hx9SX2wgWrJ0FlLSRdEUncbI/NJUDZ2dmcPXvW8u+YmBgOHjyIt7c3zZo1IzIyklmzZhEeHk54eDizZs3CxcWF8ePHA6DX65k0aRIvvPACPj4+eHt78+KLL9KxY0eGDh1qrduyORdSDKw6UlTF3KOpi9T+CCFqRX6eCRSFqR+vwsc/sMKyxesLllU201TIwctGzqaacG7RHecW3QlwgcOLXiMnJ8eqyUTxQtKpKVVf7NVWEjfxF5tLgPbt28dtt91m+fe0adMAmDBhAkuWLGH69OkYjUaeeeYZ0tLS6N27N+vWrcPd3d1yzLx589BqtYwbNw6j0ciQIUNYsmQJGo2m3u/HVs35/SSFZgXjuX0E9bjd2uEIIRoZF3c9bnrvCssYMtPLLesGBPtDhjGfvReuciIhkys5EPDQLMb+5wAPdA9mVAdf3HTl/xmrq1qXshaSrkhOZjrvThqB0WiUBMiG2FwCNGjQoAonxlKpVERFRREVFVVuGScnJxYsWMCCBQvqIMKGb+e5VH49kohaBWmbFsMDkgAJIWyT3tmBoe0C6NXcm+0nL3EyMZO4DBfe/zOWOWtPYTi+CcPxTZguHQel5IKrdV3rUryQtGiYbC4BEnWroNDMWz8XLR1yb2d/3k+JtXJEQghROQ9nB7r5Kmx4fQKj3l7BRaMj6Tjh3uUO3LvcgbODihC9I008HAhyd0AxZkqti6iQJEB2ZsXeOE4mZqF3dmByv6a8b+2AhBCiGpQ8IxHB7gwKCCY+3ciJhCzOJWdjzDdzOsXE6ZSiNcbcHdX43vUy/95+iQ7NTPi66fBydcDHtei/Oq10ibB3kgDZkZRsE++vOwXAtGGt8XR2sHJEQghxc1QqFU29XGjq5cJgsz+X0nKIvZrDxdQcUg15ZOWZcW17K1/sjIed8aWO16pVqNUqtGoVGlXR/xePBVHx13xzKkCjVuGq0+Km0+Kq0+CgMuN9+7McTMjB16jFw8kBvbMDrhX0RxK2R35aduTtn4+TnpNP+yAPHu7djPS0q9YOSQghakyjVhHq40qojyuEg6mgkAsJySz/bB5PTH2VKwYzVw15pBrySMvJo9CsUGBWwKyQV9WL3LB6vXuXEUTHGyH+r6Hwro4aAjyc8PfQEeDhRJDeSWqabJgkQHZi46kkVh+6jFoF797bEa2mQU4CLoQQldJpNTTxcCRr74/84/Yv8PX1tewzmxWycgsw5hdSqCgUFipF/zUXdaAuHoNz/VCc/EIzBlMhBlMB2aYCElPTeemNd+h51+MYC9Vk5uaTlVuAIa+Q8ykGzqcYAFCrINjTmWBXFVrvJhUO8BH1TxIgO5BtKuAfq44C8Hi/MDo19bRuQEIIUU/Km5Fayw1/ANVFs1Kry/pyqAEcAXc14Eiqk4aM7csZEDnFMgosv9BMcpaJK5m5XMkykZiRS4Yxn0tpRi6lQZOn/s3dXxxgdMcARkf4EuBe8coDMnFi3ZMEyA788+fjxKcbaeLpzLRhra0djhBC1LnqzkgNpWelrkxBfr7l/x006qLaHk9ny7b0nDwupOZwOj6Vy5km4jPhs+2X+HRrLMbz0WQfXo/x3B4o45oycWLdkwSokVt3LJFv98WhUsEH4zpLJz0hhF2ozozUUPGs1OWVzS8oqLCcp4sjXVwcCeIqc2aO5+6Z33DZ5ERiNri06oVLq164OqjpFORMa18dWnVRx2uZOLF+yF/DRiw5y8SrK48A8LdbW3BLCx8rRySEEPWrKjNSQ8WzUpdXtjqUPCNtAz24NbAJaTl5HLucyfHLmRjyC9l50cDhxFy6h3oR0URf7XOLmyMJUCNVaFaYuuIAqYY82ga6M224NH0JIYQt8HJxpH8rX24J8+bY5Uz2xaaRbSpgy5kU9l5Io1uwE6hkoEpdkyfcSM3fcJod51JxcdSwcHxXGYophBA2RqtR0znEk4l9mzOkrT8eTlqM+YVsjzUQ+NhcDsZnWTvERk0SoEZo46kkFvx5FoDZYzvSyt+9kiOEEEJYi0atIqKJnsf6NGdgaz8cNSp0ga148pvj/N+3B7mSmWvtEBslSYAambNJ2Tz/zQEAHrmlGXd1aWLliIQQQlSFRq2iS4gn90V4knXod1TAqgPxDP1gM9/tjZN5hGqZJECNSJohj0lL95KVW0CPUC9eH9Xe2iEJIYSoJmcHNVfXLuCj0U3pEOhKlqmA6T8c5uHPt3M85jIpKSklXgaDwdohN0jSCbqRyM0v5Omvo4lNzaGJpzOfPdpd+v0IIUQDVDyH0Zj+XUClxqPn3Xje+gg7YjK448OtXP3jcwxH/7SUlzmDbo4kQI1AoVlh2ncH2XX+Kq6OGhZN7IGvW8WzjAohhLBNZc1hlGYsYEtMNim44XvnNHo8/Ar9m7tSmJMpcwbdJEmAGjhFUYhafYxfjyTiqFHz+WM9CHHXkJKSUumx5U0RL4QQwvqun5PITQ8P+fsRfTGNXedTuZCeR+pJMwNDJem5WZIANWCKovDubyf5alcsKhXMe6ALXYKcCW3enNQqJEDFrp/OXQghhG1Sq1X0bO5NM28XfjuaSIYxnzWnMvHoM45Cs3SQri5JgBooRVF4f90p/r3lPAAz747gzk5BpKSkkJqSwiuLfsPFw7PCc1R1OnchhBC2I8DDiYd6hbDxZDKnrmThNeAxnvvfSRY+4k6Ah5O1w2swJAFqgBRFYc7vp/h00zkA3hrTgYd7h5Yo4+LhWSfTuQshhLA+nVbD7R0C8Hc2s/l0KnsvwogPt/LB/Z25ra2/tcNrECQBagAMBgNGoxEAs6Lwrz9i+f7gFQD+b1Az7mztZunzI/16hBDCPqhUKlr7OrFixlQGvLyYc1fzeHzJXsZ3D+S5W0Nw1JY9042zs7N0mEYSIJtnMBj+6tOj0eI7IhLXDoNQFDNXf/+EyPfWElnGcdKvRwghGr+8XCMFaZf587U78Rr0OB49xrA8OpHFa7aRsnoOBWmXSx0jw+aLSAJk44xGI6kpKfzf57+y/YqaK9kFqFQwMMyDVv94E3izRHnp1yOEEPbDMmT+o+/w8Q/kYnoeWy5kQ2ArQv/+OX2budHKxxGVSgVATma6DJu/RhKgBkDr3ZT1lyDLVICjVs2dHYNo5u1SZlnp1yOEEPaneMh8ez00Cyjg92OJXEo3suVCNldy3bmtjZ9MjnsDWQrDxu29mEHgo++TZTLj4aTlgR4h5SY/QgghhJuTlnu6NaFPCx9UKjiVmMU3e+JIzJBFVa8nNUA2ymxW+GLreeb8fgqNkxv+rlru6haCi6P8yIQQQlRMrVLRK8ybpl7OrD1WNGfQd9FxdA50BrX8HQGpAbJJyVkmJi7Zy+zfTlJoVjAc28SINh6S/AghhKiWYE9nxvdqRri/G4oCBxOMBE2Yx8krsoCqJEA2ZuuZZEZ8uJUtp5PRadXMGB5Gyi/vo1WrrB2aEEKIBsjJQcPIjkGMjAjESavC0T+MCcuO8sG6U+QVmK0dntVIAmQjjHmFvLPmOI/9dw8p2SZaB7jx85T+3NNJJrQSQghRc+EB7ozt4Inh5FYKFVjw51numL+FjSeTrB2aVUgCZAO2n03hjg+38MXWGBQFxvduxk/P9qd1gLu1QxNCCNGIODuoSfnpPd4d3QpfNx3nUww8vmQvjy/ew7nkbGuHV6+kU4kVXUrLYdavJ/j1SCIAQXonZt4dwZB2AVaOTAghRGM2tI0Pd3ZvwYI/z7J4ewwbTyWz9cwWJvZtzuSBLfFz11k7xDonCZAVXEpO49+bY/juYCKmAgW1Cu7tHMCztzbFTaexLGsBsrSFEEKIuuHu5MBrI9vxYM8QZq45wZ8nk/jPthi+2hXLQ72a8bcBLQj2dLZ2mHVGEqB6Nv/348z7/Tgqx6JfqtyLR7i64d+8n3yB9ys4Tpa2EEIIUVuu/3LtoYI5o8LY0cGLf2+/xLFEA0t2XGDZrljGdArg6dtaE94Iu2RIAlTPEjNyUDk646WDns3cadp9IKqxg8otL0tbCCGEqC15uUZQqWjbtm25ZZxCO6PvMw6n0M6sPJjIyoOJ9Aj1YlyPEG6PCETv7FCPEdedRp0AffLJJ/zrX/8iISGBDh06MH/+fG699VarxvR47yYseCOSJ/75L9w9fSotL0tbCCGEqC2WtcM+XoWPf2CFZS9eSeOnP7bj3qYP+2LT2Bebxj9+PEr/cF8GhPvSP9yXln5ulnXGGppGmwB9++23REZG8sknn9CvXz/+/e9/M2LECI4fP06zZs2sFpePqwM5p7Y32F8YIYQQDV/x2mEVaQYkr3qHzTHx/BmTw+qDlzl1JYs/Tybx57Wh8wEeOvq18qVriCdtAj1oE+jeYGqIGm0CNHfuXCZNmsSTTz4JwPz58/n999/59NNPmT17tpWjE0IIIRoGPzdHnr0tmGdva8XpawnQ9rMp7Im5ypVMEyv3x7Nyf7ylfJDeiVb+bjTxdCZQ70SQ3olAvTM+ro7onR3wcHbAXadFbeUJfhtlApSXl0d0dDSvvPJKie3Dhw9nx44dVopKCCGEaHiu7zDtrYH7Oui5r4MeU0EYhy9nsfdiJqeTcjibnENiVh4JGbkkVLLwqloF7k5aZoxsz7ieIXV9C2VqlAlQSkoKhYWFBASUnE8nICCAxMTEMo8xmUyYTCbLvzMyMgDIzMys1diysrIASLsST25O5WuxpCcnFJVPSkClVD5leXXKy7ltOxY5t23HIue27Vga6rltKZaMlCsAFXaYvpFK54aDdzBaryZo3bzRuPugcfNG4+aN2tkDtc4VtYMOM5CWCxnpKWRm6qt8/qoo/rutKErFBZVGKD4+XgGUHTt2lNg+c+ZMpU2bNmUe8+abbyqAvOQlL3nJS17yagSvuLi4CnOFRlkD5Ovri0ajKVXbk5SUVKpWqNirr77KtGnTLP82m81cvXoVHx+fRtthOTMzk5CQEOLi4vDw8LB2ODZDnkvZ5LmUTZ5L2eS5lE2eS9lq87koikJWVhbBwcEVlmuUCZCjoyPdu3dn/fr13HPPPZbt69ev56677irzGJ1Oh05XcupvT0/PugzTZnh4eMgbsQzyXMomz6Vs8lzKJs+lbPJcylZbz0Wv11daplEmQADTpk3j0UcfpUePHvTp04fPP/+cixcv8ve//93aoQkhhBDCyhptAvTAAw+QmprK22+/TUJCAhEREfz666+EhoZaOzQhhBBCWFmjTYAAnnnmGZ555hlrh2GzdDodb775ZqmmP3snz6Vs8lzKJs+lbPJcyibPpWzWeC4qRalsnJgQQgghROOitnYAQgghhBD1TRIgIYQQQtgdSYCEEEIIYXckARJCCCGE3ZEEyA7Mnj2bnj174u7ujr+/P3fffTenTp0qUUZRFKKioggODsbZ2ZlBgwZx7NgxK0Vc/2bPno1KpSIyMtKyzV6fSXx8PI888gg+Pj64uLjQpUsXoqOjLfvt8bkUFBTwj3/8g7CwMJydnWnRogVvv/02ZvNfaynZw3PZsmULo0ePJjg4GJVKxY8//lhif1WegclkYsqUKfj6+uLq6sqYMWO4dOlSPd5F7avoueTn5/Pyyy/TsWNHXF1dCQ4O5rHHHuPy5cslzmFvz+VGkydPRqVSMX/+/BLb6/K5SAJkBzZv3syzzz7Lrl27WL9+PQUFBQwfPhyD4a/FWOfMmcPcuXNZuHAhe/fuJTAwkGHDhlkWb23M9u7dy+eff06nTp1KbLfHZ5KWlka/fv1wcHDgt99+4/jx43zwwQclZkW3x+fy3nvv8dlnn7Fw4UJOnDjBnDlz+Ne//sWCBQssZezhuRgMBjp37szChQvL3F+VZxAZGcmqVatYsWIF27ZtIzs7m1GjRlFYWFhft1HrKnouOTk57N+/n9dff539+/ezcuVKTp8+zZgxY0qUs7fncr0ff/yR3bt3l7l0RZ0+lxqvPCoanKSkJAVQNm/erCiKopjNZiUwMFB59913LWVyc3MVvV6vfPbZZ9YKs15kZWUp4eHhyvr165WBAwcqU6dOVRTFfp/Jyy+/rPTv37/c/fb6XO68807liSeeKLFt7NixyiOPPKIoin0+F0BZtWqV5d9VeQbp6emKg4ODsmLFCkuZ+Ph4Ra1WK2vXrq232OvSjc+lLHv27FEAJTY2VlEU+34uly5dUpo0aaIcPXpUCQ0NVebNm2fZV9fPRWqA7FBGRgYA3t7eAMTExJCYmMjw4cMtZXQ6HQMHDmTHjh1WibG+PPvss9x5550MHTq0xHZ7fSarV6+mR48e3H///fj7+9O1a1e++OILy357fS79+/fnjz/+4PTp0wAcOnSIbdu2MXLkSMB+n8v1qvIMoqOjyc/PL1EmODiYiIgIu3lOUPQZrFKpLDWr9vpczGYzjz76KC+99BIdOnQotb+un0ujnglalKYoCtOmTaN///5EREQAkJiYCEBAQECJsgEBAcTGxtZ7jPVlxYoV7N+/n71795baZ6/P5Pz583z66adMmzaN1157jT179vD888+j0+l47LHH7Pa5vPzyy2RkZNC2bVs0Gg2FhYW88847PPTQQ4D9/r5cryrPIDExEUdHR7y8vEqVKT6+scvNzeWVV15h/PjxlkU/7fW5vPfee2i1Wp5//vky99f1c5EEyM4899xzHD58mG3btpXap1KpSvxbUZRS2xqLuLg4pk6dyrp163Byciq3nD09Eyj6RtajRw9mzZoFQNeuXTl27Biffvopjz32mKWcvT2Xb7/9lmXLlrF8+XI6dOjAwYMHiYyMJDg4mAkTJljK2dtzKcvNPAN7eU75+fk8+OCDmM1mPvnkk0rLN+bnEh0dzYcffsj+/furfY+19VykCcyOTJkyhdWrV7Nx40aaNm1q2R4YGAhQKqNOSkoq9W2usYiOjiYpKYnu3buj1WrRarVs3ryZjz76CK1Wa7lve3omAEFBQbRv377Etnbt2nHx4kXAPn9XAF566SVeeeUVHnzwQTp27Mijjz7K//3f/zF79mzAfp/L9aryDAIDA8nLyyMtLa3cMo1Vfn4+48aNIyYmhvXr11tqf8A+n8vWrVtJSkqiWbNmls/g2NhYXnjhBZo3bw7U/XORBMgOKIrCc889x8qVK/nzzz8JCwsrsT8sLIzAwEDWr19v2ZaXl8fmzZvp27dvfYdbL4YMGcKRI0c4ePCg5dWjRw8efvhhDh48SIsWLezumQD069ev1BQJp0+fJjQ0FLDP3xUoGsmjVpf8uNRoNJZh8Pb6XK5XlWfQvXt3HBwcSpRJSEjg6NGjjfo5FSc/Z86cYcOGDfj4+JTYb4/P5dFHH+Xw4cMlPoODg4N56aWX+P3334F6eC417kYtbN7TTz+t6PV6ZdOmTUpCQoLllZOTYynz7rvvKnq9Xlm5cqVy5MgR5aGHHlKCgoKUzMxMK0Zev64fBaYo9vlM9uzZo2i1WuWdd95Rzpw5o3z99deKi4uLsmzZMksZe3wuEyZMUJo0aaL88ssvSkxMjLJy5UrF19dXmT59uqWMPTyXrKws5cCBA8qBAwcUQJk7d65y4MABy2imqjyDv//970rTpk2VDRs2KPv371cGDx6sdO7cWSkoKLDWbdVYRc8lPz9fGTNmjNK0aVPl4MGDJT6DTSaT5Rz29lzKcuMoMEWp2+ciCZAdAMp8LV682FLGbDYrb775phIYGKjodDplwIABypEjR6wXtBXcmADZ6zP5+eeflYiICEWn0ylt27ZVPv/88xL77fG5ZGZmKlOnTlWaNWumODk5KS1atFBmzJhR4g+YPTyXjRs3lvlZMmHCBEVRqvYMjEaj8txzzyne3t6Ks7OzMmrUKOXixYtWuJvaU9FziYmJKfczeOPGjZZz2NtzKUtZCVBdPheVoihKzeuRhBBCCCEaDukDJIQQQgi7IwmQEEIIIeyOJEBCCCGEsDuSAAkhhBDC7kgCJIQQQgi7IwmQEEIIIeyOJEBCCCGEsDuSAAkhbEbz5s0t6wAJIURdkgRICDugUqmq9aqqqKgoVCoVmzZtqrvgK7FkyZJq3dvEiROtFmtdio6OZtKkSYSHh+Pq6oqzszMtW7bk0UcfLbGWEsDEiRNRqVRcuHDBOsEKYQO01g5ACFH33nzzzVLb3nrrLfR6PZGRkfUfUC3q0qVLqfs7ePAgP/30EwMHDmTQoEGlyjcmZrOZF198kXnz5qHVahk8eDBjxozBwcGB8+fPs2bNGpYtW8bbb7/N66+/bu1whbAZkgAJYQeioqJKbXvrrbfw9PQsc19D0qVLl1JJzZIlS/jpp58YNGhQg7+/yvzjH/9g3rx5dOnShf/973+0bNmyxH6j0cjChQtJTU21UoRC2CZpAhNClJCTk0NUVBRt27bFyckJb29v7rzzTnbs2FGi3KBBg3jrrbcAuO222yxNTNf34dm4cSNPPPEEbdq0wc3NDTc3N3r06MHnn39en7dkcX2T3dKlS+nevTsuLi6WWqKMjAzee+89Bg4cSHBwMI6OjgQHB/PYY49x7ty5Cs/33Xff0a1bN5ydnQkKCuL555/HaDSWOuaHH35g4MCB+Pv74+TkREhICHfccQc//vhjte/n7NmzzJkzBx8fH9auXVsq+QFwdnbmpZdesvysmjdvztKlSwEICwuz/NxurCkTorGTGiAhhIXJZGLIkCHs2rWLbt26ERkZSVJSEt9++y3r1q3j22+/ZezYsQCWvjSbN29mwoQJlsTH09PTcr733nuPs2fPcsstt3DPPfeQnp7O2rVrmTx5MqdOneKDDz6o5zss8q9//YuNGzcyZswYhg0bhlZb9FF44sQJ3njjDW677TbuueceXF1dOXnyJMuXL2fNmjXs37+f0NDQUuf7+OOP+e2337jrrrsYNGgQa9euZcGCBaSmpvL1119byn366ac888wzBAUFcc899+Dj40NCQgJ79uzhxx9/5O67767WfSxZsoTCwkImT55MQEBAhWV1Oh0AkZGRLFmyhEOHDjF16lTLz0s6nwu7UytrygshGhxACQ0NLbHt7bffVgDl4YcfVsxms2X7oUOHFJ1Op3h5eSmZmZmW7W+++aYCKBs3bizzGufPny+1LT8/Xxk2bJii0WiU2NjYEvtCQ0NLxXQzFi9erADKm2++WWJ7cbyurq7K4cOHSx2Xnp6upKamltr+559/Kmq1WnnyySfLPJ9er1dOnjxp2Z6Tk6O0bt1aUalUSnx8vGV7t27dFEdHRyUpKanUNVJSUqp7m8qgQYMUQNmwYUO1jpswYYICKDExMdW+phCNhTSBCSEslixZgoODA++++26J0WCdOnVi4sSJpKWl8dNPP1X5fGFhYaW2abVa/v73v1NYWMjGjRtrJe7q+tvf/kbHjh1Lbdfr9Xh7e5faftttt9GhQwc2bNhQ5vmmTp1KmzZtLP92dnbmoYceQlEUoqOjS5R1cHDAwcGh1Dl8fHyqexskJiYC0LRp02ofK4S9kwRICAFAZmYm58+fp1WrVmX+QS3uI3Lw4MEqnzMrK4s333yTzp074+bmZulvcu+99wJw+fLl2gi92nr16lXuvk2bNnH33XcTFBSEg4ODJeYjR46UG2+3bt1KbSt+hunp6ZZt48aNw2AwEBERwYsvvsgvv/xSYr8Qov5IHyAhBFCUAAHl9iUJDAwEijoKV0VeXh6DBg1i//79dO3alUcffRQfHx+0Wi0XLlxg6dKlmEym2gm+msq7x++//54HHngANzc3br/9dpo3b46LiwsqlYolS5YQGxtb5nF6vb7UtuJ+RYWFhZZt06dPx8fHh88++4y5c+fywQcfoNVqGTlyJPPnzy+zxqwigYGBnDx5kvj4+BI1UEKIykkCJIQAwMPDA4ArV66Uub94e3G5yvz000/s37+fJ598ki+++KLEvhUrVlhGIllDeZM9RkVF4eTkRHR0NOHh4SX2rVixolau++STT/Lkk0+SmprK1q1b+eabb/juu+84c+YMR44cQaPRVPl8/fr1Y9OmTfzxxx8MHjy4xvEJYU+kCUwIARQlNi1atODs2bPEx8eX2r9582ag5ESCxX+sr6/lKFY8bHzMmDGl9m3durU2Qq51586do127dqWSn8uXL5c5DL4mfHx8uPvuu/n2228ZPHgwJ06c4OzZs9U6x8SJE9FoNHz++eckJydXWPb62raKfm5C2AtJgIQQFhMmTCA/P59XX30VRVEs248ePcrixYvR6/UlhmoXdxi+dOlSqXMVDxfftm1bie2bN28uVSNkK0JDQzl79myJWrDc3FyefvppCgoKanz+33//vdR58vPzuXr1KlDUebo6WrVqxfTp00lJSWHEiBHExMSUKpObm8vcuXNLTAhZ0c9NCHshTWBCCIvp06ezZs0avvrqK06cOMGQIUNITk7m22+/JT8/ny+//BJ3d3dL+eIJEGfMmMHJkyfR6/Xo9XqefvppRo8eTfPmzZkzZw5Hjx4lIiKCU6dO8csvv3D33Xfzww8/WPFOyzZlyhSmTJlC165due+++ygoKGD9+vUoikLnzp05dOhQjc7/wAMP4OLiQv/+/QkNDSU/P5/169dz/PhxHnjgAZo1a1btc86cOZPc3FzmzZtHmzZtGDx4MBERETg4OBATE8OGDRtITU1l5syZlmMGDx7M+++/z+TJk7n//vtxdXWlWbNmjB8/vkb3J0SDYuVh+EIIK6GMeYAURVGys7OV119/XWndurXi6OioeHp6KiNGjFC2bt1a5nmWLFmidOzYUdHpdKXOef78eeXee+9V/Pz8FJf/b+9+cRQJojgA9wpCMxaDowUoNEHWDfBI4AKcgwMQUCA5AwY8hhugOQMJb9RMZmd3/mzITma3vk92Kt3VpvJL5/V7Dw/R7/dju93Gfr//bZ+er+oD9FbfotvtFsvlMnq9XpRlGa1WK6bTaVwul0gpxesj8737Pe1hvV4/X1ssFjEcDqPdbkdZltFsNmMwGMRqtYrr9XrXOx+Px5hMJtHpdKLRaES9Xo+qqmI0GsVut/tl/Xw+j263G7VaLYqiiJTSXc+Hf82PiBffuQEAMqAGCADIjgAEAGRHETTwLZ1Op09NSK+q6nkw6//g5d9a75nNZj8NngX+jBog4FvabDbFeDz+cF1KqTgcDn9/Q1/krSaNr53PZxPc4Q4CEACQHTVAAEB2BCAAIDsCEACQHQEIAMiOAAQAZEcAAgCyIwABANkRgACA7AhAAEB2HgHTATEiXzx+7AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHRCAYAAAB+XS2HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABuNElEQVR4nO3deVxU9f4/8NeZAYZFGPZNEFFRUdxxwQ23NMutLDXLtGtWt9RMzfJ6S+xa/rTSSrP6ek1zN8vMykzNfUVxV8QNBGTfhn1Y5vP7A5nryLDOAIO8no/HPIRzPuec9zkMzMtzPudzJCGEABERERHpkNV3AURERESmiCGJiIiISA+GJCIiIiI9GJKIiIiI9GBIIiIiItKDIYmIiIhID4YkIiIiIj0YkoiIiIj0YEgiIiIi0oMhiYxqwIABkCQJhw8fru9SAADNmzeHJEmIiorSmW5qdQKmWZMx/fzzz+jVqxdsbGwgSRIkSarvkh5b5R3f8t5jISEhkCQJISEhdVNgNUVFRUGSJDRv3ry+S2nQeByrjyGJtEoDRelLJpPBzs4O3t7eeOKJJ/Dvf/8b169fr5NavvjiC4SEhCAjI6NOtlfbDh8+jJCQkMc2AFVm//79eO6553DmzBk0a9YMffr0QZ8+faq9nsTERJibm0OSpBotX99KP6T0BfdHlbZ79D2zfv16hISEVLp8Q/K4/b4DJb/zD/89ffhvateuXfHhhx8afX8fx+NY38zquwAyPX5+fnB1dQUA5OfnIyUlBQcOHMCBAwfw8ccfY+zYsfjuu+/g5ORUZtlmzZqhTZs2sLa2NqiGL774Avfu3cOUKVNgb29f4/W0bNkSlpaWMDc3N6geQx0+fBiLFi0CUPK/eX2MdexM0TfffAMA+OyzzzBnzpwar2fr1q0oKioCAJw8eRJ37txBy5YtjVJjQ7F+/XocOXIEAwYMKPeMQJs2baq1TmdnZ7Rp0wbOzs5GqLD6Kvt9Nzc3R5s2bdC0adO6L84ISgO9EAKxsbG4ePEiLly4gI0bN+LEiRPw9PQ0ynYe9+NYHxiSqIx//etfmDJlis60lJQUbN68GYsXL8bPP/+Ma9eu4fTp01AqlTrtNmzYUIeVVu7vv/+u7xKqzNSOnTHduHEDAPDUU08ZtJ6NGzcCAOzt7ZGRkYFNmzZh4cKFBtf3uCk93lU1ffp0TJ8+vZaqMVzTpk2rvU+m5Pjx4zrfh4aGYsyYMYiKisK7776LzZs310kdDf041gdebqMqcXZ2xttvv41z587Bw8MDN27cwKxZs+q7LGog8vLyAABWVlY1Xsf169dx/vx5WFlZ4fPPPwfwv9BE1JD06NED//nPfwAAu3fvRnFxcT1XROVhSKJq8fHxwerVqwEAmzZtQkxMjM788jqGFhUV4csvv0SPHj1ga2sLhUIBT09P9O7dGwsXLtReQ1+/fj0kScK9e/cAAL6+vjrX9EvXW3q9f8CAASgqKsKyZcvQoUMHWFtb61yCKK/j9sNCQ0Px9NNPw9HRETY2Nujduzd27dqlt21lnaunTJkCSZKwfv167TRJkrSX2hYtWqSzPw+fsato3UIIbNq0CcHBwbC3t4eVlRXatm2L9957D2lpaXprebjz7p9//on+/fvD1tYWSqUSw4cPx4ULF8o9JhXJycnB4sWL0bFjR9jY2MDOzg49e/bE119/rb0U9ug+lR7/h3+e1e0kXBqIRowYgYkTJ8LOzg537tzBqVOndNqtWrUKkiRhxIgR5a4rLS0NFhYWMDc3R2pqqs68CxcuYOTIkXBwcECTJk3Qq1cv/PTTTwDK7xBdF0rf80eOHAEADBw4UOe99Oh7rjp16uu4/XD/qYpeD283IyMDa9euxejRo9GqVStYWVlBqVSiZ8+e+Oqrr8q8P6r6+15Zh+PU1FTMmzcPbdq0gZWVFRwcHDBgwABs3rwZQogy7Uu3O2XKFKjVaoSEhKBVq1awtLSEt7c3Zs+ejZycnCofv5ro3r07ACA7OxspKSk68xrKcWwMeLmNqm3UqFHw9PREXFwc9u3bh6lTp1a6zIQJE/Dzzz8DKOkn5OjoiISEBISGhuLUqVN45pln0LlzZ7i5uaFPnz44d+4c1Go1AgMDoVAotOt59PKeEAJjxozBH3/8gZYtW6Jdu3bIz8+v8r4cO3YMixcvhoWFBdq2bYv79+9r6/n8888xe/bsKq+rPH369EF0dDRiYmLg7e2NZs2aaee1bt260uWFEHjppZewZcsWAECLFi1gb2+Pq1evYtmyZdi+fTsOHjyIFi1a6F3+22+/xZtvvgl3d3e0bt0aERER2Lt3L44fP46zZ8+ibdu2Vd6X5ORkDB48GFeuXIFMJkNAQAAKCwsRGhqK0NBQ/Prrr9i9ezcsLS0BAB06dEBRUZHen+fDx6EyGo1Ge0li4sSJsLS0xLPPPov169dj48aNCAoK0rYdP3483nnnHezbtw9paWlwdHQss76ffvoJhYWFeOqpp3T61h04cAAjRoyAWq2GnZ0d/P39ER0djeeffx7Lly+vcr21QalUok+fPrhy5QoyMzMREBCg8/vg5uZm1O1ZWlpW2Dn+1KlT0Gg0OtN+//13vPrqq7CwsICHhwc6dOiA1NRUnDt3DqGhodi3bx92794NmUymrbk6v+/63L59G4MGDUJMTAwsLCwQEBCAjIwMHDlyBEeOHMG+ffu0IeJRhYWFGDp0KI4dO4Z27dqhefPmuHXrFlasWIGrV69i3759VT1c1Zabm6v9+tF+iA3tOD7WBNEDPj4+AoBYt25dpW3Hjh0rAIjXX39dZ3pwcLAAIA4dOqSddu7cOQFAeHt7i+vXr+u0V6lUYs2aNSI6OlpvLZGRkXq3f+jQIQFAyOVy4erqKk6ePKmdl5eXV+l6Sus0MzMTEyZMENnZ2UIIITQajfjqq6+08y5evFjp/j1s8uTJeo/hwoULBQCxcOFCvctVtO6VK1cKAMLW1lbs27dPOz0+Pl706dNHABA9e/Yssz4AAoCwtrbWqSczM1MMHjxYABDjx48vtx59Sn/u7du3F7dv39ZOP3v2rHBzcxMAxLx588osV9nPszJ///23ACAcHByEWq0WQgixf/9+AUA4Ojpqp5UaNmyYACC+++47vesbMGCAACA2bdqknZaZmSnc3d0FAPHKK6+I3NxcIUTJe2LVqlVCoVBoj2lNRUZGatdR2bEobffo+6Gy9+DDyz6qvGWr8v582CeffCIAiGbNmomkpCTt9EuXLonff/9d5Ofn67S/c+eO6N+/vwAg1q9fX2Z9lb0/So+bj4+PznSNRiMCAwMFABEcHCwSEhK08/78809hY2MjAIjVq1frLLdu3ToBQJibm4t27dqJiIgI7bxTp04JOzs7AUD8+eefVToe+pT+jSrv/fLhhx8KAKJFixZl5jWU49gYMCSRVnVC0qxZswQA8cwzz+hM1/dHeOvWrQKAeOedd6pdS2UhCYD4+eefq72e0jpdXV11QlWpZ599VgAQL7/8cqX79zBjhySNRiO8vb0FALFixYoyy8TGxgoLCwsBQPz9998680qPz4wZM8osd/nyZQFAKJXKcut51M2bN4UkSQKAOH/+fJn5P/74owAgbGxsRGZmps48Q0PSlClTBADx6quvaqcVFxdrQ80vv/yi0/6HH34QAMSAAQPKrOv+/ftCJpMJa2trkZWVpZ3+7bffCgCibdu2orCwsMxypT/bxh6Sfv/9d+3x0/c+KM/t27cFAPHEE0+UmVfTD/fSoKxQKER8fHyZ5ZYtW6ZdTqPRaKeXhiRJksTZs2fLLDd79mwBQMycObPK+/cofSFJo9GImJgY8fnnn2tD95o1a6q1XlM6jo0B+yRRjdjY2AAAsrKyKm3r7e0NoOROs/L6z9SUUqnE6NGja7z81KlTtZeGHvbmm28CAP76668ar9sYwsPDERMTA0tLS0ybNq3M/KZNm2Ls2LEAUO6lgVdffbXMtA4dOsDS0hIqlapMn5zy7N+/H0II9O3bF126dCkzf+zYsfDy8kJOTg5OnDhRpXVWRV5envZS7cSJE7XTZTIZJkyYAKBsB+5nnnkGVlZWOHr0KOLi4nTmbd++HRqNBiNHjkSTJk109g8AJk2aBDOzsj0RXnnlFePsUAMWERGBF198ERqNBmvXrtX7PlCr1diyZQumTZuGYcOGoV+/fujbty8mT54MALh06ZLR6il9zz///PNwd3cvM/+NN96AQqHAvXv3EBERUWZ+586dERgYWGZ6aX+hu3fvGqXOh8dJ8vb2xpw5c2BnZ4eVK1fq/f0EGtZxfJyxTxLVSHZ2NgDAzs6u0rZBQUHo2bMnzpw5ox2Ysn///ggODkbXrl0Nusbt5+cHuVxe4+X9/f0rnJ6YmIjMzMwq7WdtuHnzJoCS/julwfRR7du312n7qPLGEXJxcUFMTAyys7P1jnlVXi3t2rXTO18mk6Ft27aIjY3FzZs38eSTT1a6zqrYtWsXsrKy4OnpieDgYJ15L774Ir744gv8/vvvSE9Ph4ODAwDA1tYWI0aMwI4dO7B9+3a888472mW2bt0KAHjhhRd01nXr1i0AQMeOHfXWUd70xkKlUmH06NFQqVSYP3++NqA+LDo6GkOHDq3wg9SY/1Gq7D1pa2sLb29v3L59Gzdv3izT/668343SceJK/84ZqrRvV0FBAW7fvo309HQolUr069dPb/uGdhwfZzyTRDUSHR0N4H9/TCoik8nw559/4u2334aVlRV+/fVXzJkzB4GBgfD19dW5O6a6ygsOVVVe/Q9Pr8rZstpS+ke6ouNc2mG3vDrLO0alnT5FFe9aMUYtNVF6lmjChAnamksFBgaidevWKCgowI8//qgzr/SsU2koAoA7d+7g7NmzsLe3x/Dhw3Xal97NZGtrq7eO8qZXx8OBvqLbvh++e8mQ/wQYi0ajwcSJExEREYGnn34aixcv1ttuypQpiIiIQM+ePbF3714kJCSgoKAAQggUFhYCQJk7swxh6HvSWL8blTl+/DiOHz+O0NBQJCQkYOHChbh9+zaefPLJMne2AQ3vOD7OGJKo2jQajfa26x49elRpGQcHB3zxxRdITk7GhQsX8OWXX2LgwIG4d+8eXnnlFe0t1nUtOTm50ukPfziWnvUq74+nsW8bLr0clJSUVG6bxMREAMb5EDe1WhITE7WXApYvX673FvTS/wU/eslt+PDhsLe3x9mzZ3H79m0A/wtMY8eOhYWFhU770g/M8s4eGOPD4eG7jCp6dMTD86pyZ1Jtmz9/Pvbs2YO2bdtiy5YtZcIqAMTFxeHQoUOwtrbGnj17MGzYMLi5uWlHu390uBBjMKXfj6qysLBASEgIRo8ejYSEBLz//vs683kcTQtDElXbrl27kJCQAHNzcwwdOrRay0qShM6dO2PmzJk4ePCg9g/EmjVryrSrC+Hh4RVOd3Nz07nUVvpBWl64Kv0wflRN96d0iIDo6OhyP7yvXbum07a2lK6/vOf3aTQa7Wi+xqply5YtKC4uhkKhgJubW7kvADhx4oROHxKFQoFnn30WwP/CUem/D/dtenT/Ll++rLeWK1euGLw/dnZ22j4fV69eLbdd6bbkcnmZS0J1fQv2tm3bsGzZMtjb22P37t3lXnouHaOnbdu2eoddqKgPjaG/H+W9J7OysrShorZ/P6pryZIlkMlkWL9+vc7fDR5H08KQRNVy79497eMLXn75ZYOfAdSrVy8AKNO5tnRk5tKRmmvL2rVroVary0wvHTDz0RBYOhbR2bNnyyxz7ty5cv+A1XR//P390axZM+Tn5+O///1vmflxcXHaTs3Dhg2r1rqra+jQoZAkCcePH9c7EOXOnTsRGxsLGxsboz18tvTs0Pvvv4+EhIRyX6XjJG3atEln+YcvuV26dAnXr1+Hh4eH3ufnPfHEE9p16LsUZshl4YeVvqcerfVhpY+o6dOnT5lLQnX1uwEA58+fxz/+8Q/IZDJs3boVfn5+5bYtrSspKUnvmdZly5ZVumx196n0Pb9jxw4kJCSUmf/dd99BrVbDx8en2s+zq23+/v4YNWoUiouLsXTpUu10HkfTwpBEVZKSkoKvvvoKgYGBiI+PR7t27ao8uN7mzZvxn//8p8yo16mpqfjqq68AAF27dtWZVxpGSkcXri2pqamYOnWq9jKZEAKrV6/Gzp07IZfLywwmWdqPZc2aNQgNDdVOv3XrFiZPnqz3rijgf/tz8uTJavUlkCQJ7777LgBg4cKFOs+iS0xMxIQJE1BQUIBevXph4MCBVV5vTbRq1Up7Zubll1/WOWtz/vx5zJw5E0DJc8CMcUr+2rVr2jD20ksvVdi2dP6jwWPgwIHw8PBAeHi49qzl+PHj9V4ueuGFF+Du7o7r16/jjTfe0A5KKoTAN998ox3M01Bz586Fubk5Dhw4gHnz5ukMKlhYWIjPPvsMP/zwA4CSy1yPqqvfjaSkJIwZMwZ5eXlYunRppR3x27dvDwcHB8TGxuLjjz/WfsDn5+fj7bffrnCE95ru06BBg9C9e3eo1Wq88MILOpeL9u3bpx3p/v333zfJQRDfe+89ACWhODY2FgCPo8mpn5EHyBSVjrHh5+cn+vTpI/r06SMCAwNF8+bNteN9ABDPP/+8SE1N1bsOfeOwrFixQrts06ZNRffu3UVAQIB2fJ+mTZuKe/fu6axnw4YN2mUCAgJEcHCwCA4OFhcuXBBC/G8MkuDg4CrtU3njJH300UfCwsJC2NraisDAQOHp6and7rJly8qsT6PRiCFDhggAQiaTiTZt2oiAgAAhk8lE//79xcSJE/WOk6RSqYSDg4MAIDw8PESfPn1EcHCwWLJkSYXHrnSbpesFIFq1aiW6du2qPX7NmjUTd+7cKVNrafvqHpuKJCUliQ4dOgigZCDPTp06iXbt2mm3NWTIEL3jTtVkW++9954AIIKCgiptm5KSIszNzQUAcerUKZ15pWN6lb7OnDlT7nr279+vPa5KpVJ0795d+574/PPPtT93Q/3www/aeq2srESXLl1Et27dhK2trXb8no8//ljvskePHtXuS+vWrUX//v1FcHCwzsCH5f3sqzNOUulYQnK5XPv3QN9rz5492mVWrVql3ba7u7sIDAwUdnZ2QpIksWbNmnLrquz3vbzxfYQQ4tatW8LLy0s7zk/Xrl1Fq1attOubNGlSmbF9Svdt8uTJeo9xVf++VKSywSRL9evXTwAQb7/9tnZaQzmOjQFDEmmVfpA9/GrSpInw8vISQ4YMEQsWLCgzYvaj9P0Rjo6OFkuXLhVPPPGEaNasmbC0tBROTk6ia9euYvHixSI9PV3vur788kvRsWNHYWVlVWZgPWOFpEOHDokzZ86I4cOHC3t7e2FlZSV69eoldu7cWe46s7KyxOzZs4WXl5ewsLAQvr6+YsGCBSI/P7/cwSSFKBmVevjw4cLR0VHIZLIyf6QrGiRQo9GIDRs2iH79+gk7OzuhUCiEn5+fePfdd0VKSoreOmsjJAkhRHZ2tvjoo49EQECAsLKyEjY2NqJ79+5i5cqVoqCgwCjbKi4u1v7B/vrrr6u0zMiRIwUA8eabb+pMDw0N1R6Lli1bVrqesLAw8fTTTwulUqndt61bt4rs7GxteDKGa9euiWnTpolWrVoJKysroVAohI+Pj3jxxRfLBL1HbdmyRfTo0UM7EvKj7zljhqTKXo++1zdt2iQ6d+4sLCwshL29vRg0aJA2wFX0nqzo972iD3chhEhOThZz584Vfn5+QqFQCDs7O9G/f3+xceNGvR/sphSSfv/9dwGUjIz/8OjlDeE4NgaSEI30qXVERNUQFhaGwMBAdOrUCRcvXqzvcoioDrBPEhFRFaxbtw4AjNYpnYhMH0MSEdEDhw4dwrZt23TueCwsLMTy5cvxzTffQCaT6X08DBE9nvhYEiKiB0oHNzU3N4evry/s7Oxw8+ZNZGZmAigZ26Zz584AgAsXLmDGjBlVXvfKlSv1PuuMTN8nn3yCPXv2VKmth4cHduzYUcsVUV1hSCIieqBfv36YPn06Dh06hLi4ONy9exeOjo4IDg7G9OnTdcbNUqlU1XqQr0qlqo2SqQ7cvHmzyj9rHx+fWq6G6hI7bhMRERHpwT5JRERERHrwcpsBNBoN4uLiYGtr2/hGISUiImqghBDIysqCp6en3hH4SzEkGSAuLg7e3t71XQYRERHVQExMDLy8vMqdz5BkgNLnU8XExJT7ZGwiIiIyLZmZmfD29q70OZMMSQYovcRmZ2fHkERERNTAVNZVhh23iYiIiPRgSCIiIiLSgyGJiIiISA+GJCIiIiI9GJKIiIiI9GBIIiIiItKDIYmIiIhID4YkIiIiIj0YkoiIiIj0YEgiIiIi0oMhiYiIiEgPhiQiIiIiPRiSiIiIiPRgSCIiIiLSw6y+CyD9oqOjkZKSYrT1OTs7o1mzZkZbHxER0eOOIckERUdHo62/P/Jyc422Titra9wID2dQIiIiqiKGJBOUkpKCvNxcvPjep3Br1tLg9SVG38Hmpe8iJSWFIYmIiKiKGJJMmFuzlvDya1/fZRARETVK7LhNREREpAdDEhEREZEeDElEREREejAkEREREenBkERERESkB0MSERERkR4MSURERER6MCQRERER6cGQRERERKQHQxIRERGRHgxJRERERHowJBERERHpwZBEREREpAdDEhEREZEeDElEREREejAkEREREenBkERERESkB0MSERERkR4MSURERER6MCQRERER6cGQRERERKQHQxIRERGRHgxJRERERHowJBERERHpwZBEREREpAdDEhEREZEeDElEREREejAkEREREenBkERERESkB0MSERERkR4MSURERER6MCQRERER6cGQRERERKQHQxIRERGRHgxJRERERHowJBERERHpYXIhacmSJejevTtsbW3h6uqKMWPGICIiQqfNlClTIEmSzqtXr146bdRqNWbMmAFnZ2fY2Nhg1KhRiI2N1WmTnp6OSZMmQalUQqlUYtKkScjIyKjtXSQiIqIGwORC0pEjR/DWW2/h9OnT2L9/P4qKijB06FDk5OTotHvyyScRHx+vfe3Zs0dn/qxZs/DLL79g27ZtOH78OLKzszFixAgUFxdr20ycOBEXL17E3r17sXfvXly8eBGTJk2qk/0kIiIi02ZW3wU8au/evTrfr1u3Dq6urggLC0P//v210xUKBdzd3fWuQ6VSYe3atdi4cSOGDBkCANi0aRO8vb1x4MABDBs2DOHh4di7dy9Onz6Nnj17AgDWrFmDoKAgREREoE2bNrW0h0RERNQQmNyZpEepVCoAgKOjo870w4cPw9XVFa1bt8a0adOQlJSknRcWFobCwkIMHTpUO83T0xMBAQE4efIkAODUqVNQKpXagAQAvXr1glKp1LYhIiKixsvkziQ9TAiB2bNno2/fvggICNBOHz58OJ5//nn4+PggMjISH3zwAQYNGoSwsDAoFAokJCTAwsICDg4OOutzc3NDQkICACAhIQGurq5ltunq6qpt8yi1Wg21Wq39PjMz0xi7SURERCbIpEPS9OnTcfnyZRw/flxn+vjx47VfBwQEIDAwED4+Pvjjjz/w7LPPlrs+IQQkSdJ+//DX5bV52JIlS7Bo0aLq7gYRERE1QCZ7uW3GjBnYvXs3Dh06BC8vrwrbenh4wMfHB7du3QIAuLu7o6CgAOnp6TrtkpKS4Obmpm2TmJhYZl3JycnaNo+aP38+VCqV9hUTE1OTXSMiIqIGwORCkhAC06dPx86dO3Hw4EH4+vpWukxqaipiYmLg4eEBAOjWrRvMzc2xf/9+bZv4+HhcvXoVvXv3BgAEBQVBpVIhNDRU2+bMmTNQqVTaNo9SKBSws7PTeREREdHjyeQut7311lvYsmULfv31V9ja2mr7BymVSlhZWSE7OxshISEYO3YsPDw8EBUVhX/9619wdnbGM888o207depUzJkzB05OTnB0dMTcuXPRoUMH7d1u/v7+ePLJJzFt2jR89913AIDXXnsNI0aM4J1tREREZHoh6ZtvvgEADBgwQGf6unXrMGXKFMjlcly5cgUbNmxARkYGPDw8MHDgQGzfvh22trba9itWrICZmRnGjRuHvLw8DB48GOvXr4dcLte22bx5M2bOnKm9C27UqFFYtWpV7e8kERERmTyTC0lCiArnW1lZ4a+//qp0PZaWlli5ciVWrlxZbhtHR0ds2rSp2jUSERHR48/k+iQRERERmQKGJCIiIiI9GJKIiIiI9GBIIiIiItKDIYmIiIhID4YkIiIiIj0YkoiIiIj0YEgiIiIi0oMhiYiIiEgPhiQiIiIiPRiSiIiIiPRgSCIiIiLSgyGJiIiISA+GJCIiIiI9GJKIiIiI9GBIIiIiItKDIYmIiIhID4YkIiIiIj0YkoiIiIj0YEgiIiIi0oMhiYiIiEgPhiQiIiIiPRiSiIiIiPRgSCIiIiLSgyGJiIiISA+GJCIiIiI9GJKIiIiI9GBIIiIiItKDIYmIiIhID4YkIiIiIj0YkoiIiIj0YEgiIiIi0oMhiYiIiEgPhiQiIiIiPRiSiIiIiPRgSCIiIiLSgyGJiIiISA+GJCIiIiI9GJKIiIiI9GBIIiIiItKDIYmIiIhID4YkIiIiIj0YkoiIiIj0YEgiIiIi0oMhiYiIiEgPhiQiIiIiPRiSiIiIiPRgSCIiIiLSgyGJiIiISA+GJCIiIiI9GJKIiIiI9DC5kLRkyRJ0794dtra2cHV1xZgxYxAREaHTRgiBkJAQeHp6wsrKCgMGDMC1a9d02qjVasyYMQPOzs6wsbHBqFGjEBsbq9MmPT0dkyZNglKphFKpxKRJk5CRkVHbu0hEREQNgMmFpCNHjuCtt97C6dOnsX//fhQVFWHo0KHIycnRtlm2bBmWL1+OVatW4ezZs3B3d8cTTzyBrKwsbZtZs2bhl19+wbZt23D8+HFkZ2djxIgRKC4u1raZOHEiLl68iL1792Lv3r24ePEiJk2aVKf7S0RERKbJrL4LeNTevXt1vl+3bh1cXV0RFhaG/v37QwiBL774AgsWLMCzzz4LAPjhhx/g5uaGLVu24PXXX4dKpcLatWuxceNGDBkyBACwadMmeHt748CBAxg2bBjCw8Oxd+9enD59Gj179gQArFmzBkFBQYiIiECbNm3qdseJiIjIpJjcmaRHqVQqAICjoyMAIDIyEgkJCRg6dKi2jUKhQHBwME6ePAkACAsLQ2FhoU4bT09PBAQEaNucOnUKSqVSG5AAoFevXlAqldo2j1Kr1cjMzNR5ERER0ePJpEOSEAKzZ89G3759ERAQAABISEgAALi5uem0dXNz085LSEiAhYUFHBwcKmzj6upaZpuurq7aNo9asmSJtv+SUqmEt7e3YTtIREREJsukQ9L06dNx+fJlbN26tcw8SZJ0vhdClJn2qEfb6Gtf0Xrmz58PlUqlfcXExFRlN4iIiKgBMtmQNGPGDOzevRuHDh2Cl5eXdrq7uzsAlDnbk5SUpD275O7ujoKCAqSnp1fYJjExscx2k5OTy5ylKqVQKGBnZ6fzIiIioseTyYUkIQSmT5+OnTt34uDBg/D19dWZ7+vrC3d3d+zfv187raCgAEeOHEHv3r0BAN26dYO5ublOm/j4eFy9elXbJigoCCqVCqGhodo2Z86cgUql0rYhIiKixsvk7m576623sGXLFvz666+wtbXVnjFSKpWwsrKCJEmYNWsWPvnkE/j5+cHPzw+ffPIJrK2tMXHiRG3bqVOnYs6cOXBycoKjoyPmzp2LDh06aO928/f3x5NPPolp06bhu+++AwC89tprGDFiBO9sIyIiItMLSd988w0AYMCAATrT161bhylTpgAA5s2bh7y8PLz55ptIT09Hz549sW/fPtja2mrbr1ixAmZmZhg3bhzy8vIwePBgrF+/HnK5XNtm8+bNmDlzpvYuuFGjRmHVqlW1u4NERETUIEhCCFHfRTRUmZmZUCqVUKlURu2fdP78eXTr1g2zv94JL7/2Bq8v9tY1LH/rWYSFhaFr165GqJCIiKjhqurnt8n1SSIiIiIyBQxJRERERHowJBERERHpwZBEREREpAdDEhEREZEeDElEREREejAkEREREenBkERERESkh0EhqUuXLvjmm2+QmZlprHqIiIiITIJBISk8PBzTp0+Hh4cHpkyZguPHjxurLiIiIqJ6ZVBISkhIwIoVK9CqVSts2LABwcHB8Pf3x/Lly5GSkmKsGomIiIjqnEEhyd7eHjNnzsSlS5cQGhqKadOmIT4+HnPnzoWXlxfGjx+Pffv2GatWIiIiojpjtI7bgYGB+PbbbxEfH4/vv/8ePXr0wI4dOzB8+HD4+vri448/Rnx8vLE2R0RERFSrjH53m5WVFUaNGoVnnnkGnp6eEELg3r17+OCDD9C8eXNMnz4dubm5xt4sERERkVEZNSQdOHAAEyZMQNOmTTF37lxoNBr861//QkREBLZt26a9G2769OnG3CwRERGR0ZkZuoK4uDh8//33WLduHaKiogAATzzxBF577TWMHj0acrkcAODn54dx48Zh5MiR+PXXXw3dLBEREVGtMigkjRw5Env37kVxcTHc3Nzw/vvvY9q0aWjevHm5y/Tu3Rt79uwxZLNEREREtc6gkLRnzx4MGTJEe9bIzKzy1Y0cORKenp6GbJaIiIio1hkUkm7fvg1fX99qLRMQEICAgABDNktERERU6wzquF3dgERERETUUBgUkpYvXw5nZ2fExcXpnR8XFwcXFxd89dVXhmyGiIiIqM4ZFJJ27NiBjh07ltvHyNPTE507d8a2bdsM2QwRERFRnTMoJN28ebPS/kXt27fHrVu3DNkMERERUZ0zKCTl5ubCxsamwjaWlpbIzs42ZDNEREREdc6gkOTj44OTJ09W2ObUqVPw8vIyZDNEREREdc6gkDRixAgcP34c33//vd75//3vf3H8+HGMHDnSkM0QERER1TmDxkl67733sG3bNkybNg2bNm3CE088gaZNm+L+/fvYt28fjh49Ck9PT8yfP99Y9RIRERHVCYNCkouLCw4dOoSXXnoJhw8fxuHDhyFJEoQQAIAePXpg06ZNcHFxMUqxRERERHXF4Afc+vn54cyZMzh37hxCQ0ORkZEBe3t79OjRA4GBgcaokYiIiKjOGRySSgUGBjIUERER0WPDoI7bRERERI8rg88kJScnY926dTh79iwyMjJQXFxcpo0kSfj7778N3RQRERFRnTEoJF2+fBmDBg1Cenq6trO2PpIkGbIZIiIiojpn0OW2OXPmIC0tDQsWLEBkZCQKCwuh0WjKvPSdXSIiIiIyZQadSTp16hTGjBmDjz76yFj1EBEREZkEg84kWVhYoGXLlsaqhYiIiMhkGBSSBg0ahHPnzhmrFiIiIiKTYVBI+vTTT3Ht2jV89tlnxqqHiIiIyCQY1CfpP//5D9q3b4/33nsP3377LTp16gSlUlmmnSRJWLt2rSGbIiIiIqpTBoWk9evXa7++e/cu7t69q7cdQxIRERE1NAaFpMjISGPVQURERGRSDApJPj4+xqqDiIiIyKQY9dltaWlpiImJMeYqiYiIiOqFwSFJpVLh7bffhpubG1xcXODr66udd+bMGTz11FMICwszdDNEREREdcqgkJSWloaePXti5cqV8Pb2hr+/v84z3Dp27IgTJ05g8+bNBhdKREREVJcMCkkhISG4efMmtm7dinPnzuH555/XmW9lZYXg4GAcPHjQoCKJiIiI6ppBIWn37t0YMWIExo8fX24bHx8fxMbGGrIZIiIiojpnUEiKj49Hu3btKmxjaWmJnJwcQzZDREREVOcMCklOTk6V3s1248YNeHh4GLIZIiIiojpnUEjq378/du/ejfv37+udf/36dezduxdDhgwxZDNEREREdc6gkLRgwQIUFRWhT58+2LJlC1JSUgAA4eHhWLt2LQYNGgSFQoF3333XKMUSERER1RWDQlKHDh2wfft2ZGRkYNKkSVi9ejWEEAgICMC0adOQl5eHH3/8EX5+flVe59GjRzFy5Eh4enpCkiTs2rVLZ/6UKVMgSZLOq1evXjpt1Go1ZsyYAWdnZ9jY2GDUqFFlOo+np6dj0qRJUCqVUCqVmDRpEjIyMmp6KIiIiOgxY9BjSQBg1KhRuHv3Ln744QecOXMGaWlpsLOzQ8+ePfHKK6/A2dm5WuvLyclBp06d8Morr2Ds2LF62zz55JNYt26d9nsLCwud+bNmzcJvv/2Gbdu2wcnJCXPmzMGIESMQFhYGuVwOAJg4cSJiY2Oxd+9eAMBrr72GSZMm4bfffqtWvURERPR4MjgkAYCjoyPeeecdY6wKw4cPx/Dhwytso1Ao4O7urneeSqXC2rVrsXHjRm1fqE2bNsHb2xsHDhzAsGHDEB4ejr179+L06dPo2bMnAGDNmjUICgpCREQE2rRpY5R9ISIioobLqM9uqyuHDx+Gq6srWrdujWnTpiEpKUk7LywsDIWFhRg6dKh2mqenJwICAnDy5EkAwKlTp6BUKrUBCQB69eoFpVKpbaOPWq1GZmamzouIiIgeTwadSdqwYUOV27788suGbEpr+PDheP755+Hj44PIyEh88MEHGDRoEMLCwqBQKJCQkAALCws4ODjoLOfm5oaEhAQAQEJCAlxdXcus29XVVdtGnyVLlmDRokVG2Q8iIiIybQaFpNJO1BURQkCSJKOFpIdH9w4ICEBgYCB8fHzwxx9/4Nlnn620jlL66n60zaPmz5+P2bNna7/PzMyEt7d3dXeBiIiIGgCDQtLDnacfplKpcP78eWzZsgWjRo3CyJEjDdlMhTw8PODj44Nbt24BANzd3VFQUID09HSds0lJSUno3bu3tk1iYmKZdSUnJ8PNza3cbSkUCigUCiPvAREREZkig0LS5MmTK5z/+uuvY/DgwfjnP/9pyGYqlJqaipiYGO2o3t26dYO5uTn279+PcePGASh5fMrVq1exbNkyAEBQUBBUKhVCQ0PRo0cPAMCZM2egUqm0QYqIiIgaN6Pc3VaeoKAgjBw5Eh9++CEGDx5cpWWys7Nx+/Zt7feRkZG4ePEiHB0d4ejoiJCQEIwdOxYeHh6IiorCv/71Lzg7O+OZZ54BACiVSkydOhVz5syBk5MTHB0dMXfuXHTo0EF7t5u/vz+efPJJTJs2Dd999x2AkiEARowYwTvbiIiICEAthyQA2v5CVXXu3DkMHDhQ+31pH6DJkyfjm2++wZUrV7BhwwZkZGTAw8MDAwcOxPbt22Fra6tdZsWKFTAzM8O4ceOQl5eHwYMHY/369doxkgBg8+bNmDlzpvYuuFGjRmHVqlWG7i4RERE9Jmo1JAkhcPToUVhZWVV5mQEDBkAIUe78v/76q9J1WFpaYuXKlVi5cmW5bRwdHbFp06Yq10VERESNi0Eh6ejRo3qnFxUV4f79+9iwYQPOnj2LSZMmGbIZIiIiojpnUEgaMGBAhbfMCyEQFBSE5cuXG7IZIiIiojpnUEj68MMP9YYkmUwGBwcHBAYGlnn4LBEREVFDYFBICgkJMVIZRERERKalQT67jYiIiKi2GXQmKTo6usbLNmvWzJBNExEREdUqg0JS8+bNK312mz6SJKGoqMiQTRMRERHVKoNC0ssvv4zIyEgcO3YM9vb26Ny5M9zc3JCYmIiLFy8iIyMD/fv3h6+vr7HqJSIiIqoTBoWkd999F3369MG//vUvzJ8/HzY2Ntp5OTk5+Pjjj/HNN99g9erVaNeuncHFEhEREdUVgzpuz5s3Dz169MDixYt1AhIA2NjY4JNPPkH37t3x3nvvGVQkERERUV0zKCSdOHECPXr0qLBN9+7dcezYMUM2Q0RERFTnDApJGo0Gt2/frrDNrVu3KnwWGxEREZEpMigk9e/fHz///DO2bdumd/7WrVuxc+dO9O/f35DNEBEREdU5gzpuL1u2DMeOHcOLL76IpUuXom/fvnB1dUVSUhKOHz+Oy5cvw9bWFkuXLjVWvURERER1wqCQ1K5dO5w4cQLTp0/H0aNHcenSJZ35/fv3x9dff80724iIiKjBMSgkAUBAQAAOHz6MmJgYXLp0CSqVCkqlEp06dYK3t7cxaqSHFBVrUFCsgZW5vEYDeRIREVHVGBySSnl7ezMU1aLkLDWu3FchIiELBcUaWJrL4GpriV4tHOGhtKrv8oiIiB47RglJBQUFOHDgAG7cuIGcnBx88MEHAID8/HxkZmbC2dkZMhmfpVtTN+Izse96Ih6+RzC/UIPotFzEpOUisLkDevo6QS7jmSUiIiJjMTgk7d69G6+99hqSk5MhhIAkSdqQdPnyZQQFBWHjxo2YOHGiwcU2RuEPAhIANHeyRtdmDnBXWiI9pwAXYjJwIyELZ6PSkZylxsiOnpAxKBERERmFwYNJPvfcc1AoFPjyyy/LBKEePXqgVatW+Pnnnw0qsrGKz5O0ASmgqR1GdfKEt6M1zOUyuNpZYlh7dzwV4A4zmYSo1FwcjEjimFRERERGYtCZpMWLF8Pe3h7nzp2Di4sLUlNTy7Tp1q0bQkNDDdlMoyRZWOFCWsmPp72nHQa1cdXbUdvPzRZymYTfL8fjWlwm7CzN0cPXsa7LJSIieuwYdCbp9OnTGD16NFxcXMpt4+3tjYSEBEM20yjZ93sJecUSlFbmGNDapcI72Vq4NMGANiU/g1N3UxGvyqurMomIiB5bBoUktVoNpVJZYRuVSsVO29V0O60Atl1HAAAGtnGBmbzy49fRyx7+7rYAgP3XE1FUrKnVGomIiB53BqWXFi1a4Ny5cxW2OXXqFNq2bWvIZhqVomINvg1TQZLJ4W1dDB8nmyov27+1C6wt5EjPLcTpyLRarJKIiOjxZ1BIGjt2LI4dO4YNGzbonf/ZZ5/h6tWrGD9+vCGbaVTkMglP+9mgMO0+OjoUV2tZS3M5BrV1BQCcv1dyxxsRERHVjEEh6d1334W/vz9eeeUVDB06FH///TcAYN68eejXrx/ee+89dO7cGdOnTzdKsY2BJEkY2Nwacf/9Jyzl1V++pUsT+Lk2gQBw7HYy73YjIiKqIYPubmvSpAmOHTuG6dOn48cff0RxccmZj88++wySJGHcuHFYvXo1FAqFUYptVETN+xT1aeWMu8k5iEnLw720XOMNq05ERNSIGPz56eDggM2bN+Orr77C2bNnkZaWBjs7O3Tv3h1ubm7GqJGqSWlljo7eSlyIzsDxWykI5ogARERE1WZQSBo0aBD69u2Ljz76CE5OTnjyySeNVRcZqEdzR1yPy0RqTgHuKXh3IRERUXUZ9Ol55swZFBUVGasWMiJLczm6Ny85hRSukgOyGnRwIiIiasQMCkn+/v6IiooyUilkbB29lLAylyO3WIJNu+D6LoeIiKhBMSgkzZgxA7t378b169eNVQ8Zkblchq4+9gAAZdB4FGt4pxsREVFVGdQnydfXFwMGDECvXr3w+uuvaztr63uERv/+/Q3ZFNVQx6b2OHs3BXBsiuMx+egeWN8VERERNQwGhaQBAwZAkiQIIfD5559X+Hyx0uEBqG5ZmMngZ1uMayoz7AzPxqwxosKfExEREZUwKCR9+OGH/MBtAFraanAlKRcxmdY4fDMZA9u41ndJREREJq/aIUkulyMkJAQffPABQkJCAJTc5XbmzBnMnDnT2PWREZjLgKxLe6Hs8SzWHL3LkERERFQF1e64LYQo86iLvXv34p133jFaUWR8Wed2Qy4BJ++k4up9VX2XQ0REZPI4ymAjUZyVgj7elgCANcfu1nM1REREpo8hqREZ1aYJAOD3y/G4n5FXz9UQERGZNoakRqSFgzn6tHJCsUZg3fHI+i6HiIjIpDEkNTLT+rUAAGwNjYYqr7CeqyEiIjJdNRoCYNOmTTh9+rT2+9u3bwMAnnrqKb3tJUnCH3/8UZNNkZEFt3ZBa7cmuJmYja2h0XgjuGV9l0RERGSSahSSbt++rQ1GD9u7d6/e9hxLyXRIkoRX+7XAvJ8uY92JSPyjjy8szHhCkYiI6FHVDkmRkezL0tCN7uyJT/+KQGKmGr9disPYbl71XRIREZHJqXZI8vHxqY06qA4pzOSY0rs5Pv0rAmuPR+LZrk15to+IiOgRvM7SSE3s0QyW5jJcj8/E6btp9V0OERGRyWFIaqQcbCzw3IPLbGuPc3BJIiKiRzEkNWKv9PEFABwIT8Ld5Ox6roaIiMi0MCQ1Yi1dmmBw25KH3a47EVW/xRAREZkYhqRGbmq/krNJO8JikJFbUM/VEBERmQ6TC0lHjx7FyJEj4enpCUmSsGvXLp35QgiEhITA09MTVlZWGDBgAK5du6bTRq1WY8aMGXB2doaNjQ1GjRqF2NhYnTbp6emYNGkSlEollEolJk2ahIyMjFreO9MT1MIJ7TzskF+oweYz0fVdDhERkckwuZCUk5ODTp06YdWqVXrnL1u2DMuXL8eqVatw9uxZuLu744knnkBWVpa2zaxZs/DLL79g27ZtOH78OLKzszFixAgUFxdr20ycOBEXL17E3r17sXfvXly8eBGTJk2q9f0zNSWDS5acTfrhZBQKijT1XBEREZFpqNGI27Vp+PDhGD58uN55Qgh88cUXWLBgAZ599lkAwA8//AA3Nzds2bIFr7/+OlQqFdauXYuNGzdiyJAhAEoeo+Lt7Y0DBw5g2LBhCA8Px969e3H69Gn07NkTALBmzRoEBQUhIiICbdq0qZudNREjOnri//15A0lZavxxJQ7PdOHgkkRERCZ3JqkikZGRSEhIwNChQ7XTFAoFgoODcfLkSQBAWFgYCgsLddp4enoiICBA2+bUqVNQKpXagAQAvXr1glKp1LbRR61WIzMzU+f1OLAwk2Fy7+YAgP87GgkhRP0WREREZAIaVEhKSEgAALi5uelMd3Nz085LSEiAhYUFHBwcKmzj6upaZv2urq7aNvosWbJE24dJqVTC29vboP0xJS/2bAZrCznC4zNx5GZyfZdDRERU7xpUSCr16CM0hBCVPlbj0Tb62le2nvnz50OlUmlfMTEx1azcdNlbW+CFHs0AAN8cvlPP1RAREdW/BhWS3N3dAaDM2Z6kpCTt2SV3d3cUFBQgPT29wjaJiYll1p+cnFzmLNXDFAoF7OzsdF6Pk1f7+cJcLuFMZBrC7qVXvgAREdFjrEGFJF9fX7i7u2P//v3aaQUFBThy5Ah69+4NAOjWrRvMzc112sTHx+Pq1avaNkFBQVCpVAgNDdW2OXPmDFQqlbZNY+ShtMIzXZoC4NkkIiIik7u7LTs7G7dv39Z+HxkZiYsXL8LR0RHNmjXDrFmz8Mknn8DPzw9+fn745JNPYG1tjYkTJwIAlEolpk6dijlz5sDJyQmOjo6YO3cuOnTooL3bzd/fH08++SSmTZuG7777DgDw2muvYcSIEY/1nW3h4eGVtunnXIQdAA6EJ+KXQ2fgozTX287Z2RnNmjUzcoVERESmw+RC0rlz5zBw4EDt97NnzwYATJ48GevXr8e8efOQl5eHN998E+np6ejZsyf27dsHW1tb7TIrVqyAmZkZxo0bh7y8PAwePBjr16+HXC7Xttm8eTNmzpypvQtu1KhR5Y7N1NBlppV0xH7ppZeq1N55zHzYtOmDaZ//iNQ/luttY2VtjRvh4QxKRET02JIE7/eusczMTCiVSqhUKqP2Tzp//jy6deuG2V/vhJdfe4PXF/b3bmxe+i6efn0B2nTsVmn7dLWEg4nmkCAwzLMQNo9E6cToO9i89F2EhYWha9euBtdHRERUl6r6+W1yZ5Ko9jh5+lQpdHkBuFUYi5i0PMTLXDDAr+xwCURERI+7BtVxm+pOoI8jAOBqXCZyC4rquRoiIqK6x5BEenk7WMHNToFijcD56Iz6LoeIiKjOMSSRXpIkoaevEwDgUkwGctQ8m0RERI0LQxKVq7mTNdzsFCjSCIRFc3BJIiJqXBiSqFySJKFXi5KzSZdjVTybREREjQpDElXIx9EaHkpLFGsEzkal1Xc5REREdYYhiSr08NmkK/dVUOUV1nNFREREdYMhiSrVzNEazRytoRHAyTsp9V0OERFRnWBIoirp06rkbNLNxGykF0j1XA0REVHtY0iiKnG1tUQb95Ln411Jl1fSmoiIqOFjSKIqC2rhBLkkIVktg1XLHvVdDhERUa1iSKIqU1qZo0szewCAw6BXUVjMZyMTEdHjiyGJqqV7c0dYygTMHT3xx62c+i6HiIio1jAkUbVYmMnQ3r4YALDjejaSMvPruSIiIqLawZBE1eZjo4E67ibyigT+80d4fZdDRERUKxiSqNokCUjb9zVkEvDbpTgcvZlc3yUREREZHUMS1UhB4h0Mb2UNAPjg16vILyyu54qIiIiMiyGJamxigC3c7SxxLzUXXxy4Vd/lEBERGRVDEtWYlbkMH41uDwD4v6N3cCkmo34LIiIiMiKGJDLI0PbuGN3ZExoBzN1xCeoiXnYjIqLHA0MSGSxkZHs4N1HgVlI2VuznZTciIno8MCSRwRxsLPDxMwEAgO+O3sGpO6n1XBEREZHhGJLIKIa1d8eE7t4QAnhn+0Vk5BbUd0lEREQGYUgio/lwZDu0cLZBQmY+3vv5MoTgs92IiKjhYkgio7G2MMNXL3SBuVzCX9cSsfZ4ZH2XREREVGMMSWRUAU2V+PfT7QAA/+/PGzgblVbPFREREdUMQxIZ3ctBPhjVyRNFGoG3Np/nQ3CJiKhBYkgio5MkCUue7QA/1yZIylJj2sYwPraEiIgaHIYkqhU2CjOseTkQSitzXIrJwPvsyE1ERA0MQxLVmubONvjmxa4wk0nYdTEOX/7NgSaJiKjhYEiiWtW7lTMWPXi+2xcHbmH72eh6roiIiKhqGJKo1r3Y0wdvDWwJAPjXL1fxd3hiPVdERERUOYYkqhNzh7bB2K5eKNYI/HPzeZy8nVLfJREREVXIrL4LoIYrPDy8Wu3HtxCISVAgNE6Nf6wPxQf9HeHvbAFnZ2c0a9aslqokIiKqGYYkqrbMtGQAwEsvvVT9heVmcB37IeDbFfP/jEHSzx9BlnoXN8LDGZSIiMikMCRRteVlZwIAnn59Adp07Fbt5Ys0wMlkDZJhDc+JnyBhx0dISUlhSCIiIpPCkEQ15uTpAy+/9jVa1quVBnuuJiAyJQcuz/4bx6Pz0LWrkQskIiIyADtuU70wk8vwdAcPeFsXQ5KbYcXpDGwN5fAARERkOhiSqN7IZRK6OxUj68IeCADzd17BV3/f4sjcRERkEhiSqF5JEpC2bzWeaWsDAFi+/yamb7mA3IKieq6MiIgaO4YkMgmTOtphybMdYC6X8MeVeDz/7Sncz8ir77KIiKgRY0gik/FCj2bYMq0XnGwscC0uE6NXHce5qLT6LouIiBophiQyKd2bO2L3jL5o52GHlOwCTPi/01h9+DY0GvZTIiKiusWQRCanqb0VfvpnEEZ28kSRRmDZ3gi8tPYMElT59V0aERE1IgxJZJKsLczw1YTOWDa2I6zM5Th5JxVPfnkU+64l1HdpRETUSDAkkcmSJAnjunvj95l9EdDUDhm5hXhtYxje3XEJqtzC+i6PiIgecwxJZPJaujTBz//sjWn9fAEAO8JiMXj5EfxxOZ5jKhERUa3hY0nIJISHh1faZrgH0HygE1afy8D9LDXe2nIe3T0VmNZVCWdrubads7MznwNHREQGY0iiepWZlgwAeOmll6q+kNwMyl7joAx6HmfjgDORUVCd2o7Mc78CxUWwsrbGjfBwBiUiIjIIQxLVq7zsTADA068vQJuO3aq1bGYBEJamQRqs4TDgFXgNmQLvovv4a+kbSElJYUgiIiKDNLg+SSEhIZAkSefl7u6unS+EQEhICDw9PWFlZYUBAwbg2rVrOutQq9WYMWMGnJ2dYWNjg1GjRiE2Nraud4Ue4uTpAy+/9tV6tWvfDi/1bY2h7dxgo5Ajp0jCDXjBbcLHuJvOjt1ERGSYBheSAKB9+/aIj4/Xvq5cuaKdt2zZMixfvhyrVq3C2bNn4e7ujieeeAJZWVnaNrNmzcIvv/yCbdu24fjx48jOzsaIESNQXFxcH7tDBpAkCf4edni5V3N0b+4AGQQsfTph7v4UTN9yHpEpOfVdIhERNVANMiSZmZnB3d1d+3JxcQFQchbpiy++wIIFC/Dss88iICAAP/zwA3Jzc7FlyxYAgEqlwtq1a/H5559jyJAh6NKlCzZt2oQrV67gwIED9blbZAALMxl6t3TGUM9C5Fw/DAD4/XI8hiw/gvk7LyNexefAERFR9TTIkHTr1i14enrC19cXEyZMwN27dwEAkZGRSEhIwNChQ7VtFQoFgoODcfLkSQBAWFgYCgsLddp4enoiICBA26Y8arUamZmZOi8yLTZmQMpvn+Hzoc4Y1NYVxRqBraExCF52GP/edQUxabn1XSIRETUQDa7jds+ePbFhwwa0bt0aiYmJWLx4MXr37o1r164hIaFkNGY3NzedZdzc3HDv3j0AQEJCAiwsLODg4FCmTeny5VmyZAkWLVpkxL2h2pIffxvTO/pjsKcTNl/JwvXkAmw6HY2tZ6LR38cKY/2bwNO28rc/hxMgImq8GlxIGj58uPbrDh06ICgoCC1btsQPP/yAXr16ASjpp/IwIUSZaY+qSpv58+dj9uzZ2u8zMzPh7e1d3V2gWlTekAIK7wAoe4+HVfMuOBSVh4N3s5EbcQKqUz+iMDmq3PVxOAEiosarwYWkR9nY2KBDhw64desWxowZA6DkbJGHh4e2TVJSkvbskru7OwoKCpCenq5zNikpKQm9e/eucFsKhQIKhcL4O0FGU9mQAmnqQtzIlCM+Tw4b//6w8e8Pd0sNWtsVw1kh8HBOToy+g81L3+VwAkREjVSDD0lqtRrh4eHo168ffH194e7ujv3796NLly4AgIKCAhw5cgRLly4FAHTr1g3m5ubYv38/xo0bBwCIj4/H1atXsWzZsnrbDzKu0iEFHuUFoCOA5Cw1zkal4VZSNhLyZUjIl8HFVoGu3vbwc7OFXFbxWUUiInr8NbiQNHfuXIwcORLNmjVDUlISFi9ejMzMTEyePBmSJGHWrFn45JNP4OfnBz8/P3zyySewtrbGxIkTAQBKpRJTp07FnDlz4OTkBEdHR8ydOxcdOnTAkCFD6nnvqK642CrwVAcPpOcW4EJ0BsLjM5GcpcZf1xNx/E4KOnnZw4kjQhARNWoNLiTFxsbihRdeQEpKClxcXNCrVy+cPn0aPj4+AIB58+YhLy8Pb775JtLT09GzZ0/s27cPtra22nWsWLECZmZmGDduHPLy8jB48GCsX78ecrm8vM3SY8rB2gKD2roiqKUTrtxX4VJMBnLUxTh5JxVyyRyOQ99CZEYhutZ3oUREVOcaXEjatm1bhfMlSUJISAhCQkLKbWNpaYmVK1di5cqVRq6OGiorczl6NHdE12b2uJWYjfPR6UjJLoBtl+GYsy8FWyJOYlIvHwzv4A6FGcM0EVFj0CDHSSKqLWYyGfw97DCxRzP0dy1Ezo1jkEtA2L10zNp+EUFLDuL//XmD4y0RETUCDElEekiSBBdLgZRfl+K7Ea6Y/URreCgtkZZTgG+P3EH/Tw/hlXWh+Ds8EcUaUd/lEhFRLWhwl9uI6pqjlRwz+/jhzQEt8feNJGw6fQ/HbqXgUEQyDkUkw0Npiee6eeG5bl7wcbKp73KJiMhIGJKIqshMLsOw9u4Y1t4dkSk52HLmHnaExSJelY+VB29j5cHb6OHriHGB3niqgzusLfjrRUTUkPGvOFEN+DrbYMHT7TBnaBvsv56IHWGxOHYrGaGRaQiNTMPCX69iREdPPB/ohW4+DpWO5k5ERKaHIYmoEuHh4RXObwpgVmczvNTaFYejcnEwKg8J2cXYfi4G28/FwNNWjgE+VujbzAoBzd05ejcRUQPBkERUjvKeA1cVCq/2aNJxCKzb9EVclhW2XM3GlqvZKEw4gdljgzEpuB1c7SyNXTIRERkRQxJROSp7DlxVFGmA2NwixOTKkJQvwdy9NVaeiMfXJ+MR1NIJozp54sn2HlBamxuzdCIiMgKGJKJKlPccuKpq/uDf2zeuYeP67xE0YQYiUgtx4nYqTtxOxb93XUVwa1eM7OSBgW1dYWfJwEREZAoYkojqiKUcyDr/O16ePQGOPf1wPCYfx6PzcE9VhAPhiTgQnggzGRDgqkDPpgr08LSEg1XFo3s7Ozuzj9NjJjo6GikpKUZbH98jRDXHkERUR8rr42Tu7AMb/36wbtMHcPLGxQQ1Liao8e25DKjv30DerVPIvXkKRRkJZdZpZW2NG+Hh/BB8TERHR6Otvz/yco03ojvfI0Q1x5BEVEeq0scps7AA8bky3M+TIb1ABkuvdrD0ageHgVNhZ66Bp5WAu5UGjhYCSTF3sHnpu0hJSeEH4GMiJSUFebm5ePG9T+HWrKXB60uM5nuEyBAMSUR1rLI+Tu0e/JuVX4i7yTm4k5yN2Iw8ZBbKkFkI3MiUQ2Emg4t1a9gEDEJGfnHdFE51xq1ZS533SFGxBnmFxcgv1CC/sLjkVVTytbpQg0KNBsUaoX1phIBMkpBnLYfTiDn4z757cA1TwcpMgpW5BGszGawtJNhbymFvKYODpQy2FjLIZRWP58VLd9TYMCQRmShbS3N08rZHJ2975BcWIzIlB5EpOYhOy4W6SIPYIjmcn56Nf+xOQoew4+jn54w+rZzRzccBluYV92Ui05GjLkK8Kh8JqnycjsyFMmg8zqfJEXbxPrLVRchWFyG/UFPDtcvRpP1AXMgAkFHxJTyhKUZxTgaKc9JRnJ2GooyE/71UCSjKSISlhZyX7qhRYUgiagAszeXw97CDv4cdNBqBhMx8XLl1D5duRkLh3gpX7qtw5b4Kqw/fgbkMaONsgQ6uFujoqkBLR3OYVXKGAOBZAmMrKtYgNacAiZn5SMxUIzEzH0kPvo7PzEeCKg/xqnxk5RfpLGfffxIiswFk64YamVTyPrA0l8PSTKb9WmEug7ms5CxQ6UsmAUIA925eQdjB3+Ef9AQc3bxQKEqGpSgSQIFGgroYyC+WoNYAkkwOM1snmNk6lbtPxdnpeP3HG+jkm4FWrk3Q0qXk1dTBqtKzUEQNEUMSUQMjk0nwtLdChiYBf/0wCzIbe1j5doWlT2dY+nQCbJ1wNakAV5MKsBXZ0KhzoY67AfX9cKhjr0MdfxOiIK/MetnBt2L5hcVIzy1ARm6h9t/Sr1V5hUjPKUBaTgESs/KRlKlGSrYaGlG1ddsqzOCutISNVIDj+39H976D4enpgSaWZmiiKHkpzGTVfrxN0c10HD67C21HPIXO3duW206jEcgtLEauugg5BcXIzi+CKr8QqrxCZOYVIiOvEAVFGsibOCA8pRDhKTE6yyvMZPB1tkFLbXCyQSvXJmjh3ARWFjyrSQ0XQxJRA1XaEXz4S29pO4ILAWQXFSApX4bkfBmS1RIKFNaw8u0KK9+uD5YUsDcXcFKUvOwtNMiJv4MtJtzB15i3xRcUC6Rm5aMAZsgu0CCrQDz4V4PsB6+sAoFsdcm00ukFNej6JZdJcGmigKudAq62lnB78K+HvSU8lCUvNztL2D4YG+v8+fPoNvsrtBsxAF5NlUbZ36qQySRtGCvP3Yhr+L+P52HZN+tRbO2MOw/6y91NyYG6SIMbCVm4kZCls4wkAT6O1mjjbos2brZo426HNu62aO5kDTO5rLZ3i8hgDElEDZy+juD+D/4VQiAluwBxqjzEZ+QjTpWHrPwiZBRKyCgE7mSXtDOT2sJt4v/D2gsq3BWxCGhqh1YuTUzig6xKt8XLzSG3cYC8ieODfx/6WjvdHjLLJpCZ1/xxMKK4CJr8LBTnZUGTnwVNXslLKszDC2NHoamTEg5WMjhYyeFoKYOd4tHO0IUPXllAFpCZBWQ+NLey5wTWJwsZUJBwG845UfBvZoUBzgD8m6BYY4Pk3GLEZhbhflYR7j/4NzazCFkFAlGpuYhKzcVf1xK16zKXAV52ZvBqIkNzRwV8lGZopjSHk1X1z5Y9jJeMydgYkogeY5IkwcVWARdbBTp5lUzLzi8qCU2qfMSr8pCSXYAiDWDpHYA/buXij1uXAADmcgnNnWzQwsUGLV2aoIVLEzRztEZTByu42SpqPUBpNAIZeYUIuxMP4eKHJya8CYW9G/KLJeQ/6EtT+nWhqN4Hq9AUwwwaWFmYwUImYCFDyb9yPPR92WlmEiBJNgBsALgDAO5ePYdd33yJlQf+z2j7np2dbbR1GUtNnmUos1bCwqU5zJ19YO7i8+DrZii0sEJkRhEiM4BjsQXa9sW5KhQk3nnodRdF6fEAqnbdkpeMydgYkogamSaWZmhtaYvWbrYASsLIjfBwbP3vV5jyzodILlLgelwmstRFuJWUjVtJ2QASddYhkwB3O0u4Ky3haGMBB2sLONhYwN7aXNt/RmFWMlSBuVwGjRAPXkCxRiCvsKTfS+ndW1kPvs7MK0RqjhopWQVIyVaj6EGnHrcJH+MmAGSUv19ySYK1Qg4bCzPYKOSwfvCvjYUZrB98b2Uux42Tf2H7p3Px8qLv0Dko2ODjmRh9B4Bhz/grFR56BH/+8CXy8/MNrsvYjPEsQ6DkknBOcQGuX7uOy1cuo3mvp6CxcUR2oQS5tfKRS8OAmSRgb/HgZV7yr625wKP9xDkmFNUGhiSiRk4mk2BnIZBz7RD+0eUzdO3aFRqNwP2MPNxNycHd5GzcSc7GnaQc3M/IQ7wqD4XFAnGqfMSpav/D3NZCQur9KDT18oajgxLWFo8EIQs5bKrRsdkMGlT1zER1GPqMP+B/gcuUGWM/ASAn7g6On/oRnZ8cgs5BbbR3AyZnqZGUpUZSVr72LGeKWkKK+n/LymUSXG0VcLMr6dflbmcJYfwfKRFDEhGVJZNJ8Ha0hrejNYJbu+jM02gEUrLViM3IQ6IqH+kP7vBKzylAem4h8gqLoC7UQJWdi5x8NYo0JR14ZRIgkyTIAFiYSbA2k2BlLoO1uQQrMwnW5jJYmUtQKmRweDDIoZ1Chts3b+Cl/7yFF77eCS8/9/o5IFTrzOQyuNmVdGQvpdEIpOX+LzglP3gVFGseXC7Ox8UHN9pZyszh8swC7AzPhlqZio5eSthU0BGdqCr4DiKiapHJJLjaWcLVrvwO0LXxDDJT7KdDtUsmk+DcRAHnJgr4e5RME6Kkr1piZskAnPGqfKRkq5GvkWDdOgibrmRh05XTkElAazdbdGnmgK7N7NHD1xHNHK0N6hhOjQ9DEhFpGevuqvDwcKM9g8yU++lQ3ZMkqaQPnLUF2rrbASgZuPNa+A3s3PoDRrw8HVFZQJwqXzsswdbQaAAl/eh6+Dqih68jevo6opVrE4YmqhBDEhHV6M6lqrBxdGsU/XSofpnJZXBSCGSd3YWn334O/r39kZpbjFtpBbiZWogbqQW4nVaIhMx87L4Uh92X4gAAdgoZ/J3N0c5FgXYuFvC1N4PsQWjicAIEMCQREYx351Ipnv2hulZZ0JfMFLDwbA1L7wAovAKgaNoGmbDEmftqnLlf0iu8OFeF/HuXkH/vEkTiDVw/c5RBqZFjSCIiLWPducSzP1TXqhv0NQJILygsuXMuX4YUtQRYK2Hj3x82/v0BAOM2XMeg9ir0a+WMoJZOsLe2qNV9INPDkERERI+N6gT9h88RFWsEEjPzEZ2Wi9txKUjJE0jIBracicaWM9GQJKBjUyWC27hiUFtXdGyqhIwP9X3sMSQREVGjJ3/w4GhPeyt4FSdgxTsv4l9frEO6hSsuJRYgNrMIl2JVuBSrwld/34KdQoau7gp081Sgs5sCNhYVj0DPPk4NE0MSERHRQzLTkiEK8vDxmxO00+RNnGDp2xVWLQNh1bwLMmGNw/fycPheHoSmGOrY68i7cw55d8+iMCW6zDr5yJSGiSGJiIjoIZX1b9IIIEVdiIQ8GRLyZMgqksOyWQdYNusAh4GvwFou4G6lgbuVBq4KgZRYPjKloWJIIiIi0qOi/k0PRx1VXiGiUnIQmZqD2PQ85BYDd7PluJsth5lMgotVGzTpOBRpecV1UzgZDUMSERGRAZRW5ujkbY9O3vYoLNYgJj0XkSk5iErJRba6CPF5MjgNn4lXf0tCxwvHMaitK4b4u6G9px0HszRxDElERERGYi6XoYVzE7RwbgIhBFKyC3Ax4i4uhN+BwrMNLseqcDlWhS8O3IKbnQKD2rphiL8rerd0hpWFvL7Lp0cwJBEREdUCSZLgYquAv1KDPzfOwYHjoUi1cMeB8EQcu5WCxEw1toZGY2toNBRmMvRt5YxB/q4Y3NYN7sryn41IdYchiYiIqA4kRN2Ev78crQJk+Ie/C64mqXEuTo1z8flIydXg7xtJ+PtGEhbgKnztzdDd0xLdPBVo6WCufVwKwOEE6hJDEhERUS2qyrMRzV2aw6pld1i36gkLz9aIzChCZEY2fryejaLsNOTdOYu826HIv3cRluZyDidQRxiSiIiIalF1H5mSX1yEhDwZ4vNkSMqXgCaOsO00DLadhkGCBjl3wrDp9D1MsXOBp71VbZffqDEkERER1YHqPDKl1YN/izQa3E/PQ2RKDiJTcpCZXwTrlt3xf+cz8X/nD8Lfww5D/EseldLJy56PSjEyhiQiIiITZSaTwcfJBj5ONghuLRB+PRw/btuMoOem4WZqIcLjMxEen4mVB2/DuYkCg9q6YFBbN/Tzc4aNgh/xhuIRJCIiagAkSYKdhUDmmZ8wacYYNO3TBufj83EuTo0LCWqkZKvx47lY/HguFmYyIMBVge4eJc+Xc7Up/+OeHcHLx5BERETUQJTbCVxmBkvv9rBq1QNWLXsADh64mKDGxQQ11lwACpIikXf3HPIjLyD//nWguEi7KJ8rVz6GJCIiogaiKp3AhQCyigoQ/+DZcilqCRauvrBw9YWy1/OQSwLOCgE3Sw3MMu7hl6Vv87ly5WBIIiIiamCq0gm83YN/8wuLEZWag+jUXNxLy0VuQTES8yUk5ssAtETTN9djVWgGxsjj0KelE5yaKGq9/oaCIYmIiOgxZmkuR1t3O7R1t4MQAqk5BdrAFJueAzNbZxyMysPBqAsAAD/XJujVwgk9Wziip68TXGwbb2hiSCIiImokJEmCcxMFnJso0NXHAfciruG7zz/Cax+uQIRKhhsJWbiVlI1bSdnYePoeAKCliw16tnBCrxZO6OXrCFe7xvPIFIYkIiKiRkouA/KjLqKHxX1M7u+PTLU1ricX4FqyGteSC3Avowh3knNwJzkHW85EAwDcm8jRxskCrR3N0drJAj72ZjCTPZ6PTWFIIiIiaqQqe2SKzLIJFF7tYdmsAxTeAbBwa4GEbCAhOw9H7uUBADSFahQk3IY67gYK4iIgpd/D9XMnH4ugxJBERETUSFX3kSkFmiKkqSWkFUhIU8uQppZQaK6ApXd7WHr/ryP5mHXX0NknEe087NDO0w7tPOzQzNG6wY0IzpBERETUyFXnkSktHvpaCIH03EIkZOYjQZWP6KR0ZKgF0vKAgzeScPBGkratjYUc/g+FprYedmjpYgNbS3Mj743xNPqQtHr1anz66aeIj49H+/bt8cUXX6Bfv371XRYREZHJkyQJjjYWcLSxQDsPO8TKk7Fi1kQsXrUOQtkUkRmFiMwoQrSqEDkFxTh3Lx3n7qXrrMPRSgYvOzM0tTWDl52Z9msHSxlcXFzq9bJdow5J27dvx6xZs7B69Wr06dMH3333HYYPH47r168/FtdSiYiI6lJmWjJEYT4WvP6C7gxJBnMnL1i4toC5qy8s3FrCwtkH8iYOSMvTIC2vAJcTC3QW0RTkQ5N5Biv/MQDP9G6H+tCoQ9Ly5csxdepUvPrqqwCAL774An/99Re++eYbLFmypJ6rIyIialiq38epAFmFkvaVWSghq0hCbhEgs7CEzNkHOVmZtV12uRptSCooKEBYWBjef/99nelDhw7FyZMn66kqIiKihq86fZz0KdYI3LpxHRu+XIzmz3xnxMqqp9GGpJSUFBQXF8PNzU1nupubGxISEvQuo1aroVartd+rVCoAQGamcVNudnY2ACD21jWo83INXl9i9B0AQELUTdyxsTap9bE201gfazON9bE201gfazON9WXERiI/8jw06lyjf86Wrk8IUXFD0Ujdv39fABAnT57Umb548WLRpk0bvcssXLhQAOCLL7744osvvh6DV0xMTIVZodGeSXJ2doZcLi9z1igpKanM2aVS8+fPx+zZs7XfazQapKWlwcnJCZJkvLEfMjMz4e3tjZiYGNjZ2RltvVQWj3Xd4HGuGzzOdYPHue7U1rEWQiArKwuenp4Vtmu0IcnCwgLdunXD/v378cwzz2in79+/H6NHj9a7jEKhgEKh+6A/e3v7WqvRzs6Ov4B1hMe6bvA41w0e57rB41x3auNYK5XKSts02pAEALNnz8akSZMQGBiIoKAg/N///R+io6Pxxhtv1HdpREREVM8adUgaP348UlNT8dFHHyE+Ph4BAQHYs2cPfHx86rs0IiIiqmeNOiQBwJtvvok333yzvsvQoVAosHDhwjKX9sj4eKzrBo9z3eBxrhs8znWnvo+1JERl978RERERNT6y+i6AiIiIyBQxJBERERHpwZBEREREpAdDEhEREZEeDEn1ZPXq1fD19YWlpSW6deuGY8eOVdj+yJEj6NatGywtLdGiRQt8++23dVRpw1ad47xz50488cQTcHFxgZ2dHYKCgvDXX3/VYbUNW3Xf06VOnDgBMzMzdO7cuXYLfExU9zir1WosWLAAPj4+UCgUaNmyJb7//vs6qrbhqu5x3rx5Mzp16gRra2t4eHjglVdeQWpqah1V2zAdPXoUI0eOhKenJyRJwq5duypdps4/C43zJDSqjm3btglzc3OxZs0acf36dfH2228LGxsbce/ePb3t7969K6ytrcXbb78trl+/LtasWSPMzc3FTz/9VMeVNyzVPc5vv/22WLp0qQgNDRU3b94U8+fPF+bm5uL8+fN1XHnDU91jXSojI0O0aNFCDB06VHTq1Kluim3AanKcR40aJXr27Cn2798vIiMjxZkzZ8SJEyfqsOqGp7rH+dixY0Imk4kvv/xS3L17Vxw7dky0b99ejBkzpo4rb1j27NkjFixYIH7++WcBQPzyyy8Vtq+Pz0KGpHrQo0cP8cYbb+hMa9u2rXj//ff1tp83b55o27atzrTXX39d9OrVq9ZqfBxU9zjr065dO7Fo0SJjl/bYqemxHj9+vPj3v/8tFi5cyJBUBdU9zn/++adQKpUiNTW1Lsp7bFT3OH/66aeiRYsWOtO++uor4eXlVWs1Pm6qEpLq47OQl9vqWEFBAcLCwjB06FCd6UOHDsXJkyf1LnPq1Kky7YcNG4Zz586hsLCw1mptyGpynB+l0WiQlZUFR0fH2ijxsVHTY71u3TrcuXMHCxcurO0SHws1Oc67d+9GYGAgli1bhqZNm6J169aYO3cu8vLy6qLkBqkmx7l3796IjY3Fnj17IIRAYmIifvrpJzz99NN1UXKjUR+fhY1+xO26lpKSguLiYri5uelMd3NzQ0JCgt5lEhIS9LYvKipCSkoKPDw8aq3ehqomx/lRn3/+OXJycjBu3LjaKPGxUZNjfevWLbz//vs4duwYzMz4Z6gqanKc7969i+PHj8PS0hK//PILUlJS8OabbyItLY39kspRk+Pcu3dvbN68GePHj0d+fj6KioowatQorFy5si5KbjTq47OQZ5LqiSRJOt8LIcpMq6y9vumkq7rHudTWrVsREhKC7du3w9XVtbbKe6xU9VgXFxdj4sSJWLRoEVq3bl1X5T02qvOe1mg0kCQJmzdvRo8ePfDUU09h+fLlWL9+Pc8mVaI6x/n69euYOXMmPvzwQ4SFhWHv3r2IjIzkw9JrQV1/FvK/cHXM2dkZcrm8zP9IkpKSyiTkUu7u7nrbm5mZwcnJqdZqbchqcpxLbd++HVOnTsWOHTswZMiQ2izzsVDdY52VlYVz587hwoULmD59OoCSD3MhBMzMzLBv3z4MGjSoTmpvSGrynvbw8EDTpk2hVCq10/z9/SGEQGxsLPz8/Gq15oaoJsd5yZIl6NOnD959910AQMeOHWFjY4N+/fph8eLFPNtvJPXxWcgzSXXMwsIC3bp1w/79+3Wm79+/H71799a7TFBQUJn2+/btQ2BgIMzNzWut1oasJscZKDmDNGXKFGzZsoX9Caqousfazs4OV65cwcWLF7WvN954A23atMHFixfRs2fPuiq9QanJe7pPnz6Ii4tDdna2dtrNmzchk8ng5eVVq/U2VDU5zrm5uZDJdD9O5XI5gP+d6SDD1ctnYa11Cadyld5eunbtWnH9+nUxa9YsYWNjI6KiooQQQrz//vti0qRJ2valtz2+88474vr162Lt2rUcAqAKqnuct2zZIszMzMTXX38t4uPjta+MjIz62oUGo7rH+lG8u61qqnucs7KyhJeXl3juuefEtWvXxJEjR4Sfn5949dVX62sXGoTqHud169YJMzMzsXr1anHnzh1x/PhxERgYKHr06FFfu9AgZGVliQsXLogLFy4IAGL58uXiwoUL2qEWTOGzkCGpnnz99dfCx8dHWFhYiK5du4ojR45o502ePFkEBwfrtD98+LDo0qWLsLCwEM2bNxfffPNNHVfcMFXnOAcHBwsAZV6TJ0+u+8IboOq+px/GkFR11T3O4eHhYsiQIcLKykp4eXmJ2bNni9zc3DquuuGp7nH+6quvRLt27YSVlZXw8PAQL774ooiNja3jqhuWQ4cOVfg31xQ+CyUheC6QiIiI6FHsk0RERESkB0MSERERkR4MSURERER6MCQRERER6cGQRERERKQHQxIRERGRHgxJRERERHowJBGRyTl8+DAkSUJISIjO9AEDBpR5kGV5beuLJEkYMGBAfZdhsvT9DIlMFUMSkYl6+eWXIUkS3N3dUVRUVN/l6LV+/fpKA0p5bRpqmGjIH/KlP4uHX1ZWVmjdujVmzJhR5uGhNRESEgJJknD48GHDCyaqZ2b1XQARlZWZmYmff/4ZkiQhMTERf/zxB0aPHl3fZdWZHj16IDw8HM7OzkZtWxfCw8NhbW1d32VUaPDgwejbty8AICUlBQcPHsSqVauwa9cunD9/Hi4uLrW27Q0bNiA3N7fW1k9kTAxJRCZo69atyM3Nxdy5c/H5559j7dq1jSokWVtbo23btkZvWxdMqZbyDBkyBO+//772e41Gg5EjR2LPnj1YtWoVFi1aVGvbbtasWa2tm8jYeLmNyAStXbsWFhYWmD9/Pvr06YM9e/YgPj4eAHDv3j3IZDIMHjxY77L5+flQKpVo1aqVzvSoqCiMHz8ejo6OaNKkCYKDg3H06NE6vzxS2ocIAI4cOaJz6Wf9+vU6barSz0hf29J9Ku/18GW+mzdvYt68eejatSucnJxgaWmJ1q1b4/3330d2drbOtiRJwpEjR7Rfl76mTJmi00bfZcTU1FS888478PX1hUKhgKurK8aPH4/r16+XaTtlyhRIkoSoqCisXr0a/v7+sLS0hI+PDxYtWgSNRlPpcakOmUym3YewsDCdeSqVCkuXLkVwcDA8PT1hYWEBT09PvPzyy7hz545O2wEDBmgD1sCBA7XHp3nz5jpt9F2uLCoqwooVK9CpUydYWVlBqVRi4MCB+OOPP4y6r0TVwTNJRCbmypUrOHv2LJ555hk4Ojri5ZdfxvHjx/HDDz/g/fffh4+PD/r164fDhw/j/v37aNq0qc7yv/76KzIzM/HOO+9op92/fx+9e/dGfHw8nnrqKXTq1AkREREYOnQoBg4cWKf717x5cyxcuBCLFi2Cj4+PTsDo3LmzUbZRXl+ns2fPYs+ePTqXw3bu3Im1a9di4MCBGDBgADQaDU6fPo2lS5fiyJEjOHr0KMzNzQEACxcuxPr163Hv3j0sXLiwynWnpqaiV69euH37NgYMGIAJEyYgKioKP/30E/744w/s378fQUFBZZZ79913cfjwYYwYMQJDhw7Frl27EBISgoKCAnz88cfVPzAVKH3WuZmZ7sdCeHg4PvzwQwwcOBDPPPMMbGxscOPGDWzZsgV//PEHzp8/Dx8fHwDQ/iyPHDmCyZMna8ORvb19pdseP348du7cidatW+Ott95CTk4OfvzxR4wYMQJffvklZs6cadT9JaoSQUQm5e233xYAxM6dO4UQQmRkZAhLS0vh5+enbbNmzRoBQCxbtqzM8iNGjBAAxK1bt7TTXnrpJQFAfPrppzpt161bJwAIAOLQoUPVrrV0+YULF1a7DQARHBysd5lDhw7pXSY4OFg8+mervLaPioyMFC4uLsLBwUFERERop8fGxgq1Wl2m/aJFiwQAsWnTpkprqGy//vGPfwgAYv78+TrT9+7dKwAIPz8/UVxcrJ0+efJkAUD4+vqKuLg47fTk5GRhb28vbG1t9dZcmdKfxZIlS3SmFxUViWHDhul9j2RkZIjU1NQy6zp48KCQyWTi1Vdf1Zm+cOHCCt9P+o7fhg0btMft4f2KiYkRrq6uwtzcXNy9e7c6u0pkFLzcRmRCCgoKsGnTJjg4OODpp58GACiVSowePRq3bt3C0aNHAQDPP/88FAoFNm3apLN8SkoK/vrrL/Tq1Ut7uU2tVmPHjh1wc3Mr87/xyZMnN4g+NIbKzMzEiBEjkJ6ejh07dqB169baeU2bNoWFhUWZZaZPnw4AOHDggEHbLigowNatW+Hk5IR///vfOvOGDRuGYcOG4datWzh58mSZZT/44AN4eHhov3d2dsbo0aORlZWFiIiIGtd04MABhISEICQkBDNmzED79u2175t//vOfOm2VSiUcHR3LrGPgwIFo3769wccHgPYy67Jly3R+Fl5eXnjnnXdQWFiIzZs3G7wdoupiSCIyIbt27UJqairGjx+v82Hx8ssvAwC+//57ACUfXCNHjsTly5dx5coVbbtt27ahsLAQkyZN0k6LiIiAWq1GYGBgmTAgSZLeyzyPk+LiYrzwwgu4du0aVq5cWaYvlxAC33//Pfr37w9HR0fI5XJIkgQnJycAQFxcnEHbv3HjBvLy8tCjRw+9d72VXhq8ePFimXldu3YtM83LywsAkJGRUeOa/v77byxatAiLFi3CqlWrEBERgaCgIBw6dAg2NjZl2h8+fBhjxoyBh4cHzM3NtX2Nrly5YvDxAYALFy7AysoKPXr0KDOvouNDVNsYkohMSGkIejjkACVnHNzd3bFjxw5kZmbqtHn4f9ibNm2Cubk5xo8fr51W2r6827rd3NxqXK9MVvInpKKOxKXzStvWtTlz5mDPnj2YOXMm3njjjTLzZ86cialTpyIqKgqjRo3CvHnzsHDhQm2fI7VabdD2S49/ecfZ3d0dQEkH6Ucplcoy00r7DBUXF9e4piVLlkAIgeLiYty5cweTJk3CqVOnMG3atDJtd+zYgUGDBuHgwYPo27cvZs2ahQ8//BALFy6Ej48PCgoKalxHqczMzBodH6Laxo7bRCYiJiYG+/fvBwD06dOn3Hbbtm3Da6+9huHDh8PZ2RlbtmzBkiVLcOfOHZw5cwajR4/WngUBADs7OwBAcnKy3vUlJibWuObSD/HU1NRy26SkpOi0rUvfffcdvvzySwwbNgzLly8vMz8pKQlff/01OnbsiFOnTumc6UlISDDKrfClx7+841w6vbRdXZLJZGjRogV++OEH3Lt3D5s2bcLYsWMxZswYbZuQkBBYWloiLCwMfn5+Ostv27bNKHXY2dmZ5PEhYkgiMhHr1q2DRqNB37590aZNmzLzCwoKsHHjRqxduxavvfYazM3NMW7cOKxevRpHjhzR3sL/0ksv6SzXpk0bKBQKhIWFoaCgQOeSmxACp0+frnHNHTp0AACcOnWq3Dal8zp27KgzXSaTGXQ2pDIHDx7E9OnT0a5dO2zfvh1yubxMm7t370IIgSFDhpS5FHbs2DG96y1dT3Fxsd51Pqpt27awtLTE2bNnkZubW2Y7pUMKGOvOvpqQJAlffvklunbtivnz52PkyJHafbtz5w7at29fJiDFxcWVGQIA0D0+VdWlSxccPHgQoaGhZS65mcLxocaLl9uITIAQAuvWrYMkSdiwYQP++9//lnlt2LABXbp0QWhoKK5evQrgf5fcNm3ahM2bN8Pe3h4jR47UWbdCocBzzz2HhIQEfPXVVzrzNmzYgPDw8BrX3aJFC/Tt2xcXLlzQdr592IEDB/Dbb7+hefPm6Nevn848R0dHxMbG1njbFbl58yaee+45KJVK/Pbbb+WexSq9df3kyZM6lwxjY2N1Blt8WGkn5qrWbmFhgRdeeAEpKSlYsmSJzrwDBw7gzz//RKtWrSo8e1gXOnfujDFjxmhv7y/l4+OD27dv65zpyc/Pxz//+U+9j8up7vEBSm4gAID58+ejsLBQO/3+/ftYvnw5zMzM8OKLL1Z7n4gMxTNJRCbg77//RlRUFAYOHAhfX99y273yyiu4cOEC1q5dixUrVqBXr17w8/PDhg0bUFhYiGnTpkGhUJRZbsmSJThw4ADeffddHDp0CJ07d0ZERAR+//13PPnkk9i7d2+N+wz997//Rf/+/fHKK69g/fr16NGjB+RyOS5fvoy9e/fC2toaGzduLDP+zqBBg/Djjz/iueeeQ5cuXSCXy/H0009rz04ZYtasWUhPT8fw4cOxYcOGMvObN2+OKVOmwMPDA2PHjsXPP/+MwMBADB48GImJifj9998xaNAg3L17t8yygwYNwk8//YTnn38eTz31FCwtLdGhQwft3Yj6lI65tHjxYpw8eRI9e/bUjpNkbW2NdevW1VufrYeFhIRg165d+Oijj/DCCy/AzMwMM2bMwIwZM9ClSxc899xzKCoqwv79+yGEQKdOnXDp0iWddZQOIrlgwQLcuHEDSqUSSqWyzF1zD5s0aRJ27tyJX3/9FR07dsSIESO04ySlpqbi888/R4sWLWp794nKqs/xB4ioxIQJEwQAsXHjxgrbpaSkCAsLC+Hs7KwdT6Z0PB8A4siRI+Uue/fuXfH8888LpVIprK2tRb9+/cSRI0fE9OnTBQBx4cKFGtcfFxcnZs+eLdq2bSusrKyEQqEQLVq0EK+99prOeE0Pi4+PF+PGjRPOzs5CJpMJAGLdunVCCMPHSSptV97r4XGMsrKyxJw5c0Tz5s2FQqEQfn5+4j//+Y8oKCjQO+ZRYWGhmDdvnmjWrJkwMzMTAMTkyZO18/UtI0TJGEczZ84UPj4+wtzcXDg7O4vnnntOXLlypUzb0nGSIiMjy8yrbByiipQ3TtLDxo4dKwCItWvXCiGE0Gg04ttvvxXt27cXlpaWwt3dXUydOlUkJiaWO2bU+vXrRYcOHYRCoRAAhI+Pj3ZeecsUFhaKzz77TLucra2tCA4OFr/++mu195PIWCQhHgyzSkSNUt++fXHq1CmoVCo0adKkvsshIjIZ9X9+l4jqROmz3x62efNmnDhxAkOGDGFAIiJ6BM8kETUSTk5O6NKlC9q1awe5XI6LFy/i8OHDsLW1xYkTJ4zSF4iI6HHCkETUSCxYsAC//fYboqOjkZOTAxcXFwwcOBAffPCB9tEkGRkZ+OKLL6q0vpCQkNorlqokKipK712Fj7K3t8esWbNqvR6ixw1DEhFpRUVFVXh33cP4p6P+HT58GAMHDqy0nY+PD6Kiomq/IKLHDEMSERERkR7suE1ERESkB0MSERERkR4MSURERER6MCQRERER6cGQRERERKQHQxIRERGRHgxJRERERHowJBERERHpwZBEREREpMf/B7nfYNjUxec7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column_name in data_raw.columns:\n",
    "    # Plotting the distribution\n",
    "    sns.histplot(df[column_name], kde=True)\n",
    "    plt.title(f'Distribution of {column_name}', fontsize=16)\n",
    "    plt.xlabel(column_name, fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   Attrition_Flag            10127 non-null  category\n",
      " 1   Customer_Age              10127 non-null  int64   \n",
      " 2   Gender                    10127 non-null  category\n",
      " 3   Dependent_count           10127 non-null  int64   \n",
      " 4   Education_Level           10127 non-null  category\n",
      " 5   Marital_Status            10127 non-null  category\n",
      " 6   Income_Category           10127 non-null  category\n",
      " 7   Card_Category             10127 non-null  category\n",
      " 8   Months_on_book            10127 non-null  int64   \n",
      " 9   Total_Relationship_Count  10127 non-null  int64   \n",
      " 10  Months_Inactive_12_mon    10127 non-null  int64   \n",
      " 11  Contacts_Count_12_mon     10127 non-null  int64   \n",
      " 12  Credit_Limit              10127 non-null  float64 \n",
      " 13  Total_Revolving_Bal       10127 non-null  int64   \n",
      " 14  Avg_Open_To_Buy           10127 non-null  float64 \n",
      " 15  Total_Amt_Chng_Q4_Q1      10127 non-null  float64 \n",
      " 16  Total_Trans_Amt           10127 non-null  int64   \n",
      " 17  Total_Trans_Ct            10127 non-null  int64   \n",
      " 18  Total_Ct_Chng_Q4_Q1       10127 non-null  float64 \n",
      " 19  Avg_Utilization_Ratio     10127 non-null  float64 \n",
      "dtypes: category(6), float64(5), int64(9)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "# convert bool and object to category \n",
    "cat_types = ['bool','object','category']\n",
    "data_clean = data_raw.copy()\n",
    "data_clean[data_clean.select_dtypes(cat_types).columns] = data_clean.select_dtypes(cat_types).apply(lambda x: x.astype('category'))\n",
    "data_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]\n",
       "Categories (2, int64): [1, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_clean.drop('Attrition_Flag',errors='ignore',axis=1)\n",
    "codes = {'Existing Customer':0, 'Attrited Customer':1}\n",
    "data_clean['Attrition_Flag'] = data_clean['Attrition_Flag'].map(codes)\n",
    "y = data_clean.Attrition_Flag\n",
    "y.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: ['F', 'M']\n",
      "Education_Level: ['College', 'Doctorate', 'Graduate', 'High School', 'Post-Graduate', 'Uneducated', 'Unknown']\n",
      "Marital_Status: ['Divorced', 'Married', 'Single', 'Unknown']\n",
      "Income_Category: ['$120K +', '$40K - $60K', '$60K - $80K', '$80K - $120K', 'Less than $40K', 'Unknown']\n",
      "Card_Category: ['Blue', 'Gold', 'Platinum', 'Silver']\n"
     ]
    }
   ],
   "source": [
    "for col in X.select_dtypes('category').columns:\n",
    "    print(col + ': '+ str(X[col].cat.categories.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Attrition_Flag\n",
       " 0    6799\n",
       " 1    1302\n",
       " Name: count, dtype: int64,\n",
       " Attrition_Flag\n",
       " 0    1701\n",
       " 1     325\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle= True,stratify = y)\n",
    "y_train.value_counts(), y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8101 entries, 2856 to 7469\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   Customer_Age              8101 non-null   int64   \n",
      " 1   Gender                    8101 non-null   category\n",
      " 2   Dependent_count           8101 non-null   int64   \n",
      " 3   Education_Level           8101 non-null   category\n",
      " 4   Marital_Status            8101 non-null   category\n",
      " 5   Income_Category           8101 non-null   category\n",
      " 6   Card_Category             8101 non-null   category\n",
      " 7   Months_on_book            8101 non-null   int64   \n",
      " 8   Total_Relationship_Count  8101 non-null   int64   \n",
      " 9   Months_Inactive_12_mon    8101 non-null   int64   \n",
      " 10  Contacts_Count_12_mon     8101 non-null   int64   \n",
      " 11  Credit_Limit              8101 non-null   float64 \n",
      " 12  Total_Revolving_Bal       8101 non-null   int64   \n",
      " 13  Avg_Open_To_Buy           8101 non-null   float64 \n",
      " 14  Total_Amt_Chng_Q4_Q1      8101 non-null   float64 \n",
      " 15  Total_Trans_Amt           8101 non-null   int64   \n",
      " 16  Total_Trans_Ct            8101 non-null   int64   \n",
      " 17  Total_Ct_Chng_Q4_Q1       8101 non-null   float64 \n",
      " 18  Avg_Utilization_Ratio     8101 non-null   float64 \n",
      "dtypes: category(5), float64(5), int64(9)\n",
      "memory usage: 990.0 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting all column names with category dtype\n",
    "categorical_features = X_train.select_dtypes(include='category').columns\n",
    "\n",
    "# Getting the indices of these categorical columns\n",
    "categorical_indices = [X_train.columns.get_loc(col) for col in categorical_features]\n",
    "categorical_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "0:\tlearn: 0.6861380\ttotal: 61.9ms\tremaining: 3.03s\n",
      "1:\tlearn: 0.6792884\ttotal: 64.1ms\tremaining: 1.54s\n",
      "2:\tlearn: 0.6727760\ttotal: 66ms\tremaining: 1.03s\n",
      "3:\tlearn: 0.6663671\ttotal: 69ms\tremaining: 793ms\n",
      "4:\tlearn: 0.6603005\ttotal: 71.4ms\tremaining: 643ms\n",
      "5:\tlearn: 0.6544924\ttotal: 73.6ms\tremaining: 540ms\n",
      "6:\tlearn: 0.6488410\ttotal: 76.4ms\tremaining: 469ms\n",
      "7:\tlearn: 0.6432103\ttotal: 79ms\tremaining: 415ms\n",
      "8:\tlearn: 0.6373483\ttotal: 81.1ms\tremaining: 369ms\n",
      "9:\tlearn: 0.6314694\ttotal: 83.2ms\tremaining: 333ms\n",
      "10:\tlearn: 0.6259912\ttotal: 85.8ms\tremaining: 304ms\n",
      "11:\tlearn: 0.6207071\ttotal: 88.8ms\tremaining: 281ms\n",
      "12:\tlearn: 0.6156564\ttotal: 90.7ms\tremaining: 258ms\n",
      "13:\tlearn: 0.6104164\ttotal: 93.1ms\tremaining: 240ms\n",
      "14:\tlearn: 0.6052768\ttotal: 95.3ms\tremaining: 222ms\n",
      "15:\tlearn: 0.5998796\ttotal: 97.1ms\tremaining: 206ms\n",
      "16:\tlearn: 0.5946755\ttotal: 99.1ms\tremaining: 192ms\n",
      "17:\tlearn: 0.5897853\ttotal: 101ms\tremaining: 179ms\n",
      "18:\tlearn: 0.5850445\ttotal: 103ms\tremaining: 167ms\n",
      "19:\tlearn: 0.5801199\ttotal: 105ms\tremaining: 157ms\n",
      "20:\tlearn: 0.5754610\ttotal: 107ms\tremaining: 148ms\n",
      "21:\tlearn: 0.5707026\ttotal: 109ms\tremaining: 138ms\n",
      "22:\tlearn: 0.5663601\ttotal: 110ms\tremaining: 129ms\n",
      "23:\tlearn: 0.5620907\ttotal: 111ms\tremaining: 121ms\n",
      "24:\tlearn: 0.5574051\ttotal: 112ms\tremaining: 112ms\n",
      "25:\tlearn: 0.5530084\ttotal: 114ms\tremaining: 105ms\n",
      "26:\tlearn: 0.5486653\ttotal: 115ms\tremaining: 98.1ms\n",
      "27:\tlearn: 0.5444238\ttotal: 116ms\tremaining: 91.2ms\n",
      "28:\tlearn: 0.5402682\ttotal: 117ms\tremaining: 84.8ms\n",
      "29:\tlearn: 0.5361486\ttotal: 118ms\tremaining: 78.7ms\n",
      "30:\tlearn: 0.5320445\ttotal: 119ms\tremaining: 73ms\n",
      "31:\tlearn: 0.5280222\ttotal: 120ms\tremaining: 67.5ms\n",
      "32:\tlearn: 0.5241568\ttotal: 121ms\tremaining: 62.3ms\n",
      "33:\tlearn: 0.5204760\ttotal: 122ms\tremaining: 57.4ms\n",
      "34:\tlearn: 0.5167722\ttotal: 123ms\tremaining: 52.7ms\n",
      "35:\tlearn: 0.5130075\ttotal: 124ms\tremaining: 48.2ms\n",
      "36:\tlearn: 0.5092117\ttotal: 125ms\tremaining: 43.9ms\n",
      "37:\tlearn: 0.5057481\ttotal: 126ms\tremaining: 39.7ms\n",
      "38:\tlearn: 0.5022402\ttotal: 127ms\tremaining: 35.8ms\n",
      "39:\tlearn: 0.4986059\ttotal: 128ms\tremaining: 32ms\n",
      "40:\tlearn: 0.4949176\ttotal: 129ms\tremaining: 28.3ms\n",
      "41:\tlearn: 0.4914229\ttotal: 130ms\tremaining: 24.7ms\n",
      "42:\tlearn: 0.4880900\ttotal: 131ms\tremaining: 21.3ms\n",
      "43:\tlearn: 0.4846531\ttotal: 132ms\tremaining: 18ms\n",
      "44:\tlearn: 0.4814013\ttotal: 133ms\tremaining: 14.8ms\n",
      "45:\tlearn: 0.4779849\ttotal: 135ms\tremaining: 11.7ms\n",
      "46:\tlearn: 0.4749921\ttotal: 136ms\tremaining: 8.66ms\n",
      "47:\tlearn: 0.4720740\ttotal: 137ms\tremaining: 5.7ms\n",
      "48:\tlearn: 0.4689798\ttotal: 138ms\tremaining: 2.81ms\n",
      "49:\tlearn: 0.4659974\ttotal: 139ms\tremaining: 0us\n",
      "0:\tlearn: 0.6865315\ttotal: 1.08ms\tremaining: 53.1ms\n",
      "1:\tlearn: 0.6799610\ttotal: 2.17ms\tremaining: 52.1ms\n",
      "2:\tlearn: 0.6738172\ttotal: 3.25ms\tremaining: 51ms\n",
      "3:\tlearn: 0.6672677\ttotal: 4.2ms\tremaining: 48.3ms\n",
      "4:\tlearn: 0.6612721\ttotal: 5.22ms\tremaining: 47ms\n",
      "5:\tlearn: 0.6555663\ttotal: 6.17ms\tremaining: 45.2ms\n",
      "6:\tlearn: 0.6496321\ttotal: 7.01ms\tremaining: 43.1ms\n",
      "7:\tlearn: 0.6434927\ttotal: 7.85ms\tremaining: 41.2ms\n",
      "8:\tlearn: 0.6376305\ttotal: 8.85ms\tremaining: 40.3ms\n",
      "9:\tlearn: 0.6322127\ttotal: 9.89ms\tremaining: 39.6ms\n",
      "10:\tlearn: 0.6267621\ttotal: 10.8ms\tremaining: 38.4ms\n",
      "11:\tlearn: 0.6216421\ttotal: 11.8ms\tremaining: 37.3ms\n",
      "12:\tlearn: 0.6166142\ttotal: 12.8ms\tremaining: 36.3ms\n",
      "13:\tlearn: 0.6114660\ttotal: 14ms\tremaining: 36ms\n",
      "14:\tlearn: 0.6063442\ttotal: 15ms\tremaining: 35ms\n",
      "15:\tlearn: 0.6008706\ttotal: 16ms\tremaining: 34.1ms\n",
      "16:\tlearn: 0.5956678\ttotal: 17.3ms\tremaining: 33.7ms\n",
      "17:\tlearn: 0.5908301\ttotal: 18.4ms\tremaining: 32.6ms\n",
      "18:\tlearn: 0.5861000\ttotal: 19.2ms\tremaining: 31.3ms\n",
      "19:\tlearn: 0.5812165\ttotal: 20ms\tremaining: 30ms\n",
      "20:\tlearn: 0.5765116\ttotal: 21ms\tremaining: 29ms\n",
      "21:\tlearn: 0.5720435\ttotal: 22ms\tremaining: 28ms\n",
      "22:\tlearn: 0.5677669\ttotal: 22.9ms\tremaining: 26.9ms\n",
      "23:\tlearn: 0.5632639\ttotal: 23.8ms\tremaining: 25.8ms\n",
      "24:\tlearn: 0.5587314\ttotal: 24.7ms\tremaining: 24.7ms\n",
      "25:\tlearn: 0.5543994\ttotal: 25.6ms\tremaining: 23.6ms\n",
      "26:\tlearn: 0.5499368\ttotal: 26.6ms\tremaining: 22.7ms\n",
      "27:\tlearn: 0.5457275\ttotal: 27.7ms\tremaining: 21.8ms\n",
      "28:\tlearn: 0.5415294\ttotal: 28.9ms\tremaining: 20.9ms\n",
      "29:\tlearn: 0.5373813\ttotal: 29.8ms\tremaining: 19.9ms\n",
      "30:\tlearn: 0.5335033\ttotal: 31.1ms\tremaining: 19ms\n",
      "31:\tlearn: 0.5295433\ttotal: 32.2ms\tremaining: 18.1ms\n",
      "32:\tlearn: 0.5256856\ttotal: 33.3ms\tremaining: 17.2ms\n",
      "33:\tlearn: 0.5221165\ttotal: 34.5ms\tremaining: 16.2ms\n",
      "34:\tlearn: 0.5184291\ttotal: 35.5ms\tremaining: 15.2ms\n",
      "35:\tlearn: 0.5147284\ttotal: 36.4ms\tremaining: 14.2ms\n",
      "36:\tlearn: 0.5109685\ttotal: 37.4ms\tremaining: 13.2ms\n",
      "37:\tlearn: 0.5074868\ttotal: 38.4ms\tremaining: 12.1ms\n",
      "38:\tlearn: 0.5038808\ttotal: 40.1ms\tremaining: 11.3ms\n",
      "39:\tlearn: 0.5004452\ttotal: 41.1ms\tremaining: 10.3ms\n",
      "40:\tlearn: 0.4967613\ttotal: 42.2ms\tremaining: 9.27ms\n",
      "41:\tlearn: 0.4932233\ttotal: 43.3ms\tremaining: 8.25ms\n",
      "42:\tlearn: 0.4898901\ttotal: 45.2ms\tremaining: 7.35ms\n",
      "43:\tlearn: 0.4864308\ttotal: 46.4ms\tremaining: 6.33ms\n",
      "44:\tlearn: 0.4830251\ttotal: 47.6ms\tremaining: 5.28ms\n",
      "45:\tlearn: 0.4796551\ttotal: 48.7ms\tremaining: 4.24ms\n",
      "46:\tlearn: 0.4766093\ttotal: 49.9ms\tremaining: 3.18ms\n",
      "47:\tlearn: 0.4733253\ttotal: 50.9ms\tremaining: 2.12ms\n",
      "48:\tlearn: 0.4706770\ttotal: 52.4ms\tremaining: 1.07ms\n",
      "49:\tlearn: 0.4674899\ttotal: 53.4ms\tremaining: 0us\n",
      "0:\tlearn: 0.6866330\ttotal: 1.06ms\tremaining: 51.8ms\n",
      "1:\tlearn: 0.6798802\ttotal: 1.94ms\tremaining: 46.5ms\n",
      "2:\tlearn: 0.6737146\ttotal: 2.98ms\tremaining: 46.8ms\n",
      "3:\tlearn: 0.6671319\ttotal: 3.85ms\tremaining: 44.3ms\n",
      "4:\tlearn: 0.6611352\ttotal: 4.79ms\tremaining: 43.1ms\n",
      "5:\tlearn: 0.6554174\ttotal: 5.57ms\tremaining: 40.8ms\n",
      "6:\tlearn: 0.6494356\ttotal: 6.57ms\tremaining: 40.3ms\n",
      "7:\tlearn: 0.6437560\ttotal: 7.6ms\tremaining: 39.9ms\n",
      "8:\tlearn: 0.6379567\ttotal: 8.46ms\tremaining: 38.6ms\n",
      "9:\tlearn: 0.6322825\ttotal: 9.37ms\tremaining: 37.5ms\n",
      "10:\tlearn: 0.6267912\ttotal: 10.3ms\tremaining: 36.6ms\n",
      "11:\tlearn: 0.6213273\ttotal: 11.8ms\tremaining: 37.5ms\n",
      "12:\tlearn: 0.6162597\ttotal: 12.7ms\tremaining: 36.3ms\n",
      "13:\tlearn: 0.6110739\ttotal: 13.8ms\tremaining: 35.4ms\n",
      "14:\tlearn: 0.6059571\ttotal: 14.7ms\tremaining: 34.3ms\n",
      "15:\tlearn: 0.6004762\ttotal: 15.7ms\tremaining: 33.4ms\n",
      "16:\tlearn: 0.5952509\ttotal: 16.8ms\tremaining: 32.6ms\n",
      "17:\tlearn: 0.5904167\ttotal: 17.7ms\tremaining: 31.4ms\n",
      "18:\tlearn: 0.5857239\ttotal: 18.8ms\tremaining: 30.6ms\n",
      "19:\tlearn: 0.5808816\ttotal: 19.7ms\tremaining: 29.6ms\n",
      "20:\tlearn: 0.5762201\ttotal: 20.6ms\tremaining: 28.5ms\n",
      "21:\tlearn: 0.5715897\ttotal: 21.8ms\tremaining: 27.8ms\n",
      "22:\tlearn: 0.5671136\ttotal: 22.7ms\tremaining: 26.6ms\n",
      "23:\tlearn: 0.5626259\ttotal: 23.7ms\tremaining: 25.7ms\n",
      "24:\tlearn: 0.5579129\ttotal: 24.7ms\tremaining: 24.7ms\n",
      "25:\tlearn: 0.5535229\ttotal: 25.8ms\tremaining: 23.8ms\n",
      "26:\tlearn: 0.5489995\ttotal: 26.9ms\tremaining: 22.9ms\n",
      "27:\tlearn: 0.5450002\ttotal: 27.9ms\tremaining: 21.9ms\n",
      "28:\tlearn: 0.5407901\ttotal: 28.8ms\tremaining: 20.9ms\n",
      "29:\tlearn: 0.5364760\ttotal: 29.8ms\tremaining: 19.9ms\n",
      "30:\tlearn: 0.5325882\ttotal: 30.8ms\tremaining: 18.9ms\n",
      "31:\tlearn: 0.5285169\ttotal: 31.8ms\tremaining: 17.9ms\n",
      "32:\tlearn: 0.5246476\ttotal: 32.7ms\tremaining: 16.9ms\n",
      "33:\tlearn: 0.5206732\ttotal: 34.8ms\tremaining: 16.4ms\n",
      "34:\tlearn: 0.5169921\ttotal: 35.8ms\tremaining: 15.3ms\n",
      "35:\tlearn: 0.5132683\ttotal: 36.9ms\tremaining: 14.3ms\n",
      "36:\tlearn: 0.5094261\ttotal: 37.9ms\tremaining: 13.3ms\n",
      "37:\tlearn: 0.5057340\ttotal: 39ms\tremaining: 12.3ms\n",
      "38:\tlearn: 0.5021458\ttotal: 40ms\tremaining: 11.3ms\n",
      "39:\tlearn: 0.4985493\ttotal: 41.8ms\tremaining: 10.4ms\n",
      "40:\tlearn: 0.4948400\ttotal: 42.8ms\tremaining: 9.4ms\n",
      "41:\tlearn: 0.4912323\ttotal: 43.9ms\tremaining: 8.36ms\n",
      "42:\tlearn: 0.4878729\ttotal: 44.9ms\tremaining: 7.3ms\n",
      "43:\tlearn: 0.4845817\ttotal: 45.9ms\tremaining: 6.26ms\n",
      "44:\tlearn: 0.4812404\ttotal: 47ms\tremaining: 5.22ms\n",
      "45:\tlearn: 0.4778412\ttotal: 48ms\tremaining: 4.17ms\n",
      "46:\tlearn: 0.4745562\ttotal: 49.1ms\tremaining: 3.14ms\n",
      "47:\tlearn: 0.4717190\ttotal: 50.3ms\tremaining: 2.1ms\n",
      "48:\tlearn: 0.4685525\ttotal: 51.3ms\tremaining: 1.05ms\n",
      "49:\tlearn: 0.4656348\ttotal: 52.5ms\tremaining: 0us\n",
      "0:\tlearn: 0.6587869\ttotal: 1.55ms\tremaining: 75.9ms\n",
      "1:\tlearn: 0.6277024\ttotal: 2.61ms\tremaining: 62.7ms\n",
      "2:\tlearn: 0.6002804\ttotal: 3.51ms\tremaining: 55ms\n",
      "3:\tlearn: 0.5744365\ttotal: 4.64ms\tremaining: 53.4ms\n",
      "4:\tlearn: 0.5543254\ttotal: 5.47ms\tremaining: 49.2ms\n",
      "5:\tlearn: 0.5342259\ttotal: 7.15ms\tremaining: 52.4ms\n",
      "6:\tlearn: 0.5143736\ttotal: 8.05ms\tremaining: 49.5ms\n",
      "7:\tlearn: 0.4970632\ttotal: 9ms\tremaining: 47.2ms\n",
      "8:\tlearn: 0.4798956\ttotal: 9.87ms\tremaining: 45ms\n",
      "9:\tlearn: 0.4640039\ttotal: 10.9ms\tremaining: 43.8ms\n",
      "10:\tlearn: 0.4492816\ttotal: 12ms\tremaining: 42.5ms\n",
      "11:\tlearn: 0.4357062\ttotal: 13ms\tremaining: 41.1ms\n",
      "12:\tlearn: 0.4224677\ttotal: 14ms\tremaining: 39.9ms\n",
      "13:\tlearn: 0.4104241\ttotal: 15ms\tremaining: 38.7ms\n",
      "14:\tlearn: 0.3985346\ttotal: 16.1ms\tremaining: 37.5ms\n",
      "15:\tlearn: 0.3871813\ttotal: 17.1ms\tremaining: 36.3ms\n",
      "16:\tlearn: 0.3770388\ttotal: 18ms\tremaining: 35ms\n",
      "17:\tlearn: 0.3675435\ttotal: 19.1ms\tremaining: 34ms\n",
      "18:\tlearn: 0.3593683\ttotal: 20.2ms\tremaining: 32.9ms\n",
      "19:\tlearn: 0.3510520\ttotal: 21.7ms\tremaining: 32.6ms\n",
      "20:\tlearn: 0.3440138\ttotal: 22.8ms\tremaining: 31.4ms\n",
      "21:\tlearn: 0.3360549\ttotal: 23.8ms\tremaining: 30.3ms\n",
      "22:\tlearn: 0.3289642\ttotal: 24.8ms\tremaining: 29.1ms\n",
      "23:\tlearn: 0.3225022\ttotal: 26ms\tremaining: 28.1ms\n",
      "24:\tlearn: 0.3157418\ttotal: 27ms\tremaining: 27ms\n",
      "25:\tlearn: 0.3103230\ttotal: 28.2ms\tremaining: 26ms\n",
      "26:\tlearn: 0.3044198\ttotal: 29.1ms\tremaining: 24.8ms\n",
      "27:\tlearn: 0.2996312\ttotal: 30.2ms\tremaining: 23.7ms\n",
      "28:\tlearn: 0.2945064\ttotal: 31.2ms\tremaining: 22.6ms\n",
      "29:\tlearn: 0.2894295\ttotal: 32.2ms\tremaining: 21.5ms\n",
      "30:\tlearn: 0.2848083\ttotal: 33.3ms\tremaining: 20.4ms\n",
      "31:\tlearn: 0.2801246\ttotal: 34.2ms\tremaining: 19.3ms\n",
      "32:\tlearn: 0.2765656\ttotal: 35.3ms\tremaining: 18.2ms\n",
      "33:\tlearn: 0.2714625\ttotal: 36.3ms\tremaining: 17.1ms\n",
      "34:\tlearn: 0.2676457\ttotal: 37.4ms\tremaining: 16ms\n",
      "35:\tlearn: 0.2640770\ttotal: 38.4ms\tremaining: 14.9ms\n",
      "36:\tlearn: 0.2616587\ttotal: 39.4ms\tremaining: 13.8ms\n",
      "37:\tlearn: 0.2575728\ttotal: 40.3ms\tremaining: 12.7ms\n",
      "38:\tlearn: 0.2531767\ttotal: 41.2ms\tremaining: 11.6ms\n",
      "39:\tlearn: 0.2506512\ttotal: 42.2ms\tremaining: 10.6ms\n",
      "40:\tlearn: 0.2474296\ttotal: 43.3ms\tremaining: 9.51ms\n",
      "41:\tlearn: 0.2453993\ttotal: 44.4ms\tremaining: 8.45ms\n",
      "42:\tlearn: 0.2423681\ttotal: 45.4ms\tremaining: 7.39ms\n",
      "43:\tlearn: 0.2391699\ttotal: 46.4ms\tremaining: 6.32ms\n",
      "44:\tlearn: 0.2351199\ttotal: 47.4ms\tremaining: 5.26ms\n",
      "45:\tlearn: 0.2330965\ttotal: 48.5ms\tremaining: 4.21ms\n",
      "46:\tlearn: 0.2297833\ttotal: 49.4ms\tremaining: 3.15ms\n",
      "47:\tlearn: 0.2274244\ttotal: 50.4ms\tremaining: 2.1ms\n",
      "48:\tlearn: 0.2259768\ttotal: 51.4ms\tremaining: 1.05ms\n",
      "49:\tlearn: 0.2228085\ttotal: 52.4ms\tremaining: 0us\n",
      "0:\tlearn: 0.6607234\ttotal: 1.77ms\tremaining: 86.5ms\n",
      "1:\tlearn: 0.6307502\ttotal: 2.77ms\tremaining: 66.6ms\n",
      "2:\tlearn: 0.6046076\ttotal: 3.78ms\tremaining: 59.2ms\n",
      "3:\tlearn: 0.5784138\ttotal: 4.73ms\tremaining: 54.4ms\n",
      "4:\tlearn: 0.5560641\ttotal: 5.71ms\tremaining: 51.3ms\n",
      "5:\tlearn: 0.5360413\ttotal: 6.76ms\tremaining: 49.6ms\n",
      "6:\tlearn: 0.5158230\ttotal: 7.79ms\tremaining: 47.9ms\n",
      "7:\tlearn: 0.4965348\ttotal: 8.71ms\tremaining: 45.7ms\n",
      "8:\tlearn: 0.4786960\ttotal: 9.58ms\tremaining: 43.6ms\n",
      "9:\tlearn: 0.4628909\ttotal: 10.5ms\tremaining: 41.9ms\n",
      "10:\tlearn: 0.4482403\ttotal: 11.4ms\tremaining: 40.5ms\n",
      "11:\tlearn: 0.4348037\ttotal: 12.4ms\tremaining: 39.3ms\n",
      "12:\tlearn: 0.4214966\ttotal: 13.3ms\tremaining: 37.9ms\n",
      "13:\tlearn: 0.4101442\ttotal: 14.5ms\tremaining: 37.4ms\n",
      "14:\tlearn: 0.3985474\ttotal: 16.2ms\tremaining: 37.8ms\n",
      "15:\tlearn: 0.3868735\ttotal: 17.3ms\tremaining: 36.7ms\n",
      "16:\tlearn: 0.3764239\ttotal: 18.5ms\tremaining: 35.8ms\n",
      "17:\tlearn: 0.3671323\ttotal: 19.5ms\tremaining: 34.7ms\n",
      "18:\tlearn: 0.3590171\ttotal: 20.5ms\tremaining: 33.5ms\n",
      "19:\tlearn: 0.3502580\ttotal: 21.5ms\tremaining: 32.3ms\n",
      "20:\tlearn: 0.3429247\ttotal: 22.5ms\tremaining: 31ms\n",
      "21:\tlearn: 0.3353362\ttotal: 23.6ms\tremaining: 30ms\n",
      "22:\tlearn: 0.3289173\ttotal: 24.6ms\tremaining: 28.9ms\n",
      "23:\tlearn: 0.3219688\ttotal: 25.6ms\tremaining: 27.7ms\n",
      "24:\tlearn: 0.3152650\ttotal: 26.6ms\tremaining: 26.6ms\n",
      "25:\tlearn: 0.3091526\ttotal: 27.7ms\tremaining: 25.6ms\n",
      "26:\tlearn: 0.3034778\ttotal: 28.9ms\tremaining: 24.7ms\n",
      "27:\tlearn: 0.2986941\ttotal: 29.9ms\tremaining: 23.5ms\n",
      "28:\tlearn: 0.2934214\ttotal: 30.8ms\tremaining: 22.3ms\n",
      "29:\tlearn: 0.2894761\ttotal: 31.8ms\tremaining: 21.2ms\n",
      "30:\tlearn: 0.2846919\ttotal: 32.9ms\tremaining: 20.2ms\n",
      "31:\tlearn: 0.2806514\ttotal: 33.9ms\tremaining: 19.1ms\n",
      "32:\tlearn: 0.2767636\ttotal: 35ms\tremaining: 18ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33:\tlearn: 0.2731444\ttotal: 36.3ms\tremaining: 17.1ms\n",
      "34:\tlearn: 0.2686895\ttotal: 37.4ms\tremaining: 16ms\n",
      "35:\tlearn: 0.2648681\ttotal: 38.5ms\tremaining: 15ms\n",
      "36:\tlearn: 0.2624869\ttotal: 39.6ms\tremaining: 13.9ms\n",
      "37:\tlearn: 0.2597600\ttotal: 40.5ms\tremaining: 12.8ms\n",
      "38:\tlearn: 0.2560070\ttotal: 41.5ms\tremaining: 11.7ms\n",
      "39:\tlearn: 0.2535150\ttotal: 42.5ms\tremaining: 10.6ms\n",
      "40:\tlearn: 0.2493205\ttotal: 43.7ms\tremaining: 9.6ms\n",
      "41:\tlearn: 0.2471896\ttotal: 45ms\tremaining: 8.57ms\n",
      "42:\tlearn: 0.2440628\ttotal: 46.4ms\tremaining: 7.55ms\n",
      "43:\tlearn: 0.2408267\ttotal: 47.4ms\tremaining: 6.47ms\n",
      "44:\tlearn: 0.2372571\ttotal: 48.6ms\tremaining: 5.4ms\n",
      "45:\tlearn: 0.2344882\ttotal: 49.7ms\tremaining: 4.33ms\n",
      "46:\tlearn: 0.2321351\ttotal: 51ms\tremaining: 3.25ms\n",
      "47:\tlearn: 0.2286197\ttotal: 52.2ms\tremaining: 2.18ms\n",
      "48:\tlearn: 0.2272677\ttotal: 53.4ms\tremaining: 1.09ms\n",
      "49:\tlearn: 0.2239700\ttotal: 54.5ms\tremaining: 0us\n",
      "0:\tlearn: 0.6612216\ttotal: 1.13ms\tremaining: 55.6ms\n",
      "1:\tlearn: 0.6303016\ttotal: 2.19ms\tremaining: 52.7ms\n",
      "2:\tlearn: 0.6040696\ttotal: 3.23ms\tremaining: 50.6ms\n",
      "3:\tlearn: 0.5777684\ttotal: 4.25ms\tremaining: 48.8ms\n",
      "4:\tlearn: 0.5555155\ttotal: 5.39ms\tremaining: 48.5ms\n",
      "5:\tlearn: 0.5356384\ttotal: 6.31ms\tremaining: 46.3ms\n",
      "6:\tlearn: 0.5150863\ttotal: 7.25ms\tremaining: 44.5ms\n",
      "7:\tlearn: 0.4975932\ttotal: 8.28ms\tremaining: 43.5ms\n",
      "8:\tlearn: 0.4802666\ttotal: 9.26ms\tremaining: 42.2ms\n",
      "9:\tlearn: 0.4641361\ttotal: 10.2ms\tremaining: 40.8ms\n",
      "10:\tlearn: 0.4493540\ttotal: 11.2ms\tremaining: 39.6ms\n",
      "11:\tlearn: 0.4353135\ttotal: 12.2ms\tremaining: 38.5ms\n",
      "12:\tlearn: 0.4220610\ttotal: 13.3ms\tremaining: 37.7ms\n",
      "13:\tlearn: 0.4099330\ttotal: 14.3ms\tremaining: 36.7ms\n",
      "14:\tlearn: 0.3981193\ttotal: 15.3ms\tremaining: 35.8ms\n",
      "15:\tlearn: 0.3863772\ttotal: 16.4ms\tremaining: 34.9ms\n",
      "16:\tlearn: 0.3760803\ttotal: 17.5ms\tremaining: 34ms\n",
      "17:\tlearn: 0.3673931\ttotal: 18.5ms\tremaining: 33ms\n",
      "18:\tlearn: 0.3593683\ttotal: 19.5ms\tremaining: 31.8ms\n",
      "19:\tlearn: 0.3505014\ttotal: 20.4ms\tremaining: 30.6ms\n",
      "20:\tlearn: 0.3435344\ttotal: 21.5ms\tremaining: 29.6ms\n",
      "21:\tlearn: 0.3355398\ttotal: 22.4ms\tremaining: 28.5ms\n",
      "22:\tlearn: 0.3283186\ttotal: 23.4ms\tremaining: 27.5ms\n",
      "23:\tlearn: 0.3207109\ttotal: 24.4ms\tremaining: 26.5ms\n",
      "24:\tlearn: 0.3135429\ttotal: 25.4ms\tremaining: 25.4ms\n",
      "25:\tlearn: 0.3077688\ttotal: 26.5ms\tremaining: 24.5ms\n",
      "26:\tlearn: 0.3016078\ttotal: 27.5ms\tremaining: 23.5ms\n",
      "27:\tlearn: 0.2971430\ttotal: 28.5ms\tremaining: 22.4ms\n",
      "28:\tlearn: 0.2918023\ttotal: 29.4ms\tremaining: 21.3ms\n",
      "29:\tlearn: 0.2876907\ttotal: 30.5ms\tremaining: 20.3ms\n",
      "30:\tlearn: 0.2817182\ttotal: 31.9ms\tremaining: 19.6ms\n",
      "31:\tlearn: 0.2768406\ttotal: 33ms\tremaining: 18.6ms\n",
      "32:\tlearn: 0.2735268\ttotal: 34.1ms\tremaining: 17.6ms\n",
      "33:\tlearn: 0.2687172\ttotal: 35.1ms\tremaining: 16.5ms\n",
      "34:\tlearn: 0.2652702\ttotal: 36.1ms\tremaining: 15.5ms\n",
      "35:\tlearn: 0.2619879\ttotal: 37ms\tremaining: 14.4ms\n",
      "36:\tlearn: 0.2591692\ttotal: 38ms\tremaining: 13.4ms\n",
      "37:\tlearn: 0.2566671\ttotal: 39ms\tremaining: 12.3ms\n",
      "38:\tlearn: 0.2539392\ttotal: 40.2ms\tremaining: 11.3ms\n",
      "39:\tlearn: 0.2508668\ttotal: 41.9ms\tremaining: 10.5ms\n",
      "40:\tlearn: 0.2481127\ttotal: 43ms\tremaining: 9.43ms\n",
      "41:\tlearn: 0.2458712\ttotal: 44ms\tremaining: 8.37ms\n",
      "42:\tlearn: 0.2427009\ttotal: 45ms\tremaining: 7.32ms\n",
      "43:\tlearn: 0.2395958\ttotal: 45.9ms\tremaining: 6.26ms\n",
      "44:\tlearn: 0.2355066\ttotal: 46.9ms\tremaining: 5.21ms\n",
      "45:\tlearn: 0.2338404\ttotal: 47.9ms\tremaining: 4.17ms\n",
      "46:\tlearn: 0.2303829\ttotal: 49ms\tremaining: 3.13ms\n",
      "47:\tlearn: 0.2289038\ttotal: 50.1ms\tremaining: 2.09ms\n",
      "48:\tlearn: 0.2266893\ttotal: 51.1ms\tremaining: 1.04ms\n",
      "49:\tlearn: 0.2243982\ttotal: 52.1ms\tremaining: 0us\n",
      "0:\tlearn: 0.6261369\ttotal: 917us\tremaining: 45ms\n",
      "1:\tlearn: 0.5711238\ttotal: 1.93ms\tremaining: 46.3ms\n",
      "2:\tlearn: 0.5290549\ttotal: 3.01ms\tremaining: 47.2ms\n",
      "3:\tlearn: 0.4896400\ttotal: 3.95ms\tremaining: 45.4ms\n",
      "4:\tlearn: 0.4616613\ttotal: 4.85ms\tremaining: 43.7ms\n",
      "5:\tlearn: 0.4351532\ttotal: 5.84ms\tremaining: 42.8ms\n",
      "6:\tlearn: 0.4083842\ttotal: 6.89ms\tremaining: 42.3ms\n",
      "7:\tlearn: 0.3853398\ttotal: 7.98ms\tremaining: 41.9ms\n",
      "8:\tlearn: 0.3649717\ttotal: 9.17ms\tremaining: 41.8ms\n",
      "9:\tlearn: 0.3475873\ttotal: 10.1ms\tremaining: 40.5ms\n",
      "10:\tlearn: 0.3336251\ttotal: 11.1ms\tremaining: 39.5ms\n",
      "11:\tlearn: 0.3192453\ttotal: 12.1ms\tremaining: 38.3ms\n",
      "12:\tlearn: 0.3046072\ttotal: 13.1ms\tremaining: 37.2ms\n",
      "13:\tlearn: 0.2943584\ttotal: 14.1ms\tremaining: 36.3ms\n",
      "14:\tlearn: 0.2843694\ttotal: 15ms\tremaining: 35.1ms\n",
      "15:\tlearn: 0.2743251\ttotal: 16.1ms\tremaining: 34.1ms\n",
      "16:\tlearn: 0.2679931\ttotal: 17.2ms\tremaining: 33.3ms\n",
      "17:\tlearn: 0.2598270\ttotal: 18.2ms\tremaining: 32.3ms\n",
      "18:\tlearn: 0.2549603\ttotal: 19.3ms\tremaining: 31.5ms\n",
      "19:\tlearn: 0.2467851\ttotal: 21.1ms\tremaining: 31.6ms\n",
      "20:\tlearn: 0.2409994\ttotal: 22.1ms\tremaining: 30.5ms\n",
      "21:\tlearn: 0.2351311\ttotal: 23.2ms\tremaining: 29.5ms\n",
      "22:\tlearn: 0.2294298\ttotal: 24.2ms\tremaining: 28.4ms\n",
      "23:\tlearn: 0.2245049\ttotal: 26ms\tremaining: 28.2ms\n",
      "24:\tlearn: 0.2200183\ttotal: 27ms\tremaining: 27ms\n",
      "25:\tlearn: 0.2176683\ttotal: 28.1ms\tremaining: 25.9ms\n",
      "26:\tlearn: 0.2144512\ttotal: 29.2ms\tremaining: 24.9ms\n",
      "27:\tlearn: 0.2116197\ttotal: 31.1ms\tremaining: 24.4ms\n",
      "28:\tlearn: 0.2077501\ttotal: 32ms\tremaining: 23.2ms\n",
      "29:\tlearn: 0.2039610\ttotal: 33ms\tremaining: 22ms\n",
      "30:\tlearn: 0.2004850\ttotal: 34.1ms\tremaining: 20.9ms\n",
      "31:\tlearn: 0.1986012\ttotal: 35ms\tremaining: 19.7ms\n",
      "32:\tlearn: 0.1945695\ttotal: 36.1ms\tremaining: 18.6ms\n",
      "33:\tlearn: 0.1923050\ttotal: 37.2ms\tremaining: 17.5ms\n",
      "34:\tlearn: 0.1893445\ttotal: 38.3ms\tremaining: 16.4ms\n",
      "35:\tlearn: 0.1855194\ttotal: 39.4ms\tremaining: 15.3ms\n",
      "36:\tlearn: 0.1841878\ttotal: 40.6ms\tremaining: 14.2ms\n",
      "37:\tlearn: 0.1806590\ttotal: 41.6ms\tremaining: 13.1ms\n",
      "38:\tlearn: 0.1780521\ttotal: 42.6ms\tremaining: 12ms\n",
      "39:\tlearn: 0.1760342\ttotal: 43.6ms\tremaining: 10.9ms\n",
      "40:\tlearn: 0.1730427\ttotal: 44.8ms\tremaining: 9.83ms\n",
      "41:\tlearn: 0.1695700\ttotal: 45.8ms\tremaining: 8.72ms\n",
      "42:\tlearn: 0.1659441\ttotal: 46.8ms\tremaining: 7.62ms\n",
      "43:\tlearn: 0.1637540\ttotal: 47.8ms\tremaining: 6.52ms\n",
      "44:\tlearn: 0.1622889\ttotal: 48.9ms\tremaining: 5.44ms\n",
      "45:\tlearn: 0.1597461\ttotal: 50ms\tremaining: 4.35ms\n",
      "46:\tlearn: 0.1576415\ttotal: 51ms\tremaining: 3.26ms\n",
      "47:\tlearn: 0.1564349\ttotal: 52.1ms\tremaining: 2.17ms\n",
      "48:\tlearn: 0.1556529\ttotal: 53.2ms\tremaining: 1.08ms\n",
      "49:\tlearn: 0.1546194\ttotal: 54.2ms\tremaining: 0us\n",
      "0:\tlearn: 0.6299335\ttotal: 2.37ms\tremaining: 116ms\n",
      "1:\tlearn: 0.5755108\ttotal: 3.39ms\tremaining: 81.4ms\n",
      "2:\tlearn: 0.5325012\ttotal: 4.46ms\tremaining: 69.8ms\n",
      "3:\tlearn: 0.4924858\ttotal: 5.26ms\tremaining: 60.5ms\n",
      "4:\tlearn: 0.4647458\ttotal: 6.33ms\tremaining: 56.9ms\n",
      "5:\tlearn: 0.4374284\ttotal: 7.23ms\tremaining: 53ms\n",
      "6:\tlearn: 0.4098479\ttotal: 8.18ms\tremaining: 50.2ms\n",
      "7:\tlearn: 0.3864773\ttotal: 9.11ms\tremaining: 47.9ms\n",
      "8:\tlearn: 0.3662012\ttotal: 9.99ms\tremaining: 45.5ms\n",
      "9:\tlearn: 0.3483559\ttotal: 11ms\tremaining: 43.9ms\n",
      "10:\tlearn: 0.3329818\ttotal: 11.9ms\tremaining: 42.2ms\n",
      "11:\tlearn: 0.3212489\ttotal: 13ms\tremaining: 41.2ms\n",
      "12:\tlearn: 0.3078066\ttotal: 14.1ms\tremaining: 40.2ms\n",
      "13:\tlearn: 0.2980056\ttotal: 15.2ms\tremaining: 39.2ms\n",
      "14:\tlearn: 0.2884818\ttotal: 16.2ms\tremaining: 37.7ms\n",
      "15:\tlearn: 0.2781380\ttotal: 17.2ms\tremaining: 36.5ms\n",
      "16:\tlearn: 0.2726991\ttotal: 18.3ms\tremaining: 35.5ms\n",
      "17:\tlearn: 0.2646915\ttotal: 19.3ms\tremaining: 34.3ms\n",
      "18:\tlearn: 0.2562103\ttotal: 20.3ms\tremaining: 33.1ms\n",
      "19:\tlearn: 0.2473448\ttotal: 21.3ms\tremaining: 32ms\n",
      "20:\tlearn: 0.2429238\ttotal: 22.3ms\tremaining: 30.8ms\n",
      "21:\tlearn: 0.2359389\ttotal: 23.2ms\tremaining: 29.5ms\n",
      "22:\tlearn: 0.2305757\ttotal: 24.1ms\tremaining: 28.3ms\n",
      "23:\tlearn: 0.2243873\ttotal: 25.1ms\tremaining: 27.2ms\n",
      "24:\tlearn: 0.2199470\ttotal: 26ms\tremaining: 26ms\n",
      "25:\tlearn: 0.2163272\ttotal: 27ms\tremaining: 24.9ms\n",
      "26:\tlearn: 0.2127849\ttotal: 27.9ms\tremaining: 23.8ms\n",
      "27:\tlearn: 0.2098278\ttotal: 28.9ms\tremaining: 22.7ms\n",
      "28:\tlearn: 0.2065871\ttotal: 29.8ms\tremaining: 21.6ms\n",
      "29:\tlearn: 0.2045155\ttotal: 31ms\tremaining: 20.6ms\n",
      "30:\tlearn: 0.1999185\ttotal: 32ms\tremaining: 19.6ms\n",
      "31:\tlearn: 0.1974566\ttotal: 33ms\tremaining: 18.6ms\n",
      "32:\tlearn: 0.1952402\ttotal: 33.9ms\tremaining: 17.5ms\n",
      "33:\tlearn: 0.1911943\ttotal: 35ms\tremaining: 16.5ms\n",
      "34:\tlearn: 0.1879774\ttotal: 36ms\tremaining: 15.4ms\n",
      "35:\tlearn: 0.1862153\ttotal: 37.1ms\tremaining: 14.4ms\n",
      "36:\tlearn: 0.1849216\ttotal: 38ms\tremaining: 13.4ms\n",
      "37:\tlearn: 0.1822297\ttotal: 39.2ms\tremaining: 12.4ms\n",
      "38:\tlearn: 0.1790442\ttotal: 40.1ms\tremaining: 11.3ms\n",
      "39:\tlearn: 0.1773266\ttotal: 41.1ms\tremaining: 10.3ms\n",
      "40:\tlearn: 0.1739374\ttotal: 42ms\tremaining: 9.22ms\n",
      "41:\tlearn: 0.1724651\ttotal: 43ms\tremaining: 8.2ms\n",
      "42:\tlearn: 0.1710176\ttotal: 44.1ms\tremaining: 7.17ms\n",
      "43:\tlearn: 0.1688659\ttotal: 45.2ms\tremaining: 6.16ms\n",
      "44:\tlearn: 0.1657251\ttotal: 46.1ms\tremaining: 5.12ms\n",
      "45:\tlearn: 0.1635830\ttotal: 47.3ms\tremaining: 4.11ms\n",
      "46:\tlearn: 0.1616833\ttotal: 48.5ms\tremaining: 3.09ms\n",
      "47:\tlearn: 0.1604681\ttotal: 49.5ms\tremaining: 2.06ms\n",
      "48:\tlearn: 0.1598573\ttotal: 50.5ms\tremaining: 1.03ms\n",
      "49:\tlearn: 0.1584291\ttotal: 51.6ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6309064\ttotal: 936us\tremaining: 45.9ms\n",
      "1:\tlearn: 0.5755147\ttotal: 1.8ms\tremaining: 43.2ms\n",
      "2:\tlearn: 0.5322418\ttotal: 2.76ms\tremaining: 43.2ms\n",
      "3:\tlearn: 0.4919388\ttotal: 3.76ms\tremaining: 43.3ms\n",
      "4:\tlearn: 0.4641759\ttotal: 4.71ms\tremaining: 42.4ms\n",
      "5:\tlearn: 0.4375851\ttotal: 5.63ms\tremaining: 41.3ms\n",
      "6:\tlearn: 0.4095659\ttotal: 6.63ms\tremaining: 40.7ms\n",
      "7:\tlearn: 0.3886471\ttotal: 7.62ms\tremaining: 40ms\n",
      "8:\tlearn: 0.3676345\ttotal: 8.47ms\tremaining: 38.6ms\n",
      "9:\tlearn: 0.3501873\ttotal: 9.68ms\tremaining: 38.7ms\n",
      "10:\tlearn: 0.3342045\ttotal: 10.7ms\tremaining: 38ms\n",
      "11:\tlearn: 0.3193491\ttotal: 11.7ms\tremaining: 37ms\n",
      "12:\tlearn: 0.3065746\ttotal: 12.8ms\tremaining: 36.5ms\n",
      "13:\tlearn: 0.2962276\ttotal: 13.9ms\tremaining: 35.6ms\n",
      "14:\tlearn: 0.2862748\ttotal: 15.3ms\tremaining: 35.7ms\n",
      "15:\tlearn: 0.2756069\ttotal: 16.5ms\tremaining: 35ms\n",
      "16:\tlearn: 0.2696746\ttotal: 17.6ms\tremaining: 34.1ms\n",
      "17:\tlearn: 0.2620287\ttotal: 18.5ms\tremaining: 32.9ms\n",
      "18:\tlearn: 0.2568684\ttotal: 19.5ms\tremaining: 31.9ms\n",
      "19:\tlearn: 0.2468943\ttotal: 20.6ms\tremaining: 30.9ms\n",
      "20:\tlearn: 0.2425982\ttotal: 21.5ms\tremaining: 29.7ms\n",
      "21:\tlearn: 0.2360547\ttotal: 22.5ms\tremaining: 28.7ms\n",
      "22:\tlearn: 0.2303776\ttotal: 23.6ms\tremaining: 27.7ms\n",
      "23:\tlearn: 0.2250615\ttotal: 24.6ms\tremaining: 26.7ms\n",
      "24:\tlearn: 0.2208416\ttotal: 25.8ms\tremaining: 25.8ms\n",
      "25:\tlearn: 0.2185700\ttotal: 27.4ms\tremaining: 25.3ms\n",
      "26:\tlearn: 0.2124504\ttotal: 28.3ms\tremaining: 24.1ms\n",
      "27:\tlearn: 0.2090741\ttotal: 29.3ms\tremaining: 23ms\n",
      "28:\tlearn: 0.2055526\ttotal: 30.2ms\tremaining: 21.9ms\n",
      "29:\tlearn: 0.2034786\ttotal: 31.2ms\tremaining: 20.8ms\n",
      "30:\tlearn: 0.1992136\ttotal: 32.3ms\tremaining: 19.8ms\n",
      "31:\tlearn: 0.1969596\ttotal: 33.3ms\tremaining: 18.7ms\n",
      "32:\tlearn: 0.1934421\ttotal: 34.3ms\tremaining: 17.7ms\n",
      "33:\tlearn: 0.1915070\ttotal: 35.4ms\tremaining: 16.6ms\n",
      "34:\tlearn: 0.1893570\ttotal: 36.4ms\tremaining: 15.6ms\n",
      "35:\tlearn: 0.1873072\ttotal: 37.4ms\tremaining: 14.6ms\n",
      "36:\tlearn: 0.1832977\ttotal: 38.5ms\tremaining: 13.5ms\n",
      "37:\tlearn: 0.1811115\ttotal: 39.5ms\tremaining: 12.5ms\n",
      "38:\tlearn: 0.1790222\ttotal: 40.5ms\tremaining: 11.4ms\n",
      "39:\tlearn: 0.1775695\ttotal: 41.5ms\tremaining: 10.4ms\n",
      "40:\tlearn: 0.1752108\ttotal: 42.7ms\tremaining: 9.37ms\n",
      "41:\tlearn: 0.1736989\ttotal: 43.7ms\tremaining: 8.32ms\n",
      "42:\tlearn: 0.1716776\ttotal: 44.9ms\tremaining: 7.3ms\n",
      "43:\tlearn: 0.1684574\ttotal: 45.9ms\tremaining: 6.26ms\n",
      "44:\tlearn: 0.1664328\ttotal: 46.9ms\tremaining: 5.21ms\n",
      "45:\tlearn: 0.1653146\ttotal: 48ms\tremaining: 4.17ms\n",
      "46:\tlearn: 0.1632414\ttotal: 49ms\tremaining: 3.13ms\n",
      "47:\tlearn: 0.1621915\ttotal: 49.9ms\tremaining: 2.08ms\n",
      "48:\tlearn: 0.1614288\ttotal: 51ms\tremaining: 1.04ms\n",
      "49:\tlearn: 0.1588869\ttotal: 52.2ms\tremaining: 0us\n",
      "0:\tlearn: 0.6861380\ttotal: 1.62ms\tremaining: 160ms\n",
      "1:\tlearn: 0.6792884\ttotal: 2.59ms\tremaining: 127ms\n",
      "2:\tlearn: 0.6727760\ttotal: 3.5ms\tremaining: 113ms\n",
      "3:\tlearn: 0.6663671\ttotal: 4.44ms\tremaining: 107ms\n",
      "4:\tlearn: 0.6603005\ttotal: 5.31ms\tremaining: 101ms\n",
      "5:\tlearn: 0.6544924\ttotal: 6.24ms\tremaining: 97.8ms\n",
      "6:\tlearn: 0.6488410\ttotal: 7.17ms\tremaining: 95.2ms\n",
      "7:\tlearn: 0.6432103\ttotal: 8.05ms\tremaining: 92.5ms\n",
      "8:\tlearn: 0.6373483\ttotal: 8.9ms\tremaining: 90ms\n",
      "9:\tlearn: 0.6314694\ttotal: 9.8ms\tremaining: 88.2ms\n",
      "10:\tlearn: 0.6259912\ttotal: 11ms\tremaining: 88.8ms\n",
      "11:\tlearn: 0.6207071\ttotal: 12.5ms\tremaining: 91.3ms\n",
      "12:\tlearn: 0.6156564\ttotal: 13.6ms\tremaining: 90.8ms\n",
      "13:\tlearn: 0.6104164\ttotal: 14.7ms\tremaining: 90.3ms\n",
      "14:\tlearn: 0.6052768\ttotal: 15.7ms\tremaining: 89.2ms\n",
      "15:\tlearn: 0.5998796\ttotal: 16.7ms\tremaining: 87.9ms\n",
      "16:\tlearn: 0.5946755\ttotal: 17.7ms\tremaining: 86.4ms\n",
      "17:\tlearn: 0.5897853\ttotal: 18.6ms\tremaining: 84.6ms\n",
      "18:\tlearn: 0.5850445\ttotal: 19.5ms\tremaining: 83ms\n",
      "19:\tlearn: 0.5801199\ttotal: 20.6ms\tremaining: 82.4ms\n",
      "20:\tlearn: 0.5754610\ttotal: 21.7ms\tremaining: 81.7ms\n",
      "21:\tlearn: 0.5707026\ttotal: 22.6ms\tremaining: 80.1ms\n",
      "22:\tlearn: 0.5663601\ttotal: 23.5ms\tremaining: 78.6ms\n",
      "23:\tlearn: 0.5620907\ttotal: 24.6ms\tremaining: 78.1ms\n",
      "24:\tlearn: 0.5574051\ttotal: 25.6ms\tremaining: 76.7ms\n",
      "25:\tlearn: 0.5530084\ttotal: 26.6ms\tremaining: 75.6ms\n",
      "26:\tlearn: 0.5486653\ttotal: 27.6ms\tremaining: 74.5ms\n",
      "27:\tlearn: 0.5444238\ttotal: 28.6ms\tremaining: 73.6ms\n",
      "28:\tlearn: 0.5402682\ttotal: 29.5ms\tremaining: 72.3ms\n",
      "29:\tlearn: 0.5361486\ttotal: 30.5ms\tremaining: 71.2ms\n",
      "30:\tlearn: 0.5320445\ttotal: 31.4ms\tremaining: 70ms\n",
      "31:\tlearn: 0.5280222\ttotal: 32.4ms\tremaining: 68.8ms\n",
      "32:\tlearn: 0.5241568\ttotal: 33.4ms\tremaining: 67.7ms\n",
      "33:\tlearn: 0.5204760\ttotal: 35.2ms\tremaining: 68.3ms\n",
      "34:\tlearn: 0.5167722\ttotal: 36.2ms\tremaining: 67.2ms\n",
      "35:\tlearn: 0.5130075\ttotal: 37.1ms\tremaining: 66ms\n",
      "36:\tlearn: 0.5092117\ttotal: 38ms\tremaining: 64.7ms\n",
      "37:\tlearn: 0.5057481\ttotal: 39.1ms\tremaining: 63.8ms\n",
      "38:\tlearn: 0.5022402\ttotal: 40.1ms\tremaining: 62.8ms\n",
      "39:\tlearn: 0.4986059\ttotal: 41.3ms\tremaining: 62ms\n",
      "40:\tlearn: 0.4949176\ttotal: 42.3ms\tremaining: 60.8ms\n",
      "41:\tlearn: 0.4914229\ttotal: 43.3ms\tremaining: 59.8ms\n",
      "42:\tlearn: 0.4880900\ttotal: 44.3ms\tremaining: 58.7ms\n",
      "43:\tlearn: 0.4846531\ttotal: 45.3ms\tremaining: 57.7ms\n",
      "44:\tlearn: 0.4814013\ttotal: 46.4ms\tremaining: 56.7ms\n",
      "45:\tlearn: 0.4779849\ttotal: 47.3ms\tremaining: 55.6ms\n",
      "46:\tlearn: 0.4749921\ttotal: 48.4ms\tremaining: 54.5ms\n",
      "47:\tlearn: 0.4720740\ttotal: 49.4ms\tremaining: 53.5ms\n",
      "48:\tlearn: 0.4689798\ttotal: 50.4ms\tremaining: 52.4ms\n",
      "49:\tlearn: 0.4659974\ttotal: 51.3ms\tremaining: 51.3ms\n",
      "50:\tlearn: 0.4631186\ttotal: 52.3ms\tremaining: 50.2ms\n",
      "51:\tlearn: 0.4602007\ttotal: 53.2ms\tremaining: 49.1ms\n",
      "52:\tlearn: 0.4571512\ttotal: 54.2ms\tremaining: 48.1ms\n",
      "53:\tlearn: 0.4542296\ttotal: 55.3ms\tremaining: 47.1ms\n",
      "54:\tlearn: 0.4513054\ttotal: 56.3ms\tremaining: 46ms\n",
      "55:\tlearn: 0.4483644\ttotal: 57.4ms\tremaining: 45.1ms\n",
      "56:\tlearn: 0.4455656\ttotal: 58.3ms\tremaining: 44ms\n",
      "57:\tlearn: 0.4426011\ttotal: 59.3ms\tremaining: 42.9ms\n",
      "58:\tlearn: 0.4398056\ttotal: 60.4ms\tremaining: 41.9ms\n",
      "59:\tlearn: 0.4370856\ttotal: 61.5ms\tremaining: 41ms\n",
      "60:\tlearn: 0.4343600\ttotal: 62.5ms\tremaining: 39.9ms\n",
      "61:\tlearn: 0.4316327\ttotal: 63.7ms\tremaining: 39ms\n",
      "62:\tlearn: 0.4289753\ttotal: 64.8ms\tremaining: 38ms\n",
      "63:\tlearn: 0.4264670\ttotal: 65.8ms\tremaining: 37ms\n",
      "64:\tlearn: 0.4238380\ttotal: 66.7ms\tremaining: 35.9ms\n",
      "65:\tlearn: 0.4212025\ttotal: 67.8ms\tremaining: 34.9ms\n",
      "66:\tlearn: 0.4188162\ttotal: 68.8ms\tremaining: 33.9ms\n",
      "67:\tlearn: 0.4164413\ttotal: 69.8ms\tremaining: 32.9ms\n",
      "68:\tlearn: 0.4142781\ttotal: 70.9ms\tremaining: 31.9ms\n",
      "69:\tlearn: 0.4118548\ttotal: 72ms\tremaining: 30.8ms\n",
      "70:\tlearn: 0.4094948\ttotal: 73ms\tremaining: 29.8ms\n",
      "71:\tlearn: 0.4070199\ttotal: 74.1ms\tremaining: 28.8ms\n",
      "72:\tlearn: 0.4047153\ttotal: 75.1ms\tremaining: 27.8ms\n",
      "73:\tlearn: 0.4024579\ttotal: 76.1ms\tremaining: 26.7ms\n",
      "74:\tlearn: 0.4003043\ttotal: 77ms\tremaining: 25.7ms\n",
      "75:\tlearn: 0.3979421\ttotal: 78.1ms\tremaining: 24.7ms\n",
      "76:\tlearn: 0.3957710\ttotal: 79.2ms\tremaining: 23.6ms\n",
      "77:\tlearn: 0.3937696\ttotal: 80.2ms\tremaining: 22.6ms\n",
      "78:\tlearn: 0.3916019\ttotal: 81.4ms\tremaining: 21.6ms\n",
      "79:\tlearn: 0.3893691\ttotal: 82.5ms\tremaining: 20.6ms\n",
      "80:\tlearn: 0.3873526\ttotal: 83.6ms\tremaining: 19.6ms\n",
      "81:\tlearn: 0.3854093\ttotal: 84.5ms\tremaining: 18.6ms\n",
      "82:\tlearn: 0.3834063\ttotal: 85.6ms\tremaining: 17.5ms\n",
      "83:\tlearn: 0.3814602\ttotal: 86.6ms\tremaining: 16.5ms\n",
      "84:\tlearn: 0.3794077\ttotal: 87.6ms\tremaining: 15.5ms\n",
      "85:\tlearn: 0.3773895\ttotal: 88.6ms\tremaining: 14.4ms\n",
      "86:\tlearn: 0.3755304\ttotal: 89.5ms\tremaining: 13.4ms\n",
      "87:\tlearn: 0.3739417\ttotal: 90.5ms\tremaining: 12.3ms\n",
      "88:\tlearn: 0.3720021\ttotal: 91.5ms\tremaining: 11.3ms\n",
      "89:\tlearn: 0.3702303\ttotal: 92.4ms\tremaining: 10.3ms\n",
      "90:\tlearn: 0.3685094\ttotal: 93.4ms\tremaining: 9.24ms\n",
      "91:\tlearn: 0.3667351\ttotal: 94.4ms\tremaining: 8.21ms\n",
      "92:\tlearn: 0.3648305\ttotal: 95.5ms\tremaining: 7.19ms\n",
      "93:\tlearn: 0.3629534\ttotal: 96.5ms\tremaining: 6.16ms\n",
      "94:\tlearn: 0.3613118\ttotal: 97.4ms\tremaining: 5.13ms\n",
      "95:\tlearn: 0.3597022\ttotal: 98.5ms\tremaining: 4.11ms\n",
      "96:\tlearn: 0.3582940\ttotal: 99.7ms\tremaining: 3.08ms\n",
      "97:\tlearn: 0.3565385\ttotal: 101ms\tremaining: 2.06ms\n",
      "98:\tlearn: 0.3550129\ttotal: 102ms\tremaining: 1.03ms\n",
      "99:\tlearn: 0.3534000\ttotal: 103ms\tremaining: 0us\n",
      "0:\tlearn: 0.6865315\ttotal: 955us\tremaining: 94.5ms\n",
      "1:\tlearn: 0.6799610\ttotal: 1.83ms\tremaining: 89.7ms\n",
      "2:\tlearn: 0.6738172\ttotal: 2.77ms\tremaining: 89.6ms\n",
      "3:\tlearn: 0.6672677\ttotal: 3.66ms\tremaining: 87.9ms\n",
      "4:\tlearn: 0.6612721\ttotal: 4.59ms\tremaining: 87.2ms\n",
      "5:\tlearn: 0.6555663\ttotal: 5.37ms\tremaining: 84.1ms\n",
      "6:\tlearn: 0.6496321\ttotal: 6.4ms\tremaining: 85ms\n",
      "7:\tlearn: 0.6434927\ttotal: 7.34ms\tremaining: 84.4ms\n",
      "8:\tlearn: 0.6376305\ttotal: 8.18ms\tremaining: 82.7ms\n",
      "9:\tlearn: 0.6322127\ttotal: 8.95ms\tremaining: 80.5ms\n",
      "10:\tlearn: 0.6267621\ttotal: 9.74ms\tremaining: 78.8ms\n",
      "11:\tlearn: 0.6216421\ttotal: 10.7ms\tremaining: 78.6ms\n",
      "12:\tlearn: 0.6166142\ttotal: 11.6ms\tremaining: 77.8ms\n",
      "13:\tlearn: 0.6114660\ttotal: 13.2ms\tremaining: 81.4ms\n",
      "14:\tlearn: 0.6063442\ttotal: 14.2ms\tremaining: 80.7ms\n",
      "15:\tlearn: 0.6008706\ttotal: 15.3ms\tremaining: 80.2ms\n",
      "16:\tlearn: 0.5956678\ttotal: 16.2ms\tremaining: 79ms\n",
      "17:\tlearn: 0.5908301\ttotal: 17.1ms\tremaining: 77.9ms\n",
      "18:\tlearn: 0.5861000\ttotal: 18.1ms\tremaining: 77.1ms\n",
      "19:\tlearn: 0.5812165\ttotal: 19.1ms\tremaining: 76.2ms\n",
      "20:\tlearn: 0.5765116\ttotal: 20ms\tremaining: 75.3ms\n",
      "21:\tlearn: 0.5720435\ttotal: 21ms\tremaining: 74.6ms\n",
      "22:\tlearn: 0.5677669\ttotal: 22.2ms\tremaining: 74.2ms\n",
      "23:\tlearn: 0.5632639\ttotal: 23.2ms\tremaining: 73.4ms\n",
      "24:\tlearn: 0.5587314\ttotal: 24.1ms\tremaining: 72.3ms\n",
      "25:\tlearn: 0.5543994\ttotal: 25.3ms\tremaining: 71.9ms\n",
      "26:\tlearn: 0.5499368\ttotal: 26.2ms\tremaining: 70.7ms\n",
      "27:\tlearn: 0.5457275\ttotal: 27.1ms\tremaining: 69.6ms\n",
      "28:\tlearn: 0.5415294\ttotal: 28ms\tremaining: 68.6ms\n",
      "29:\tlearn: 0.5373813\ttotal: 29ms\tremaining: 67.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30:\tlearn: 0.5335033\ttotal: 30.2ms\tremaining: 67.3ms\n",
      "31:\tlearn: 0.5295433\ttotal: 31.2ms\tremaining: 66.3ms\n",
      "32:\tlearn: 0.5256856\ttotal: 32.2ms\tremaining: 65.4ms\n",
      "33:\tlearn: 0.5221165\ttotal: 33.2ms\tremaining: 64.4ms\n",
      "34:\tlearn: 0.5184291\ttotal: 34.2ms\tremaining: 63.6ms\n",
      "35:\tlearn: 0.5147284\ttotal: 35.3ms\tremaining: 62.7ms\n",
      "36:\tlearn: 0.5109685\ttotal: 36.4ms\tremaining: 62ms\n",
      "37:\tlearn: 0.5074868\ttotal: 37.3ms\tremaining: 60.9ms\n",
      "38:\tlearn: 0.5038808\ttotal: 38.3ms\tremaining: 60ms\n",
      "39:\tlearn: 0.5004452\ttotal: 39.3ms\tremaining: 59ms\n",
      "40:\tlearn: 0.4967613\ttotal: 41.2ms\tremaining: 59.3ms\n",
      "41:\tlearn: 0.4932233\ttotal: 42.2ms\tremaining: 58.3ms\n",
      "42:\tlearn: 0.4898901\ttotal: 43.2ms\tremaining: 57.3ms\n",
      "43:\tlearn: 0.4864308\ttotal: 44.3ms\tremaining: 56.4ms\n",
      "44:\tlearn: 0.4830251\ttotal: 45.3ms\tremaining: 55.4ms\n",
      "45:\tlearn: 0.4796551\ttotal: 46.3ms\tremaining: 54.4ms\n",
      "46:\tlearn: 0.4766093\ttotal: 47.4ms\tremaining: 53.5ms\n",
      "47:\tlearn: 0.4733253\ttotal: 48.5ms\tremaining: 52.5ms\n",
      "48:\tlearn: 0.4706770\ttotal: 49.4ms\tremaining: 51.4ms\n",
      "49:\tlearn: 0.4674899\ttotal: 50.3ms\tremaining: 50.3ms\n",
      "50:\tlearn: 0.4644926\ttotal: 51.4ms\tremaining: 49.4ms\n",
      "51:\tlearn: 0.4617438\ttotal: 52.9ms\tremaining: 48.8ms\n",
      "52:\tlearn: 0.4585667\ttotal: 53.9ms\tremaining: 47.8ms\n",
      "53:\tlearn: 0.4553923\ttotal: 54.9ms\tremaining: 46.7ms\n",
      "54:\tlearn: 0.4524459\ttotal: 55.8ms\tremaining: 45.6ms\n",
      "55:\tlearn: 0.4494953\ttotal: 56.7ms\tremaining: 44.6ms\n",
      "56:\tlearn: 0.4467303\ttotal: 57.8ms\tremaining: 43.6ms\n",
      "57:\tlearn: 0.4437430\ttotal: 58.9ms\tremaining: 42.6ms\n",
      "58:\tlearn: 0.4409570\ttotal: 60ms\tremaining: 41.7ms\n",
      "59:\tlearn: 0.4382157\ttotal: 61ms\tremaining: 40.7ms\n",
      "60:\tlearn: 0.4353652\ttotal: 62ms\tremaining: 39.7ms\n",
      "61:\tlearn: 0.4325889\ttotal: 63ms\tremaining: 38.6ms\n",
      "62:\tlearn: 0.4299213\ttotal: 64ms\tremaining: 37.6ms\n",
      "63:\tlearn: 0.4272755\ttotal: 65.1ms\tremaining: 36.6ms\n",
      "64:\tlearn: 0.4246890\ttotal: 66.1ms\tremaining: 35.6ms\n",
      "65:\tlearn: 0.4220316\ttotal: 67ms\tremaining: 34.5ms\n",
      "66:\tlearn: 0.4194413\ttotal: 68ms\tremaining: 33.5ms\n",
      "67:\tlearn: 0.4168336\ttotal: 69ms\tremaining: 32.5ms\n",
      "68:\tlearn: 0.4142706\ttotal: 70.1ms\tremaining: 31.5ms\n",
      "69:\tlearn: 0.4118810\ttotal: 71.2ms\tremaining: 30.5ms\n",
      "70:\tlearn: 0.4095161\ttotal: 72.3ms\tremaining: 29.5ms\n",
      "71:\tlearn: 0.4070341\ttotal: 73.3ms\tremaining: 28.5ms\n",
      "72:\tlearn: 0.4047141\ttotal: 74.2ms\tremaining: 27.5ms\n",
      "73:\tlearn: 0.4024190\ttotal: 75.2ms\tremaining: 26.4ms\n",
      "74:\tlearn: 0.4004502\ttotal: 76.2ms\tremaining: 25.4ms\n",
      "75:\tlearn: 0.3980770\ttotal: 77.2ms\tremaining: 24.4ms\n",
      "76:\tlearn: 0.3959160\ttotal: 78.3ms\tremaining: 23.4ms\n",
      "77:\tlearn: 0.3937709\ttotal: 79.4ms\tremaining: 22.4ms\n",
      "78:\tlearn: 0.3915986\ttotal: 80.5ms\tremaining: 21.4ms\n",
      "79:\tlearn: 0.3894528\ttotal: 81.6ms\tremaining: 20.4ms\n",
      "80:\tlearn: 0.3874096\ttotal: 82.6ms\tremaining: 19.4ms\n",
      "81:\tlearn: 0.3853471\ttotal: 83.7ms\tremaining: 18.4ms\n",
      "82:\tlearn: 0.3833638\ttotal: 84.6ms\tremaining: 17.3ms\n",
      "83:\tlearn: 0.3814051\ttotal: 85.6ms\tremaining: 16.3ms\n",
      "84:\tlearn: 0.3793663\ttotal: 86.5ms\tremaining: 15.3ms\n",
      "85:\tlearn: 0.3774004\ttotal: 87.6ms\tremaining: 14.3ms\n",
      "86:\tlearn: 0.3755534\ttotal: 88.7ms\tremaining: 13.2ms\n",
      "87:\tlearn: 0.3739450\ttotal: 89.7ms\tremaining: 12.2ms\n",
      "88:\tlearn: 0.3720452\ttotal: 90.8ms\tremaining: 11.2ms\n",
      "89:\tlearn: 0.3704040\ttotal: 91.7ms\tremaining: 10.2ms\n",
      "90:\tlearn: 0.3687212\ttotal: 92.7ms\tremaining: 9.16ms\n",
      "91:\tlearn: 0.3669130\ttotal: 93.7ms\tremaining: 8.15ms\n",
      "92:\tlearn: 0.3650267\ttotal: 94.8ms\tremaining: 7.13ms\n",
      "93:\tlearn: 0.3632622\ttotal: 95.7ms\tremaining: 6.11ms\n",
      "94:\tlearn: 0.3615779\ttotal: 96.7ms\tremaining: 5.09ms\n",
      "95:\tlearn: 0.3599682\ttotal: 97.7ms\tremaining: 4.07ms\n",
      "96:\tlearn: 0.3583394\ttotal: 98.7ms\tremaining: 3.05ms\n",
      "97:\tlearn: 0.3565718\ttotal: 99.7ms\tremaining: 2.03ms\n",
      "98:\tlearn: 0.3549736\ttotal: 101ms\tremaining: 1.02ms\n",
      "99:\tlearn: 0.3534052\ttotal: 102ms\tremaining: 0us\n",
      "0:\tlearn: 0.6866330\ttotal: 1ms\tremaining: 99ms\n",
      "1:\tlearn: 0.6798802\ttotal: 1.93ms\tremaining: 94.5ms\n",
      "2:\tlearn: 0.6737146\ttotal: 3ms\tremaining: 96.9ms\n",
      "3:\tlearn: 0.6671319\ttotal: 3.89ms\tremaining: 93.5ms\n",
      "4:\tlearn: 0.6611352\ttotal: 4.89ms\tremaining: 93ms\n",
      "5:\tlearn: 0.6554174\ttotal: 5.78ms\tremaining: 90.6ms\n",
      "6:\tlearn: 0.6494356\ttotal: 6.64ms\tremaining: 88.2ms\n",
      "7:\tlearn: 0.6437560\ttotal: 7.51ms\tremaining: 86.4ms\n",
      "8:\tlearn: 0.6379567\ttotal: 8.34ms\tremaining: 84.3ms\n",
      "9:\tlearn: 0.6322825\ttotal: 9.22ms\tremaining: 83ms\n",
      "10:\tlearn: 0.6267912\ttotal: 10ms\tremaining: 81ms\n",
      "11:\tlearn: 0.6213273\ttotal: 10.9ms\tremaining: 79.6ms\n",
      "12:\tlearn: 0.6162597\ttotal: 11.7ms\tremaining: 78.5ms\n",
      "13:\tlearn: 0.6110739\ttotal: 12.7ms\tremaining: 78.2ms\n",
      "14:\tlearn: 0.6059571\ttotal: 13.7ms\tremaining: 77.5ms\n",
      "15:\tlearn: 0.6004762\ttotal: 14.7ms\tremaining: 77.4ms\n",
      "16:\tlearn: 0.5952509\ttotal: 16ms\tremaining: 77.9ms\n",
      "17:\tlearn: 0.5904167\ttotal: 17ms\tremaining: 77.3ms\n",
      "18:\tlearn: 0.5857239\ttotal: 18ms\tremaining: 76.6ms\n",
      "19:\tlearn: 0.5808816\ttotal: 18.9ms\tremaining: 75.6ms\n",
      "20:\tlearn: 0.5762201\ttotal: 19.9ms\tremaining: 75ms\n",
      "21:\tlearn: 0.5715897\ttotal: 20.9ms\tremaining: 74ms\n",
      "22:\tlearn: 0.5671136\ttotal: 22ms\tremaining: 73.6ms\n",
      "23:\tlearn: 0.5626259\ttotal: 22.9ms\tremaining: 72.5ms\n",
      "24:\tlearn: 0.5579129\ttotal: 23.8ms\tremaining: 71.3ms\n",
      "25:\tlearn: 0.5535229\ttotal: 24.8ms\tremaining: 70.5ms\n",
      "26:\tlearn: 0.5489995\ttotal: 25.8ms\tremaining: 69.8ms\n",
      "27:\tlearn: 0.5450002\ttotal: 27.1ms\tremaining: 69.6ms\n",
      "28:\tlearn: 0.5407901\ttotal: 28ms\tremaining: 68.6ms\n",
      "29:\tlearn: 0.5364760\ttotal: 28.9ms\tremaining: 67.5ms\n",
      "30:\tlearn: 0.5325882\ttotal: 29.9ms\tremaining: 66.5ms\n",
      "31:\tlearn: 0.5285169\ttotal: 30.9ms\tremaining: 65.7ms\n",
      "32:\tlearn: 0.5246476\ttotal: 32ms\tremaining: 65ms\n",
      "33:\tlearn: 0.5206732\ttotal: 33ms\tremaining: 64ms\n",
      "34:\tlearn: 0.5169921\ttotal: 34.1ms\tremaining: 63.3ms\n",
      "35:\tlearn: 0.5132683\ttotal: 35ms\tremaining: 62.3ms\n",
      "36:\tlearn: 0.5094261\ttotal: 35.9ms\tremaining: 61.2ms\n",
      "37:\tlearn: 0.5057340\ttotal: 37ms\tremaining: 60.3ms\n",
      "38:\tlearn: 0.5021458\ttotal: 38.1ms\tremaining: 59.5ms\n",
      "39:\tlearn: 0.4985493\ttotal: 39.1ms\tremaining: 58.7ms\n",
      "40:\tlearn: 0.4948400\ttotal: 40ms\tremaining: 57.6ms\n",
      "41:\tlearn: 0.4912323\ttotal: 41ms\tremaining: 56.7ms\n",
      "42:\tlearn: 0.4878729\ttotal: 42.1ms\tremaining: 55.8ms\n",
      "43:\tlearn: 0.4845817\ttotal: 43.3ms\tremaining: 55.1ms\n",
      "44:\tlearn: 0.4812404\ttotal: 44.3ms\tremaining: 54.1ms\n",
      "45:\tlearn: 0.4778412\ttotal: 45.3ms\tremaining: 53.2ms\n",
      "46:\tlearn: 0.4745562\ttotal: 46.6ms\tremaining: 52.5ms\n",
      "47:\tlearn: 0.4717190\ttotal: 47.6ms\tremaining: 51.5ms\n",
      "48:\tlearn: 0.4685525\ttotal: 48.5ms\tremaining: 50.5ms\n",
      "49:\tlearn: 0.4656348\ttotal: 49.5ms\tremaining: 49.5ms\n",
      "50:\tlearn: 0.4625821\ttotal: 50.5ms\tremaining: 48.5ms\n",
      "51:\tlearn: 0.4596654\ttotal: 51.6ms\tremaining: 47.6ms\n",
      "52:\tlearn: 0.4566651\ttotal: 52.7ms\tremaining: 46.7ms\n",
      "53:\tlearn: 0.4537196\ttotal: 53.8ms\tremaining: 45.9ms\n",
      "54:\tlearn: 0.4507686\ttotal: 54.8ms\tremaining: 44.8ms\n",
      "55:\tlearn: 0.4478205\ttotal: 55.8ms\tremaining: 43.8ms\n",
      "56:\tlearn: 0.4450255\ttotal: 56.8ms\tremaining: 42.8ms\n",
      "57:\tlearn: 0.4420963\ttotal: 57.9ms\tremaining: 41.9ms\n",
      "58:\tlearn: 0.4393487\ttotal: 58.9ms\tremaining: 40.9ms\n",
      "59:\tlearn: 0.4366369\ttotal: 59.9ms\tremaining: 39.9ms\n",
      "60:\tlearn: 0.4339328\ttotal: 61ms\tremaining: 39ms\n",
      "61:\tlearn: 0.4312339\ttotal: 62ms\tremaining: 38ms\n",
      "62:\tlearn: 0.4285379\ttotal: 63.1ms\tremaining: 37ms\n",
      "63:\tlearn: 0.4258996\ttotal: 64ms\tremaining: 36ms\n",
      "64:\tlearn: 0.4232534\ttotal: 65ms\tremaining: 35ms\n",
      "65:\tlearn: 0.4208075\ttotal: 66.1ms\tremaining: 34.1ms\n",
      "66:\tlearn: 0.4183997\ttotal: 67.1ms\tremaining: 33ms\n",
      "67:\tlearn: 0.4158123\ttotal: 68.2ms\tremaining: 32.1ms\n",
      "68:\tlearn: 0.4137176\ttotal: 69.2ms\tremaining: 31.1ms\n",
      "69:\tlearn: 0.4112877\ttotal: 70.4ms\tremaining: 30.2ms\n",
      "70:\tlearn: 0.4090449\ttotal: 71.5ms\tremaining: 29.2ms\n",
      "71:\tlearn: 0.4065424\ttotal: 72.6ms\tremaining: 28.2ms\n",
      "72:\tlearn: 0.4042490\ttotal: 73.7ms\tremaining: 27.3ms\n",
      "73:\tlearn: 0.4020431\ttotal: 74.7ms\tremaining: 26.3ms\n",
      "74:\tlearn: 0.3998838\ttotal: 75.7ms\tremaining: 25.2ms\n",
      "75:\tlearn: 0.3975410\ttotal: 76.8ms\tremaining: 24.3ms\n",
      "76:\tlearn: 0.3953755\ttotal: 77.8ms\tremaining: 23.2ms\n",
      "77:\tlearn: 0.3931148\ttotal: 79.5ms\tremaining: 22.4ms\n",
      "78:\tlearn: 0.3909670\ttotal: 80.6ms\tremaining: 21.4ms\n",
      "79:\tlearn: 0.3887954\ttotal: 81.5ms\tremaining: 20.4ms\n",
      "80:\tlearn: 0.3867554\ttotal: 82.5ms\tremaining: 19.3ms\n",
      "81:\tlearn: 0.3848607\ttotal: 83.5ms\tremaining: 18.3ms\n",
      "82:\tlearn: 0.3827655\ttotal: 84.6ms\tremaining: 17.3ms\n",
      "83:\tlearn: 0.3807570\ttotal: 85.5ms\tremaining: 16.3ms\n",
      "84:\tlearn: 0.3786870\ttotal: 86.6ms\tremaining: 15.3ms\n",
      "85:\tlearn: 0.3766719\ttotal: 87.8ms\tremaining: 14.3ms\n",
      "86:\tlearn: 0.3748233\ttotal: 88.8ms\tremaining: 13.3ms\n",
      "87:\tlearn: 0.3732118\ttotal: 89.8ms\tremaining: 12.2ms\n",
      "88:\tlearn: 0.3712363\ttotal: 90.8ms\tremaining: 11.2ms\n",
      "89:\tlearn: 0.3694446\ttotal: 91.8ms\tremaining: 10.2ms\n",
      "90:\tlearn: 0.3676805\ttotal: 93.5ms\tremaining: 9.25ms\n",
      "91:\tlearn: 0.3659116\ttotal: 94.6ms\tremaining: 8.22ms\n",
      "92:\tlearn: 0.3639739\ttotal: 95.5ms\tremaining: 7.19ms\n",
      "93:\tlearn: 0.3622392\ttotal: 96.6ms\tremaining: 6.16ms\n",
      "94:\tlearn: 0.3604502\ttotal: 97.7ms\tremaining: 5.14ms\n",
      "95:\tlearn: 0.3585979\ttotal: 98.6ms\tremaining: 4.11ms\n",
      "96:\tlearn: 0.3567923\ttotal: 99.5ms\tremaining: 3.08ms\n",
      "97:\tlearn: 0.3553067\ttotal: 101ms\tremaining: 2.05ms\n",
      "98:\tlearn: 0.3539030\ttotal: 102ms\tremaining: 1.03ms\n",
      "99:\tlearn: 0.3525249\ttotal: 103ms\tremaining: 0us\n",
      "0:\tlearn: 0.6587869\ttotal: 990us\tremaining: 98.1ms\n",
      "1:\tlearn: 0.6277024\ttotal: 2.11ms\tremaining: 103ms\n",
      "2:\tlearn: 0.6002804\ttotal: 2.93ms\tremaining: 94.8ms\n",
      "3:\tlearn: 0.5744365\ttotal: 3.91ms\tremaining: 93.8ms\n",
      "4:\tlearn: 0.5543254\ttotal: 4.75ms\tremaining: 90.3ms\n",
      "5:\tlearn: 0.5342259\ttotal: 5.58ms\tremaining: 87.4ms\n",
      "6:\tlearn: 0.5143736\ttotal: 6.46ms\tremaining: 85.8ms\n",
      "7:\tlearn: 0.4970632\ttotal: 7.23ms\tremaining: 83.2ms\n",
      "8:\tlearn: 0.4798956\ttotal: 8.26ms\tremaining: 83.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\tlearn: 0.4640039\ttotal: 9.3ms\tremaining: 83.7ms\n",
      "10:\tlearn: 0.4492816\ttotal: 10.7ms\tremaining: 86.7ms\n",
      "11:\tlearn: 0.4357062\ttotal: 11.8ms\tremaining: 86.9ms\n",
      "12:\tlearn: 0.4224677\ttotal: 12.9ms\tremaining: 86.3ms\n",
      "13:\tlearn: 0.4104241\ttotal: 14.1ms\tremaining: 86.5ms\n",
      "14:\tlearn: 0.3985346\ttotal: 15.1ms\tremaining: 85.8ms\n",
      "15:\tlearn: 0.3871813\ttotal: 16.3ms\tremaining: 85.6ms\n",
      "16:\tlearn: 0.3770388\ttotal: 17.6ms\tremaining: 85.8ms\n",
      "17:\tlearn: 0.3675435\ttotal: 18.8ms\tremaining: 85.5ms\n",
      "18:\tlearn: 0.3593683\ttotal: 20.1ms\tremaining: 85.7ms\n",
      "19:\tlearn: 0.3510520\ttotal: 21.2ms\tremaining: 84.9ms\n",
      "20:\tlearn: 0.3440138\ttotal: 22.3ms\tremaining: 84ms\n",
      "21:\tlearn: 0.3360549\ttotal: 23.4ms\tremaining: 83ms\n",
      "22:\tlearn: 0.3289642\ttotal: 24.6ms\tremaining: 82.4ms\n",
      "23:\tlearn: 0.3225022\ttotal: 25.7ms\tremaining: 81.4ms\n",
      "24:\tlearn: 0.3157418\ttotal: 26.8ms\tremaining: 80.5ms\n",
      "25:\tlearn: 0.3103230\ttotal: 28.5ms\tremaining: 81.2ms\n",
      "26:\tlearn: 0.3044198\ttotal: 29.8ms\tremaining: 80.5ms\n",
      "27:\tlearn: 0.2996312\ttotal: 31ms\tremaining: 79.7ms\n",
      "28:\tlearn: 0.2945064\ttotal: 32.4ms\tremaining: 79.4ms\n",
      "29:\tlearn: 0.2894295\ttotal: 33.8ms\tremaining: 78.9ms\n",
      "30:\tlearn: 0.2848083\ttotal: 35.6ms\tremaining: 79.3ms\n",
      "31:\tlearn: 0.2801246\ttotal: 36.9ms\tremaining: 78.4ms\n",
      "32:\tlearn: 0.2765656\ttotal: 38.3ms\tremaining: 77.7ms\n",
      "33:\tlearn: 0.2714625\ttotal: 39.7ms\tremaining: 77ms\n",
      "34:\tlearn: 0.2676457\ttotal: 41ms\tremaining: 76.2ms\n",
      "35:\tlearn: 0.2640770\ttotal: 42.5ms\tremaining: 75.5ms\n",
      "36:\tlearn: 0.2616587\ttotal: 44.9ms\tremaining: 76.5ms\n",
      "37:\tlearn: 0.2575728\ttotal: 46.5ms\tremaining: 75.8ms\n",
      "38:\tlearn: 0.2531767\ttotal: 47.6ms\tremaining: 74.4ms\n",
      "39:\tlearn: 0.2506512\ttotal: 48.7ms\tremaining: 73.1ms\n",
      "40:\tlearn: 0.2474296\ttotal: 50.1ms\tremaining: 72.1ms\n",
      "41:\tlearn: 0.2453993\ttotal: 51.3ms\tremaining: 70.8ms\n",
      "42:\tlearn: 0.2423681\ttotal: 52.5ms\tremaining: 69.6ms\n",
      "43:\tlearn: 0.2391699\ttotal: 53.5ms\tremaining: 68.1ms\n",
      "44:\tlearn: 0.2351199\ttotal: 54.5ms\tremaining: 66.6ms\n",
      "45:\tlearn: 0.2330965\ttotal: 55.6ms\tremaining: 65.3ms\n",
      "46:\tlearn: 0.2297833\ttotal: 56.6ms\tremaining: 63.9ms\n",
      "47:\tlearn: 0.2274244\ttotal: 57.7ms\tremaining: 62.5ms\n",
      "48:\tlearn: 0.2259768\ttotal: 58.9ms\tremaining: 61.3ms\n",
      "49:\tlearn: 0.2228085\ttotal: 60.4ms\tremaining: 60.4ms\n",
      "50:\tlearn: 0.2212879\ttotal: 61.6ms\tremaining: 59.2ms\n",
      "51:\tlearn: 0.2195374\ttotal: 64.3ms\tremaining: 59.3ms\n",
      "52:\tlearn: 0.2182132\ttotal: 65.5ms\tremaining: 58.1ms\n",
      "53:\tlearn: 0.2149107\ttotal: 66.7ms\tremaining: 56.8ms\n",
      "54:\tlearn: 0.2123130\ttotal: 67.9ms\tremaining: 55.5ms\n",
      "55:\tlearn: 0.2108286\ttotal: 68.9ms\tremaining: 54.1ms\n",
      "56:\tlearn: 0.2092913\ttotal: 69.9ms\tremaining: 52.8ms\n",
      "57:\tlearn: 0.2078185\ttotal: 70.9ms\tremaining: 51.3ms\n",
      "58:\tlearn: 0.2056412\ttotal: 71.8ms\tremaining: 49.9ms\n",
      "59:\tlearn: 0.2045516\ttotal: 72.9ms\tremaining: 48.6ms\n",
      "60:\tlearn: 0.2025007\ttotal: 74ms\tremaining: 47.3ms\n",
      "61:\tlearn: 0.2002937\ttotal: 75ms\tremaining: 45.9ms\n",
      "62:\tlearn: 0.1981862\ttotal: 76ms\tremaining: 44.6ms\n",
      "63:\tlearn: 0.1972218\ttotal: 77ms\tremaining: 43.3ms\n",
      "64:\tlearn: 0.1952272\ttotal: 78.1ms\tremaining: 42ms\n",
      "65:\tlearn: 0.1934683\ttotal: 79ms\tremaining: 40.7ms\n",
      "66:\tlearn: 0.1915591\ttotal: 80.1ms\tremaining: 39.4ms\n",
      "67:\tlearn: 0.1897332\ttotal: 81.3ms\tremaining: 38.3ms\n",
      "68:\tlearn: 0.1880293\ttotal: 82.4ms\tremaining: 37ms\n",
      "69:\tlearn: 0.1866007\ttotal: 83.3ms\tremaining: 35.7ms\n",
      "70:\tlearn: 0.1850045\ttotal: 85ms\tremaining: 34.7ms\n",
      "71:\tlearn: 0.1838732\ttotal: 86.3ms\tremaining: 33.6ms\n",
      "72:\tlearn: 0.1829324\ttotal: 87.5ms\tremaining: 32.4ms\n",
      "73:\tlearn: 0.1815385\ttotal: 88.7ms\tremaining: 31.2ms\n",
      "74:\tlearn: 0.1807730\ttotal: 90.4ms\tremaining: 30.1ms\n",
      "75:\tlearn: 0.1798754\ttotal: 91.6ms\tremaining: 28.9ms\n",
      "76:\tlearn: 0.1790857\ttotal: 92.6ms\tremaining: 27.7ms\n",
      "77:\tlearn: 0.1771629\ttotal: 93.6ms\tremaining: 26.4ms\n",
      "78:\tlearn: 0.1752517\ttotal: 95ms\tremaining: 25.2ms\n",
      "79:\tlearn: 0.1737779\ttotal: 96.1ms\tremaining: 24ms\n",
      "80:\tlearn: 0.1733163\ttotal: 97.1ms\tremaining: 22.8ms\n",
      "81:\tlearn: 0.1725696\ttotal: 98.1ms\tremaining: 21.5ms\n",
      "82:\tlearn: 0.1720669\ttotal: 99.2ms\tremaining: 20.3ms\n",
      "83:\tlearn: 0.1710646\ttotal: 100ms\tremaining: 19.1ms\n",
      "84:\tlearn: 0.1703289\ttotal: 101ms\tremaining: 17.9ms\n",
      "85:\tlearn: 0.1694477\ttotal: 103ms\tremaining: 16.7ms\n",
      "86:\tlearn: 0.1685757\ttotal: 104ms\tremaining: 15.5ms\n",
      "87:\tlearn: 0.1677799\ttotal: 105ms\tremaining: 14.3ms\n",
      "88:\tlearn: 0.1663746\ttotal: 106ms\tremaining: 13.1ms\n",
      "89:\tlearn: 0.1648532\ttotal: 107ms\tremaining: 11.9ms\n",
      "90:\tlearn: 0.1640246\ttotal: 108ms\tremaining: 10.7ms\n",
      "91:\tlearn: 0.1629955\ttotal: 109ms\tremaining: 9.47ms\n",
      "92:\tlearn: 0.1620538\ttotal: 110ms\tremaining: 8.29ms\n",
      "93:\tlearn: 0.1612290\ttotal: 111ms\tremaining: 7.1ms\n",
      "94:\tlearn: 0.1603491\ttotal: 112ms\tremaining: 5.91ms\n",
      "95:\tlearn: 0.1591229\ttotal: 113ms\tremaining: 4.72ms\n",
      "96:\tlearn: 0.1581985\ttotal: 114ms\tremaining: 3.53ms\n",
      "97:\tlearn: 0.1572310\ttotal: 115ms\tremaining: 2.35ms\n",
      "98:\tlearn: 0.1563401\ttotal: 116ms\tremaining: 1.17ms\n",
      "99:\tlearn: 0.1551051\ttotal: 117ms\tremaining: 0us\n",
      "0:\tlearn: 0.6607234\ttotal: 1.1ms\tremaining: 109ms\n",
      "1:\tlearn: 0.6307502\ttotal: 2.04ms\tremaining: 100ms\n",
      "2:\tlearn: 0.6046076\ttotal: 3.04ms\tremaining: 98.1ms\n",
      "3:\tlearn: 0.5784138\ttotal: 3.96ms\tremaining: 95ms\n",
      "4:\tlearn: 0.5560641\ttotal: 5ms\tremaining: 95ms\n",
      "5:\tlearn: 0.5360413\ttotal: 5.87ms\tremaining: 91.9ms\n",
      "6:\tlearn: 0.5158230\ttotal: 6.77ms\tremaining: 90ms\n",
      "7:\tlearn: 0.4965348\ttotal: 7.72ms\tremaining: 88.8ms\n",
      "8:\tlearn: 0.4786960\ttotal: 8.62ms\tremaining: 87.1ms\n",
      "9:\tlearn: 0.4628909\ttotal: 9.51ms\tremaining: 85.6ms\n",
      "10:\tlearn: 0.4482403\ttotal: 10.5ms\tremaining: 84.7ms\n",
      "11:\tlearn: 0.4348037\ttotal: 11.5ms\tremaining: 84.3ms\n",
      "12:\tlearn: 0.4214966\ttotal: 12.4ms\tremaining: 83.3ms\n",
      "13:\tlearn: 0.4101442\ttotal: 13.6ms\tremaining: 83.3ms\n",
      "14:\tlearn: 0.3985474\ttotal: 14.6ms\tremaining: 83ms\n",
      "15:\tlearn: 0.3868735\ttotal: 15.6ms\tremaining: 82.1ms\n",
      "16:\tlearn: 0.3764239\ttotal: 16.7ms\tremaining: 81.3ms\n",
      "17:\tlearn: 0.3671323\ttotal: 17.6ms\tremaining: 80.1ms\n",
      "18:\tlearn: 0.3590171\ttotal: 18.6ms\tremaining: 79.1ms\n",
      "19:\tlearn: 0.3502580\ttotal: 19.6ms\tremaining: 78.2ms\n",
      "20:\tlearn: 0.3429247\ttotal: 20.6ms\tremaining: 77.6ms\n",
      "21:\tlearn: 0.3353362\ttotal: 21.6ms\tremaining: 76.5ms\n",
      "22:\tlearn: 0.3289173\ttotal: 22.4ms\tremaining: 75.1ms\n",
      "23:\tlearn: 0.3219688\ttotal: 23.4ms\tremaining: 74ms\n",
      "24:\tlearn: 0.3152650\ttotal: 24.3ms\tremaining: 73ms\n",
      "25:\tlearn: 0.3091526\ttotal: 25.4ms\tremaining: 72.3ms\n",
      "26:\tlearn: 0.3034778\ttotal: 26.5ms\tremaining: 71.7ms\n",
      "27:\tlearn: 0.2986941\ttotal: 27.5ms\tremaining: 70.7ms\n",
      "28:\tlearn: 0.2934214\ttotal: 28.5ms\tremaining: 69.8ms\n",
      "29:\tlearn: 0.2894761\ttotal: 29.6ms\tremaining: 69.1ms\n",
      "30:\tlearn: 0.2846919\ttotal: 30.8ms\tremaining: 68.5ms\n",
      "31:\tlearn: 0.2806514\ttotal: 31.9ms\tremaining: 67.8ms\n",
      "32:\tlearn: 0.2767636\ttotal: 33ms\tremaining: 66.9ms\n",
      "33:\tlearn: 0.2731444\ttotal: 34.7ms\tremaining: 67.4ms\n",
      "34:\tlearn: 0.2686895\ttotal: 35.7ms\tremaining: 66.2ms\n",
      "35:\tlearn: 0.2648681\ttotal: 36.7ms\tremaining: 65.2ms\n",
      "36:\tlearn: 0.2624869\ttotal: 37.7ms\tremaining: 64.2ms\n",
      "37:\tlearn: 0.2597600\ttotal: 38.6ms\tremaining: 63ms\n",
      "38:\tlearn: 0.2560070\ttotal: 39.7ms\tremaining: 62.1ms\n",
      "39:\tlearn: 0.2535150\ttotal: 40.8ms\tremaining: 61.2ms\n",
      "40:\tlearn: 0.2493205\ttotal: 41.8ms\tremaining: 60.1ms\n",
      "41:\tlearn: 0.2471896\ttotal: 42.8ms\tremaining: 59.1ms\n",
      "42:\tlearn: 0.2440628\ttotal: 43.8ms\tremaining: 58ms\n",
      "43:\tlearn: 0.2408267\ttotal: 44.9ms\tremaining: 57.2ms\n",
      "44:\tlearn: 0.2372571\ttotal: 46ms\tremaining: 56.2ms\n",
      "45:\tlearn: 0.2344882\ttotal: 47.1ms\tremaining: 55.3ms\n",
      "46:\tlearn: 0.2321351\ttotal: 48.2ms\tremaining: 54.3ms\n",
      "47:\tlearn: 0.2286197\ttotal: 49.2ms\tremaining: 53.3ms\n",
      "48:\tlearn: 0.2272677\ttotal: 50.2ms\tremaining: 52.2ms\n",
      "49:\tlearn: 0.2239700\ttotal: 51.3ms\tremaining: 51.3ms\n",
      "50:\tlearn: 0.2225472\ttotal: 52.3ms\tremaining: 50.3ms\n",
      "51:\tlearn: 0.2206521\ttotal: 53.3ms\tremaining: 49.2ms\n",
      "52:\tlearn: 0.2185086\ttotal: 54.4ms\tremaining: 48.2ms\n",
      "53:\tlearn: 0.2154158\ttotal: 55.5ms\tremaining: 47.3ms\n",
      "54:\tlearn: 0.2127901\ttotal: 56.5ms\tremaining: 46.2ms\n",
      "55:\tlearn: 0.2106914\ttotal: 57.4ms\tremaining: 45.1ms\n",
      "56:\tlearn: 0.2091352\ttotal: 58.5ms\tremaining: 44.1ms\n",
      "57:\tlearn: 0.2072940\ttotal: 59.6ms\tremaining: 43.2ms\n",
      "58:\tlearn: 0.2060704\ttotal: 60.6ms\tremaining: 42.1ms\n",
      "59:\tlearn: 0.2049915\ttotal: 61.6ms\tremaining: 41ms\n",
      "60:\tlearn: 0.2030249\ttotal: 62.5ms\tremaining: 39.9ms\n",
      "61:\tlearn: 0.2013938\ttotal: 63.4ms\tremaining: 38.8ms\n",
      "62:\tlearn: 0.1992361\ttotal: 64.4ms\tremaining: 37.8ms\n",
      "63:\tlearn: 0.1983500\ttotal: 65.5ms\tremaining: 36.8ms\n",
      "64:\tlearn: 0.1969068\ttotal: 66.6ms\tremaining: 35.9ms\n",
      "65:\tlearn: 0.1955965\ttotal: 67.7ms\tremaining: 34.9ms\n",
      "66:\tlearn: 0.1937739\ttotal: 68.8ms\tremaining: 33.9ms\n",
      "67:\tlearn: 0.1919041\ttotal: 69.8ms\tremaining: 32.9ms\n",
      "68:\tlearn: 0.1909861\ttotal: 70.9ms\tremaining: 31.8ms\n",
      "69:\tlearn: 0.1892687\ttotal: 71.9ms\tremaining: 30.8ms\n",
      "70:\tlearn: 0.1876588\ttotal: 72.9ms\tremaining: 29.8ms\n",
      "71:\tlearn: 0.1865709\ttotal: 74ms\tremaining: 28.8ms\n",
      "72:\tlearn: 0.1856462\ttotal: 75.2ms\tremaining: 27.8ms\n",
      "73:\tlearn: 0.1840243\ttotal: 76.1ms\tremaining: 26.7ms\n",
      "74:\tlearn: 0.1833813\ttotal: 77ms\tremaining: 25.7ms\n",
      "75:\tlearn: 0.1822179\ttotal: 78.1ms\tremaining: 24.7ms\n",
      "76:\tlearn: 0.1805127\ttotal: 79.1ms\tremaining: 23.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77:\tlearn: 0.1791991\ttotal: 80.5ms\tremaining: 22.7ms\n",
      "78:\tlearn: 0.1772893\ttotal: 81.7ms\tremaining: 21.7ms\n",
      "79:\tlearn: 0.1755958\ttotal: 82.8ms\tremaining: 20.7ms\n",
      "80:\tlearn: 0.1739916\ttotal: 83.9ms\tremaining: 19.7ms\n",
      "81:\tlearn: 0.1732658\ttotal: 90.1ms\tremaining: 19.8ms\n",
      "82:\tlearn: 0.1728200\ttotal: 91.5ms\tremaining: 18.7ms\n",
      "83:\tlearn: 0.1718847\ttotal: 92.9ms\tremaining: 17.7ms\n",
      "84:\tlearn: 0.1711129\ttotal: 94.1ms\tremaining: 16.6ms\n",
      "85:\tlearn: 0.1699458\ttotal: 95.2ms\tremaining: 15.5ms\n",
      "86:\tlearn: 0.1691468\ttotal: 96.4ms\tremaining: 14.4ms\n",
      "87:\tlearn: 0.1677868\ttotal: 97.4ms\tremaining: 13.3ms\n",
      "88:\tlearn: 0.1667608\ttotal: 98.6ms\tremaining: 12.2ms\n",
      "89:\tlearn: 0.1653145\ttotal: 99.9ms\tremaining: 11.1ms\n",
      "90:\tlearn: 0.1647328\ttotal: 101ms\tremaining: 10ms\n",
      "91:\tlearn: 0.1638094\ttotal: 102ms\tremaining: 8.88ms\n",
      "92:\tlearn: 0.1626862\ttotal: 103ms\tremaining: 7.77ms\n",
      "93:\tlearn: 0.1615224\ttotal: 104ms\tremaining: 6.66ms\n",
      "94:\tlearn: 0.1607203\ttotal: 105ms\tremaining: 5.54ms\n",
      "95:\tlearn: 0.1595411\ttotal: 106ms\tremaining: 4.43ms\n",
      "96:\tlearn: 0.1587053\ttotal: 107ms\tremaining: 3.32ms\n",
      "97:\tlearn: 0.1578309\ttotal: 108ms\tremaining: 2.21ms\n",
      "98:\tlearn: 0.1568191\ttotal: 109ms\tremaining: 1.1ms\n",
      "99:\tlearn: 0.1556916\ttotal: 110ms\tremaining: 0us\n",
      "0:\tlearn: 0.6612216\ttotal: 1.08ms\tremaining: 107ms\n",
      "1:\tlearn: 0.6303016\ttotal: 1.99ms\tremaining: 97.6ms\n",
      "2:\tlearn: 0.6040696\ttotal: 3.14ms\tremaining: 102ms\n",
      "3:\tlearn: 0.5777684\ttotal: 4.03ms\tremaining: 96.7ms\n",
      "4:\tlearn: 0.5555155\ttotal: 4.97ms\tremaining: 94.5ms\n",
      "5:\tlearn: 0.5356384\ttotal: 5.82ms\tremaining: 91.2ms\n",
      "6:\tlearn: 0.5150863\ttotal: 6.64ms\tremaining: 88.2ms\n",
      "7:\tlearn: 0.4975932\ttotal: 7.52ms\tremaining: 86.5ms\n",
      "8:\tlearn: 0.4802666\ttotal: 8.37ms\tremaining: 84.7ms\n",
      "9:\tlearn: 0.4641361\ttotal: 9.28ms\tremaining: 83.5ms\n",
      "10:\tlearn: 0.4493540\ttotal: 10.3ms\tremaining: 83.2ms\n",
      "11:\tlearn: 0.4353135\ttotal: 11.2ms\tremaining: 81.8ms\n",
      "12:\tlearn: 0.4220610\ttotal: 12.1ms\tremaining: 80.8ms\n",
      "13:\tlearn: 0.4099330\ttotal: 13.1ms\tremaining: 80.2ms\n",
      "14:\tlearn: 0.3981193\ttotal: 14ms\tremaining: 79.2ms\n",
      "15:\tlearn: 0.3863772\ttotal: 15.2ms\tremaining: 79.7ms\n",
      "16:\tlearn: 0.3760803\ttotal: 16.1ms\tremaining: 78.8ms\n",
      "17:\tlearn: 0.3673931\ttotal: 17.2ms\tremaining: 78.4ms\n",
      "18:\tlearn: 0.3593683\ttotal: 18.2ms\tremaining: 77.8ms\n",
      "19:\tlearn: 0.3505014\ttotal: 19.2ms\tremaining: 76.8ms\n",
      "20:\tlearn: 0.3435344\ttotal: 20.2ms\tremaining: 76ms\n",
      "21:\tlearn: 0.3355398\ttotal: 21.2ms\tremaining: 75.3ms\n",
      "22:\tlearn: 0.3283186\ttotal: 22.3ms\tremaining: 74.6ms\n",
      "23:\tlearn: 0.3207109\ttotal: 23.4ms\tremaining: 74ms\n",
      "24:\tlearn: 0.3135429\ttotal: 24.4ms\tremaining: 73.3ms\n",
      "25:\tlearn: 0.3077688\ttotal: 25.7ms\tremaining: 73.1ms\n",
      "26:\tlearn: 0.3016078\ttotal: 26.7ms\tremaining: 72.2ms\n",
      "27:\tlearn: 0.2971430\ttotal: 27.5ms\tremaining: 70.8ms\n",
      "28:\tlearn: 0.2918023\ttotal: 28.5ms\tremaining: 69.9ms\n",
      "29:\tlearn: 0.2876907\ttotal: 29.6ms\tremaining: 69.1ms\n",
      "30:\tlearn: 0.2817182\ttotal: 30.7ms\tremaining: 68.4ms\n",
      "31:\tlearn: 0.2768406\ttotal: 31.9ms\tremaining: 67.7ms\n",
      "32:\tlearn: 0.2735268\ttotal: 33.5ms\tremaining: 68ms\n",
      "33:\tlearn: 0.2687172\ttotal: 34.5ms\tremaining: 67ms\n",
      "34:\tlearn: 0.2652702\ttotal: 35.5ms\tremaining: 66ms\n",
      "35:\tlearn: 0.2619879\ttotal: 36.5ms\tremaining: 64.9ms\n",
      "36:\tlearn: 0.2591692\ttotal: 37.7ms\tremaining: 64.3ms\n",
      "37:\tlearn: 0.2566671\ttotal: 38.7ms\tremaining: 63.2ms\n",
      "38:\tlearn: 0.2539392\ttotal: 39.8ms\tremaining: 62.3ms\n",
      "39:\tlearn: 0.2508668\ttotal: 41ms\tremaining: 61.5ms\n",
      "40:\tlearn: 0.2481127\ttotal: 42ms\tremaining: 60.4ms\n",
      "41:\tlearn: 0.2458712\ttotal: 43.1ms\tremaining: 59.5ms\n",
      "42:\tlearn: 0.2427009\ttotal: 44.3ms\tremaining: 58.8ms\n",
      "43:\tlearn: 0.2395958\ttotal: 45.4ms\tremaining: 57.8ms\n",
      "44:\tlearn: 0.2355066\ttotal: 46.4ms\tremaining: 56.7ms\n",
      "45:\tlearn: 0.2338404\ttotal: 47.5ms\tremaining: 55.7ms\n",
      "46:\tlearn: 0.2303829\ttotal: 48.5ms\tremaining: 54.7ms\n",
      "47:\tlearn: 0.2289038\ttotal: 49.5ms\tremaining: 53.6ms\n",
      "48:\tlearn: 0.2266893\ttotal: 50.5ms\tremaining: 52.6ms\n",
      "49:\tlearn: 0.2243982\ttotal: 51.5ms\tremaining: 51.5ms\n",
      "50:\tlearn: 0.2220494\ttotal: 52.5ms\tremaining: 50.5ms\n",
      "51:\tlearn: 0.2204969\ttotal: 53.6ms\tremaining: 49.5ms\n",
      "52:\tlearn: 0.2182351\ttotal: 54.7ms\tremaining: 48.5ms\n",
      "53:\tlearn: 0.2146252\ttotal: 55.8ms\tremaining: 47.5ms\n",
      "54:\tlearn: 0.2118682\ttotal: 56.7ms\tremaining: 46.4ms\n",
      "55:\tlearn: 0.2097515\ttotal: 57.8ms\tremaining: 45.4ms\n",
      "56:\tlearn: 0.2081896\ttotal: 58.9ms\tremaining: 44.4ms\n",
      "57:\tlearn: 0.2064032\ttotal: 59.8ms\tremaining: 43.3ms\n",
      "58:\tlearn: 0.2037847\ttotal: 61ms\tremaining: 42.4ms\n",
      "59:\tlearn: 0.2015156\ttotal: 61.9ms\tremaining: 41.3ms\n",
      "60:\tlearn: 0.1991261\ttotal: 63ms\tremaining: 40.3ms\n",
      "61:\tlearn: 0.1979311\ttotal: 64ms\tremaining: 39.2ms\n",
      "62:\tlearn: 0.1956409\ttotal: 65.2ms\tremaining: 38.3ms\n",
      "63:\tlearn: 0.1944233\ttotal: 66.3ms\tremaining: 37.3ms\n",
      "64:\tlearn: 0.1927724\ttotal: 67.4ms\tremaining: 36.3ms\n",
      "65:\tlearn: 0.1910070\ttotal: 68.3ms\tremaining: 35.2ms\n",
      "66:\tlearn: 0.1898502\ttotal: 69.9ms\tremaining: 34.4ms\n",
      "67:\tlearn: 0.1886132\ttotal: 71ms\tremaining: 33.4ms\n",
      "68:\tlearn: 0.1879422\ttotal: 72.1ms\tremaining: 32.4ms\n",
      "69:\tlearn: 0.1861912\ttotal: 73ms\tremaining: 31.3ms\n",
      "70:\tlearn: 0.1849873\ttotal: 73.9ms\tremaining: 30.2ms\n",
      "71:\tlearn: 0.1837776\ttotal: 74.9ms\tremaining: 29.1ms\n",
      "72:\tlearn: 0.1828298\ttotal: 76ms\tremaining: 28.1ms\n",
      "73:\tlearn: 0.1814495\ttotal: 77.1ms\tremaining: 27.1ms\n",
      "74:\tlearn: 0.1807740\ttotal: 78.1ms\tremaining: 26ms\n",
      "75:\tlearn: 0.1797568\ttotal: 79ms\tremaining: 24.9ms\n",
      "76:\tlearn: 0.1779819\ttotal: 80.1ms\tremaining: 23.9ms\n",
      "77:\tlearn: 0.1763112\ttotal: 81.1ms\tremaining: 22.9ms\n",
      "78:\tlearn: 0.1746582\ttotal: 82ms\tremaining: 21.8ms\n",
      "79:\tlearn: 0.1730730\ttotal: 83.1ms\tremaining: 20.8ms\n",
      "80:\tlearn: 0.1715925\ttotal: 84.1ms\tremaining: 19.7ms\n",
      "81:\tlearn: 0.1710032\ttotal: 85.1ms\tremaining: 18.7ms\n",
      "82:\tlearn: 0.1705019\ttotal: 86.3ms\tremaining: 17.7ms\n",
      "83:\tlearn: 0.1691675\ttotal: 87.4ms\tremaining: 16.7ms\n",
      "84:\tlearn: 0.1679717\ttotal: 88.5ms\tremaining: 15.6ms\n",
      "85:\tlearn: 0.1668388\ttotal: 89.6ms\tremaining: 14.6ms\n",
      "86:\tlearn: 0.1652770\ttotal: 90.5ms\tremaining: 13.5ms\n",
      "87:\tlearn: 0.1647621\ttotal: 91.6ms\tremaining: 12.5ms\n",
      "88:\tlearn: 0.1636799\ttotal: 92.7ms\tremaining: 11.5ms\n",
      "89:\tlearn: 0.1625169\ttotal: 93.7ms\tremaining: 10.4ms\n",
      "90:\tlearn: 0.1616552\ttotal: 94.8ms\tremaining: 9.37ms\n",
      "91:\tlearn: 0.1607586\ttotal: 95.8ms\tremaining: 8.33ms\n",
      "92:\tlearn: 0.1601574\ttotal: 96.7ms\tremaining: 7.28ms\n",
      "93:\tlearn: 0.1594950\ttotal: 97.8ms\tremaining: 6.24ms\n",
      "94:\tlearn: 0.1591960\ttotal: 98.7ms\tremaining: 5.2ms\n",
      "95:\tlearn: 0.1581152\ttotal: 99.7ms\tremaining: 4.16ms\n",
      "96:\tlearn: 0.1570481\ttotal: 101ms\tremaining: 3.12ms\n",
      "97:\tlearn: 0.1560086\ttotal: 102ms\tremaining: 2.08ms\n",
      "98:\tlearn: 0.1549263\ttotal: 103ms\tremaining: 1.04ms\n",
      "99:\tlearn: 0.1538883\ttotal: 104ms\tremaining: 0us\n",
      "0:\tlearn: 0.6261369\ttotal: 1.61ms\tremaining: 160ms\n",
      "1:\tlearn: 0.5711238\ttotal: 2.6ms\tremaining: 127ms\n",
      "2:\tlearn: 0.5290549\ttotal: 3.51ms\tremaining: 114ms\n",
      "3:\tlearn: 0.4896400\ttotal: 4.56ms\tremaining: 110ms\n",
      "4:\tlearn: 0.4616613\ttotal: 5.5ms\tremaining: 105ms\n",
      "5:\tlearn: 0.4351532\ttotal: 6.51ms\tremaining: 102ms\n",
      "6:\tlearn: 0.4083842\ttotal: 7.54ms\tremaining: 100ms\n",
      "7:\tlearn: 0.3853398\ttotal: 8.47ms\tremaining: 97.4ms\n",
      "8:\tlearn: 0.3649717\ttotal: 9.63ms\tremaining: 97.4ms\n",
      "9:\tlearn: 0.3475873\ttotal: 10.5ms\tremaining: 94.2ms\n",
      "10:\tlearn: 0.3336251\ttotal: 11.4ms\tremaining: 91.9ms\n",
      "11:\tlearn: 0.3192453\ttotal: 12.3ms\tremaining: 90ms\n",
      "12:\tlearn: 0.3046072\ttotal: 13.1ms\tremaining: 87.9ms\n",
      "13:\tlearn: 0.2943584\ttotal: 14.2ms\tremaining: 87ms\n",
      "14:\tlearn: 0.2843694\ttotal: 15.1ms\tremaining: 85.5ms\n",
      "15:\tlearn: 0.2743251\ttotal: 16ms\tremaining: 84.1ms\n",
      "16:\tlearn: 0.2679931\ttotal: 17.1ms\tremaining: 83.3ms\n",
      "17:\tlearn: 0.2598270\ttotal: 18.1ms\tremaining: 82.4ms\n",
      "18:\tlearn: 0.2549603\ttotal: 19.3ms\tremaining: 82.3ms\n",
      "19:\tlearn: 0.2467851\ttotal: 21ms\tremaining: 84.2ms\n",
      "20:\tlearn: 0.2409994\ttotal: 22.2ms\tremaining: 83.5ms\n",
      "21:\tlearn: 0.2351311\ttotal: 23.9ms\tremaining: 84.6ms\n",
      "22:\tlearn: 0.2294298\ttotal: 24.8ms\tremaining: 82.9ms\n",
      "23:\tlearn: 0.2245049\ttotal: 25.8ms\tremaining: 81.6ms\n",
      "24:\tlearn: 0.2200183\ttotal: 26.9ms\tremaining: 80.6ms\n",
      "25:\tlearn: 0.2176683\ttotal: 27.9ms\tremaining: 79.4ms\n",
      "26:\tlearn: 0.2144512\ttotal: 28.9ms\tremaining: 78.1ms\n",
      "27:\tlearn: 0.2116197\ttotal: 30ms\tremaining: 77ms\n",
      "28:\tlearn: 0.2077501\ttotal: 31.1ms\tremaining: 76.1ms\n",
      "29:\tlearn: 0.2039610\ttotal: 32ms\tremaining: 74.6ms\n",
      "30:\tlearn: 0.2004850\ttotal: 32.9ms\tremaining: 73.3ms\n",
      "31:\tlearn: 0.1986012\ttotal: 33.9ms\tremaining: 72.1ms\n",
      "32:\tlearn: 0.1945695\ttotal: 34.9ms\tremaining: 70.8ms\n",
      "33:\tlearn: 0.1923050\ttotal: 36ms\tremaining: 70ms\n",
      "34:\tlearn: 0.1893445\ttotal: 37.1ms\tremaining: 68.9ms\n",
      "35:\tlearn: 0.1855194\ttotal: 38.1ms\tremaining: 67.8ms\n",
      "36:\tlearn: 0.1841878\ttotal: 39.3ms\tremaining: 66.9ms\n",
      "37:\tlearn: 0.1806590\ttotal: 40.4ms\tremaining: 65.9ms\n",
      "38:\tlearn: 0.1780521\ttotal: 41.5ms\tremaining: 64.9ms\n",
      "39:\tlearn: 0.1760342\ttotal: 42.6ms\tremaining: 63.8ms\n",
      "40:\tlearn: 0.1730427\ttotal: 43.6ms\tremaining: 62.8ms\n",
      "41:\tlearn: 0.1695700\ttotal: 44.6ms\tremaining: 61.6ms\n",
      "42:\tlearn: 0.1659441\ttotal: 45.8ms\tremaining: 60.7ms\n",
      "43:\tlearn: 0.1637540\ttotal: 46.8ms\tremaining: 59.5ms\n",
      "44:\tlearn: 0.1622889\ttotal: 47.8ms\tremaining: 58.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45:\tlearn: 0.1597461\ttotal: 48.9ms\tremaining: 57.4ms\n",
      "46:\tlearn: 0.1576415\ttotal: 50.1ms\tremaining: 56.5ms\n",
      "47:\tlearn: 0.1564349\ttotal: 51.2ms\tremaining: 55.5ms\n",
      "48:\tlearn: 0.1556529\ttotal: 52.4ms\tremaining: 54.5ms\n",
      "49:\tlearn: 0.1546194\ttotal: 53.5ms\tremaining: 53.5ms\n",
      "50:\tlearn: 0.1530831\ttotal: 54.4ms\tremaining: 52.3ms\n",
      "51:\tlearn: 0.1521613\ttotal: 55.7ms\tremaining: 51.5ms\n",
      "52:\tlearn: 0.1511542\ttotal: 56.7ms\tremaining: 50.3ms\n",
      "53:\tlearn: 0.1498586\ttotal: 57.7ms\tremaining: 49.1ms\n",
      "54:\tlearn: 0.1474913\ttotal: 58.7ms\tremaining: 48ms\n",
      "55:\tlearn: 0.1454520\ttotal: 59.9ms\tremaining: 47.1ms\n",
      "56:\tlearn: 0.1447312\ttotal: 61ms\tremaining: 46ms\n",
      "57:\tlearn: 0.1436089\ttotal: 62.2ms\tremaining: 45.1ms\n",
      "58:\tlearn: 0.1417446\ttotal: 63.3ms\tremaining: 44ms\n",
      "59:\tlearn: 0.1403897\ttotal: 64.5ms\tremaining: 43ms\n",
      "60:\tlearn: 0.1389674\ttotal: 65.7ms\tremaining: 42ms\n",
      "61:\tlearn: 0.1372391\ttotal: 66.6ms\tremaining: 40.8ms\n",
      "62:\tlearn: 0.1361772\ttotal: 67.8ms\tremaining: 39.8ms\n",
      "63:\tlearn: 0.1352578\ttotal: 68.7ms\tremaining: 38.7ms\n",
      "64:\tlearn: 0.1333253\ttotal: 70ms\tremaining: 37.7ms\n",
      "65:\tlearn: 0.1323263\ttotal: 71ms\tremaining: 36.6ms\n",
      "66:\tlearn: 0.1315178\ttotal: 72.2ms\tremaining: 35.6ms\n",
      "67:\tlearn: 0.1304027\ttotal: 73.4ms\tremaining: 34.5ms\n",
      "68:\tlearn: 0.1294145\ttotal: 74.5ms\tremaining: 33.5ms\n",
      "69:\tlearn: 0.1284925\ttotal: 75.5ms\tremaining: 32.4ms\n",
      "70:\tlearn: 0.1278439\ttotal: 76.6ms\tremaining: 31.3ms\n",
      "71:\tlearn: 0.1270533\ttotal: 77.8ms\tremaining: 30.2ms\n",
      "72:\tlearn: 0.1264122\ttotal: 79ms\tremaining: 29.2ms\n",
      "73:\tlearn: 0.1254387\ttotal: 80.1ms\tremaining: 28.1ms\n",
      "74:\tlearn: 0.1250849\ttotal: 81.3ms\tremaining: 27.1ms\n",
      "75:\tlearn: 0.1243475\ttotal: 82.3ms\tremaining: 26ms\n",
      "76:\tlearn: 0.1233330\ttotal: 83.6ms\tremaining: 25ms\n",
      "77:\tlearn: 0.1220535\ttotal: 84.8ms\tremaining: 23.9ms\n",
      "78:\tlearn: 0.1209266\ttotal: 85.9ms\tremaining: 22.8ms\n",
      "79:\tlearn: 0.1201821\ttotal: 87ms\tremaining: 21.7ms\n",
      "80:\tlearn: 0.1188618\ttotal: 87.9ms\tremaining: 20.6ms\n",
      "81:\tlearn: 0.1183542\ttotal: 89.1ms\tremaining: 19.6ms\n",
      "82:\tlearn: 0.1179387\ttotal: 90.3ms\tremaining: 18.5ms\n",
      "83:\tlearn: 0.1168648\ttotal: 91.7ms\tremaining: 17.5ms\n",
      "84:\tlearn: 0.1160740\ttotal: 92.7ms\tremaining: 16.4ms\n",
      "85:\tlearn: 0.1149310\ttotal: 93.6ms\tremaining: 15.2ms\n",
      "86:\tlearn: 0.1139856\ttotal: 94.7ms\tremaining: 14.1ms\n",
      "87:\tlearn: 0.1137149\ttotal: 95.8ms\tremaining: 13.1ms\n",
      "88:\tlearn: 0.1128430\ttotal: 96.9ms\tremaining: 12ms\n",
      "89:\tlearn: 0.1120841\ttotal: 97.9ms\tremaining: 10.9ms\n",
      "90:\tlearn: 0.1118656\ttotal: 98.9ms\tremaining: 9.78ms\n",
      "91:\tlearn: 0.1110427\ttotal: 99.9ms\tremaining: 8.69ms\n",
      "92:\tlearn: 0.1099211\ttotal: 101ms\tremaining: 7.6ms\n",
      "93:\tlearn: 0.1089457\ttotal: 102ms\tremaining: 6.51ms\n",
      "94:\tlearn: 0.1084603\ttotal: 103ms\tremaining: 5.42ms\n",
      "95:\tlearn: 0.1076360\ttotal: 104ms\tremaining: 4.34ms\n",
      "96:\tlearn: 0.1069333\ttotal: 105ms\tremaining: 3.26ms\n",
      "97:\tlearn: 0.1064890\ttotal: 106ms\tremaining: 2.17ms\n",
      "98:\tlearn: 0.1056829\ttotal: 108ms\tremaining: 1.09ms\n",
      "99:\tlearn: 0.1050311\ttotal: 109ms\tremaining: 0us\n",
      "0:\tlearn: 0.6299335\ttotal: 1.61ms\tremaining: 159ms\n",
      "1:\tlearn: 0.5755108\ttotal: 2.66ms\tremaining: 130ms\n",
      "2:\tlearn: 0.5325012\ttotal: 3.65ms\tremaining: 118ms\n",
      "3:\tlearn: 0.4924858\ttotal: 4.61ms\tremaining: 111ms\n",
      "4:\tlearn: 0.4647458\ttotal: 5.69ms\tremaining: 108ms\n",
      "5:\tlearn: 0.4374284\ttotal: 6.59ms\tremaining: 103ms\n",
      "6:\tlearn: 0.4098479\ttotal: 7.46ms\tremaining: 99.1ms\n",
      "7:\tlearn: 0.3864773\ttotal: 8.37ms\tremaining: 96.2ms\n",
      "8:\tlearn: 0.3662012\ttotal: 9.32ms\tremaining: 94.2ms\n",
      "9:\tlearn: 0.3483559\ttotal: 10.2ms\tremaining: 91.8ms\n",
      "10:\tlearn: 0.3329818\ttotal: 11.2ms\tremaining: 90.5ms\n",
      "11:\tlearn: 0.3212489\ttotal: 12.1ms\tremaining: 88.7ms\n",
      "12:\tlearn: 0.3078066\ttotal: 13.3ms\tremaining: 88.8ms\n",
      "13:\tlearn: 0.2980056\ttotal: 14.2ms\tremaining: 87ms\n",
      "14:\tlearn: 0.2884818\ttotal: 15.2ms\tremaining: 86.2ms\n",
      "15:\tlearn: 0.2781380\ttotal: 16.2ms\tremaining: 85.3ms\n",
      "16:\tlearn: 0.2726991\ttotal: 17.3ms\tremaining: 84.3ms\n",
      "17:\tlearn: 0.2646915\ttotal: 18.2ms\tremaining: 82.7ms\n",
      "18:\tlearn: 0.2562103\ttotal: 19.1ms\tremaining: 81.5ms\n",
      "19:\tlearn: 0.2473448\ttotal: 20.1ms\tremaining: 80.4ms\n",
      "20:\tlearn: 0.2429238\ttotal: 21.2ms\tremaining: 79.9ms\n",
      "21:\tlearn: 0.2359389\ttotal: 22.4ms\tremaining: 79.4ms\n",
      "22:\tlearn: 0.2305757\ttotal: 23.5ms\tremaining: 78.5ms\n",
      "23:\tlearn: 0.2243873\ttotal: 24.5ms\tremaining: 77.7ms\n",
      "24:\tlearn: 0.2199470\ttotal: 25.5ms\tremaining: 76.6ms\n",
      "25:\tlearn: 0.2163272\ttotal: 26.7ms\tremaining: 75.9ms\n",
      "26:\tlearn: 0.2127849\ttotal: 27.7ms\tremaining: 74.8ms\n",
      "27:\tlearn: 0.2098278\ttotal: 28.8ms\tremaining: 74ms\n",
      "28:\tlearn: 0.2065871\ttotal: 29.9ms\tremaining: 73.2ms\n",
      "29:\tlearn: 0.2045155\ttotal: 31ms\tremaining: 72.3ms\n",
      "30:\tlearn: 0.1999185\ttotal: 32ms\tremaining: 71.2ms\n",
      "31:\tlearn: 0.1974566\ttotal: 33.1ms\tremaining: 70.3ms\n",
      "32:\tlearn: 0.1952402\ttotal: 34.8ms\tremaining: 70.7ms\n",
      "33:\tlearn: 0.1911943\ttotal: 35.9ms\tremaining: 69.7ms\n",
      "34:\tlearn: 0.1879774\ttotal: 37.1ms\tremaining: 68.9ms\n",
      "35:\tlearn: 0.1862153\ttotal: 38.2ms\tremaining: 68ms\n",
      "36:\tlearn: 0.1849216\ttotal: 39.2ms\tremaining: 66.7ms\n",
      "37:\tlearn: 0.1822297\ttotal: 40.2ms\tremaining: 65.6ms\n",
      "38:\tlearn: 0.1790442\ttotal: 41.1ms\tremaining: 64.3ms\n",
      "39:\tlearn: 0.1773266\ttotal: 42.2ms\tremaining: 63.2ms\n",
      "40:\tlearn: 0.1739374\ttotal: 43.1ms\tremaining: 62.1ms\n",
      "41:\tlearn: 0.1724651\ttotal: 44.1ms\tremaining: 60.9ms\n",
      "42:\tlearn: 0.1710176\ttotal: 45.2ms\tremaining: 59.9ms\n",
      "43:\tlearn: 0.1688659\ttotal: 46.3ms\tremaining: 58.9ms\n",
      "44:\tlearn: 0.1657251\ttotal: 47.4ms\tremaining: 57.9ms\n",
      "45:\tlearn: 0.1635830\ttotal: 48.4ms\tremaining: 56.8ms\n",
      "46:\tlearn: 0.1616833\ttotal: 49.4ms\tremaining: 55.8ms\n",
      "47:\tlearn: 0.1604681\ttotal: 50.5ms\tremaining: 54.7ms\n",
      "48:\tlearn: 0.1598573\ttotal: 51.4ms\tremaining: 53.5ms\n",
      "49:\tlearn: 0.1584291\ttotal: 52.3ms\tremaining: 52.3ms\n",
      "50:\tlearn: 0.1566697\ttotal: 53.3ms\tremaining: 51.2ms\n",
      "51:\tlearn: 0.1557707\ttotal: 54.2ms\tremaining: 50ms\n",
      "52:\tlearn: 0.1539039\ttotal: 55.2ms\tremaining: 49ms\n",
      "53:\tlearn: 0.1511734\ttotal: 56.2ms\tremaining: 47.9ms\n",
      "54:\tlearn: 0.1489353\ttotal: 57.3ms\tremaining: 46.9ms\n",
      "55:\tlearn: 0.1476012\ttotal: 58.6ms\tremaining: 46ms\n",
      "56:\tlearn: 0.1466183\ttotal: 59.5ms\tremaining: 44.9ms\n",
      "57:\tlearn: 0.1456441\ttotal: 60.5ms\tremaining: 43.8ms\n",
      "58:\tlearn: 0.1446114\ttotal: 61.6ms\tremaining: 42.8ms\n",
      "59:\tlearn: 0.1430365\ttotal: 62.6ms\tremaining: 41.7ms\n",
      "60:\tlearn: 0.1414078\ttotal: 63.6ms\tremaining: 40.7ms\n",
      "61:\tlearn: 0.1400094\ttotal: 64.7ms\tremaining: 39.7ms\n",
      "62:\tlearn: 0.1384157\ttotal: 65.8ms\tremaining: 38.6ms\n",
      "63:\tlearn: 0.1378877\ttotal: 66.7ms\tremaining: 37.5ms\n",
      "64:\tlearn: 0.1371097\ttotal: 67.7ms\tremaining: 36.5ms\n",
      "65:\tlearn: 0.1361280\ttotal: 68.7ms\tremaining: 35.4ms\n",
      "66:\tlearn: 0.1354153\ttotal: 69.8ms\tremaining: 34.4ms\n",
      "67:\tlearn: 0.1344646\ttotal: 70.9ms\tremaining: 33.4ms\n",
      "68:\tlearn: 0.1340478\ttotal: 72ms\tremaining: 32.3ms\n",
      "69:\tlearn: 0.1325731\ttotal: 73.1ms\tremaining: 31.3ms\n",
      "70:\tlearn: 0.1315908\ttotal: 74.1ms\tremaining: 30.3ms\n",
      "71:\tlearn: 0.1301820\ttotal: 75ms\tremaining: 29.2ms\n",
      "72:\tlearn: 0.1296999\ttotal: 76.1ms\tremaining: 28.2ms\n",
      "73:\tlearn: 0.1283754\ttotal: 77.2ms\tremaining: 27.1ms\n",
      "74:\tlearn: 0.1279497\ttotal: 78.3ms\tremaining: 26.1ms\n",
      "75:\tlearn: 0.1269851\ttotal: 79.4ms\tremaining: 25.1ms\n",
      "76:\tlearn: 0.1258099\ttotal: 80.5ms\tremaining: 24ms\n",
      "77:\tlearn: 0.1244052\ttotal: 81.5ms\tremaining: 23ms\n",
      "78:\tlearn: 0.1230120\ttotal: 82.6ms\tremaining: 22ms\n",
      "79:\tlearn: 0.1219166\ttotal: 83.7ms\tremaining: 20.9ms\n",
      "80:\tlearn: 0.1208869\ttotal: 84.7ms\tremaining: 19.9ms\n",
      "81:\tlearn: 0.1203987\ttotal: 85.7ms\tremaining: 18.8ms\n",
      "82:\tlearn: 0.1195114\ttotal: 86.9ms\tremaining: 17.8ms\n",
      "83:\tlearn: 0.1190375\ttotal: 87.9ms\tremaining: 16.8ms\n",
      "84:\tlearn: 0.1181480\ttotal: 89.1ms\tremaining: 15.7ms\n",
      "85:\tlearn: 0.1173790\ttotal: 90.2ms\tremaining: 14.7ms\n",
      "86:\tlearn: 0.1166301\ttotal: 91.2ms\tremaining: 13.6ms\n",
      "87:\tlearn: 0.1156718\ttotal: 92.1ms\tremaining: 12.6ms\n",
      "88:\tlearn: 0.1149651\ttotal: 93.2ms\tremaining: 11.5ms\n",
      "89:\tlearn: 0.1145099\ttotal: 94.3ms\tremaining: 10.5ms\n",
      "90:\tlearn: 0.1136467\ttotal: 95.4ms\tremaining: 9.44ms\n",
      "91:\tlearn: 0.1131165\ttotal: 96.5ms\tremaining: 8.39ms\n",
      "92:\tlearn: 0.1118343\ttotal: 97.5ms\tremaining: 7.34ms\n",
      "93:\tlearn: 0.1113620\ttotal: 98.7ms\tremaining: 6.3ms\n",
      "94:\tlearn: 0.1105720\ttotal: 99.7ms\tremaining: 5.25ms\n",
      "95:\tlearn: 0.1100840\ttotal: 101ms\tremaining: 4.2ms\n",
      "96:\tlearn: 0.1094905\ttotal: 102ms\tremaining: 3.15ms\n",
      "97:\tlearn: 0.1088401\ttotal: 103ms\tremaining: 2.1ms\n",
      "98:\tlearn: 0.1085327\ttotal: 104ms\tremaining: 1.05ms\n",
      "99:\tlearn: 0.1075074\ttotal: 105ms\tremaining: 0us\n",
      "0:\tlearn: 0.6309064\ttotal: 929us\tremaining: 92ms\n",
      "1:\tlearn: 0.5755147\ttotal: 1.81ms\tremaining: 88.9ms\n",
      "2:\tlearn: 0.5322418\ttotal: 2.81ms\tremaining: 90.9ms\n",
      "3:\tlearn: 0.4919388\ttotal: 3.8ms\tremaining: 91.2ms\n",
      "4:\tlearn: 0.4641759\ttotal: 4.78ms\tremaining: 90.9ms\n",
      "5:\tlearn: 0.4375851\ttotal: 5.65ms\tremaining: 88.6ms\n",
      "6:\tlearn: 0.4095659\ttotal: 6.52ms\tremaining: 86.6ms\n",
      "7:\tlearn: 0.3886471\ttotal: 7.42ms\tremaining: 85.3ms\n",
      "8:\tlearn: 0.3676345\ttotal: 8.38ms\tremaining: 84.7ms\n",
      "9:\tlearn: 0.3501873\ttotal: 9.34ms\tremaining: 84ms\n",
      "10:\tlearn: 0.3342045\ttotal: 10.2ms\tremaining: 82.5ms\n",
      "11:\tlearn: 0.3193491\ttotal: 11.1ms\tremaining: 81.1ms\n",
      "12:\tlearn: 0.3065746\ttotal: 11.9ms\tremaining: 79.7ms\n",
      "13:\tlearn: 0.2962276\ttotal: 12.8ms\tremaining: 78.6ms\n",
      "14:\tlearn: 0.2862748\ttotal: 13.9ms\tremaining: 78.7ms\n",
      "15:\tlearn: 0.2756069\ttotal: 14.9ms\tremaining: 78ms\n",
      "16:\tlearn: 0.2696746\ttotal: 16ms\tremaining: 78.2ms\n",
      "17:\tlearn: 0.2620287\ttotal: 17ms\tremaining: 77.6ms\n",
      "18:\tlearn: 0.2568684\ttotal: 18.1ms\tremaining: 77.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:\tlearn: 0.2468943\ttotal: 19.9ms\tremaining: 79.7ms\n",
      "20:\tlearn: 0.2425982\ttotal: 21ms\tremaining: 79ms\n",
      "21:\tlearn: 0.2360547\ttotal: 22ms\tremaining: 77.9ms\n",
      "22:\tlearn: 0.2303776\ttotal: 22.8ms\tremaining: 76.5ms\n",
      "23:\tlearn: 0.2250615\ttotal: 23.8ms\tremaining: 75.5ms\n",
      "24:\tlearn: 0.2208416\ttotal: 24.9ms\tremaining: 74.7ms\n",
      "25:\tlearn: 0.2185700\ttotal: 25.9ms\tremaining: 73.7ms\n",
      "26:\tlearn: 0.2124504\ttotal: 27ms\tremaining: 73.1ms\n",
      "27:\tlearn: 0.2090741\ttotal: 28ms\tremaining: 71.9ms\n",
      "28:\tlearn: 0.2055526\ttotal: 29.1ms\tremaining: 71.2ms\n",
      "29:\tlearn: 0.2034786\ttotal: 30.1ms\tremaining: 70.2ms\n",
      "30:\tlearn: 0.1992136\ttotal: 30.9ms\tremaining: 68.9ms\n",
      "31:\tlearn: 0.1969596\ttotal: 31.9ms\tremaining: 67.8ms\n",
      "32:\tlearn: 0.1934421\ttotal: 32.9ms\tremaining: 66.7ms\n",
      "33:\tlearn: 0.1915070\ttotal: 33.8ms\tremaining: 65.6ms\n",
      "34:\tlearn: 0.1893570\ttotal: 34.9ms\tremaining: 64.8ms\n",
      "35:\tlearn: 0.1873072\ttotal: 35.9ms\tremaining: 63.8ms\n",
      "36:\tlearn: 0.1832977\ttotal: 36.8ms\tremaining: 62.6ms\n",
      "37:\tlearn: 0.1811115\ttotal: 37.9ms\tremaining: 61.8ms\n",
      "38:\tlearn: 0.1790222\ttotal: 38.9ms\tremaining: 60.9ms\n",
      "39:\tlearn: 0.1775695\ttotal: 39.8ms\tremaining: 59.7ms\n",
      "40:\tlearn: 0.1752108\ttotal: 40.8ms\tremaining: 58.7ms\n",
      "41:\tlearn: 0.1736989\ttotal: 42.6ms\tremaining: 58.9ms\n",
      "42:\tlearn: 0.1716776\ttotal: 43.7ms\tremaining: 58ms\n",
      "43:\tlearn: 0.1684574\ttotal: 44.7ms\tremaining: 56.9ms\n",
      "44:\tlearn: 0.1664328\ttotal: 45.8ms\tremaining: 56ms\n",
      "45:\tlearn: 0.1653146\ttotal: 46.9ms\tremaining: 55ms\n",
      "46:\tlearn: 0.1632414\ttotal: 48ms\tremaining: 54.1ms\n",
      "47:\tlearn: 0.1621915\ttotal: 49ms\tremaining: 53ms\n",
      "48:\tlearn: 0.1614288\ttotal: 50ms\tremaining: 52ms\n",
      "49:\tlearn: 0.1588869\ttotal: 51ms\tremaining: 51ms\n",
      "50:\tlearn: 0.1577789\ttotal: 52.2ms\tremaining: 50.2ms\n",
      "51:\tlearn: 0.1568208\ttotal: 53.3ms\tremaining: 49.2ms\n",
      "52:\tlearn: 0.1546170\ttotal: 54.2ms\tremaining: 48.1ms\n",
      "53:\tlearn: 0.1532927\ttotal: 55.5ms\tremaining: 47.2ms\n",
      "54:\tlearn: 0.1510495\ttotal: 56.4ms\tremaining: 46.2ms\n",
      "55:\tlearn: 0.1494850\ttotal: 57.6ms\tremaining: 45.2ms\n",
      "56:\tlearn: 0.1482678\ttotal: 58.6ms\tremaining: 44.2ms\n",
      "57:\tlearn: 0.1470004\ttotal: 59.4ms\tremaining: 43ms\n",
      "58:\tlearn: 0.1449417\ttotal: 60.3ms\tremaining: 41.9ms\n",
      "59:\tlearn: 0.1441986\ttotal: 61.2ms\tremaining: 40.8ms\n",
      "60:\tlearn: 0.1424658\ttotal: 62.2ms\tremaining: 39.8ms\n",
      "61:\tlearn: 0.1413079\ttotal: 63.3ms\tremaining: 38.8ms\n",
      "62:\tlearn: 0.1396684\ttotal: 64.4ms\tremaining: 37.8ms\n",
      "63:\tlearn: 0.1391191\ttotal: 65.4ms\tremaining: 36.8ms\n",
      "64:\tlearn: 0.1378440\ttotal: 66.3ms\tremaining: 35.7ms\n",
      "65:\tlearn: 0.1364643\ttotal: 67.6ms\tremaining: 34.8ms\n",
      "66:\tlearn: 0.1356792\ttotal: 68.8ms\tremaining: 33.9ms\n",
      "67:\tlearn: 0.1349683\ttotal: 69.8ms\tremaining: 32.9ms\n",
      "68:\tlearn: 0.1347577\ttotal: 70.9ms\tremaining: 31.9ms\n",
      "69:\tlearn: 0.1331697\ttotal: 72ms\tremaining: 30.9ms\n",
      "70:\tlearn: 0.1326499\ttotal: 73.2ms\tremaining: 29.9ms\n",
      "71:\tlearn: 0.1315304\ttotal: 74.2ms\tremaining: 28.9ms\n",
      "72:\tlearn: 0.1310102\ttotal: 75.2ms\tremaining: 27.8ms\n",
      "73:\tlearn: 0.1298107\ttotal: 76.3ms\tremaining: 26.8ms\n",
      "74:\tlearn: 0.1294078\ttotal: 77.3ms\tremaining: 25.8ms\n",
      "75:\tlearn: 0.1279777\ttotal: 78.4ms\tremaining: 24.8ms\n",
      "76:\tlearn: 0.1276598\ttotal: 79.5ms\tremaining: 23.8ms\n",
      "77:\tlearn: 0.1270527\ttotal: 80.4ms\tremaining: 22.7ms\n",
      "78:\tlearn: 0.1256872\ttotal: 81.5ms\tremaining: 21.7ms\n",
      "79:\tlearn: 0.1250897\ttotal: 82.6ms\tremaining: 20.7ms\n",
      "80:\tlearn: 0.1243228\ttotal: 83.7ms\tremaining: 19.6ms\n",
      "81:\tlearn: 0.1236342\ttotal: 84.9ms\tremaining: 18.6ms\n",
      "82:\tlearn: 0.1230211\ttotal: 85.9ms\tremaining: 17.6ms\n",
      "83:\tlearn: 0.1217426\ttotal: 86.9ms\tremaining: 16.6ms\n",
      "84:\tlearn: 0.1207041\ttotal: 87.9ms\tremaining: 15.5ms\n",
      "85:\tlearn: 0.1200077\ttotal: 89ms\tremaining: 14.5ms\n",
      "86:\tlearn: 0.1190130\ttotal: 90.1ms\tremaining: 13.5ms\n",
      "87:\tlearn: 0.1183851\ttotal: 91.2ms\tremaining: 12.4ms\n",
      "88:\tlearn: 0.1176301\ttotal: 92.3ms\tremaining: 11.4ms\n",
      "89:\tlearn: 0.1164205\ttotal: 94ms\tremaining: 10.4ms\n",
      "90:\tlearn: 0.1159957\ttotal: 95.2ms\tremaining: 9.41ms\n",
      "91:\tlearn: 0.1154711\ttotal: 96.3ms\tremaining: 8.37ms\n",
      "92:\tlearn: 0.1147582\ttotal: 97.3ms\tremaining: 7.33ms\n",
      "93:\tlearn: 0.1144836\ttotal: 98.3ms\tremaining: 6.28ms\n",
      "94:\tlearn: 0.1134517\ttotal: 99.4ms\tremaining: 5.23ms\n",
      "95:\tlearn: 0.1125756\ttotal: 100ms\tremaining: 4.18ms\n",
      "96:\tlearn: 0.1121335\ttotal: 102ms\tremaining: 3.14ms\n",
      "97:\tlearn: 0.1117270\ttotal: 103ms\tremaining: 2.1ms\n",
      "98:\tlearn: 0.1108047\ttotal: 104ms\tremaining: 1.05ms\n",
      "99:\tlearn: 0.1100569\ttotal: 105ms\tremaining: 0us\n",
      "0:\tlearn: 0.6799936\ttotal: 3.39ms\tremaining: 675ms\n",
      "1:\tlearn: 0.6686076\ttotal: 6.06ms\tremaining: 600ms\n",
      "2:\tlearn: 0.6573123\ttotal: 9.49ms\tremaining: 623ms\n",
      "3:\tlearn: 0.6460629\ttotal: 12ms\tremaining: 590ms\n",
      "4:\tlearn: 0.6354051\ttotal: 15.4ms\tremaining: 602ms\n",
      "5:\tlearn: 0.6236592\ttotal: 18.1ms\tremaining: 585ms\n",
      "6:\tlearn: 0.6127054\ttotal: 20.7ms\tremaining: 572ms\n",
      "7:\tlearn: 0.6034623\ttotal: 23.5ms\tremaining: 563ms\n",
      "8:\tlearn: 0.5925361\ttotal: 26.1ms\tremaining: 555ms\n",
      "9:\tlearn: 0.5827082\ttotal: 28.7ms\tremaining: 546ms\n",
      "10:\tlearn: 0.5756714\ttotal: 31.4ms\tremaining: 540ms\n",
      "11:\tlearn: 0.5667290\ttotal: 34ms\tremaining: 533ms\n",
      "12:\tlearn: 0.5586915\ttotal: 36.8ms\tremaining: 529ms\n",
      "13:\tlearn: 0.5498497\ttotal: 39.3ms\tremaining: 522ms\n",
      "14:\tlearn: 0.5404526\ttotal: 42ms\tremaining: 518ms\n",
      "15:\tlearn: 0.5340288\ttotal: 45.7ms\tremaining: 526ms\n",
      "16:\tlearn: 0.5248672\ttotal: 48.3ms\tremaining: 520ms\n",
      "17:\tlearn: 0.5176798\ttotal: 51ms\tremaining: 516ms\n",
      "18:\tlearn: 0.5097770\ttotal: 53.7ms\tremaining: 511ms\n",
      "19:\tlearn: 0.5016228\ttotal: 56.3ms\tremaining: 507ms\n",
      "20:\tlearn: 0.4941415\ttotal: 59.2ms\tremaining: 505ms\n",
      "21:\tlearn: 0.4866813\ttotal: 62.8ms\tremaining: 508ms\n",
      "22:\tlearn: 0.4798574\ttotal: 65.5ms\tremaining: 504ms\n",
      "23:\tlearn: 0.4724980\ttotal: 68.1ms\tremaining: 499ms\n",
      "24:\tlearn: 0.4660199\ttotal: 70.7ms\tremaining: 495ms\n",
      "25:\tlearn: 0.4595651\ttotal: 73.6ms\tremaining: 492ms\n",
      "26:\tlearn: 0.4537102\ttotal: 76.2ms\tremaining: 488ms\n",
      "27:\tlearn: 0.4473513\ttotal: 79ms\tremaining: 485ms\n",
      "28:\tlearn: 0.4412453\ttotal: 81.7ms\tremaining: 482ms\n",
      "29:\tlearn: 0.4361197\ttotal: 84.8ms\tremaining: 480ms\n",
      "30:\tlearn: 0.4323076\ttotal: 87.5ms\tremaining: 477ms\n",
      "31:\tlearn: 0.4286340\ttotal: 90.2ms\tremaining: 474ms\n",
      "32:\tlearn: 0.4236328\ttotal: 93ms\tremaining: 471ms\n",
      "33:\tlearn: 0.4194465\ttotal: 95.5ms\tremaining: 466ms\n",
      "34:\tlearn: 0.4144936\ttotal: 98.3ms\tremaining: 463ms\n",
      "35:\tlearn: 0.4094096\ttotal: 101ms\tremaining: 460ms\n",
      "36:\tlearn: 0.4053683\ttotal: 104ms\tremaining: 457ms\n",
      "37:\tlearn: 0.4012153\ttotal: 106ms\tremaining: 452ms\n",
      "38:\tlearn: 0.3968681\ttotal: 109ms\tremaining: 449ms\n",
      "39:\tlearn: 0.3922717\ttotal: 112ms\tremaining: 447ms\n",
      "40:\tlearn: 0.3879209\ttotal: 114ms\tremaining: 443ms\n",
      "41:\tlearn: 0.3847288\ttotal: 117ms\tremaining: 440ms\n",
      "42:\tlearn: 0.3806215\ttotal: 120ms\tremaining: 437ms\n",
      "43:\tlearn: 0.3769991\ttotal: 123ms\tremaining: 436ms\n",
      "44:\tlearn: 0.3729177\ttotal: 127ms\tremaining: 436ms\n",
      "45:\tlearn: 0.3691184\ttotal: 129ms\tremaining: 432ms\n",
      "46:\tlearn: 0.3664394\ttotal: 132ms\tremaining: 430ms\n",
      "47:\tlearn: 0.3627689\ttotal: 135ms\tremaining: 427ms\n",
      "48:\tlearn: 0.3588845\ttotal: 138ms\tremaining: 426ms\n",
      "49:\tlearn: 0.3562106\ttotal: 141ms\tremaining: 422ms\n",
      "50:\tlearn: 0.3529534\ttotal: 143ms\tremaining: 419ms\n",
      "51:\tlearn: 0.3502707\ttotal: 146ms\tremaining: 416ms\n",
      "52:\tlearn: 0.3475828\ttotal: 149ms\tremaining: 414ms\n",
      "53:\tlearn: 0.3440877\ttotal: 152ms\tremaining: 411ms\n",
      "54:\tlearn: 0.3416518\ttotal: 155ms\tremaining: 407ms\n",
      "55:\tlearn: 0.3388315\ttotal: 158ms\tremaining: 406ms\n",
      "56:\tlearn: 0.3368547\ttotal: 161ms\tremaining: 403ms\n",
      "57:\tlearn: 0.3348505\ttotal: 164ms\tremaining: 400ms\n",
      "58:\tlearn: 0.3323440\ttotal: 166ms\tremaining: 397ms\n",
      "59:\tlearn: 0.3300171\ttotal: 169ms\tremaining: 394ms\n",
      "60:\tlearn: 0.3277174\ttotal: 172ms\tremaining: 391ms\n",
      "61:\tlearn: 0.3251482\ttotal: 175ms\tremaining: 389ms\n",
      "62:\tlearn: 0.3223621\ttotal: 177ms\tremaining: 386ms\n",
      "63:\tlearn: 0.3199777\ttotal: 180ms\tremaining: 383ms\n",
      "64:\tlearn: 0.3181059\ttotal: 183ms\tremaining: 379ms\n",
      "65:\tlearn: 0.3164449\ttotal: 185ms\tremaining: 376ms\n",
      "66:\tlearn: 0.3142744\ttotal: 188ms\tremaining: 374ms\n",
      "67:\tlearn: 0.3123981\ttotal: 191ms\tremaining: 371ms\n",
      "68:\tlearn: 0.3093951\ttotal: 194ms\tremaining: 368ms\n",
      "69:\tlearn: 0.3076777\ttotal: 197ms\tremaining: 365ms\n",
      "70:\tlearn: 0.3060542\ttotal: 199ms\tremaining: 362ms\n",
      "71:\tlearn: 0.3040333\ttotal: 202ms\tremaining: 359ms\n",
      "72:\tlearn: 0.3022441\ttotal: 205ms\tremaining: 356ms\n",
      "73:\tlearn: 0.3009066\ttotal: 207ms\tremaining: 353ms\n",
      "74:\tlearn: 0.2976486\ttotal: 210ms\tremaining: 350ms\n",
      "75:\tlearn: 0.2957134\ttotal: 213ms\tremaining: 347ms\n",
      "76:\tlearn: 0.2940569\ttotal: 216ms\tremaining: 344ms\n",
      "77:\tlearn: 0.2929556\ttotal: 218ms\tremaining: 341ms\n",
      "78:\tlearn: 0.2913916\ttotal: 221ms\tremaining: 339ms\n",
      "79:\tlearn: 0.2897177\ttotal: 224ms\tremaining: 335ms\n",
      "80:\tlearn: 0.2868072\ttotal: 226ms\tremaining: 333ms\n",
      "81:\tlearn: 0.2852542\ttotal: 229ms\tremaining: 330ms\n",
      "82:\tlearn: 0.2840822\ttotal: 232ms\tremaining: 327ms\n",
      "83:\tlearn: 0.2827321\ttotal: 235ms\tremaining: 324ms\n",
      "84:\tlearn: 0.2801544\ttotal: 238ms\tremaining: 322ms\n",
      "85:\tlearn: 0.2791118\ttotal: 241ms\tremaining: 319ms\n",
      "86:\tlearn: 0.2778822\ttotal: 243ms\tremaining: 316ms\n",
      "87:\tlearn: 0.2762070\ttotal: 246ms\tremaining: 313ms\n",
      "88:\tlearn: 0.2752741\ttotal: 250ms\tremaining: 311ms\n",
      "89:\tlearn: 0.2738810\ttotal: 252ms\tremaining: 308ms\n",
      "90:\tlearn: 0.2726846\ttotal: 255ms\tremaining: 306ms\n",
      "91:\tlearn: 0.2714680\ttotal: 258ms\tremaining: 303ms\n",
      "92:\tlearn: 0.2703546\ttotal: 261ms\tremaining: 300ms\n",
      "93:\tlearn: 0.2693335\ttotal: 264ms\tremaining: 298ms\n",
      "94:\tlearn: 0.2667991\ttotal: 268ms\tremaining: 296ms\n",
      "95:\tlearn: 0.2654042\ttotal: 270ms\tremaining: 293ms\n",
      "96:\tlearn: 0.2643141\ttotal: 273ms\tremaining: 290ms\n",
      "97:\tlearn: 0.2636869\ttotal: 276ms\tremaining: 287ms\n",
      "98:\tlearn: 0.2629858\ttotal: 280ms\tremaining: 285ms\n",
      "99:\tlearn: 0.2624963\ttotal: 282ms\tremaining: 282ms\n",
      "100:\tlearn: 0.2603180\ttotal: 285ms\tremaining: 279ms\n",
      "101:\tlearn: 0.2586017\ttotal: 287ms\tremaining: 276ms\n",
      "102:\tlearn: 0.2575770\ttotal: 290ms\tremaining: 273ms\n",
      "103:\tlearn: 0.2555562\ttotal: 293ms\tremaining: 270ms\n",
      "104:\tlearn: 0.2546406\ttotal: 296ms\tremaining: 267ms\n",
      "105:\tlearn: 0.2537897\ttotal: 299ms\tremaining: 265ms\n",
      "106:\tlearn: 0.2519247\ttotal: 302ms\tremaining: 262ms\n",
      "107:\tlearn: 0.2509788\ttotal: 305ms\tremaining: 259ms\n",
      "108:\tlearn: 0.2502528\ttotal: 308ms\tremaining: 257ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109:\tlearn: 0.2494224\ttotal: 311ms\tremaining: 254ms\n",
      "110:\tlearn: 0.2482484\ttotal: 313ms\tremaining: 251ms\n",
      "111:\tlearn: 0.2474738\ttotal: 316ms\tremaining: 248ms\n",
      "112:\tlearn: 0.2467331\ttotal: 319ms\tremaining: 246ms\n",
      "113:\tlearn: 0.2455246\ttotal: 322ms\tremaining: 243ms\n",
      "114:\tlearn: 0.2447480\ttotal: 325ms\tremaining: 240ms\n",
      "115:\tlearn: 0.2439997\ttotal: 328ms\tremaining: 237ms\n",
      "116:\tlearn: 0.2430815\ttotal: 330ms\tremaining: 234ms\n",
      "117:\tlearn: 0.2421854\ttotal: 333ms\tremaining: 232ms\n",
      "118:\tlearn: 0.2414421\ttotal: 336ms\tremaining: 228ms\n",
      "119:\tlearn: 0.2396308\ttotal: 338ms\tremaining: 226ms\n",
      "120:\tlearn: 0.2388402\ttotal: 341ms\tremaining: 223ms\n",
      "121:\tlearn: 0.2382734\ttotal: 344ms\tremaining: 220ms\n",
      "122:\tlearn: 0.2376048\ttotal: 347ms\tremaining: 217ms\n",
      "123:\tlearn: 0.2360248\ttotal: 350ms\tremaining: 214ms\n",
      "124:\tlearn: 0.2354170\ttotal: 353ms\tremaining: 212ms\n",
      "125:\tlearn: 0.2346414\ttotal: 356ms\tremaining: 209ms\n",
      "126:\tlearn: 0.2337494\ttotal: 358ms\tremaining: 206ms\n",
      "127:\tlearn: 0.2324892\ttotal: 362ms\tremaining: 203ms\n",
      "128:\tlearn: 0.2308760\ttotal: 364ms\tremaining: 201ms\n",
      "129:\tlearn: 0.2299558\ttotal: 367ms\tremaining: 198ms\n",
      "130:\tlearn: 0.2294328\ttotal: 370ms\tremaining: 195ms\n",
      "131:\tlearn: 0.2287978\ttotal: 373ms\tremaining: 192ms\n",
      "132:\tlearn: 0.2282070\ttotal: 375ms\tremaining: 189ms\n",
      "133:\tlearn: 0.2276633\ttotal: 378ms\tremaining: 186ms\n",
      "134:\tlearn: 0.2263127\ttotal: 381ms\tremaining: 183ms\n",
      "135:\tlearn: 0.2256350\ttotal: 384ms\tremaining: 181ms\n",
      "136:\tlearn: 0.2241794\ttotal: 386ms\tremaining: 178ms\n",
      "137:\tlearn: 0.2237651\ttotal: 389ms\tremaining: 175ms\n",
      "138:\tlearn: 0.2229902\ttotal: 392ms\tremaining: 172ms\n",
      "139:\tlearn: 0.2223454\ttotal: 395ms\tremaining: 169ms\n",
      "140:\tlearn: 0.2218837\ttotal: 397ms\tremaining: 166ms\n",
      "141:\tlearn: 0.2213324\ttotal: 400ms\tremaining: 163ms\n",
      "142:\tlearn: 0.2204947\ttotal: 403ms\tremaining: 161ms\n",
      "143:\tlearn: 0.2199134\ttotal: 406ms\tremaining: 158ms\n",
      "144:\tlearn: 0.2193772\ttotal: 409ms\tremaining: 155ms\n",
      "145:\tlearn: 0.2190001\ttotal: 411ms\tremaining: 152ms\n",
      "146:\tlearn: 0.2184697\ttotal: 414ms\tremaining: 149ms\n",
      "147:\tlearn: 0.2176275\ttotal: 417ms\tremaining: 146ms\n",
      "148:\tlearn: 0.2171660\ttotal: 420ms\tremaining: 144ms\n",
      "149:\tlearn: 0.2161144\ttotal: 423ms\tremaining: 141ms\n",
      "150:\tlearn: 0.2150840\ttotal: 426ms\tremaining: 138ms\n",
      "151:\tlearn: 0.2146700\ttotal: 428ms\tremaining: 135ms\n",
      "152:\tlearn: 0.2139810\ttotal: 432ms\tremaining: 133ms\n",
      "153:\tlearn: 0.2127143\ttotal: 435ms\tremaining: 130ms\n",
      "154:\tlearn: 0.2122427\ttotal: 437ms\tremaining: 127ms\n",
      "155:\tlearn: 0.2118219\ttotal: 440ms\tremaining: 124ms\n",
      "156:\tlearn: 0.2108138\ttotal: 443ms\tremaining: 121ms\n",
      "157:\tlearn: 0.2104049\ttotal: 445ms\tremaining: 118ms\n",
      "158:\tlearn: 0.2093469\ttotal: 448ms\tremaining: 115ms\n",
      "159:\tlearn: 0.2089907\ttotal: 451ms\tremaining: 113ms\n",
      "160:\tlearn: 0.2084838\ttotal: 454ms\tremaining: 110ms\n",
      "161:\tlearn: 0.2080079\ttotal: 456ms\tremaining: 107ms\n",
      "162:\tlearn: 0.2069493\ttotal: 459ms\tremaining: 104ms\n",
      "163:\tlearn: 0.2060417\ttotal: 462ms\tremaining: 101ms\n",
      "164:\tlearn: 0.2055138\ttotal: 464ms\tremaining: 98.5ms\n",
      "165:\tlearn: 0.2045480\ttotal: 467ms\tremaining: 95.6ms\n",
      "166:\tlearn: 0.2041127\ttotal: 470ms\tremaining: 92.8ms\n",
      "167:\tlearn: 0.2035493\ttotal: 472ms\tremaining: 90ms\n",
      "168:\tlearn: 0.2031799\ttotal: 476ms\tremaining: 87.3ms\n",
      "169:\tlearn: 0.2026787\ttotal: 479ms\tremaining: 84.5ms\n",
      "170:\tlearn: 0.2023143\ttotal: 481ms\tremaining: 81.6ms\n",
      "171:\tlearn: 0.2018743\ttotal: 484ms\tremaining: 78.8ms\n",
      "172:\tlearn: 0.2013390\ttotal: 487ms\tremaining: 76ms\n",
      "173:\tlearn: 0.2005167\ttotal: 490ms\tremaining: 73.2ms\n",
      "174:\tlearn: 0.2002131\ttotal: 493ms\tremaining: 70.4ms\n",
      "175:\tlearn: 0.1998599\ttotal: 495ms\tremaining: 67.5ms\n",
      "176:\tlearn: 0.1993849\ttotal: 498ms\tremaining: 64.7ms\n",
      "177:\tlearn: 0.1990317\ttotal: 500ms\tremaining: 61.8ms\n",
      "178:\tlearn: 0.1985724\ttotal: 503ms\tremaining: 59ms\n",
      "179:\tlearn: 0.1982331\ttotal: 506ms\tremaining: 56.3ms\n",
      "180:\tlearn: 0.1978082\ttotal: 509ms\tremaining: 53.5ms\n",
      "181:\tlearn: 0.1973874\ttotal: 513ms\tremaining: 50.7ms\n",
      "182:\tlearn: 0.1971051\ttotal: 515ms\tremaining: 47.9ms\n",
      "183:\tlearn: 0.1962793\ttotal: 518ms\tremaining: 45.1ms\n",
      "184:\tlearn: 0.1955143\ttotal: 521ms\tremaining: 42.2ms\n",
      "185:\tlearn: 0.1951461\ttotal: 524ms\tremaining: 39.4ms\n",
      "186:\tlearn: 0.1946935\ttotal: 526ms\tremaining: 36.6ms\n",
      "187:\tlearn: 0.1942576\ttotal: 529ms\tremaining: 33.8ms\n",
      "188:\tlearn: 0.1939642\ttotal: 532ms\tremaining: 31ms\n",
      "189:\tlearn: 0.1935949\ttotal: 535ms\tremaining: 28.1ms\n",
      "190:\tlearn: 0.1932197\ttotal: 538ms\tremaining: 25.3ms\n",
      "191:\tlearn: 0.1923735\ttotal: 541ms\tremaining: 22.5ms\n",
      "192:\tlearn: 0.1920133\ttotal: 544ms\tremaining: 19.7ms\n",
      "193:\tlearn: 0.1910339\ttotal: 546ms\tremaining: 16.9ms\n",
      "194:\tlearn: 0.1906939\ttotal: 549ms\tremaining: 14.1ms\n",
      "195:\tlearn: 0.1902981\ttotal: 553ms\tremaining: 11.3ms\n",
      "196:\tlearn: 0.1896855\ttotal: 555ms\tremaining: 8.45ms\n",
      "197:\tlearn: 0.1893311\ttotal: 558ms\tremaining: 5.63ms\n",
      "198:\tlearn: 0.1887344\ttotal: 561ms\tremaining: 2.82ms\n",
      "199:\tlearn: 0.1880904\ttotal: 563ms\tremaining: 0us\n",
      "0:\tlearn: 0.6816672\ttotal: 3.05ms\tremaining: 607ms\n",
      "1:\tlearn: 0.6709115\ttotal: 5.58ms\tremaining: 553ms\n",
      "2:\tlearn: 0.6596434\ttotal: 8.34ms\tremaining: 548ms\n",
      "3:\tlearn: 0.6483339\ttotal: 11.1ms\tremaining: 545ms\n",
      "4:\tlearn: 0.6374359\ttotal: 13.5ms\tremaining: 525ms\n",
      "5:\tlearn: 0.6259026\ttotal: 16ms\tremaining: 518ms\n",
      "6:\tlearn: 0.6146484\ttotal: 18.7ms\tremaining: 517ms\n",
      "7:\tlearn: 0.6045290\ttotal: 21.2ms\tremaining: 509ms\n",
      "8:\tlearn: 0.5937368\ttotal: 24.5ms\tremaining: 520ms\n",
      "9:\tlearn: 0.5839931\ttotal: 27.3ms\tremaining: 518ms\n",
      "10:\tlearn: 0.5768903\ttotal: 29.9ms\tremaining: 514ms\n",
      "11:\tlearn: 0.5668303\ttotal: 32.5ms\tremaining: 509ms\n",
      "12:\tlearn: 0.5582618\ttotal: 35.7ms\tremaining: 513ms\n",
      "13:\tlearn: 0.5494647\ttotal: 38.3ms\tremaining: 509ms\n",
      "14:\tlearn: 0.5413875\ttotal: 41.2ms\tremaining: 508ms\n",
      "15:\tlearn: 0.5337984\ttotal: 43.9ms\tremaining: 505ms\n",
      "16:\tlearn: 0.5262701\ttotal: 46.5ms\tremaining: 501ms\n",
      "17:\tlearn: 0.5184517\ttotal: 49.8ms\tremaining: 503ms\n",
      "18:\tlearn: 0.5105951\ttotal: 52.6ms\tremaining: 501ms\n",
      "19:\tlearn: 0.5033604\ttotal: 55.2ms\tremaining: 497ms\n",
      "20:\tlearn: 0.4958802\ttotal: 57.8ms\tremaining: 493ms\n",
      "21:\tlearn: 0.4885660\ttotal: 60.3ms\tremaining: 488ms\n",
      "22:\tlearn: 0.4816621\ttotal: 63.1ms\tremaining: 486ms\n",
      "23:\tlearn: 0.4745879\ttotal: 65.7ms\tremaining: 482ms\n",
      "24:\tlearn: 0.4684575\ttotal: 68.5ms\tremaining: 479ms\n",
      "25:\tlearn: 0.4619780\ttotal: 71.2ms\tremaining: 476ms\n",
      "26:\tlearn: 0.4560152\ttotal: 74.6ms\tremaining: 478ms\n",
      "27:\tlearn: 0.4497230\ttotal: 77.5ms\tremaining: 476ms\n",
      "28:\tlearn: 0.4433585\ttotal: 80ms\tremaining: 471ms\n",
      "29:\tlearn: 0.4381405\ttotal: 82.6ms\tremaining: 468ms\n",
      "30:\tlearn: 0.4332479\ttotal: 85.1ms\tremaining: 464ms\n",
      "31:\tlearn: 0.4289205\ttotal: 88.3ms\tremaining: 464ms\n",
      "32:\tlearn: 0.4240325\ttotal: 91ms\tremaining: 460ms\n",
      "33:\tlearn: 0.4205973\ttotal: 94ms\tremaining: 459ms\n",
      "34:\tlearn: 0.4154498\ttotal: 96.9ms\tremaining: 457ms\n",
      "35:\tlearn: 0.4108850\ttotal: 100ms\tremaining: 457ms\n",
      "36:\tlearn: 0.4070863\ttotal: 103ms\tremaining: 456ms\n",
      "37:\tlearn: 0.4025367\ttotal: 106ms\tremaining: 452ms\n",
      "38:\tlearn: 0.3982851\ttotal: 109ms\tremaining: 449ms\n",
      "39:\tlearn: 0.3935677\ttotal: 112ms\tremaining: 448ms\n",
      "40:\tlearn: 0.3893279\ttotal: 115ms\tremaining: 445ms\n",
      "41:\tlearn: 0.3861946\ttotal: 118ms\tremaining: 442ms\n",
      "42:\tlearn: 0.3824027\ttotal: 120ms\tremaining: 439ms\n",
      "43:\tlearn: 0.3782454\ttotal: 123ms\tremaining: 437ms\n",
      "44:\tlearn: 0.3743628\ttotal: 126ms\tremaining: 433ms\n",
      "45:\tlearn: 0.3714675\ttotal: 129ms\tremaining: 431ms\n",
      "46:\tlearn: 0.3682533\ttotal: 131ms\tremaining: 427ms\n",
      "47:\tlearn: 0.3645670\ttotal: 134ms\tremaining: 424ms\n",
      "48:\tlearn: 0.3608292\ttotal: 136ms\tremaining: 420ms\n",
      "49:\tlearn: 0.3579894\ttotal: 139ms\tremaining: 417ms\n",
      "50:\tlearn: 0.3549075\ttotal: 142ms\tremaining: 414ms\n",
      "51:\tlearn: 0.3521327\ttotal: 144ms\tremaining: 411ms\n",
      "52:\tlearn: 0.3495736\ttotal: 147ms\tremaining: 407ms\n",
      "53:\tlearn: 0.3463447\ttotal: 149ms\tremaining: 404ms\n",
      "54:\tlearn: 0.3438839\ttotal: 152ms\tremaining: 401ms\n",
      "55:\tlearn: 0.3411546\ttotal: 155ms\tremaining: 398ms\n",
      "56:\tlearn: 0.3391684\ttotal: 158ms\tremaining: 395ms\n",
      "57:\tlearn: 0.3359883\ttotal: 160ms\tremaining: 392ms\n",
      "58:\tlearn: 0.3338174\ttotal: 162ms\tremaining: 388ms\n",
      "59:\tlearn: 0.3314224\ttotal: 165ms\tremaining: 385ms\n",
      "60:\tlearn: 0.3279988\ttotal: 168ms\tremaining: 382ms\n",
      "61:\tlearn: 0.3257082\ttotal: 170ms\tremaining: 379ms\n",
      "62:\tlearn: 0.3231504\ttotal: 173ms\tremaining: 376ms\n",
      "63:\tlearn: 0.3193270\ttotal: 176ms\tremaining: 374ms\n",
      "64:\tlearn: 0.3172133\ttotal: 179ms\tremaining: 371ms\n",
      "65:\tlearn: 0.3150456\ttotal: 182ms\tremaining: 369ms\n",
      "66:\tlearn: 0.3128594\ttotal: 185ms\tremaining: 367ms\n",
      "67:\tlearn: 0.3108888\ttotal: 187ms\tremaining: 364ms\n",
      "68:\tlearn: 0.3096229\ttotal: 190ms\tremaining: 360ms\n",
      "69:\tlearn: 0.3078118\ttotal: 193ms\tremaining: 358ms\n",
      "70:\tlearn: 0.3062614\ttotal: 196ms\tremaining: 356ms\n",
      "71:\tlearn: 0.3042896\ttotal: 200ms\tremaining: 355ms\n",
      "72:\tlearn: 0.3023618\ttotal: 202ms\tremaining: 352ms\n",
      "73:\tlearn: 0.3008575\ttotal: 205ms\tremaining: 349ms\n",
      "74:\tlearn: 0.2990264\ttotal: 208ms\tremaining: 346ms\n",
      "75:\tlearn: 0.2980372\ttotal: 211ms\tremaining: 344ms\n",
      "76:\tlearn: 0.2954860\ttotal: 213ms\tremaining: 341ms\n",
      "77:\tlearn: 0.2936080\ttotal: 216ms\tremaining: 338ms\n",
      "78:\tlearn: 0.2921738\ttotal: 219ms\tremaining: 335ms\n",
      "79:\tlearn: 0.2904839\ttotal: 222ms\tremaining: 333ms\n",
      "80:\tlearn: 0.2882892\ttotal: 224ms\tremaining: 329ms\n",
      "81:\tlearn: 0.2866612\ttotal: 227ms\tremaining: 327ms\n",
      "82:\tlearn: 0.2841065\ttotal: 229ms\tremaining: 323ms\n",
      "83:\tlearn: 0.2824298\ttotal: 232ms\tremaining: 321ms\n",
      "84:\tlearn: 0.2815289\ttotal: 235ms\tremaining: 319ms\n",
      "85:\tlearn: 0.2802349\ttotal: 238ms\tremaining: 316ms\n",
      "86:\tlearn: 0.2789213\ttotal: 242ms\tremaining: 314ms\n",
      "87:\tlearn: 0.2776525\ttotal: 245ms\tremaining: 311ms\n",
      "88:\tlearn: 0.2764599\ttotal: 248ms\tremaining: 309ms\n",
      "89:\tlearn: 0.2754033\ttotal: 250ms\tremaining: 306ms\n",
      "90:\tlearn: 0.2735923\ttotal: 253ms\tremaining: 303ms\n",
      "91:\tlearn: 0.2728959\ttotal: 256ms\tremaining: 301ms\n",
      "92:\tlearn: 0.2716743\ttotal: 259ms\tremaining: 298ms\n",
      "93:\tlearn: 0.2695878\ttotal: 262ms\tremaining: 295ms\n",
      "94:\tlearn: 0.2668902\ttotal: 265ms\tremaining: 292ms\n",
      "95:\tlearn: 0.2656068\ttotal: 267ms\tremaining: 290ms\n",
      "96:\tlearn: 0.2647216\ttotal: 270ms\tremaining: 287ms\n",
      "97:\tlearn: 0.2636296\ttotal: 273ms\tremaining: 284ms\n",
      "98:\tlearn: 0.2623013\ttotal: 276ms\tremaining: 281ms\n",
      "99:\tlearn: 0.2613406\ttotal: 279ms\tremaining: 279ms\n",
      "100:\tlearn: 0.2592980\ttotal: 281ms\tremaining: 276ms\n",
      "101:\tlearn: 0.2584034\ttotal: 284ms\tremaining: 273ms\n",
      "102:\tlearn: 0.2578969\ttotal: 288ms\tremaining: 271ms\n",
      "103:\tlearn: 0.2565077\ttotal: 291ms\tremaining: 269ms\n",
      "104:\tlearn: 0.2553956\ttotal: 294ms\tremaining: 266ms\n",
      "105:\tlearn: 0.2532487\ttotal: 296ms\tremaining: 263ms\n",
      "106:\tlearn: 0.2514866\ttotal: 299ms\tremaining: 260ms\n",
      "107:\tlearn: 0.2506561\ttotal: 302ms\tremaining: 257ms\n",
      "108:\tlearn: 0.2497065\ttotal: 305ms\tremaining: 255ms\n",
      "109:\tlearn: 0.2490388\ttotal: 308ms\tremaining: 252ms\n",
      "110:\tlearn: 0.2481019\ttotal: 311ms\tremaining: 249ms\n",
      "111:\tlearn: 0.2472674\ttotal: 314ms\tremaining: 247ms\n",
      "112:\tlearn: 0.2457340\ttotal: 317ms\tremaining: 244ms\n",
      "113:\tlearn: 0.2438652\ttotal: 320ms\tremaining: 242ms\n",
      "114:\tlearn: 0.2423822\ttotal: 324ms\tremaining: 240ms\n",
      "115:\tlearn: 0.2418222\ttotal: 327ms\tremaining: 237ms\n",
      "116:\tlearn: 0.2412896\ttotal: 330ms\tremaining: 234ms\n",
      "117:\tlearn: 0.2403917\ttotal: 333ms\tremaining: 231ms\n",
      "118:\tlearn: 0.2393595\ttotal: 335ms\tremaining: 228ms\n",
      "119:\tlearn: 0.2387174\ttotal: 338ms\tremaining: 225ms\n",
      "120:\tlearn: 0.2377580\ttotal: 341ms\tremaining: 223ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121:\tlearn: 0.2363233\ttotal: 344ms\tremaining: 220ms\n",
      "122:\tlearn: 0.2355107\ttotal: 346ms\tremaining: 217ms\n",
      "123:\tlearn: 0.2347312\ttotal: 349ms\tremaining: 214ms\n",
      "124:\tlearn: 0.2340844\ttotal: 351ms\tremaining: 211ms\n",
      "125:\tlearn: 0.2326226\ttotal: 355ms\tremaining: 208ms\n",
      "126:\tlearn: 0.2317012\ttotal: 357ms\tremaining: 205ms\n",
      "127:\tlearn: 0.2310436\ttotal: 360ms\tremaining: 203ms\n",
      "128:\tlearn: 0.2295613\ttotal: 363ms\tremaining: 200ms\n",
      "129:\tlearn: 0.2283238\ttotal: 365ms\tremaining: 197ms\n",
      "130:\tlearn: 0.2277167\ttotal: 368ms\tremaining: 194ms\n",
      "131:\tlearn: 0.2269584\ttotal: 371ms\tremaining: 191ms\n",
      "132:\tlearn: 0.2263585\ttotal: 374ms\tremaining: 188ms\n",
      "133:\tlearn: 0.2256687\ttotal: 376ms\tremaining: 185ms\n",
      "134:\tlearn: 0.2246260\ttotal: 379ms\tremaining: 182ms\n",
      "135:\tlearn: 0.2232504\ttotal: 382ms\tremaining: 180ms\n",
      "136:\tlearn: 0.2224068\ttotal: 385ms\tremaining: 177ms\n",
      "137:\tlearn: 0.2217755\ttotal: 387ms\tremaining: 174ms\n",
      "138:\tlearn: 0.2211715\ttotal: 390ms\tremaining: 171ms\n",
      "139:\tlearn: 0.2205293\ttotal: 393ms\tremaining: 168ms\n",
      "140:\tlearn: 0.2198696\ttotal: 396ms\tremaining: 166ms\n",
      "141:\tlearn: 0.2193584\ttotal: 399ms\tremaining: 163ms\n",
      "142:\tlearn: 0.2187178\ttotal: 401ms\tremaining: 160ms\n",
      "143:\tlearn: 0.2176331\ttotal: 404ms\tremaining: 157ms\n",
      "144:\tlearn: 0.2171752\ttotal: 406ms\tremaining: 154ms\n",
      "145:\tlearn: 0.2166777\ttotal: 409ms\tremaining: 151ms\n",
      "146:\tlearn: 0.2162018\ttotal: 412ms\tremaining: 149ms\n",
      "147:\tlearn: 0.2155460\ttotal: 414ms\tremaining: 146ms\n",
      "148:\tlearn: 0.2147218\ttotal: 417ms\tremaining: 143ms\n",
      "149:\tlearn: 0.2142539\ttotal: 420ms\tremaining: 140ms\n",
      "150:\tlearn: 0.2129774\ttotal: 422ms\tremaining: 137ms\n",
      "151:\tlearn: 0.2123844\ttotal: 425ms\tremaining: 134ms\n",
      "152:\tlearn: 0.2118412\ttotal: 428ms\tremaining: 131ms\n",
      "153:\tlearn: 0.2106364\ttotal: 432ms\tremaining: 129ms\n",
      "154:\tlearn: 0.2102375\ttotal: 434ms\tremaining: 126ms\n",
      "155:\tlearn: 0.2095415\ttotal: 437ms\tremaining: 123ms\n",
      "156:\tlearn: 0.2090197\ttotal: 440ms\tremaining: 121ms\n",
      "157:\tlearn: 0.2084612\ttotal: 443ms\tremaining: 118ms\n",
      "158:\tlearn: 0.2075816\ttotal: 446ms\tremaining: 115ms\n",
      "159:\tlearn: 0.2071174\ttotal: 449ms\tremaining: 112ms\n",
      "160:\tlearn: 0.2066910\ttotal: 452ms\tremaining: 109ms\n",
      "161:\tlearn: 0.2063096\ttotal: 454ms\tremaining: 107ms\n",
      "162:\tlearn: 0.2058165\ttotal: 457ms\tremaining: 104ms\n",
      "163:\tlearn: 0.2054893\ttotal: 460ms\tremaining: 101ms\n",
      "164:\tlearn: 0.2052303\ttotal: 463ms\tremaining: 98.2ms\n",
      "165:\tlearn: 0.2048352\ttotal: 466ms\tremaining: 95.4ms\n",
      "166:\tlearn: 0.2043172\ttotal: 468ms\tremaining: 92.5ms\n",
      "167:\tlearn: 0.2039397\ttotal: 471ms\tremaining: 89.7ms\n",
      "168:\tlearn: 0.2035615\ttotal: 474ms\tremaining: 86.9ms\n",
      "169:\tlearn: 0.2029358\ttotal: 477ms\tremaining: 84.1ms\n",
      "170:\tlearn: 0.2023987\ttotal: 479ms\tremaining: 81.3ms\n",
      "171:\tlearn: 0.2013908\ttotal: 484ms\tremaining: 78.8ms\n",
      "172:\tlearn: 0.2010398\ttotal: 487ms\tremaining: 76.1ms\n",
      "173:\tlearn: 0.2006923\ttotal: 490ms\tremaining: 73.2ms\n",
      "174:\tlearn: 0.1996972\ttotal: 494ms\tremaining: 70.5ms\n",
      "175:\tlearn: 0.1993497\ttotal: 496ms\tremaining: 67.7ms\n",
      "176:\tlearn: 0.1990562\ttotal: 499ms\tremaining: 64.9ms\n",
      "177:\tlearn: 0.1985964\ttotal: 502ms\tremaining: 62.1ms\n",
      "178:\tlearn: 0.1981465\ttotal: 505ms\tremaining: 59.3ms\n",
      "179:\tlearn: 0.1973080\ttotal: 508ms\tremaining: 56.4ms\n",
      "180:\tlearn: 0.1970497\ttotal: 511ms\tremaining: 53.6ms\n",
      "181:\tlearn: 0.1962227\ttotal: 515ms\tremaining: 50.9ms\n",
      "182:\tlearn: 0.1954354\ttotal: 517ms\tremaining: 48ms\n",
      "183:\tlearn: 0.1951216\ttotal: 520ms\tremaining: 45.2ms\n",
      "184:\tlearn: 0.1946785\ttotal: 523ms\tremaining: 42.4ms\n",
      "185:\tlearn: 0.1944287\ttotal: 525ms\tremaining: 39.5ms\n",
      "186:\tlearn: 0.1936472\ttotal: 528ms\tremaining: 36.7ms\n",
      "187:\tlearn: 0.1929219\ttotal: 531ms\tremaining: 33.9ms\n",
      "188:\tlearn: 0.1925399\ttotal: 534ms\tremaining: 31.1ms\n",
      "189:\tlearn: 0.1918154\ttotal: 537ms\tremaining: 28.2ms\n",
      "190:\tlearn: 0.1914031\ttotal: 540ms\tremaining: 25.5ms\n",
      "191:\tlearn: 0.1905217\ttotal: 543ms\tremaining: 22.6ms\n",
      "192:\tlearn: 0.1901810\ttotal: 546ms\tremaining: 19.8ms\n",
      "193:\tlearn: 0.1898904\ttotal: 548ms\tremaining: 17ms\n",
      "194:\tlearn: 0.1895064\ttotal: 551ms\tremaining: 14.1ms\n",
      "195:\tlearn: 0.1889308\ttotal: 554ms\tremaining: 11.3ms\n",
      "196:\tlearn: 0.1880552\ttotal: 557ms\tremaining: 8.47ms\n",
      "197:\tlearn: 0.1873848\ttotal: 559ms\tremaining: 5.65ms\n",
      "198:\tlearn: 0.1870218\ttotal: 562ms\tremaining: 2.82ms\n",
      "199:\tlearn: 0.1866676\ttotal: 565ms\tremaining: 0us\n",
      "0:\tlearn: 0.6808508\ttotal: 2.59ms\tremaining: 516ms\n",
      "1:\tlearn: 0.6678565\ttotal: 4.92ms\tremaining: 488ms\n",
      "2:\tlearn: 0.6568093\ttotal: 8.21ms\tremaining: 539ms\n",
      "3:\tlearn: 0.6454059\ttotal: 10.7ms\tremaining: 527ms\n",
      "4:\tlearn: 0.6342462\ttotal: 13.4ms\tremaining: 522ms\n",
      "5:\tlearn: 0.6226243\ttotal: 16.1ms\tremaining: 520ms\n",
      "6:\tlearn: 0.6116882\ttotal: 19.5ms\tremaining: 537ms\n",
      "7:\tlearn: 0.6017754\ttotal: 22.9ms\tremaining: 550ms\n",
      "8:\tlearn: 0.5911816\ttotal: 25.4ms\tremaining: 540ms\n",
      "9:\tlearn: 0.5815033\ttotal: 28ms\tremaining: 532ms\n",
      "10:\tlearn: 0.5727017\ttotal: 30.6ms\tremaining: 526ms\n",
      "11:\tlearn: 0.5642483\ttotal: 33.3ms\tremaining: 522ms\n",
      "12:\tlearn: 0.5553070\ttotal: 36.2ms\tremaining: 520ms\n",
      "13:\tlearn: 0.5473503\ttotal: 38.8ms\tremaining: 516ms\n",
      "14:\tlearn: 0.5398498\ttotal: 41.4ms\tremaining: 510ms\n",
      "15:\tlearn: 0.5322978\ttotal: 44.1ms\tremaining: 507ms\n",
      "16:\tlearn: 0.5242137\ttotal: 46.7ms\tremaining: 503ms\n",
      "17:\tlearn: 0.5169093\ttotal: 49.4ms\tremaining: 499ms\n",
      "18:\tlearn: 0.5091650\ttotal: 52ms\tremaining: 496ms\n",
      "19:\tlearn: 0.5013677\ttotal: 55.2ms\tremaining: 497ms\n",
      "20:\tlearn: 0.4942017\ttotal: 57.8ms\tremaining: 492ms\n",
      "21:\tlearn: 0.4867401\ttotal: 60.4ms\tremaining: 489ms\n",
      "22:\tlearn: 0.4814780\ttotal: 63.9ms\tremaining: 492ms\n",
      "23:\tlearn: 0.4748857\ttotal: 66.7ms\tremaining: 489ms\n",
      "24:\tlearn: 0.4680073\ttotal: 69.3ms\tremaining: 485ms\n",
      "25:\tlearn: 0.4617882\ttotal: 72ms\tremaining: 482ms\n",
      "26:\tlearn: 0.4563537\ttotal: 74.7ms\tremaining: 479ms\n",
      "27:\tlearn: 0.4496524\ttotal: 77.3ms\tremaining: 475ms\n",
      "28:\tlearn: 0.4435754\ttotal: 79.8ms\tremaining: 470ms\n",
      "29:\tlearn: 0.4383520\ttotal: 82.4ms\tremaining: 467ms\n",
      "30:\tlearn: 0.4333776\ttotal: 85.2ms\tremaining: 464ms\n",
      "31:\tlearn: 0.4295296\ttotal: 87.8ms\tremaining: 461ms\n",
      "32:\tlearn: 0.4249247\ttotal: 90.5ms\tremaining: 458ms\n",
      "33:\tlearn: 0.4206243\ttotal: 93.3ms\tremaining: 456ms\n",
      "34:\tlearn: 0.4150001\ttotal: 96.1ms\tremaining: 453ms\n",
      "35:\tlearn: 0.4105382\ttotal: 99.1ms\tremaining: 451ms\n",
      "36:\tlearn: 0.4070424\ttotal: 102ms\tremaining: 448ms\n",
      "37:\tlearn: 0.4025775\ttotal: 104ms\tremaining: 445ms\n",
      "38:\tlearn: 0.3983863\ttotal: 107ms\tremaining: 442ms\n",
      "39:\tlearn: 0.3942621\ttotal: 110ms\tremaining: 439ms\n",
      "40:\tlearn: 0.3904434\ttotal: 113ms\tremaining: 437ms\n",
      "41:\tlearn: 0.3863095\ttotal: 116ms\tremaining: 435ms\n",
      "42:\tlearn: 0.3824620\ttotal: 119ms\tremaining: 434ms\n",
      "43:\tlearn: 0.3783878\ttotal: 122ms\tremaining: 433ms\n",
      "44:\tlearn: 0.3745963\ttotal: 125ms\tremaining: 430ms\n",
      "45:\tlearn: 0.3715966\ttotal: 128ms\tremaining: 428ms\n",
      "46:\tlearn: 0.3691422\ttotal: 131ms\tremaining: 425ms\n",
      "47:\tlearn: 0.3651503\ttotal: 134ms\tremaining: 423ms\n",
      "48:\tlearn: 0.3613148\ttotal: 136ms\tremaining: 421ms\n",
      "49:\tlearn: 0.3581290\ttotal: 139ms\tremaining: 417ms\n",
      "50:\tlearn: 0.3547382\ttotal: 142ms\tremaining: 416ms\n",
      "51:\tlearn: 0.3519203\ttotal: 145ms\tremaining: 413ms\n",
      "52:\tlearn: 0.3492609\ttotal: 148ms\tremaining: 411ms\n",
      "53:\tlearn: 0.3463055\ttotal: 151ms\tremaining: 407ms\n",
      "54:\tlearn: 0.3438349\ttotal: 153ms\tremaining: 404ms\n",
      "55:\tlearn: 0.3411886\ttotal: 156ms\tremaining: 401ms\n",
      "56:\tlearn: 0.3386280\ttotal: 160ms\tremaining: 400ms\n",
      "57:\tlearn: 0.3365644\ttotal: 162ms\tremaining: 397ms\n",
      "58:\tlearn: 0.3337899\ttotal: 165ms\tremaining: 394ms\n",
      "59:\tlearn: 0.3313461\ttotal: 168ms\tremaining: 391ms\n",
      "60:\tlearn: 0.3290857\ttotal: 171ms\tremaining: 390ms\n",
      "61:\tlearn: 0.3265307\ttotal: 174ms\tremaining: 387ms\n",
      "62:\tlearn: 0.3239203\ttotal: 177ms\tremaining: 385ms\n",
      "63:\tlearn: 0.3211880\ttotal: 180ms\tremaining: 382ms\n",
      "64:\tlearn: 0.3190765\ttotal: 183ms\tremaining: 379ms\n",
      "65:\tlearn: 0.3174204\ttotal: 185ms\tremaining: 376ms\n",
      "66:\tlearn: 0.3151793\ttotal: 188ms\tremaining: 374ms\n",
      "67:\tlearn: 0.3132160\ttotal: 191ms\tremaining: 371ms\n",
      "68:\tlearn: 0.3106854\ttotal: 194ms\tremaining: 368ms\n",
      "69:\tlearn: 0.3088963\ttotal: 197ms\tremaining: 366ms\n",
      "70:\tlearn: 0.3069976\ttotal: 200ms\tremaining: 363ms\n",
      "71:\tlearn: 0.3045141\ttotal: 203ms\tremaining: 361ms\n",
      "72:\tlearn: 0.3033086\ttotal: 206ms\tremaining: 358ms\n",
      "73:\tlearn: 0.3020064\ttotal: 209ms\tremaining: 355ms\n",
      "74:\tlearn: 0.3004617\ttotal: 212ms\tremaining: 353ms\n",
      "75:\tlearn: 0.2984321\ttotal: 214ms\tremaining: 350ms\n",
      "76:\tlearn: 0.2951451\ttotal: 217ms\tremaining: 347ms\n",
      "77:\tlearn: 0.2940341\ttotal: 220ms\tremaining: 344ms\n",
      "78:\tlearn: 0.2916094\ttotal: 222ms\tremaining: 341ms\n",
      "79:\tlearn: 0.2899548\ttotal: 225ms\tremaining: 338ms\n",
      "80:\tlearn: 0.2880072\ttotal: 228ms\tremaining: 335ms\n",
      "81:\tlearn: 0.2852002\ttotal: 230ms\tremaining: 332ms\n",
      "82:\tlearn: 0.2842599\ttotal: 233ms\tremaining: 329ms\n",
      "83:\tlearn: 0.2829951\ttotal: 236ms\tremaining: 326ms\n",
      "84:\tlearn: 0.2802140\ttotal: 239ms\tremaining: 323ms\n",
      "85:\tlearn: 0.2791732\ttotal: 242ms\tremaining: 321ms\n",
      "86:\tlearn: 0.2779998\ttotal: 245ms\tremaining: 318ms\n",
      "87:\tlearn: 0.2764489\ttotal: 247ms\tremaining: 315ms\n",
      "88:\tlearn: 0.2754620\ttotal: 251ms\tremaining: 313ms\n",
      "89:\tlearn: 0.2745529\ttotal: 254ms\tremaining: 310ms\n",
      "90:\tlearn: 0.2722141\ttotal: 257ms\tremaining: 308ms\n",
      "91:\tlearn: 0.2710695\ttotal: 259ms\tremaining: 305ms\n",
      "92:\tlearn: 0.2697771\ttotal: 262ms\tremaining: 302ms\n",
      "93:\tlearn: 0.2685823\ttotal: 265ms\tremaining: 299ms\n",
      "94:\tlearn: 0.2675491\ttotal: 268ms\tremaining: 296ms\n",
      "95:\tlearn: 0.2660813\ttotal: 270ms\tremaining: 293ms\n",
      "96:\tlearn: 0.2648767\ttotal: 273ms\tremaining: 290ms\n",
      "97:\tlearn: 0.2629201\ttotal: 276ms\tremaining: 287ms\n",
      "98:\tlearn: 0.2616614\ttotal: 279ms\tremaining: 285ms\n",
      "99:\tlearn: 0.2610565\ttotal: 282ms\tremaining: 282ms\n",
      "100:\tlearn: 0.2599099\ttotal: 284ms\tremaining: 279ms\n",
      "101:\tlearn: 0.2589417\ttotal: 287ms\tremaining: 276ms\n",
      "102:\tlearn: 0.2578284\ttotal: 290ms\tremaining: 273ms\n",
      "103:\tlearn: 0.2567489\ttotal: 293ms\tremaining: 270ms\n",
      "104:\tlearn: 0.2557887\ttotal: 295ms\tremaining: 267ms\n",
      "105:\tlearn: 0.2549856\ttotal: 298ms\tremaining: 264ms\n",
      "106:\tlearn: 0.2530371\ttotal: 301ms\tremaining: 261ms\n",
      "107:\tlearn: 0.2522207\ttotal: 304ms\tremaining: 259ms\n",
      "108:\tlearn: 0.2514356\ttotal: 307ms\tremaining: 256ms\n",
      "109:\tlearn: 0.2504317\ttotal: 309ms\tremaining: 253ms\n",
      "110:\tlearn: 0.2483564\ttotal: 312ms\tremaining: 250ms\n",
      "111:\tlearn: 0.2472398\ttotal: 315ms\tremaining: 247ms\n",
      "112:\tlearn: 0.2465603\ttotal: 317ms\tremaining: 244ms\n",
      "113:\tlearn: 0.2454988\ttotal: 320ms\tremaining: 242ms\n",
      "114:\tlearn: 0.2446416\ttotal: 323ms\tremaining: 239ms\n",
      "115:\tlearn: 0.2439109\ttotal: 327ms\tremaining: 237ms\n",
      "116:\tlearn: 0.2433077\ttotal: 329ms\tremaining: 234ms\n",
      "117:\tlearn: 0.2423734\ttotal: 332ms\tremaining: 231ms\n",
      "118:\tlearn: 0.2416100\ttotal: 335ms\tremaining: 228ms\n",
      "119:\tlearn: 0.2406715\ttotal: 338ms\tremaining: 225ms\n",
      "120:\tlearn: 0.2399601\ttotal: 340ms\tremaining: 222ms\n",
      "121:\tlearn: 0.2395142\ttotal: 343ms\tremaining: 219ms\n",
      "122:\tlearn: 0.2380826\ttotal: 346ms\tremaining: 216ms\n",
      "123:\tlearn: 0.2373967\ttotal: 349ms\tremaining: 214ms\n",
      "124:\tlearn: 0.2367354\ttotal: 351ms\tremaining: 211ms\n",
      "125:\tlearn: 0.2360060\ttotal: 354ms\tremaining: 208ms\n",
      "126:\tlearn: 0.2343483\ttotal: 357ms\tremaining: 205ms\n",
      "127:\tlearn: 0.2329640\ttotal: 359ms\tremaining: 202ms\n",
      "128:\tlearn: 0.2311763\ttotal: 362ms\tremaining: 199ms\n",
      "129:\tlearn: 0.2302414\ttotal: 365ms\tremaining: 196ms\n",
      "130:\tlearn: 0.2295530\ttotal: 367ms\tremaining: 193ms\n",
      "131:\tlearn: 0.2287863\ttotal: 370ms\tremaining: 191ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132:\tlearn: 0.2275015\ttotal: 372ms\tremaining: 188ms\n",
      "133:\tlearn: 0.2261416\ttotal: 376ms\tremaining: 185ms\n",
      "134:\tlearn: 0.2248988\ttotal: 378ms\tremaining: 182ms\n",
      "135:\tlearn: 0.2242381\ttotal: 382ms\tremaining: 180ms\n",
      "136:\tlearn: 0.2236030\ttotal: 385ms\tremaining: 177ms\n",
      "137:\tlearn: 0.2231575\ttotal: 387ms\tremaining: 174ms\n",
      "138:\tlearn: 0.2226915\ttotal: 390ms\tremaining: 171ms\n",
      "139:\tlearn: 0.2221630\ttotal: 398ms\tremaining: 171ms\n",
      "140:\tlearn: 0.2215450\ttotal: 402ms\tremaining: 168ms\n",
      "141:\tlearn: 0.2204441\ttotal: 404ms\tremaining: 165ms\n",
      "142:\tlearn: 0.2199114\ttotal: 407ms\tremaining: 162ms\n",
      "143:\tlearn: 0.2192779\ttotal: 410ms\tremaining: 160ms\n",
      "144:\tlearn: 0.2181874\ttotal: 414ms\tremaining: 157ms\n",
      "145:\tlearn: 0.2176245\ttotal: 417ms\tremaining: 154ms\n",
      "146:\tlearn: 0.2170730\ttotal: 420ms\tremaining: 151ms\n",
      "147:\tlearn: 0.2164855\ttotal: 422ms\tremaining: 148ms\n",
      "148:\tlearn: 0.2161010\ttotal: 425ms\tremaining: 146ms\n",
      "149:\tlearn: 0.2157024\ttotal: 428ms\tremaining: 143ms\n",
      "150:\tlearn: 0.2153072\ttotal: 431ms\tremaining: 140ms\n",
      "151:\tlearn: 0.2146198\ttotal: 434ms\tremaining: 137ms\n",
      "152:\tlearn: 0.2140995\ttotal: 437ms\tremaining: 134ms\n",
      "153:\tlearn: 0.2135485\ttotal: 440ms\tremaining: 131ms\n",
      "154:\tlearn: 0.2131467\ttotal: 442ms\tremaining: 128ms\n",
      "155:\tlearn: 0.2125424\ttotal: 445ms\tremaining: 126ms\n",
      "156:\tlearn: 0.2120881\ttotal: 448ms\tremaining: 123ms\n",
      "157:\tlearn: 0.2117650\ttotal: 451ms\tremaining: 120ms\n",
      "158:\tlearn: 0.2113725\ttotal: 454ms\tremaining: 117ms\n",
      "159:\tlearn: 0.2108810\ttotal: 457ms\tremaining: 114ms\n",
      "160:\tlearn: 0.2103799\ttotal: 460ms\tremaining: 111ms\n",
      "161:\tlearn: 0.2099446\ttotal: 463ms\tremaining: 109ms\n",
      "162:\tlearn: 0.2090333\ttotal: 465ms\tremaining: 106ms\n",
      "163:\tlearn: 0.2080250\ttotal: 468ms\tremaining: 103ms\n",
      "164:\tlearn: 0.2070272\ttotal: 471ms\tremaining: 99.8ms\n",
      "165:\tlearn: 0.2060669\ttotal: 474ms\tremaining: 97.1ms\n",
      "166:\tlearn: 0.2056519\ttotal: 477ms\tremaining: 94.2ms\n",
      "167:\tlearn: 0.2051507\ttotal: 479ms\tremaining: 91.3ms\n",
      "168:\tlearn: 0.2048945\ttotal: 482ms\tremaining: 88.4ms\n",
      "169:\tlearn: 0.2045767\ttotal: 485ms\tremaining: 85.5ms\n",
      "170:\tlearn: 0.2041141\ttotal: 488ms\tremaining: 82.7ms\n",
      "171:\tlearn: 0.2038198\ttotal: 491ms\tremaining: 79.9ms\n",
      "172:\tlearn: 0.2028266\ttotal: 494ms\tremaining: 77.1ms\n",
      "173:\tlearn: 0.2024684\ttotal: 497ms\tremaining: 74.3ms\n",
      "174:\tlearn: 0.2020201\ttotal: 500ms\tremaining: 71.4ms\n",
      "175:\tlearn: 0.2014322\ttotal: 502ms\tremaining: 68.5ms\n",
      "176:\tlearn: 0.2005959\ttotal: 505ms\tremaining: 65.6ms\n",
      "177:\tlearn: 0.1996866\ttotal: 508ms\tremaining: 62.8ms\n",
      "178:\tlearn: 0.1992677\ttotal: 511ms\tremaining: 59.9ms\n",
      "179:\tlearn: 0.1987029\ttotal: 514ms\tremaining: 57.1ms\n",
      "180:\tlearn: 0.1983497\ttotal: 516ms\tremaining: 54.2ms\n",
      "181:\tlearn: 0.1979308\ttotal: 520ms\tremaining: 51.4ms\n",
      "182:\tlearn: 0.1976821\ttotal: 523ms\tremaining: 48.5ms\n",
      "183:\tlearn: 0.1969499\ttotal: 525ms\tremaining: 45.7ms\n",
      "184:\tlearn: 0.1966332\ttotal: 528ms\tremaining: 42.8ms\n",
      "185:\tlearn: 0.1961674\ttotal: 532ms\tremaining: 40ms\n",
      "186:\tlearn: 0.1956834\ttotal: 534ms\tremaining: 37.1ms\n",
      "187:\tlearn: 0.1948041\ttotal: 537ms\tremaining: 34.3ms\n",
      "188:\tlearn: 0.1944290\ttotal: 540ms\tremaining: 31.4ms\n",
      "189:\tlearn: 0.1939736\ttotal: 542ms\tremaining: 28.5ms\n",
      "190:\tlearn: 0.1932640\ttotal: 545ms\tremaining: 25.7ms\n",
      "191:\tlearn: 0.1923775\ttotal: 548ms\tremaining: 22.8ms\n",
      "192:\tlearn: 0.1921017\ttotal: 550ms\tremaining: 20ms\n",
      "193:\tlearn: 0.1913009\ttotal: 553ms\tremaining: 17.1ms\n",
      "194:\tlearn: 0.1909547\ttotal: 555ms\tremaining: 14.2ms\n",
      "195:\tlearn: 0.1902330\ttotal: 558ms\tremaining: 11.4ms\n",
      "196:\tlearn: 0.1896373\ttotal: 561ms\tremaining: 8.54ms\n",
      "197:\tlearn: 0.1894097\ttotal: 564ms\tremaining: 5.7ms\n",
      "198:\tlearn: 0.1890110\ttotal: 567ms\tremaining: 2.85ms\n",
      "199:\tlearn: 0.1883262\ttotal: 569ms\tremaining: 0us\n",
      "0:\tlearn: 0.6300079\ttotal: 2.65ms\tremaining: 527ms\n",
      "1:\tlearn: 0.5813753\ttotal: 5.2ms\tremaining: 515ms\n",
      "2:\tlearn: 0.5380096\ttotal: 7.83ms\tremaining: 514ms\n",
      "3:\tlearn: 0.4996249\ttotal: 10.6ms\tremaining: 518ms\n",
      "4:\tlearn: 0.4598131\ttotal: 13.2ms\tremaining: 514ms\n",
      "5:\tlearn: 0.4320764\ttotal: 16ms\tremaining: 518ms\n",
      "6:\tlearn: 0.4055038\ttotal: 18.6ms\tremaining: 514ms\n",
      "7:\tlearn: 0.3839096\ttotal: 21.5ms\tremaining: 515ms\n",
      "8:\tlearn: 0.3653161\ttotal: 24.1ms\tremaining: 512ms\n",
      "9:\tlearn: 0.3507624\ttotal: 26.7ms\tremaining: 506ms\n",
      "10:\tlearn: 0.3407572\ttotal: 29.5ms\tremaining: 506ms\n",
      "11:\tlearn: 0.3279477\ttotal: 32.1ms\tremaining: 502ms\n",
      "12:\tlearn: 0.3170814\ttotal: 35.4ms\tremaining: 509ms\n",
      "13:\tlearn: 0.3039859\ttotal: 38.2ms\tremaining: 508ms\n",
      "14:\tlearn: 0.2958595\ttotal: 41.2ms\tremaining: 508ms\n",
      "15:\tlearn: 0.2858677\ttotal: 43.8ms\tremaining: 503ms\n",
      "16:\tlearn: 0.2788378\ttotal: 46.3ms\tremaining: 498ms\n",
      "17:\tlearn: 0.2737223\ttotal: 49ms\tremaining: 495ms\n",
      "18:\tlearn: 0.2676999\ttotal: 52.4ms\tremaining: 499ms\n",
      "19:\tlearn: 0.2626998\ttotal: 55.3ms\tremaining: 498ms\n",
      "20:\tlearn: 0.2591448\ttotal: 58.1ms\tremaining: 495ms\n",
      "21:\tlearn: 0.2548514\ttotal: 61ms\tremaining: 494ms\n",
      "22:\tlearn: 0.2499879\ttotal: 63.9ms\tremaining: 492ms\n",
      "23:\tlearn: 0.2424416\ttotal: 66.8ms\tremaining: 490ms\n",
      "24:\tlearn: 0.2371526\ttotal: 69.4ms\tremaining: 486ms\n",
      "25:\tlearn: 0.2333679\ttotal: 72.9ms\tremaining: 488ms\n",
      "26:\tlearn: 0.2301610\ttotal: 75.5ms\tremaining: 484ms\n",
      "27:\tlearn: 0.2269387\ttotal: 78.9ms\tremaining: 485ms\n",
      "28:\tlearn: 0.2206996\ttotal: 81.5ms\tremaining: 481ms\n",
      "29:\tlearn: 0.2183764\ttotal: 84.4ms\tremaining: 478ms\n",
      "30:\tlearn: 0.2158366\ttotal: 87.2ms\tremaining: 475ms\n",
      "31:\tlearn: 0.2102830\ttotal: 90.5ms\tremaining: 475ms\n",
      "32:\tlearn: 0.2058201\ttotal: 93ms\tremaining: 471ms\n",
      "33:\tlearn: 0.2036891\ttotal: 95.8ms\tremaining: 468ms\n",
      "34:\tlearn: 0.1984435\ttotal: 98.4ms\tremaining: 464ms\n",
      "35:\tlearn: 0.1960127\ttotal: 102ms\tremaining: 465ms\n",
      "36:\tlearn: 0.1942923\ttotal: 105ms\tremaining: 464ms\n",
      "37:\tlearn: 0.1922189\ttotal: 108ms\tremaining: 461ms\n",
      "38:\tlearn: 0.1885590\ttotal: 111ms\tremaining: 458ms\n",
      "39:\tlearn: 0.1870320\ttotal: 114ms\tremaining: 455ms\n",
      "40:\tlearn: 0.1852478\ttotal: 116ms\tremaining: 451ms\n",
      "41:\tlearn: 0.1837404\ttotal: 119ms\tremaining: 448ms\n",
      "42:\tlearn: 0.1822250\ttotal: 122ms\tremaining: 446ms\n",
      "43:\tlearn: 0.1806189\ttotal: 125ms\tremaining: 443ms\n",
      "44:\tlearn: 0.1792843\ttotal: 128ms\tremaining: 439ms\n",
      "45:\tlearn: 0.1762643\ttotal: 130ms\tremaining: 437ms\n",
      "46:\tlearn: 0.1740251\ttotal: 134ms\tremaining: 435ms\n",
      "47:\tlearn: 0.1712166\ttotal: 136ms\tremaining: 431ms\n",
      "48:\tlearn: 0.1698331\ttotal: 139ms\tremaining: 428ms\n",
      "49:\tlearn: 0.1680541\ttotal: 141ms\tremaining: 424ms\n",
      "50:\tlearn: 0.1656480\ttotal: 144ms\tremaining: 422ms\n",
      "51:\tlearn: 0.1642020\ttotal: 147ms\tremaining: 419ms\n",
      "52:\tlearn: 0.1630471\ttotal: 150ms\tremaining: 416ms\n",
      "53:\tlearn: 0.1620769\ttotal: 153ms\tremaining: 413ms\n",
      "54:\tlearn: 0.1610493\ttotal: 156ms\tremaining: 413ms\n",
      "55:\tlearn: 0.1603676\ttotal: 159ms\tremaining: 409ms\n",
      "56:\tlearn: 0.1590855\ttotal: 162ms\tremaining: 407ms\n",
      "57:\tlearn: 0.1582839\ttotal: 165ms\tremaining: 404ms\n",
      "58:\tlearn: 0.1570053\ttotal: 168ms\tremaining: 400ms\n",
      "59:\tlearn: 0.1547208\ttotal: 170ms\tremaining: 397ms\n",
      "60:\tlearn: 0.1523206\ttotal: 173ms\tremaining: 394ms\n",
      "61:\tlearn: 0.1512701\ttotal: 175ms\tremaining: 391ms\n",
      "62:\tlearn: 0.1502040\ttotal: 178ms\tremaining: 388ms\n",
      "63:\tlearn: 0.1495379\ttotal: 181ms\tremaining: 385ms\n",
      "64:\tlearn: 0.1476994\ttotal: 184ms\tremaining: 382ms\n",
      "65:\tlearn: 0.1470095\ttotal: 187ms\tremaining: 380ms\n",
      "66:\tlearn: 0.1455277\ttotal: 190ms\tremaining: 376ms\n",
      "67:\tlearn: 0.1440828\ttotal: 193ms\tremaining: 374ms\n",
      "68:\tlearn: 0.1435247\ttotal: 195ms\tremaining: 371ms\n",
      "69:\tlearn: 0.1429233\ttotal: 198ms\tremaining: 368ms\n",
      "70:\tlearn: 0.1417943\ttotal: 201ms\tremaining: 365ms\n",
      "71:\tlearn: 0.1407216\ttotal: 204ms\tremaining: 363ms\n",
      "72:\tlearn: 0.1398108\ttotal: 207ms\tremaining: 360ms\n",
      "73:\tlearn: 0.1389077\ttotal: 210ms\tremaining: 358ms\n",
      "74:\tlearn: 0.1382241\ttotal: 213ms\tremaining: 354ms\n",
      "75:\tlearn: 0.1373212\ttotal: 215ms\tremaining: 352ms\n",
      "76:\tlearn: 0.1358315\ttotal: 218ms\tremaining: 349ms\n",
      "77:\tlearn: 0.1350671\ttotal: 221ms\tremaining: 346ms\n",
      "78:\tlearn: 0.1336381\ttotal: 224ms\tremaining: 343ms\n",
      "79:\tlearn: 0.1326166\ttotal: 226ms\tremaining: 339ms\n",
      "80:\tlearn: 0.1316321\ttotal: 229ms\tremaining: 336ms\n",
      "81:\tlearn: 0.1310967\ttotal: 232ms\tremaining: 333ms\n",
      "82:\tlearn: 0.1306999\ttotal: 235ms\tremaining: 331ms\n",
      "83:\tlearn: 0.1295843\ttotal: 238ms\tremaining: 329ms\n",
      "84:\tlearn: 0.1286547\ttotal: 241ms\tremaining: 326ms\n",
      "85:\tlearn: 0.1281402\ttotal: 243ms\tremaining: 323ms\n",
      "86:\tlearn: 0.1269629\ttotal: 246ms\tremaining: 319ms\n",
      "87:\tlearn: 0.1262976\ttotal: 248ms\tremaining: 316ms\n",
      "88:\tlearn: 0.1251906\ttotal: 251ms\tremaining: 313ms\n",
      "89:\tlearn: 0.1241655\ttotal: 254ms\tremaining: 310ms\n",
      "90:\tlearn: 0.1234848\ttotal: 257ms\tremaining: 307ms\n",
      "91:\tlearn: 0.1225154\ttotal: 259ms\tremaining: 304ms\n",
      "92:\tlearn: 0.1209742\ttotal: 262ms\tremaining: 302ms\n",
      "93:\tlearn: 0.1205378\ttotal: 266ms\tremaining: 300ms\n",
      "94:\tlearn: 0.1199239\ttotal: 268ms\tremaining: 297ms\n",
      "95:\tlearn: 0.1190137\ttotal: 271ms\tremaining: 294ms\n",
      "96:\tlearn: 0.1183071\ttotal: 274ms\tremaining: 291ms\n",
      "97:\tlearn: 0.1173249\ttotal: 276ms\tremaining: 288ms\n",
      "98:\tlearn: 0.1164578\ttotal: 279ms\tremaining: 284ms\n",
      "99:\tlearn: 0.1153879\ttotal: 282ms\tremaining: 282ms\n",
      "100:\tlearn: 0.1147083\ttotal: 285ms\tremaining: 279ms\n",
      "101:\tlearn: 0.1141157\ttotal: 287ms\tremaining: 276ms\n",
      "102:\tlearn: 0.1137524\ttotal: 290ms\tremaining: 273ms\n",
      "103:\tlearn: 0.1132859\ttotal: 293ms\tremaining: 270ms\n",
      "104:\tlearn: 0.1129916\ttotal: 295ms\tremaining: 267ms\n",
      "105:\tlearn: 0.1125165\ttotal: 298ms\tremaining: 264ms\n",
      "106:\tlearn: 0.1119109\ttotal: 300ms\tremaining: 261ms\n",
      "107:\tlearn: 0.1115006\ttotal: 303ms\tremaining: 258ms\n",
      "108:\tlearn: 0.1107803\ttotal: 306ms\tremaining: 255ms\n",
      "109:\tlearn: 0.1103637\ttotal: 309ms\tremaining: 253ms\n",
      "110:\tlearn: 0.1098746\ttotal: 311ms\tremaining: 250ms\n",
      "111:\tlearn: 0.1092618\ttotal: 315ms\tremaining: 247ms\n",
      "112:\tlearn: 0.1088692\ttotal: 318ms\tremaining: 245ms\n",
      "113:\tlearn: 0.1078465\ttotal: 321ms\tremaining: 242ms\n",
      "114:\tlearn: 0.1074619\ttotal: 324ms\tremaining: 239ms\n",
      "115:\tlearn: 0.1068123\ttotal: 326ms\tremaining: 236ms\n",
      "116:\tlearn: 0.1064320\ttotal: 329ms\tremaining: 233ms\n",
      "117:\tlearn: 0.1056031\ttotal: 331ms\tremaining: 230ms\n",
      "118:\tlearn: 0.1047720\ttotal: 334ms\tremaining: 227ms\n",
      "119:\tlearn: 0.1040791\ttotal: 337ms\tremaining: 224ms\n",
      "120:\tlearn: 0.1033743\ttotal: 340ms\tremaining: 222ms\n",
      "121:\tlearn: 0.1028733\ttotal: 343ms\tremaining: 219ms\n",
      "122:\tlearn: 0.1025271\ttotal: 346ms\tremaining: 217ms\n",
      "123:\tlearn: 0.1020661\ttotal: 349ms\tremaining: 214ms\n",
      "124:\tlearn: 0.1015486\ttotal: 352ms\tremaining: 211ms\n",
      "125:\tlearn: 0.1008576\ttotal: 354ms\tremaining: 208ms\n",
      "126:\tlearn: 0.1004613\ttotal: 357ms\tremaining: 205ms\n",
      "127:\tlearn: 0.1002213\ttotal: 359ms\tremaining: 202ms\n",
      "128:\tlearn: 0.0991197\ttotal: 362ms\tremaining: 199ms\n",
      "129:\tlearn: 0.0987496\ttotal: 365ms\tremaining: 196ms\n",
      "130:\tlearn: 0.0983146\ttotal: 367ms\tremaining: 193ms\n",
      "131:\tlearn: 0.0980241\ttotal: 370ms\tremaining: 191ms\n",
      "132:\tlearn: 0.0977068\ttotal: 373ms\tremaining: 188ms\n",
      "133:\tlearn: 0.0973627\ttotal: 376ms\tremaining: 185ms\n",
      "134:\tlearn: 0.0966322\ttotal: 378ms\tremaining: 182ms\n",
      "135:\tlearn: 0.0962891\ttotal: 381ms\tremaining: 179ms\n",
      "136:\tlearn: 0.0961777\ttotal: 384ms\tremaining: 177ms\n",
      "137:\tlearn: 0.0959135\ttotal: 387ms\tremaining: 174ms\n",
      "138:\tlearn: 0.0955727\ttotal: 390ms\tremaining: 171ms\n",
      "139:\tlearn: 0.0952229\ttotal: 392ms\tremaining: 168ms\n",
      "140:\tlearn: 0.0949920\ttotal: 395ms\tremaining: 165ms\n",
      "141:\tlearn: 0.0945692\ttotal: 399ms\tremaining: 163ms\n",
      "142:\tlearn: 0.0940776\ttotal: 402ms\tremaining: 160ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143:\tlearn: 0.0938254\ttotal: 405ms\tremaining: 158ms\n",
      "144:\tlearn: 0.0934676\ttotal: 408ms\tremaining: 155ms\n",
      "145:\tlearn: 0.0929789\ttotal: 411ms\tremaining: 152ms\n",
      "146:\tlearn: 0.0926817\ttotal: 414ms\tremaining: 149ms\n",
      "147:\tlearn: 0.0925052\ttotal: 417ms\tremaining: 146ms\n",
      "148:\tlearn: 0.0918482\ttotal: 420ms\tremaining: 144ms\n",
      "149:\tlearn: 0.0914024\ttotal: 424ms\tremaining: 141ms\n",
      "150:\tlearn: 0.0911107\ttotal: 427ms\tremaining: 139ms\n",
      "151:\tlearn: 0.0905822\ttotal: 430ms\tremaining: 136ms\n",
      "152:\tlearn: 0.0900963\ttotal: 433ms\tremaining: 133ms\n",
      "153:\tlearn: 0.0899819\ttotal: 435ms\tremaining: 130ms\n",
      "154:\tlearn: 0.0898309\ttotal: 438ms\tremaining: 127ms\n",
      "155:\tlearn: 0.0895944\ttotal: 442ms\tremaining: 125ms\n",
      "156:\tlearn: 0.0893669\ttotal: 445ms\tremaining: 122ms\n",
      "157:\tlearn: 0.0891844\ttotal: 448ms\tremaining: 119ms\n",
      "158:\tlearn: 0.0888392\ttotal: 451ms\tremaining: 116ms\n",
      "159:\tlearn: 0.0885367\ttotal: 453ms\tremaining: 113ms\n",
      "160:\tlearn: 0.0884240\ttotal: 457ms\tremaining: 111ms\n",
      "161:\tlearn: 0.0881231\ttotal: 459ms\tremaining: 108ms\n",
      "162:\tlearn: 0.0879572\ttotal: 462ms\tremaining: 105ms\n",
      "163:\tlearn: 0.0877466\ttotal: 465ms\tremaining: 102ms\n",
      "164:\tlearn: 0.0874820\ttotal: 467ms\tremaining: 99.1ms\n",
      "165:\tlearn: 0.0868541\ttotal: 471ms\tremaining: 96.5ms\n",
      "166:\tlearn: 0.0866710\ttotal: 474ms\tremaining: 93.6ms\n",
      "167:\tlearn: 0.0866084\ttotal: 476ms\tremaining: 90.7ms\n",
      "168:\tlearn: 0.0862258\ttotal: 479ms\tremaining: 87.9ms\n",
      "169:\tlearn: 0.0860158\ttotal: 482ms\tremaining: 85ms\n",
      "170:\tlearn: 0.0859140\ttotal: 485ms\tremaining: 82.2ms\n",
      "171:\tlearn: 0.0857815\ttotal: 488ms\tremaining: 79.4ms\n",
      "172:\tlearn: 0.0857024\ttotal: 491ms\tremaining: 76.6ms\n",
      "173:\tlearn: 0.0852520\ttotal: 494ms\tremaining: 73.8ms\n",
      "174:\tlearn: 0.0848513\ttotal: 496ms\tremaining: 70.9ms\n",
      "175:\tlearn: 0.0844402\ttotal: 499ms\tremaining: 68.1ms\n",
      "176:\tlearn: 0.0842309\ttotal: 502ms\tremaining: 65.2ms\n",
      "177:\tlearn: 0.0841554\ttotal: 505ms\tremaining: 62.5ms\n",
      "178:\tlearn: 0.0839047\ttotal: 508ms\tremaining: 59.6ms\n",
      "179:\tlearn: 0.0836596\ttotal: 512ms\tremaining: 56.9ms\n",
      "180:\tlearn: 0.0835660\ttotal: 515ms\tremaining: 54.1ms\n",
      "181:\tlearn: 0.0830828\ttotal: 518ms\tremaining: 51.2ms\n",
      "182:\tlearn: 0.0827883\ttotal: 521ms\tremaining: 48.4ms\n",
      "183:\tlearn: 0.0824737\ttotal: 523ms\tremaining: 45.5ms\n",
      "184:\tlearn: 0.0823090\ttotal: 527ms\tremaining: 42.7ms\n",
      "185:\tlearn: 0.0818875\ttotal: 530ms\tremaining: 39.9ms\n",
      "186:\tlearn: 0.0816038\ttotal: 533ms\tremaining: 37ms\n",
      "187:\tlearn: 0.0815137\ttotal: 535ms\tremaining: 34.2ms\n",
      "188:\tlearn: 0.0809259\ttotal: 538ms\tremaining: 31.3ms\n",
      "189:\tlearn: 0.0807461\ttotal: 541ms\tremaining: 28.5ms\n",
      "190:\tlearn: 0.0806110\ttotal: 544ms\tremaining: 25.6ms\n",
      "191:\tlearn: 0.0802546\ttotal: 547ms\tremaining: 22.8ms\n",
      "192:\tlearn: 0.0797266\ttotal: 549ms\tremaining: 19.9ms\n",
      "193:\tlearn: 0.0793948\ttotal: 551ms\tremaining: 17.1ms\n",
      "194:\tlearn: 0.0790941\ttotal: 555ms\tremaining: 14.2ms\n",
      "195:\tlearn: 0.0789628\ttotal: 558ms\tremaining: 11.4ms\n",
      "196:\tlearn: 0.0788612\ttotal: 560ms\tremaining: 8.53ms\n",
      "197:\tlearn: 0.0785115\ttotal: 563ms\tremaining: 5.69ms\n",
      "198:\tlearn: 0.0781118\ttotal: 566ms\tremaining: 2.84ms\n",
      "199:\tlearn: 0.0776359\ttotal: 569ms\tremaining: 0us\n",
      "0:\tlearn: 0.6378021\ttotal: 2.38ms\tremaining: 474ms\n",
      "1:\tlearn: 0.5912913\ttotal: 5.1ms\tremaining: 505ms\n",
      "2:\tlearn: 0.5471367\ttotal: 7.54ms\tremaining: 495ms\n",
      "3:\tlearn: 0.5076844\ttotal: 10.2ms\tremaining: 501ms\n",
      "4:\tlearn: 0.4720379\ttotal: 12.8ms\tremaining: 501ms\n",
      "5:\tlearn: 0.4398201\ttotal: 15.6ms\tremaining: 504ms\n",
      "6:\tlearn: 0.4184982\ttotal: 18.4ms\tremaining: 507ms\n",
      "7:\tlearn: 0.3980436\ttotal: 21.6ms\tremaining: 519ms\n",
      "8:\tlearn: 0.3793109\ttotal: 24.3ms\tremaining: 516ms\n",
      "9:\tlearn: 0.3632333\ttotal: 27.6ms\tremaining: 525ms\n",
      "10:\tlearn: 0.3466518\ttotal: 30.3ms\tremaining: 521ms\n",
      "11:\tlearn: 0.3343469\ttotal: 33.6ms\tremaining: 527ms\n",
      "12:\tlearn: 0.3174969\ttotal: 36.2ms\tremaining: 520ms\n",
      "13:\tlearn: 0.3047198\ttotal: 39.4ms\tremaining: 524ms\n",
      "14:\tlearn: 0.2891780\ttotal: 41.9ms\tremaining: 517ms\n",
      "15:\tlearn: 0.2797605\ttotal: 44.6ms\tremaining: 513ms\n",
      "16:\tlearn: 0.2733590\ttotal: 47.1ms\tremaining: 507ms\n",
      "17:\tlearn: 0.2688835\ttotal: 50.1ms\tremaining: 506ms\n",
      "18:\tlearn: 0.2626420\ttotal: 52.9ms\tremaining: 504ms\n",
      "19:\tlearn: 0.2580500\ttotal: 55.7ms\tremaining: 502ms\n",
      "20:\tlearn: 0.2492557\ttotal: 58.4ms\tremaining: 497ms\n",
      "21:\tlearn: 0.2451978\ttotal: 61.4ms\tremaining: 497ms\n",
      "22:\tlearn: 0.2414066\ttotal: 64.3ms\tremaining: 495ms\n",
      "23:\tlearn: 0.2383297\ttotal: 66.8ms\tremaining: 490ms\n",
      "24:\tlearn: 0.2317725\ttotal: 69.5ms\tremaining: 487ms\n",
      "25:\tlearn: 0.2288947\ttotal: 73.1ms\tremaining: 489ms\n",
      "26:\tlearn: 0.2255848\ttotal: 75.9ms\tremaining: 487ms\n",
      "27:\tlearn: 0.2232344\ttotal: 78.4ms\tremaining: 482ms\n",
      "28:\tlearn: 0.2201622\ttotal: 81ms\tremaining: 477ms\n",
      "29:\tlearn: 0.2169455\ttotal: 84ms\tremaining: 476ms\n",
      "30:\tlearn: 0.2107399\ttotal: 86.8ms\tremaining: 473ms\n",
      "31:\tlearn: 0.2085155\ttotal: 89.5ms\tremaining: 470ms\n",
      "32:\tlearn: 0.2064216\ttotal: 92.3ms\tremaining: 467ms\n",
      "33:\tlearn: 0.2023290\ttotal: 94.9ms\tremaining: 463ms\n",
      "34:\tlearn: 0.2000387\ttotal: 97.6ms\tremaining: 460ms\n",
      "35:\tlearn: 0.1951309\ttotal: 102ms\tremaining: 464ms\n",
      "36:\tlearn: 0.1928054\ttotal: 105ms\tremaining: 461ms\n",
      "37:\tlearn: 0.1909682\ttotal: 107ms\tremaining: 458ms\n",
      "38:\tlearn: 0.1890523\ttotal: 111ms\tremaining: 459ms\n",
      "39:\tlearn: 0.1872172\ttotal: 114ms\tremaining: 456ms\n",
      "40:\tlearn: 0.1856789\ttotal: 117ms\tremaining: 454ms\n",
      "41:\tlearn: 0.1843585\ttotal: 120ms\tremaining: 452ms\n",
      "42:\tlearn: 0.1830367\ttotal: 123ms\tremaining: 449ms\n",
      "43:\tlearn: 0.1812500\ttotal: 126ms\tremaining: 445ms\n",
      "44:\tlearn: 0.1800318\ttotal: 128ms\tremaining: 442ms\n",
      "45:\tlearn: 0.1788021\ttotal: 131ms\tremaining: 440ms\n",
      "46:\tlearn: 0.1763059\ttotal: 134ms\tremaining: 437ms\n",
      "47:\tlearn: 0.1723395\ttotal: 137ms\tremaining: 434ms\n",
      "48:\tlearn: 0.1713380\ttotal: 140ms\tremaining: 432ms\n",
      "49:\tlearn: 0.1681649\ttotal: 143ms\tremaining: 428ms\n",
      "50:\tlearn: 0.1672675\ttotal: 146ms\tremaining: 427ms\n",
      "51:\tlearn: 0.1659439\ttotal: 150ms\tremaining: 426ms\n",
      "52:\tlearn: 0.1645951\ttotal: 153ms\tremaining: 423ms\n",
      "53:\tlearn: 0.1622926\ttotal: 156ms\tremaining: 421ms\n",
      "54:\tlearn: 0.1600802\ttotal: 159ms\tremaining: 418ms\n",
      "55:\tlearn: 0.1590685\ttotal: 161ms\tremaining: 415ms\n",
      "56:\tlearn: 0.1566025\ttotal: 164ms\tremaining: 412ms\n",
      "57:\tlearn: 0.1553737\ttotal: 167ms\tremaining: 410ms\n",
      "58:\tlearn: 0.1536401\ttotal: 170ms\tremaining: 407ms\n",
      "59:\tlearn: 0.1524699\ttotal: 173ms\tremaining: 404ms\n",
      "60:\tlearn: 0.1508166\ttotal: 176ms\tremaining: 401ms\n",
      "61:\tlearn: 0.1499414\ttotal: 179ms\tremaining: 398ms\n",
      "62:\tlearn: 0.1491607\ttotal: 181ms\tremaining: 395ms\n",
      "63:\tlearn: 0.1485316\ttotal: 184ms\tremaining: 391ms\n",
      "64:\tlearn: 0.1464977\ttotal: 187ms\tremaining: 388ms\n",
      "65:\tlearn: 0.1451383\ttotal: 190ms\tremaining: 385ms\n",
      "66:\tlearn: 0.1440921\ttotal: 192ms\tremaining: 382ms\n",
      "67:\tlearn: 0.1433118\ttotal: 196ms\tremaining: 380ms\n",
      "68:\tlearn: 0.1424175\ttotal: 198ms\tremaining: 377ms\n",
      "69:\tlearn: 0.1416120\ttotal: 201ms\tremaining: 373ms\n",
      "70:\tlearn: 0.1408164\ttotal: 204ms\tremaining: 371ms\n",
      "71:\tlearn: 0.1392467\ttotal: 207ms\tremaining: 367ms\n",
      "72:\tlearn: 0.1384718\ttotal: 210ms\tremaining: 365ms\n",
      "73:\tlearn: 0.1377142\ttotal: 212ms\tremaining: 362ms\n",
      "74:\tlearn: 0.1368590\ttotal: 215ms\tremaining: 358ms\n",
      "75:\tlearn: 0.1361811\ttotal: 218ms\tremaining: 355ms\n",
      "76:\tlearn: 0.1355679\ttotal: 221ms\tremaining: 354ms\n",
      "77:\tlearn: 0.1347368\ttotal: 224ms\tremaining: 350ms\n",
      "78:\tlearn: 0.1341265\ttotal: 227ms\tremaining: 348ms\n",
      "79:\tlearn: 0.1334048\ttotal: 230ms\tremaining: 346ms\n",
      "80:\tlearn: 0.1329062\ttotal: 233ms\tremaining: 343ms\n",
      "81:\tlearn: 0.1323282\ttotal: 236ms\tremaining: 340ms\n",
      "82:\tlearn: 0.1314688\ttotal: 239ms\tremaining: 337ms\n",
      "83:\tlearn: 0.1306235\ttotal: 243ms\tremaining: 335ms\n",
      "84:\tlearn: 0.1299453\ttotal: 246ms\tremaining: 332ms\n",
      "85:\tlearn: 0.1289267\ttotal: 248ms\tremaining: 329ms\n",
      "86:\tlearn: 0.1280217\ttotal: 251ms\tremaining: 326ms\n",
      "87:\tlearn: 0.1273585\ttotal: 254ms\tremaining: 323ms\n",
      "88:\tlearn: 0.1266068\ttotal: 256ms\tremaining: 320ms\n",
      "89:\tlearn: 0.1261149\ttotal: 259ms\tremaining: 317ms\n",
      "90:\tlearn: 0.1253302\ttotal: 262ms\tremaining: 314ms\n",
      "91:\tlearn: 0.1247369\ttotal: 265ms\tremaining: 311ms\n",
      "92:\tlearn: 0.1240357\ttotal: 268ms\tremaining: 309ms\n",
      "93:\tlearn: 0.1232760\ttotal: 271ms\tremaining: 306ms\n",
      "94:\tlearn: 0.1229914\ttotal: 274ms\tremaining: 303ms\n",
      "95:\tlearn: 0.1225270\ttotal: 277ms\tremaining: 300ms\n",
      "96:\tlearn: 0.1212473\ttotal: 279ms\tremaining: 296ms\n",
      "97:\tlearn: 0.1199503\ttotal: 282ms\tremaining: 293ms\n",
      "98:\tlearn: 0.1196239\ttotal: 284ms\tremaining: 290ms\n",
      "99:\tlearn: 0.1184784\ttotal: 287ms\tremaining: 287ms\n",
      "100:\tlearn: 0.1176184\ttotal: 290ms\tremaining: 284ms\n",
      "101:\tlearn: 0.1168047\ttotal: 293ms\tremaining: 281ms\n",
      "102:\tlearn: 0.1164318\ttotal: 296ms\tremaining: 279ms\n",
      "103:\tlearn: 0.1159011\ttotal: 299ms\tremaining: 276ms\n",
      "104:\tlearn: 0.1154913\ttotal: 302ms\tremaining: 273ms\n",
      "105:\tlearn: 0.1150536\ttotal: 305ms\tremaining: 270ms\n",
      "106:\tlearn: 0.1146097\ttotal: 308ms\tremaining: 268ms\n",
      "107:\tlearn: 0.1141296\ttotal: 311ms\tremaining: 265ms\n",
      "108:\tlearn: 0.1137979\ttotal: 313ms\tremaining: 262ms\n",
      "109:\tlearn: 0.1135032\ttotal: 316ms\tremaining: 259ms\n",
      "110:\tlearn: 0.1130293\ttotal: 319ms\tremaining: 256ms\n",
      "111:\tlearn: 0.1122141\ttotal: 322ms\tremaining: 253ms\n",
      "112:\tlearn: 0.1113238\ttotal: 324ms\tremaining: 250ms\n",
      "113:\tlearn: 0.1108050\ttotal: 327ms\tremaining: 247ms\n",
      "114:\tlearn: 0.1103710\ttotal: 330ms\tremaining: 244ms\n",
      "115:\tlearn: 0.1098283\ttotal: 333ms\tremaining: 241ms\n",
      "116:\tlearn: 0.1090362\ttotal: 336ms\tremaining: 238ms\n",
      "117:\tlearn: 0.1087079\ttotal: 338ms\tremaining: 235ms\n",
      "118:\tlearn: 0.1079058\ttotal: 341ms\tremaining: 232ms\n",
      "119:\tlearn: 0.1068843\ttotal: 344ms\tremaining: 229ms\n",
      "120:\tlearn: 0.1063775\ttotal: 346ms\tremaining: 226ms\n",
      "121:\tlearn: 0.1058777\ttotal: 349ms\tremaining: 223ms\n",
      "122:\tlearn: 0.1056963\ttotal: 353ms\tremaining: 221ms\n",
      "123:\tlearn: 0.1052006\ttotal: 356ms\tremaining: 218ms\n",
      "124:\tlearn: 0.1045898\ttotal: 358ms\tremaining: 215ms\n",
      "125:\tlearn: 0.1042813\ttotal: 361ms\tremaining: 212ms\n",
      "126:\tlearn: 0.1040826\ttotal: 364ms\tremaining: 209ms\n",
      "127:\tlearn: 0.1039770\ttotal: 366ms\tremaining: 206ms\n",
      "128:\tlearn: 0.1030892\ttotal: 369ms\tremaining: 203ms\n",
      "129:\tlearn: 0.1030862\ttotal: 372ms\tremaining: 200ms\n",
      "130:\tlearn: 0.1028251\ttotal: 376ms\tremaining: 198ms\n",
      "131:\tlearn: 0.1025502\ttotal: 379ms\tremaining: 195ms\n",
      "132:\tlearn: 0.1021399\ttotal: 382ms\tremaining: 192ms\n",
      "133:\tlearn: 0.1019569\ttotal: 386ms\tremaining: 190ms\n",
      "134:\tlearn: 0.1017587\ttotal: 388ms\tremaining: 187ms\n",
      "135:\tlearn: 0.1013014\ttotal: 392ms\tremaining: 185ms\n",
      "136:\tlearn: 0.1011159\ttotal: 395ms\tremaining: 182ms\n",
      "137:\tlearn: 0.1009050\ttotal: 398ms\tremaining: 179ms\n",
      "138:\tlearn: 0.1002757\ttotal: 400ms\tremaining: 176ms\n",
      "139:\tlearn: 0.0995904\ttotal: 403ms\tremaining: 173ms\n",
      "140:\tlearn: 0.0991340\ttotal: 406ms\tremaining: 170ms\n",
      "141:\tlearn: 0.0985523\ttotal: 408ms\tremaining: 167ms\n",
      "142:\tlearn: 0.0981178\ttotal: 412ms\tremaining: 164ms\n",
      "143:\tlearn: 0.0977244\ttotal: 415ms\tremaining: 161ms\n",
      "144:\tlearn: 0.0974181\ttotal: 417ms\tremaining: 158ms\n",
      "145:\tlearn: 0.0969465\ttotal: 421ms\tremaining: 156ms\n",
      "146:\tlearn: 0.0966613\ttotal: 424ms\tremaining: 153ms\n",
      "147:\tlearn: 0.0963854\ttotal: 426ms\tremaining: 150ms\n",
      "148:\tlearn: 0.0963760\ttotal: 429ms\tremaining: 147ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149:\tlearn: 0.0957277\ttotal: 432ms\tremaining: 144ms\n",
      "150:\tlearn: 0.0954703\ttotal: 434ms\tremaining: 141ms\n",
      "151:\tlearn: 0.0951056\ttotal: 437ms\tremaining: 138ms\n",
      "152:\tlearn: 0.0948901\ttotal: 440ms\tremaining: 135ms\n",
      "153:\tlearn: 0.0948766\ttotal: 443ms\tremaining: 132ms\n",
      "154:\tlearn: 0.0948756\ttotal: 445ms\tremaining: 129ms\n",
      "155:\tlearn: 0.0946408\ttotal: 447ms\tremaining: 126ms\n",
      "156:\tlearn: 0.0943595\ttotal: 451ms\tremaining: 123ms\n",
      "157:\tlearn: 0.0939297\ttotal: 454ms\tremaining: 121ms\n",
      "158:\tlearn: 0.0939289\ttotal: 457ms\tremaining: 118ms\n",
      "159:\tlearn: 0.0935616\ttotal: 460ms\tremaining: 115ms\n",
      "160:\tlearn: 0.0933279\ttotal: 462ms\tremaining: 112ms\n",
      "161:\tlearn: 0.0931637\ttotal: 465ms\tremaining: 109ms\n",
      "162:\tlearn: 0.0926532\ttotal: 468ms\tremaining: 106ms\n",
      "163:\tlearn: 0.0923015\ttotal: 471ms\tremaining: 103ms\n",
      "164:\tlearn: 0.0919755\ttotal: 473ms\tremaining: 100ms\n",
      "165:\tlearn: 0.0917548\ttotal: 476ms\tremaining: 97.5ms\n",
      "166:\tlearn: 0.0912993\ttotal: 479ms\tremaining: 94.6ms\n",
      "167:\tlearn: 0.0911668\ttotal: 481ms\tremaining: 91.7ms\n",
      "168:\tlearn: 0.0908950\ttotal: 484ms\tremaining: 88.8ms\n",
      "169:\tlearn: 0.0908686\ttotal: 487ms\tremaining: 85.9ms\n",
      "170:\tlearn: 0.0907083\ttotal: 489ms\tremaining: 83ms\n",
      "171:\tlearn: 0.0904320\ttotal: 492ms\tremaining: 80.2ms\n",
      "172:\tlearn: 0.0899570\ttotal: 495ms\tremaining: 77.3ms\n",
      "173:\tlearn: 0.0898921\ttotal: 498ms\tremaining: 74.4ms\n",
      "174:\tlearn: 0.0892339\ttotal: 500ms\tremaining: 71.5ms\n",
      "175:\tlearn: 0.0887798\ttotal: 503ms\tremaining: 68.6ms\n",
      "176:\tlearn: 0.0884715\ttotal: 506ms\tremaining: 65.7ms\n",
      "177:\tlearn: 0.0882632\ttotal: 509ms\tremaining: 62.9ms\n",
      "178:\tlearn: 0.0882614\ttotal: 511ms\tremaining: 60ms\n",
      "179:\tlearn: 0.0878230\ttotal: 514ms\tremaining: 57.1ms\n",
      "180:\tlearn: 0.0875961\ttotal: 517ms\tremaining: 54.2ms\n",
      "181:\tlearn: 0.0875938\ttotal: 519ms\tremaining: 51.3ms\n",
      "182:\tlearn: 0.0872939\ttotal: 522ms\tremaining: 48.5ms\n",
      "183:\tlearn: 0.0872739\ttotal: 524ms\tremaining: 45.6ms\n",
      "184:\tlearn: 0.0870662\ttotal: 527ms\tremaining: 42.7ms\n",
      "185:\tlearn: 0.0868628\ttotal: 529ms\tremaining: 39.9ms\n",
      "186:\tlearn: 0.0863763\ttotal: 532ms\tremaining: 37ms\n",
      "187:\tlearn: 0.0861390\ttotal: 536ms\tremaining: 34.2ms\n",
      "188:\tlearn: 0.0861350\ttotal: 538ms\tremaining: 31.3ms\n",
      "189:\tlearn: 0.0858617\ttotal: 541ms\tremaining: 28.5ms\n",
      "190:\tlearn: 0.0856382\ttotal: 544ms\tremaining: 25.6ms\n",
      "191:\tlearn: 0.0855542\ttotal: 547ms\tremaining: 22.8ms\n",
      "192:\tlearn: 0.0851778\ttotal: 550ms\tremaining: 19.9ms\n",
      "193:\tlearn: 0.0849530\ttotal: 553ms\tremaining: 17.1ms\n",
      "194:\tlearn: 0.0849523\ttotal: 555ms\tremaining: 14.2ms\n",
      "195:\tlearn: 0.0849507\ttotal: 558ms\tremaining: 11.4ms\n",
      "196:\tlearn: 0.0846376\ttotal: 560ms\tremaining: 8.53ms\n",
      "197:\tlearn: 0.0842866\ttotal: 563ms\tremaining: 5.69ms\n",
      "198:\tlearn: 0.0839154\ttotal: 566ms\tremaining: 2.84ms\n",
      "199:\tlearn: 0.0837165\ttotal: 569ms\tremaining: 0us\n",
      "0:\tlearn: 0.6338920\ttotal: 2.42ms\tremaining: 481ms\n",
      "1:\tlearn: 0.5779485\ttotal: 5ms\tremaining: 495ms\n",
      "2:\tlearn: 0.5359052\ttotal: 7.39ms\tremaining: 485ms\n",
      "3:\tlearn: 0.4971117\ttotal: 9.91ms\tremaining: 486ms\n",
      "4:\tlearn: 0.4632867\ttotal: 12.5ms\tremaining: 489ms\n",
      "5:\tlearn: 0.4266225\ttotal: 15.1ms\tremaining: 489ms\n",
      "6:\tlearn: 0.4071483\ttotal: 17.8ms\tremaining: 490ms\n",
      "7:\tlearn: 0.3874632\ttotal: 20.1ms\tremaining: 481ms\n",
      "8:\tlearn: 0.3668769\ttotal: 22.6ms\tremaining: 481ms\n",
      "9:\tlearn: 0.3514617\ttotal: 25.3ms\tremaining: 481ms\n",
      "10:\tlearn: 0.3380483\ttotal: 28ms\tremaining: 480ms\n",
      "11:\tlearn: 0.3226678\ttotal: 30.8ms\tremaining: 482ms\n",
      "12:\tlearn: 0.3079869\ttotal: 33.5ms\tremaining: 482ms\n",
      "13:\tlearn: 0.2981929\ttotal: 36.3ms\tremaining: 482ms\n",
      "14:\tlearn: 0.2894339\ttotal: 39.1ms\tremaining: 482ms\n",
      "15:\tlearn: 0.2797409\ttotal: 41.8ms\tremaining: 481ms\n",
      "16:\tlearn: 0.2740441\ttotal: 44.8ms\tremaining: 483ms\n",
      "17:\tlearn: 0.2679954\ttotal: 48.3ms\tremaining: 488ms\n",
      "18:\tlearn: 0.2626643\ttotal: 51ms\tremaining: 486ms\n",
      "19:\tlearn: 0.2578986\ttotal: 53.8ms\tremaining: 484ms\n",
      "20:\tlearn: 0.2546077\ttotal: 56.7ms\tremaining: 483ms\n",
      "21:\tlearn: 0.2503719\ttotal: 59.4ms\tremaining: 481ms\n",
      "22:\tlearn: 0.2463390\ttotal: 62.1ms\tremaining: 478ms\n",
      "23:\tlearn: 0.2391192\ttotal: 65.4ms\tremaining: 479ms\n",
      "24:\tlearn: 0.2314387\ttotal: 67.9ms\tremaining: 475ms\n",
      "25:\tlearn: 0.2281848\ttotal: 70.6ms\tremaining: 473ms\n",
      "26:\tlearn: 0.2255745\ttotal: 74.3ms\tremaining: 476ms\n",
      "27:\tlearn: 0.2228549\ttotal: 77ms\tremaining: 473ms\n",
      "28:\tlearn: 0.2199970\ttotal: 79.6ms\tremaining: 469ms\n",
      "29:\tlearn: 0.2175705\ttotal: 82.5ms\tremaining: 467ms\n",
      "30:\tlearn: 0.2140791\ttotal: 84.8ms\tremaining: 462ms\n",
      "31:\tlearn: 0.2124000\ttotal: 87.5ms\tremaining: 459ms\n",
      "32:\tlearn: 0.2056771\ttotal: 90.2ms\tremaining: 457ms\n",
      "33:\tlearn: 0.2030423\ttotal: 93.1ms\tremaining: 454ms\n",
      "34:\tlearn: 0.2013676\ttotal: 96.1ms\tremaining: 453ms\n",
      "35:\tlearn: 0.1989345\ttotal: 98.9ms\tremaining: 450ms\n",
      "36:\tlearn: 0.1943685\ttotal: 102ms\tremaining: 450ms\n",
      "37:\tlearn: 0.1900515\ttotal: 105ms\tremaining: 447ms\n",
      "38:\tlearn: 0.1886874\ttotal: 107ms\tremaining: 443ms\n",
      "39:\tlearn: 0.1864925\ttotal: 110ms\tremaining: 442ms\n",
      "40:\tlearn: 0.1851167\ttotal: 113ms\tremaining: 439ms\n",
      "41:\tlearn: 0.1822357\ttotal: 116ms\tremaining: 436ms\n",
      "42:\tlearn: 0.1802506\ttotal: 119ms\tremaining: 433ms\n",
      "43:\tlearn: 0.1774948\ttotal: 121ms\tremaining: 429ms\n",
      "44:\tlearn: 0.1761578\ttotal: 124ms\tremaining: 427ms\n",
      "45:\tlearn: 0.1745365\ttotal: 127ms\tremaining: 424ms\n",
      "46:\tlearn: 0.1723834\ttotal: 129ms\tremaining: 421ms\n",
      "47:\tlearn: 0.1711520\ttotal: 132ms\tremaining: 418ms\n",
      "48:\tlearn: 0.1700683\ttotal: 135ms\tremaining: 416ms\n",
      "49:\tlearn: 0.1667666\ttotal: 138ms\tremaining: 413ms\n",
      "50:\tlearn: 0.1661901\ttotal: 141ms\tremaining: 412ms\n",
      "51:\tlearn: 0.1647521\ttotal: 144ms\tremaining: 411ms\n",
      "52:\tlearn: 0.1636797\ttotal: 147ms\tremaining: 408ms\n",
      "53:\tlearn: 0.1611385\ttotal: 150ms\tremaining: 405ms\n",
      "54:\tlearn: 0.1600267\ttotal: 152ms\tremaining: 402ms\n",
      "55:\tlearn: 0.1588111\ttotal: 155ms\tremaining: 399ms\n",
      "56:\tlearn: 0.1572880\ttotal: 158ms\tremaining: 396ms\n",
      "57:\tlearn: 0.1566132\ttotal: 160ms\tremaining: 392ms\n",
      "58:\tlearn: 0.1553997\ttotal: 163ms\tremaining: 390ms\n",
      "59:\tlearn: 0.1545083\ttotal: 166ms\tremaining: 387ms\n",
      "60:\tlearn: 0.1529855\ttotal: 168ms\tremaining: 384ms\n",
      "61:\tlearn: 0.1511921\ttotal: 171ms\tremaining: 380ms\n",
      "62:\tlearn: 0.1504533\ttotal: 174ms\tremaining: 377ms\n",
      "63:\tlearn: 0.1488551\ttotal: 176ms\tremaining: 375ms\n",
      "64:\tlearn: 0.1467729\ttotal: 179ms\tremaining: 372ms\n",
      "65:\tlearn: 0.1460252\ttotal: 182ms\tremaining: 369ms\n",
      "66:\tlearn: 0.1448064\ttotal: 185ms\tremaining: 367ms\n",
      "67:\tlearn: 0.1441259\ttotal: 188ms\tremaining: 365ms\n",
      "68:\tlearn: 0.1435552\ttotal: 191ms\tremaining: 362ms\n",
      "69:\tlearn: 0.1423820\ttotal: 193ms\tremaining: 359ms\n",
      "70:\tlearn: 0.1413834\ttotal: 197ms\tremaining: 358ms\n",
      "71:\tlearn: 0.1397554\ttotal: 200ms\tremaining: 355ms\n",
      "72:\tlearn: 0.1392796\ttotal: 202ms\tremaining: 352ms\n",
      "73:\tlearn: 0.1386151\ttotal: 205ms\tremaining: 350ms\n",
      "74:\tlearn: 0.1374050\ttotal: 208ms\tremaining: 347ms\n",
      "75:\tlearn: 0.1367245\ttotal: 211ms\tremaining: 344ms\n",
      "76:\tlearn: 0.1359909\ttotal: 214ms\tremaining: 341ms\n",
      "77:\tlearn: 0.1352681\ttotal: 216ms\tremaining: 338ms\n",
      "78:\tlearn: 0.1342326\ttotal: 219ms\tremaining: 336ms\n",
      "79:\tlearn: 0.1335069\ttotal: 223ms\tremaining: 334ms\n",
      "80:\tlearn: 0.1323934\ttotal: 226ms\tremaining: 331ms\n",
      "81:\tlearn: 0.1319222\ttotal: 228ms\tremaining: 329ms\n",
      "82:\tlearn: 0.1313829\ttotal: 231ms\tremaining: 326ms\n",
      "83:\tlearn: 0.1304310\ttotal: 235ms\tremaining: 324ms\n",
      "84:\tlearn: 0.1300220\ttotal: 238ms\tremaining: 321ms\n",
      "85:\tlearn: 0.1287081\ttotal: 240ms\tremaining: 318ms\n",
      "86:\tlearn: 0.1279440\ttotal: 243ms\tremaining: 316ms\n",
      "87:\tlearn: 0.1272821\ttotal: 247ms\tremaining: 314ms\n",
      "88:\tlearn: 0.1264656\ttotal: 250ms\tremaining: 312ms\n",
      "89:\tlearn: 0.1258833\ttotal: 253ms\tremaining: 309ms\n",
      "90:\tlearn: 0.1247251\ttotal: 256ms\tremaining: 306ms\n",
      "91:\tlearn: 0.1241456\ttotal: 259ms\tremaining: 304ms\n",
      "92:\tlearn: 0.1231967\ttotal: 262ms\tremaining: 301ms\n",
      "93:\tlearn: 0.1228586\ttotal: 265ms\tremaining: 298ms\n",
      "94:\tlearn: 0.1217361\ttotal: 267ms\tremaining: 296ms\n",
      "95:\tlearn: 0.1208357\ttotal: 270ms\tremaining: 293ms\n",
      "96:\tlearn: 0.1201970\ttotal: 273ms\tremaining: 290ms\n",
      "97:\tlearn: 0.1197045\ttotal: 276ms\tremaining: 287ms\n",
      "98:\tlearn: 0.1187055\ttotal: 279ms\tremaining: 284ms\n",
      "99:\tlearn: 0.1180060\ttotal: 282ms\tremaining: 282ms\n",
      "100:\tlearn: 0.1177514\ttotal: 285ms\tremaining: 279ms\n",
      "101:\tlearn: 0.1173781\ttotal: 288ms\tremaining: 276ms\n",
      "102:\tlearn: 0.1162485\ttotal: 290ms\tremaining: 273ms\n",
      "103:\tlearn: 0.1156951\ttotal: 293ms\tremaining: 271ms\n",
      "104:\tlearn: 0.1153352\ttotal: 296ms\tremaining: 268ms\n",
      "105:\tlearn: 0.1146714\ttotal: 299ms\tremaining: 265ms\n",
      "106:\tlearn: 0.1142661\ttotal: 302ms\tremaining: 262ms\n",
      "107:\tlearn: 0.1133264\ttotal: 305ms\tremaining: 259ms\n",
      "108:\tlearn: 0.1128535\ttotal: 307ms\tremaining: 257ms\n",
      "109:\tlearn: 0.1122623\ttotal: 310ms\tremaining: 254ms\n",
      "110:\tlearn: 0.1118824\ttotal: 313ms\tremaining: 251ms\n",
      "111:\tlearn: 0.1115194\ttotal: 315ms\tremaining: 248ms\n",
      "112:\tlearn: 0.1112214\ttotal: 318ms\tremaining: 245ms\n",
      "113:\tlearn: 0.1107248\ttotal: 322ms\tremaining: 243ms\n",
      "114:\tlearn: 0.1098505\ttotal: 325ms\tremaining: 240ms\n",
      "115:\tlearn: 0.1089703\ttotal: 327ms\tremaining: 237ms\n",
      "116:\tlearn: 0.1085382\ttotal: 330ms\tremaining: 234ms\n",
      "117:\tlearn: 0.1079374\ttotal: 333ms\tremaining: 231ms\n",
      "118:\tlearn: 0.1075166\ttotal: 336ms\tremaining: 228ms\n",
      "119:\tlearn: 0.1071561\ttotal: 339ms\tremaining: 226ms\n",
      "120:\tlearn: 0.1063429\ttotal: 342ms\tremaining: 223ms\n",
      "121:\tlearn: 0.1057376\ttotal: 345ms\tremaining: 220ms\n",
      "122:\tlearn: 0.1052181\ttotal: 348ms\tremaining: 218ms\n",
      "123:\tlearn: 0.1049362\ttotal: 350ms\tremaining: 215ms\n",
      "124:\tlearn: 0.1045672\ttotal: 353ms\tremaining: 212ms\n",
      "125:\tlearn: 0.1041523\ttotal: 356ms\tremaining: 209ms\n",
      "126:\tlearn: 0.1038891\ttotal: 359ms\tremaining: 206ms\n",
      "127:\tlearn: 0.1036939\ttotal: 361ms\tremaining: 203ms\n",
      "128:\tlearn: 0.1030108\ttotal: 364ms\tremaining: 200ms\n",
      "129:\tlearn: 0.1027766\ttotal: 367ms\tremaining: 198ms\n",
      "130:\tlearn: 0.1023067\ttotal: 370ms\tremaining: 195ms\n",
      "131:\tlearn: 0.1018419\ttotal: 373ms\tremaining: 192ms\n",
      "132:\tlearn: 0.1016214\ttotal: 376ms\tremaining: 189ms\n",
      "133:\tlearn: 0.1013581\ttotal: 378ms\tremaining: 186ms\n",
      "134:\tlearn: 0.1007905\ttotal: 381ms\tremaining: 183ms\n",
      "135:\tlearn: 0.1004641\ttotal: 384ms\tremaining: 181ms\n",
      "136:\tlearn: 0.1000151\ttotal: 387ms\tremaining: 178ms\n",
      "137:\tlearn: 0.0995663\ttotal: 389ms\tremaining: 175ms\n",
      "138:\tlearn: 0.0991699\ttotal: 392ms\tremaining: 172ms\n",
      "139:\tlearn: 0.0989940\ttotal: 395ms\tremaining: 169ms\n",
      "140:\tlearn: 0.0986961\ttotal: 399ms\tremaining: 167ms\n",
      "141:\tlearn: 0.0983512\ttotal: 402ms\tremaining: 164ms\n",
      "142:\tlearn: 0.0980089\ttotal: 405ms\tremaining: 161ms\n",
      "143:\tlearn: 0.0971274\ttotal: 407ms\tremaining: 158ms\n",
      "144:\tlearn: 0.0966447\ttotal: 410ms\tremaining: 156ms\n",
      "145:\tlearn: 0.0962279\ttotal: 413ms\tremaining: 153ms\n",
      "146:\tlearn: 0.0956779\ttotal: 416ms\tremaining: 150ms\n",
      "147:\tlearn: 0.0952214\ttotal: 419ms\tremaining: 147ms\n",
      "148:\tlearn: 0.0949004\ttotal: 422ms\tremaining: 144ms\n",
      "149:\tlearn: 0.0943468\ttotal: 425ms\tremaining: 142ms\n",
      "150:\tlearn: 0.0941679\ttotal: 428ms\tremaining: 139ms\n",
      "151:\tlearn: 0.0939856\ttotal: 431ms\tremaining: 136ms\n",
      "152:\tlearn: 0.0936947\ttotal: 434ms\tremaining: 133ms\n",
      "153:\tlearn: 0.0934847\ttotal: 437ms\tremaining: 130ms\n",
      "154:\tlearn: 0.0933337\ttotal: 440ms\tremaining: 128ms\n",
      "155:\tlearn: 0.0928564\ttotal: 443ms\tremaining: 125ms\n",
      "156:\tlearn: 0.0923508\ttotal: 446ms\tremaining: 122ms\n",
      "157:\tlearn: 0.0920444\ttotal: 448ms\tremaining: 119ms\n",
      "158:\tlearn: 0.0916638\ttotal: 451ms\tremaining: 116ms\n",
      "159:\tlearn: 0.0914166\ttotal: 453ms\tremaining: 113ms\n",
      "160:\tlearn: 0.0911448\ttotal: 456ms\tremaining: 111ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161:\tlearn: 0.0909247\ttotal: 459ms\tremaining: 108ms\n",
      "162:\tlearn: 0.0907861\ttotal: 462ms\tremaining: 105ms\n",
      "163:\tlearn: 0.0905957\ttotal: 465ms\tremaining: 102ms\n",
      "164:\tlearn: 0.0901177\ttotal: 468ms\tremaining: 99.2ms\n",
      "165:\tlearn: 0.0895459\ttotal: 471ms\tremaining: 96.4ms\n",
      "166:\tlearn: 0.0892447\ttotal: 473ms\tremaining: 93.6ms\n",
      "167:\tlearn: 0.0889846\ttotal: 477ms\tremaining: 90.8ms\n",
      "168:\tlearn: 0.0886395\ttotal: 480ms\tremaining: 88ms\n",
      "169:\tlearn: 0.0882729\ttotal: 482ms\tremaining: 85.1ms\n",
      "170:\tlearn: 0.0880149\ttotal: 485ms\tremaining: 82.3ms\n",
      "171:\tlearn: 0.0875224\ttotal: 488ms\tremaining: 79.5ms\n",
      "172:\tlearn: 0.0872793\ttotal: 491ms\tremaining: 76.7ms\n",
      "173:\tlearn: 0.0870016\ttotal: 494ms\tremaining: 73.9ms\n",
      "174:\tlearn: 0.0865881\ttotal: 497ms\tremaining: 71ms\n",
      "175:\tlearn: 0.0862884\ttotal: 499ms\tremaining: 68.1ms\n",
      "176:\tlearn: 0.0859927\ttotal: 502ms\tremaining: 65.2ms\n",
      "177:\tlearn: 0.0855619\ttotal: 505ms\tremaining: 62.4ms\n",
      "178:\tlearn: 0.0854028\ttotal: 508ms\tremaining: 59.6ms\n",
      "179:\tlearn: 0.0851169\ttotal: 510ms\tremaining: 56.7ms\n",
      "180:\tlearn: 0.0849304\ttotal: 513ms\tremaining: 53.9ms\n",
      "181:\tlearn: 0.0846972\ttotal: 516ms\tremaining: 51ms\n",
      "182:\tlearn: 0.0843428\ttotal: 519ms\tremaining: 48.2ms\n",
      "183:\tlearn: 0.0839546\ttotal: 522ms\tremaining: 45.4ms\n",
      "184:\tlearn: 0.0836419\ttotal: 525ms\tremaining: 42.5ms\n",
      "185:\tlearn: 0.0834223\ttotal: 528ms\tremaining: 39.7ms\n",
      "186:\tlearn: 0.0832152\ttotal: 530ms\tremaining: 36.9ms\n",
      "187:\tlearn: 0.0828848\ttotal: 533ms\tremaining: 34ms\n",
      "188:\tlearn: 0.0825221\ttotal: 536ms\tremaining: 31.2ms\n",
      "189:\tlearn: 0.0822239\ttotal: 538ms\tremaining: 28.3ms\n",
      "190:\tlearn: 0.0820680\ttotal: 541ms\tremaining: 25.5ms\n",
      "191:\tlearn: 0.0819399\ttotal: 544ms\tremaining: 22.7ms\n",
      "192:\tlearn: 0.0814834\ttotal: 547ms\tremaining: 19.8ms\n",
      "193:\tlearn: 0.0813415\ttotal: 550ms\tremaining: 17ms\n",
      "194:\tlearn: 0.0811833\ttotal: 553ms\tremaining: 14.2ms\n",
      "195:\tlearn: 0.0810465\ttotal: 556ms\tremaining: 11.3ms\n",
      "196:\tlearn: 0.0807093\ttotal: 558ms\tremaining: 8.5ms\n",
      "197:\tlearn: 0.0804759\ttotal: 561ms\tremaining: 5.67ms\n",
      "198:\tlearn: 0.0801370\ttotal: 564ms\tremaining: 2.83ms\n",
      "199:\tlearn: 0.0799548\ttotal: 567ms\tremaining: 0us\n",
      "0:\tlearn: 0.5733778\ttotal: 3.25ms\tremaining: 647ms\n",
      "1:\tlearn: 0.4943804\ttotal: 5.87ms\tremaining: 581ms\n",
      "2:\tlearn: 0.4330211\ttotal: 8.52ms\tremaining: 560ms\n",
      "3:\tlearn: 0.3897415\ttotal: 11.1ms\tremaining: 544ms\n",
      "4:\tlearn: 0.3555882\ttotal: 13.7ms\tremaining: 533ms\n",
      "5:\tlearn: 0.3272518\ttotal: 16.4ms\tremaining: 530ms\n",
      "6:\tlearn: 0.3059514\ttotal: 19ms\tremaining: 524ms\n",
      "7:\tlearn: 0.2877930\ttotal: 21.7ms\tremaining: 520ms\n",
      "8:\tlearn: 0.2749023\ttotal: 25ms\tremaining: 530ms\n",
      "9:\tlearn: 0.2630067\ttotal: 27.8ms\tremaining: 529ms\n",
      "10:\tlearn: 0.2441124\ttotal: 30.4ms\tremaining: 523ms\n",
      "11:\tlearn: 0.2388378\ttotal: 33ms\tremaining: 517ms\n",
      "12:\tlearn: 0.2277381\ttotal: 35.9ms\tremaining: 516ms\n",
      "13:\tlearn: 0.2159301\ttotal: 38.6ms\tremaining: 513ms\n",
      "14:\tlearn: 0.2107131\ttotal: 41.2ms\tremaining: 508ms\n",
      "15:\tlearn: 0.2062498\ttotal: 44ms\tremaining: 507ms\n",
      "16:\tlearn: 0.2030126\ttotal: 47.6ms\tremaining: 513ms\n",
      "17:\tlearn: 0.1999774\ttotal: 52ms\tremaining: 526ms\n",
      "18:\tlearn: 0.1962853\ttotal: 54.7ms\tremaining: 521ms\n",
      "19:\tlearn: 0.1937615\ttotal: 57.6ms\tremaining: 518ms\n",
      "20:\tlearn: 0.1890056\ttotal: 61.1ms\tremaining: 521ms\n",
      "21:\tlearn: 0.1825975\ttotal: 63.7ms\tremaining: 516ms\n",
      "22:\tlearn: 0.1785567\ttotal: 66.5ms\tremaining: 512ms\n",
      "23:\tlearn: 0.1760920\ttotal: 69.5ms\tremaining: 509ms\n",
      "24:\tlearn: 0.1734670\ttotal: 72ms\tremaining: 504ms\n",
      "25:\tlearn: 0.1689227\ttotal: 74.7ms\tremaining: 500ms\n",
      "26:\tlearn: 0.1631251\ttotal: 77.5ms\tremaining: 497ms\n",
      "27:\tlearn: 0.1606772\ttotal: 80.2ms\tremaining: 492ms\n",
      "28:\tlearn: 0.1586962\ttotal: 83ms\tremaining: 489ms\n",
      "29:\tlearn: 0.1569392\ttotal: 85.9ms\tremaining: 487ms\n",
      "30:\tlearn: 0.1550941\ttotal: 89.6ms\tremaining: 489ms\n",
      "31:\tlearn: 0.1537712\ttotal: 92.3ms\tremaining: 484ms\n",
      "32:\tlearn: 0.1520878\ttotal: 101ms\tremaining: 512ms\n",
      "33:\tlearn: 0.1493997\ttotal: 104ms\tremaining: 508ms\n",
      "34:\tlearn: 0.1475864\ttotal: 107ms\tremaining: 503ms\n",
      "35:\tlearn: 0.1461013\ttotal: 110ms\tremaining: 499ms\n",
      "36:\tlearn: 0.1448474\ttotal: 113ms\tremaining: 497ms\n",
      "37:\tlearn: 0.1437413\ttotal: 116ms\tremaining: 493ms\n",
      "38:\tlearn: 0.1427676\ttotal: 119ms\tremaining: 492ms\n",
      "39:\tlearn: 0.1418386\ttotal: 122ms\tremaining: 487ms\n",
      "40:\tlearn: 0.1373976\ttotal: 124ms\tremaining: 482ms\n",
      "41:\tlearn: 0.1345564\ttotal: 128ms\tremaining: 480ms\n",
      "42:\tlearn: 0.1321108\ttotal: 130ms\tremaining: 476ms\n",
      "43:\tlearn: 0.1283529\ttotal: 133ms\tremaining: 472ms\n",
      "44:\tlearn: 0.1265168\ttotal: 136ms\tremaining: 468ms\n",
      "45:\tlearn: 0.1244645\ttotal: 138ms\tremaining: 463ms\n",
      "46:\tlearn: 0.1228167\ttotal: 141ms\tremaining: 460ms\n",
      "47:\tlearn: 0.1209756\ttotal: 144ms\tremaining: 455ms\n",
      "48:\tlearn: 0.1196110\ttotal: 147ms\tremaining: 452ms\n",
      "49:\tlearn: 0.1175236\ttotal: 150ms\tremaining: 450ms\n",
      "50:\tlearn: 0.1164314\ttotal: 153ms\tremaining: 446ms\n",
      "51:\tlearn: 0.1158459\ttotal: 155ms\tremaining: 442ms\n",
      "52:\tlearn: 0.1148904\ttotal: 158ms\tremaining: 438ms\n",
      "53:\tlearn: 0.1137556\ttotal: 161ms\tremaining: 434ms\n",
      "54:\tlearn: 0.1127042\ttotal: 164ms\tremaining: 433ms\n",
      "55:\tlearn: 0.1105899\ttotal: 167ms\tremaining: 429ms\n",
      "56:\tlearn: 0.1098028\ttotal: 170ms\tremaining: 426ms\n",
      "57:\tlearn: 0.1080852\ttotal: 173ms\tremaining: 424ms\n",
      "58:\tlearn: 0.1069112\ttotal: 176ms\tremaining: 420ms\n",
      "59:\tlearn: 0.1056966\ttotal: 178ms\tremaining: 416ms\n",
      "60:\tlearn: 0.1039878\ttotal: 181ms\tremaining: 412ms\n",
      "61:\tlearn: 0.1033472\ttotal: 184ms\tremaining: 409ms\n",
      "62:\tlearn: 0.1024520\ttotal: 186ms\tremaining: 405ms\n",
      "63:\tlearn: 0.1011455\ttotal: 189ms\tremaining: 402ms\n",
      "64:\tlearn: 0.1004286\ttotal: 192ms\tremaining: 399ms\n",
      "65:\tlearn: 0.0998847\ttotal: 195ms\tremaining: 396ms\n",
      "66:\tlearn: 0.0989263\ttotal: 197ms\tremaining: 392ms\n",
      "67:\tlearn: 0.0979646\ttotal: 200ms\tremaining: 389ms\n",
      "68:\tlearn: 0.0968981\ttotal: 203ms\tremaining: 385ms\n",
      "69:\tlearn: 0.0960477\ttotal: 206ms\tremaining: 382ms\n",
      "70:\tlearn: 0.0950162\ttotal: 208ms\tremaining: 378ms\n",
      "71:\tlearn: 0.0945125\ttotal: 211ms\tremaining: 375ms\n",
      "72:\tlearn: 0.0938997\ttotal: 214ms\tremaining: 372ms\n",
      "73:\tlearn: 0.0933824\ttotal: 216ms\tremaining: 369ms\n",
      "74:\tlearn: 0.0930477\ttotal: 220ms\tremaining: 366ms\n",
      "75:\tlearn: 0.0925483\ttotal: 223ms\tremaining: 364ms\n",
      "76:\tlearn: 0.0912060\ttotal: 226ms\tremaining: 361ms\n",
      "77:\tlearn: 0.0907401\ttotal: 228ms\tremaining: 357ms\n",
      "78:\tlearn: 0.0902467\ttotal: 231ms\tremaining: 354ms\n",
      "79:\tlearn: 0.0892589\ttotal: 234ms\tremaining: 351ms\n",
      "80:\tlearn: 0.0884743\ttotal: 237ms\tremaining: 348ms\n",
      "81:\tlearn: 0.0874681\ttotal: 240ms\tremaining: 345ms\n",
      "82:\tlearn: 0.0867606\ttotal: 243ms\tremaining: 342ms\n",
      "83:\tlearn: 0.0858289\ttotal: 245ms\tremaining: 339ms\n",
      "84:\tlearn: 0.0854516\ttotal: 248ms\tremaining: 336ms\n",
      "85:\tlearn: 0.0847661\ttotal: 251ms\tremaining: 333ms\n",
      "86:\tlearn: 0.0842163\ttotal: 254ms\tremaining: 330ms\n",
      "87:\tlearn: 0.0837768\ttotal: 257ms\tremaining: 327ms\n",
      "88:\tlearn: 0.0830725\ttotal: 259ms\tremaining: 324ms\n",
      "89:\tlearn: 0.0826391\ttotal: 262ms\tremaining: 320ms\n",
      "90:\tlearn: 0.0823041\ttotal: 265ms\tremaining: 317ms\n",
      "91:\tlearn: 0.0811853\ttotal: 267ms\tremaining: 314ms\n",
      "92:\tlearn: 0.0803851\ttotal: 270ms\tremaining: 311ms\n",
      "93:\tlearn: 0.0801892\ttotal: 273ms\tremaining: 308ms\n",
      "94:\tlearn: 0.0793723\ttotal: 276ms\tremaining: 305ms\n",
      "95:\tlearn: 0.0787736\ttotal: 279ms\tremaining: 302ms\n",
      "96:\tlearn: 0.0785433\ttotal: 283ms\tremaining: 300ms\n",
      "97:\tlearn: 0.0784137\ttotal: 286ms\tremaining: 297ms\n",
      "98:\tlearn: 0.0776626\ttotal: 288ms\tremaining: 294ms\n",
      "99:\tlearn: 0.0769712\ttotal: 291ms\tremaining: 291ms\n",
      "100:\tlearn: 0.0766199\ttotal: 294ms\tremaining: 289ms\n",
      "101:\tlearn: 0.0761116\ttotal: 298ms\tremaining: 286ms\n",
      "102:\tlearn: 0.0754635\ttotal: 301ms\tremaining: 283ms\n",
      "103:\tlearn: 0.0746822\ttotal: 303ms\tremaining: 280ms\n",
      "104:\tlearn: 0.0743016\ttotal: 306ms\tremaining: 277ms\n",
      "105:\tlearn: 0.0740155\ttotal: 309ms\tremaining: 274ms\n",
      "106:\tlearn: 0.0732209\ttotal: 312ms\tremaining: 271ms\n",
      "107:\tlearn: 0.0728169\ttotal: 314ms\tremaining: 268ms\n",
      "108:\tlearn: 0.0727468\ttotal: 317ms\tremaining: 265ms\n",
      "109:\tlearn: 0.0721302\ttotal: 320ms\tremaining: 262ms\n",
      "110:\tlearn: 0.0713731\ttotal: 322ms\tremaining: 259ms\n",
      "111:\tlearn: 0.0707494\ttotal: 325ms\tremaining: 256ms\n",
      "112:\tlearn: 0.0701228\ttotal: 328ms\tremaining: 253ms\n",
      "113:\tlearn: 0.0694522\ttotal: 331ms\tremaining: 249ms\n",
      "114:\tlearn: 0.0691741\ttotal: 333ms\tremaining: 246ms\n",
      "115:\tlearn: 0.0689298\ttotal: 336ms\tremaining: 243ms\n",
      "116:\tlearn: 0.0685116\ttotal: 339ms\tremaining: 240ms\n",
      "117:\tlearn: 0.0680541\ttotal: 342ms\tremaining: 237ms\n",
      "118:\tlearn: 0.0677763\ttotal: 345ms\tremaining: 235ms\n",
      "119:\tlearn: 0.0677013\ttotal: 348ms\tremaining: 232ms\n",
      "120:\tlearn: 0.0670048\ttotal: 351ms\tremaining: 229ms\n",
      "121:\tlearn: 0.0669849\ttotal: 354ms\tremaining: 226ms\n",
      "122:\tlearn: 0.0663331\ttotal: 356ms\tremaining: 223ms\n",
      "123:\tlearn: 0.0662766\ttotal: 359ms\tremaining: 220ms\n",
      "124:\tlearn: 0.0659561\ttotal: 362ms\tremaining: 217ms\n",
      "125:\tlearn: 0.0655255\ttotal: 365ms\tremaining: 214ms\n",
      "126:\tlearn: 0.0651641\ttotal: 367ms\tremaining: 211ms\n",
      "127:\tlearn: 0.0648922\ttotal: 370ms\tremaining: 208ms\n",
      "128:\tlearn: 0.0648660\ttotal: 373ms\tremaining: 205ms\n",
      "129:\tlearn: 0.0646341\ttotal: 376ms\tremaining: 203ms\n",
      "130:\tlearn: 0.0642489\ttotal: 379ms\tremaining: 200ms\n",
      "131:\tlearn: 0.0638025\ttotal: 382ms\tremaining: 197ms\n",
      "132:\tlearn: 0.0633355\ttotal: 385ms\tremaining: 194ms\n",
      "133:\tlearn: 0.0630590\ttotal: 389ms\tremaining: 191ms\n",
      "134:\tlearn: 0.0627972\ttotal: 391ms\tremaining: 188ms\n",
      "135:\tlearn: 0.0627480\ttotal: 395ms\tremaining: 186ms\n",
      "136:\tlearn: 0.0622534\ttotal: 397ms\tremaining: 183ms\n",
      "137:\tlearn: 0.0622111\ttotal: 400ms\tremaining: 180ms\n",
      "138:\tlearn: 0.0618668\ttotal: 403ms\tremaining: 177ms\n",
      "139:\tlearn: 0.0615957\ttotal: 405ms\tremaining: 174ms\n",
      "140:\tlearn: 0.0611095\ttotal: 409ms\tremaining: 171ms\n",
      "141:\tlearn: 0.0607434\ttotal: 411ms\tremaining: 168ms\n",
      "142:\tlearn: 0.0603751\ttotal: 414ms\tremaining: 165ms\n",
      "143:\tlearn: 0.0600309\ttotal: 418ms\tremaining: 162ms\n",
      "144:\tlearn: 0.0593272\ttotal: 420ms\tremaining: 159ms\n",
      "145:\tlearn: 0.0592725\ttotal: 423ms\tremaining: 157ms\n",
      "146:\tlearn: 0.0590424\ttotal: 427ms\tremaining: 154ms\n",
      "147:\tlearn: 0.0589210\ttotal: 429ms\tremaining: 151ms\n",
      "148:\tlearn: 0.0586099\ttotal: 432ms\tremaining: 148ms\n",
      "149:\tlearn: 0.0585732\ttotal: 435ms\tremaining: 145ms\n",
      "150:\tlearn: 0.0583194\ttotal: 438ms\tremaining: 142ms\n",
      "151:\tlearn: 0.0580654\ttotal: 441ms\tremaining: 139ms\n",
      "152:\tlearn: 0.0578654\ttotal: 443ms\tremaining: 136ms\n",
      "153:\tlearn: 0.0576512\ttotal: 446ms\tremaining: 133ms\n",
      "154:\tlearn: 0.0573333\ttotal: 449ms\tremaining: 130ms\n",
      "155:\tlearn: 0.0571406\ttotal: 452ms\tremaining: 128ms\n",
      "156:\tlearn: 0.0569607\ttotal: 455ms\tremaining: 125ms\n",
      "157:\tlearn: 0.0564213\ttotal: 458ms\tremaining: 122ms\n",
      "158:\tlearn: 0.0562999\ttotal: 461ms\tremaining: 119ms\n",
      "159:\tlearn: 0.0559004\ttotal: 464ms\tremaining: 116ms\n",
      "160:\tlearn: 0.0555252\ttotal: 466ms\tremaining: 113ms\n",
      "161:\tlearn: 0.0553282\ttotal: 469ms\tremaining: 110ms\n",
      "162:\tlearn: 0.0552281\ttotal: 472ms\tremaining: 107ms\n",
      "163:\tlearn: 0.0549442\ttotal: 475ms\tremaining: 104ms\n",
      "164:\tlearn: 0.0546837\ttotal: 478ms\tremaining: 101ms\n",
      "165:\tlearn: 0.0542936\ttotal: 480ms\tremaining: 98.3ms\n",
      "166:\tlearn: 0.0541147\ttotal: 483ms\tremaining: 95.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167:\tlearn: 0.0538700\ttotal: 485ms\tremaining: 92.5ms\n",
      "168:\tlearn: 0.0537303\ttotal: 488ms\tremaining: 89.5ms\n",
      "169:\tlearn: 0.0532502\ttotal: 491ms\tremaining: 86.7ms\n",
      "170:\tlearn: 0.0532015\ttotal: 494ms\tremaining: 83.8ms\n",
      "171:\tlearn: 0.0531805\ttotal: 497ms\tremaining: 81ms\n",
      "172:\tlearn: 0.0528679\ttotal: 500ms\tremaining: 78ms\n",
      "173:\tlearn: 0.0527480\ttotal: 503ms\tremaining: 75.2ms\n",
      "174:\tlearn: 0.0523003\ttotal: 506ms\tremaining: 72.2ms\n",
      "175:\tlearn: 0.0520344\ttotal: 509ms\tremaining: 69.4ms\n",
      "176:\tlearn: 0.0520049\ttotal: 512ms\tremaining: 66.5ms\n",
      "177:\tlearn: 0.0517395\ttotal: 515ms\tremaining: 63.6ms\n",
      "178:\tlearn: 0.0516717\ttotal: 518ms\tremaining: 60.8ms\n",
      "179:\tlearn: 0.0512115\ttotal: 521ms\tremaining: 57.8ms\n",
      "180:\tlearn: 0.0509860\ttotal: 524ms\tremaining: 55ms\n",
      "181:\tlearn: 0.0507223\ttotal: 526ms\tremaining: 52ms\n",
      "182:\tlearn: 0.0504782\ttotal: 530ms\tremaining: 49.2ms\n",
      "183:\tlearn: 0.0502947\ttotal: 533ms\tremaining: 46.3ms\n",
      "184:\tlearn: 0.0500825\ttotal: 535ms\tremaining: 43.4ms\n",
      "185:\tlearn: 0.0498518\ttotal: 538ms\tremaining: 40.5ms\n",
      "186:\tlearn: 0.0496772\ttotal: 541ms\tremaining: 37.6ms\n",
      "187:\tlearn: 0.0492841\ttotal: 544ms\tremaining: 34.7ms\n",
      "188:\tlearn: 0.0490482\ttotal: 546ms\tremaining: 31.8ms\n",
      "189:\tlearn: 0.0489567\ttotal: 549ms\tremaining: 28.9ms\n",
      "190:\tlearn: 0.0488207\ttotal: 552ms\tremaining: 26ms\n",
      "191:\tlearn: 0.0486130\ttotal: 555ms\tremaining: 23.1ms\n",
      "192:\tlearn: 0.0481700\ttotal: 557ms\tremaining: 20.2ms\n",
      "193:\tlearn: 0.0481544\ttotal: 560ms\tremaining: 17.3ms\n",
      "194:\tlearn: 0.0479353\ttotal: 563ms\tremaining: 14.4ms\n",
      "195:\tlearn: 0.0478332\ttotal: 566ms\tremaining: 11.6ms\n",
      "196:\tlearn: 0.0478276\ttotal: 570ms\tremaining: 8.67ms\n",
      "197:\tlearn: 0.0477559\ttotal: 573ms\tremaining: 5.79ms\n",
      "198:\tlearn: 0.0476013\ttotal: 576ms\tremaining: 2.89ms\n",
      "199:\tlearn: 0.0473242\ttotal: 578ms\tremaining: 0us\n",
      "0:\tlearn: 0.5875579\ttotal: 2.33ms\tremaining: 464ms\n",
      "1:\tlearn: 0.5107307\ttotal: 4.96ms\tremaining: 491ms\n",
      "2:\tlearn: 0.4464928\ttotal: 8.16ms\tremaining: 536ms\n",
      "3:\tlearn: 0.3974658\ttotal: 10.5ms\tremaining: 515ms\n",
      "4:\tlearn: 0.3609478\ttotal: 13.1ms\tremaining: 511ms\n",
      "5:\tlearn: 0.3314610\ttotal: 15.7ms\tremaining: 509ms\n",
      "6:\tlearn: 0.3123821\ttotal: 18.6ms\tremaining: 513ms\n",
      "7:\tlearn: 0.2917407\ttotal: 21.2ms\tremaining: 509ms\n",
      "8:\tlearn: 0.2733475\ttotal: 23.7ms\tremaining: 504ms\n",
      "9:\tlearn: 0.2652638\ttotal: 27ms\tremaining: 513ms\n",
      "10:\tlearn: 0.2531864\ttotal: 30ms\tremaining: 515ms\n",
      "11:\tlearn: 0.2394344\ttotal: 32.8ms\tremaining: 513ms\n",
      "12:\tlearn: 0.2224952\ttotal: 35.3ms\tremaining: 508ms\n",
      "13:\tlearn: 0.2104869\ttotal: 38ms\tremaining: 505ms\n",
      "14:\tlearn: 0.2005291\ttotal: 40.5ms\tremaining: 500ms\n",
      "15:\tlearn: 0.1958036\ttotal: 43.3ms\tremaining: 498ms\n",
      "16:\tlearn: 0.1923452\ttotal: 46ms\tremaining: 495ms\n",
      "17:\tlearn: 0.1891530\ttotal: 48.9ms\tremaining: 494ms\n",
      "18:\tlearn: 0.1858419\ttotal: 51.6ms\tremaining: 492ms\n",
      "19:\tlearn: 0.1818924\ttotal: 54.7ms\tremaining: 492ms\n",
      "20:\tlearn: 0.1754264\ttotal: 57.2ms\tremaining: 488ms\n",
      "21:\tlearn: 0.1723808\ttotal: 59.9ms\tremaining: 485ms\n",
      "22:\tlearn: 0.1685391\ttotal: 62.9ms\tremaining: 484ms\n",
      "23:\tlearn: 0.1653852\ttotal: 65.9ms\tremaining: 483ms\n",
      "24:\tlearn: 0.1605653\ttotal: 68.5ms\tremaining: 479ms\n",
      "25:\tlearn: 0.1585505\ttotal: 71ms\tremaining: 475ms\n",
      "26:\tlearn: 0.1560632\ttotal: 73.5ms\tremaining: 471ms\n",
      "27:\tlearn: 0.1532462\ttotal: 76.1ms\tremaining: 467ms\n",
      "28:\tlearn: 0.1510755\ttotal: 78.7ms\tremaining: 464ms\n",
      "29:\tlearn: 0.1492343\ttotal: 81.6ms\tremaining: 462ms\n",
      "30:\tlearn: 0.1478231\ttotal: 84.4ms\tremaining: 460ms\n",
      "31:\tlearn: 0.1441877\ttotal: 87.4ms\tremaining: 459ms\n",
      "32:\tlearn: 0.1421902\ttotal: 90.4ms\tremaining: 458ms\n",
      "33:\tlearn: 0.1404691\ttotal: 93.2ms\tremaining: 455ms\n",
      "34:\tlearn: 0.1373847\ttotal: 96.7ms\tremaining: 456ms\n",
      "35:\tlearn: 0.1360666\ttotal: 99.2ms\tremaining: 452ms\n",
      "36:\tlearn: 0.1333398\ttotal: 102ms\tremaining: 449ms\n",
      "37:\tlearn: 0.1321261\ttotal: 105ms\tremaining: 446ms\n",
      "38:\tlearn: 0.1308575\ttotal: 107ms\tremaining: 442ms\n",
      "39:\tlearn: 0.1290681\ttotal: 110ms\tremaining: 439ms\n",
      "40:\tlearn: 0.1281769\ttotal: 112ms\tremaining: 436ms\n",
      "41:\tlearn: 0.1269181\ttotal: 115ms\tremaining: 433ms\n",
      "42:\tlearn: 0.1242904\ttotal: 119ms\tremaining: 433ms\n",
      "43:\tlearn: 0.1230411\ttotal: 121ms\tremaining: 429ms\n",
      "44:\tlearn: 0.1208988\ttotal: 125ms\tremaining: 429ms\n",
      "45:\tlearn: 0.1201618\ttotal: 127ms\tremaining: 427ms\n",
      "46:\tlearn: 0.1182708\ttotal: 130ms\tremaining: 423ms\n",
      "47:\tlearn: 0.1164960\ttotal: 133ms\tremaining: 420ms\n",
      "48:\tlearn: 0.1157179\ttotal: 136ms\tremaining: 418ms\n",
      "49:\tlearn: 0.1148174\ttotal: 138ms\tremaining: 415ms\n",
      "50:\tlearn: 0.1134767\ttotal: 141ms\tremaining: 412ms\n",
      "51:\tlearn: 0.1126333\ttotal: 144ms\tremaining: 410ms\n",
      "52:\tlearn: 0.1118937\ttotal: 147ms\tremaining: 407ms\n",
      "53:\tlearn: 0.1101758\ttotal: 149ms\tremaining: 404ms\n",
      "54:\tlearn: 0.1089396\ttotal: 152ms\tremaining: 401ms\n",
      "55:\tlearn: 0.1083007\ttotal: 156ms\tremaining: 400ms\n",
      "56:\tlearn: 0.1075864\ttotal: 158ms\tremaining: 397ms\n",
      "57:\tlearn: 0.1059256\ttotal: 162ms\tremaining: 396ms\n",
      "58:\tlearn: 0.1055215\ttotal: 164ms\tremaining: 393ms\n",
      "59:\tlearn: 0.1045999\ttotal: 167ms\tremaining: 390ms\n",
      "60:\tlearn: 0.1040555\ttotal: 170ms\tremaining: 387ms\n",
      "61:\tlearn: 0.1030953\ttotal: 172ms\tremaining: 383ms\n",
      "62:\tlearn: 0.1024645\ttotal: 176ms\tremaining: 382ms\n",
      "63:\tlearn: 0.1019067\ttotal: 179ms\tremaining: 381ms\n",
      "64:\tlearn: 0.1013146\ttotal: 182ms\tremaining: 379ms\n",
      "65:\tlearn: 0.0996981\ttotal: 185ms\tremaining: 376ms\n",
      "66:\tlearn: 0.0990770\ttotal: 188ms\tremaining: 373ms\n",
      "67:\tlearn: 0.0987872\ttotal: 191ms\tremaining: 370ms\n",
      "68:\tlearn: 0.0983922\ttotal: 194ms\tremaining: 368ms\n",
      "69:\tlearn: 0.0969360\ttotal: 196ms\tremaining: 365ms\n",
      "70:\tlearn: 0.0958762\ttotal: 200ms\tremaining: 363ms\n",
      "71:\tlearn: 0.0956488\ttotal: 203ms\tremaining: 360ms\n",
      "72:\tlearn: 0.0952353\ttotal: 206ms\tremaining: 358ms\n",
      "73:\tlearn: 0.0952301\ttotal: 208ms\tremaining: 355ms\n",
      "74:\tlearn: 0.0944250\ttotal: 211ms\tremaining: 352ms\n",
      "75:\tlearn: 0.0935224\ttotal: 214ms\tremaining: 349ms\n",
      "76:\tlearn: 0.0934395\ttotal: 216ms\tremaining: 346ms\n",
      "77:\tlearn: 0.0928293\ttotal: 220ms\tremaining: 343ms\n",
      "78:\tlearn: 0.0923167\ttotal: 222ms\tremaining: 341ms\n",
      "79:\tlearn: 0.0917381\ttotal: 225ms\tremaining: 337ms\n",
      "80:\tlearn: 0.0908391\ttotal: 228ms\tremaining: 335ms\n",
      "81:\tlearn: 0.0898164\ttotal: 230ms\tremaining: 332ms\n",
      "82:\tlearn: 0.0888876\ttotal: 233ms\tremaining: 329ms\n",
      "83:\tlearn: 0.0886504\ttotal: 236ms\tremaining: 326ms\n",
      "84:\tlearn: 0.0886494\ttotal: 238ms\tremaining: 322ms\n",
      "85:\tlearn: 0.0875048\ttotal: 241ms\tremaining: 319ms\n",
      "86:\tlearn: 0.0872209\ttotal: 243ms\tremaining: 316ms\n",
      "87:\tlearn: 0.0862355\ttotal: 246ms\tremaining: 313ms\n",
      "88:\tlearn: 0.0861009\ttotal: 249ms\tremaining: 311ms\n",
      "89:\tlearn: 0.0856243\ttotal: 252ms\tremaining: 308ms\n",
      "90:\tlearn: 0.0847018\ttotal: 255ms\tremaining: 305ms\n",
      "91:\tlearn: 0.0842745\ttotal: 258ms\tremaining: 303ms\n",
      "92:\tlearn: 0.0840848\ttotal: 260ms\tremaining: 300ms\n",
      "93:\tlearn: 0.0833607\ttotal: 263ms\tremaining: 297ms\n",
      "94:\tlearn: 0.0824166\ttotal: 266ms\tremaining: 294ms\n",
      "95:\tlearn: 0.0818007\ttotal: 269ms\tremaining: 291ms\n",
      "96:\tlearn: 0.0813620\ttotal: 272ms\tremaining: 289ms\n",
      "97:\tlearn: 0.0809280\ttotal: 275ms\tremaining: 286ms\n",
      "98:\tlearn: 0.0809205\ttotal: 277ms\tremaining: 283ms\n",
      "99:\tlearn: 0.0798959\ttotal: 280ms\tremaining: 280ms\n",
      "100:\tlearn: 0.0795165\ttotal: 283ms\tremaining: 277ms\n",
      "101:\tlearn: 0.0789427\ttotal: 286ms\tremaining: 274ms\n",
      "102:\tlearn: 0.0783270\ttotal: 289ms\tremaining: 272ms\n",
      "103:\tlearn: 0.0779528\ttotal: 291ms\tremaining: 269ms\n",
      "104:\tlearn: 0.0774203\ttotal: 294ms\tremaining: 266ms\n",
      "105:\tlearn: 0.0774003\ttotal: 297ms\tremaining: 263ms\n",
      "106:\tlearn: 0.0773868\ttotal: 299ms\tremaining: 260ms\n",
      "107:\tlearn: 0.0767685\ttotal: 302ms\tremaining: 257ms\n",
      "108:\tlearn: 0.0764086\ttotal: 305ms\tremaining: 254ms\n",
      "109:\tlearn: 0.0757963\ttotal: 307ms\tremaining: 251ms\n",
      "110:\tlearn: 0.0753504\ttotal: 310ms\tremaining: 248ms\n",
      "111:\tlearn: 0.0746373\ttotal: 313ms\tremaining: 246ms\n",
      "112:\tlearn: 0.0742575\ttotal: 316ms\tremaining: 243ms\n",
      "113:\tlearn: 0.0737430\ttotal: 319ms\tremaining: 241ms\n",
      "114:\tlearn: 0.0736655\ttotal: 322ms\tremaining: 238ms\n",
      "115:\tlearn: 0.0733348\ttotal: 324ms\tremaining: 235ms\n",
      "116:\tlearn: 0.0729780\ttotal: 328ms\tremaining: 232ms\n",
      "117:\tlearn: 0.0726700\ttotal: 330ms\tremaining: 230ms\n",
      "118:\tlearn: 0.0726533\ttotal: 333ms\tremaining: 226ms\n",
      "119:\tlearn: 0.0726280\ttotal: 336ms\tremaining: 224ms\n",
      "120:\tlearn: 0.0719823\ttotal: 339ms\tremaining: 221ms\n",
      "121:\tlearn: 0.0719821\ttotal: 341ms\tremaining: 218ms\n",
      "122:\tlearn: 0.0716887\ttotal: 344ms\tremaining: 215ms\n",
      "123:\tlearn: 0.0716556\ttotal: 347ms\tremaining: 212ms\n",
      "124:\tlearn: 0.0716431\ttotal: 350ms\tremaining: 210ms\n",
      "125:\tlearn: 0.0715312\ttotal: 353ms\tremaining: 207ms\n",
      "126:\tlearn: 0.0707899\ttotal: 356ms\tremaining: 204ms\n",
      "127:\tlearn: 0.0707882\ttotal: 359ms\tremaining: 202ms\n",
      "128:\tlearn: 0.0699476\ttotal: 362ms\tremaining: 199ms\n",
      "129:\tlearn: 0.0695622\ttotal: 365ms\tremaining: 197ms\n",
      "130:\tlearn: 0.0695583\ttotal: 367ms\tremaining: 193ms\n",
      "131:\tlearn: 0.0692769\ttotal: 370ms\tremaining: 191ms\n",
      "132:\tlearn: 0.0690221\ttotal: 372ms\tremaining: 188ms\n",
      "133:\tlearn: 0.0689361\ttotal: 375ms\tremaining: 185ms\n",
      "134:\tlearn: 0.0686003\ttotal: 378ms\tremaining: 182ms\n",
      "135:\tlearn: 0.0682113\ttotal: 381ms\tremaining: 179ms\n",
      "136:\tlearn: 0.0679300\ttotal: 384ms\tremaining: 176ms\n",
      "137:\tlearn: 0.0673537\ttotal: 386ms\tremaining: 174ms\n",
      "138:\tlearn: 0.0670644\ttotal: 389ms\tremaining: 171ms\n",
      "139:\tlearn: 0.0670642\ttotal: 391ms\tremaining: 168ms\n",
      "140:\tlearn: 0.0664866\ttotal: 394ms\tremaining: 165ms\n",
      "141:\tlearn: 0.0661993\ttotal: 397ms\tremaining: 162ms\n",
      "142:\tlearn: 0.0657574\ttotal: 400ms\tremaining: 159ms\n",
      "143:\tlearn: 0.0652623\ttotal: 403ms\tremaining: 157ms\n",
      "144:\tlearn: 0.0651729\ttotal: 405ms\tremaining: 154ms\n",
      "145:\tlearn: 0.0649670\ttotal: 408ms\tremaining: 151ms\n",
      "146:\tlearn: 0.0646908\ttotal: 411ms\tremaining: 148ms\n",
      "147:\tlearn: 0.0642366\ttotal: 414ms\tremaining: 145ms\n",
      "148:\tlearn: 0.0641391\ttotal: 416ms\tremaining: 142ms\n",
      "149:\tlearn: 0.0636481\ttotal: 419ms\tremaining: 140ms\n",
      "150:\tlearn: 0.0632474\ttotal: 422ms\tremaining: 137ms\n",
      "151:\tlearn: 0.0628736\ttotal: 425ms\tremaining: 134ms\n",
      "152:\tlearn: 0.0624750\ttotal: 428ms\tremaining: 131ms\n",
      "153:\tlearn: 0.0620783\ttotal: 430ms\tremaining: 129ms\n",
      "154:\tlearn: 0.0619070\ttotal: 433ms\tremaining: 126ms\n",
      "155:\tlearn: 0.0615922\ttotal: 436ms\tremaining: 123ms\n",
      "156:\tlearn: 0.0614888\ttotal: 439ms\tremaining: 120ms\n",
      "157:\tlearn: 0.0609825\ttotal: 442ms\tremaining: 117ms\n",
      "158:\tlearn: 0.0608475\ttotal: 444ms\tremaining: 115ms\n",
      "159:\tlearn: 0.0604423\ttotal: 447ms\tremaining: 112ms\n",
      "160:\tlearn: 0.0600838\ttotal: 450ms\tremaining: 109ms\n",
      "161:\tlearn: 0.0599164\ttotal: 453ms\tremaining: 106ms\n",
      "162:\tlearn: 0.0598754\ttotal: 455ms\tremaining: 103ms\n",
      "163:\tlearn: 0.0597428\ttotal: 458ms\tremaining: 101ms\n",
      "164:\tlearn: 0.0596331\ttotal: 462ms\tremaining: 98ms\n",
      "165:\tlearn: 0.0594350\ttotal: 465ms\tremaining: 95.3ms\n",
      "166:\tlearn: 0.0594151\ttotal: 468ms\tremaining: 92.5ms\n",
      "167:\tlearn: 0.0591344\ttotal: 471ms\tremaining: 89.6ms\n",
      "168:\tlearn: 0.0587935\ttotal: 474ms\tremaining: 86.9ms\n",
      "169:\tlearn: 0.0585249\ttotal: 476ms\tremaining: 84.1ms\n",
      "170:\tlearn: 0.0583425\ttotal: 479ms\tremaining: 81.2ms\n",
      "171:\tlearn: 0.0580711\ttotal: 482ms\tremaining: 78.5ms\n",
      "172:\tlearn: 0.0578851\ttotal: 485ms\tremaining: 75.7ms\n",
      "173:\tlearn: 0.0575061\ttotal: 487ms\tremaining: 72.8ms\n",
      "174:\tlearn: 0.0574361\ttotal: 491ms\tremaining: 70.2ms\n",
      "175:\tlearn: 0.0572818\ttotal: 494ms\tremaining: 67.3ms\n",
      "176:\tlearn: 0.0572100\ttotal: 497ms\tremaining: 64.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177:\tlearn: 0.0569985\ttotal: 500ms\tremaining: 61.7ms\n",
      "178:\tlearn: 0.0568376\ttotal: 503ms\tremaining: 59ms\n",
      "179:\tlearn: 0.0565693\ttotal: 506ms\tremaining: 56.2ms\n",
      "180:\tlearn: 0.0564269\ttotal: 510ms\tremaining: 53.5ms\n",
      "181:\tlearn: 0.0561958\ttotal: 512ms\tremaining: 50.7ms\n",
      "182:\tlearn: 0.0558835\ttotal: 515ms\tremaining: 47.8ms\n",
      "183:\tlearn: 0.0557879\ttotal: 517ms\tremaining: 45ms\n",
      "184:\tlearn: 0.0556536\ttotal: 520ms\tremaining: 42.2ms\n",
      "185:\tlearn: 0.0554446\ttotal: 523ms\tremaining: 39.3ms\n",
      "186:\tlearn: 0.0553355\ttotal: 525ms\tremaining: 36.5ms\n",
      "187:\tlearn: 0.0552644\ttotal: 529ms\tremaining: 33.7ms\n",
      "188:\tlearn: 0.0549255\ttotal: 531ms\tremaining: 30.9ms\n",
      "189:\tlearn: 0.0546710\ttotal: 534ms\tremaining: 28.1ms\n",
      "190:\tlearn: 0.0546529\ttotal: 537ms\tremaining: 25.3ms\n",
      "191:\tlearn: 0.0546450\ttotal: 540ms\tremaining: 22.5ms\n",
      "192:\tlearn: 0.0544398\ttotal: 543ms\tremaining: 19.7ms\n",
      "193:\tlearn: 0.0544026\ttotal: 546ms\tremaining: 16.9ms\n",
      "194:\tlearn: 0.0541714\ttotal: 550ms\tremaining: 14.1ms\n",
      "195:\tlearn: 0.0541697\ttotal: 553ms\tremaining: 11.3ms\n",
      "196:\tlearn: 0.0541676\ttotal: 556ms\tremaining: 8.46ms\n",
      "197:\tlearn: 0.0541072\ttotal: 559ms\tremaining: 5.64ms\n",
      "198:\tlearn: 0.0541055\ttotal: 562ms\tremaining: 2.82ms\n",
      "199:\tlearn: 0.0538943\ttotal: 565ms\tremaining: 0us\n",
      "0:\tlearn: 0.5801630\ttotal: 2.5ms\tremaining: 498ms\n",
      "1:\tlearn: 0.4884107\ttotal: 5.04ms\tremaining: 499ms\n",
      "2:\tlearn: 0.4297750\ttotal: 7.29ms\tremaining: 479ms\n",
      "3:\tlearn: 0.3859401\ttotal: 10.1ms\tremaining: 496ms\n",
      "4:\tlearn: 0.3525200\ttotal: 12.9ms\tremaining: 501ms\n",
      "5:\tlearn: 0.3287980\ttotal: 15.8ms\tremaining: 511ms\n",
      "6:\tlearn: 0.3085710\ttotal: 18.4ms\tremaining: 507ms\n",
      "7:\tlearn: 0.2879914\ttotal: 21.1ms\tremaining: 507ms\n",
      "8:\tlearn: 0.2747690\ttotal: 24.4ms\tremaining: 519ms\n",
      "9:\tlearn: 0.2555778\ttotal: 27.4ms\tremaining: 520ms\n",
      "10:\tlearn: 0.2467533\ttotal: 30.5ms\tremaining: 525ms\n",
      "11:\tlearn: 0.2398081\ttotal: 34ms\tremaining: 532ms\n",
      "12:\tlearn: 0.2228269\ttotal: 36.8ms\tremaining: 530ms\n",
      "13:\tlearn: 0.2098770\ttotal: 39.4ms\tremaining: 524ms\n",
      "14:\tlearn: 0.1995590\ttotal: 42.3ms\tremaining: 522ms\n",
      "15:\tlearn: 0.1932680\ttotal: 45.2ms\tremaining: 520ms\n",
      "16:\tlearn: 0.1893043\ttotal: 47.9ms\tremaining: 515ms\n",
      "17:\tlearn: 0.1853562\ttotal: 50.8ms\tremaining: 513ms\n",
      "18:\tlearn: 0.1812351\ttotal: 53.5ms\tremaining: 510ms\n",
      "19:\tlearn: 0.1784684\ttotal: 56.4ms\tremaining: 508ms\n",
      "20:\tlearn: 0.1762586\ttotal: 59.4ms\tremaining: 506ms\n",
      "21:\tlearn: 0.1731004\ttotal: 62ms\tremaining: 502ms\n",
      "22:\tlearn: 0.1710815\ttotal: 64.5ms\tremaining: 496ms\n",
      "23:\tlearn: 0.1697702\ttotal: 67.4ms\tremaining: 494ms\n",
      "24:\tlearn: 0.1664385\ttotal: 70.2ms\tremaining: 492ms\n",
      "25:\tlearn: 0.1647343\ttotal: 73ms\tremaining: 488ms\n",
      "26:\tlearn: 0.1620100\ttotal: 75.9ms\tremaining: 486ms\n",
      "27:\tlearn: 0.1594891\ttotal: 78.6ms\tremaining: 483ms\n",
      "28:\tlearn: 0.1573063\ttotal: 81.1ms\tremaining: 478ms\n",
      "29:\tlearn: 0.1553751\ttotal: 83.9ms\tremaining: 475ms\n",
      "30:\tlearn: 0.1502992\ttotal: 86.7ms\tremaining: 472ms\n",
      "31:\tlearn: 0.1489691\ttotal: 89.2ms\tremaining: 468ms\n",
      "32:\tlearn: 0.1473559\ttotal: 92.1ms\tremaining: 466ms\n",
      "33:\tlearn: 0.1454417\ttotal: 94.8ms\tremaining: 463ms\n",
      "34:\tlearn: 0.1439293\ttotal: 97.9ms\tremaining: 461ms\n",
      "35:\tlearn: 0.1427629\ttotal: 101ms\tremaining: 459ms\n",
      "36:\tlearn: 0.1396106\ttotal: 103ms\tremaining: 456ms\n",
      "37:\tlearn: 0.1359807\ttotal: 106ms\tremaining: 453ms\n",
      "38:\tlearn: 0.1341594\ttotal: 109ms\tremaining: 450ms\n",
      "39:\tlearn: 0.1327278\ttotal: 112ms\tremaining: 448ms\n",
      "40:\tlearn: 0.1308238\ttotal: 115ms\tremaining: 445ms\n",
      "41:\tlearn: 0.1300820\ttotal: 118ms\tremaining: 443ms\n",
      "42:\tlearn: 0.1277699\ttotal: 120ms\tremaining: 439ms\n",
      "43:\tlearn: 0.1250479\ttotal: 124ms\tremaining: 438ms\n",
      "44:\tlearn: 0.1239975\ttotal: 126ms\tremaining: 435ms\n",
      "45:\tlearn: 0.1232857\ttotal: 129ms\tremaining: 432ms\n",
      "46:\tlearn: 0.1215602\ttotal: 132ms\tremaining: 429ms\n",
      "47:\tlearn: 0.1194136\ttotal: 135ms\tremaining: 427ms\n",
      "48:\tlearn: 0.1182866\ttotal: 137ms\tremaining: 424ms\n",
      "49:\tlearn: 0.1165108\ttotal: 140ms\tremaining: 421ms\n",
      "50:\tlearn: 0.1155705\ttotal: 143ms\tremaining: 418ms\n",
      "51:\tlearn: 0.1149048\ttotal: 146ms\tremaining: 415ms\n",
      "52:\tlearn: 0.1140180\ttotal: 149ms\tremaining: 413ms\n",
      "53:\tlearn: 0.1127414\ttotal: 152ms\tremaining: 410ms\n",
      "54:\tlearn: 0.1118985\ttotal: 154ms\tremaining: 407ms\n",
      "55:\tlearn: 0.1109840\ttotal: 157ms\tremaining: 404ms\n",
      "56:\tlearn: 0.1100789\ttotal: 160ms\tremaining: 401ms\n",
      "57:\tlearn: 0.1091090\ttotal: 163ms\tremaining: 398ms\n",
      "58:\tlearn: 0.1083799\ttotal: 166ms\tremaining: 397ms\n",
      "59:\tlearn: 0.1078650\ttotal: 169ms\tremaining: 394ms\n",
      "60:\tlearn: 0.1067328\ttotal: 171ms\tremaining: 391ms\n",
      "61:\tlearn: 0.1057408\ttotal: 174ms\tremaining: 388ms\n",
      "62:\tlearn: 0.1051009\ttotal: 177ms\tremaining: 386ms\n",
      "63:\tlearn: 0.1046408\ttotal: 180ms\tremaining: 382ms\n",
      "64:\tlearn: 0.1032611\ttotal: 182ms\tremaining: 378ms\n",
      "65:\tlearn: 0.1026731\ttotal: 185ms\tremaining: 376ms\n",
      "66:\tlearn: 0.1013964\ttotal: 188ms\tremaining: 373ms\n",
      "67:\tlearn: 0.1008362\ttotal: 191ms\tremaining: 370ms\n",
      "68:\tlearn: 0.0996398\ttotal: 194ms\tremaining: 367ms\n",
      "69:\tlearn: 0.0987868\ttotal: 196ms\tremaining: 364ms\n",
      "70:\tlearn: 0.0976217\ttotal: 199ms\tremaining: 361ms\n",
      "71:\tlearn: 0.0971893\ttotal: 202ms\tremaining: 358ms\n",
      "72:\tlearn: 0.0960522\ttotal: 204ms\tremaining: 356ms\n",
      "73:\tlearn: 0.0951466\ttotal: 207ms\tremaining: 353ms\n",
      "74:\tlearn: 0.0945543\ttotal: 210ms\tremaining: 350ms\n",
      "75:\tlearn: 0.0938707\ttotal: 213ms\tremaining: 348ms\n",
      "76:\tlearn: 0.0932747\ttotal: 216ms\tremaining: 346ms\n",
      "77:\tlearn: 0.0926105\ttotal: 220ms\tremaining: 344ms\n",
      "78:\tlearn: 0.0920335\ttotal: 223ms\tremaining: 341ms\n",
      "79:\tlearn: 0.0908451\ttotal: 225ms\tremaining: 338ms\n",
      "80:\tlearn: 0.0903234\ttotal: 228ms\tremaining: 335ms\n",
      "81:\tlearn: 0.0900526\ttotal: 231ms\tremaining: 333ms\n",
      "82:\tlearn: 0.0896276\ttotal: 234ms\tremaining: 330ms\n",
      "83:\tlearn: 0.0890344\ttotal: 237ms\tremaining: 327ms\n",
      "84:\tlearn: 0.0882209\ttotal: 240ms\tremaining: 324ms\n",
      "85:\tlearn: 0.0880653\ttotal: 243ms\tremaining: 322ms\n",
      "86:\tlearn: 0.0878303\ttotal: 246ms\tremaining: 320ms\n",
      "87:\tlearn: 0.0876717\ttotal: 249ms\tremaining: 317ms\n",
      "88:\tlearn: 0.0872229\ttotal: 252ms\tremaining: 314ms\n",
      "89:\tlearn: 0.0864394\ttotal: 255ms\tremaining: 311ms\n",
      "90:\tlearn: 0.0853672\ttotal: 257ms\tremaining: 308ms\n",
      "91:\tlearn: 0.0847213\ttotal: 261ms\tremaining: 306ms\n",
      "92:\tlearn: 0.0841117\ttotal: 263ms\tremaining: 303ms\n",
      "93:\tlearn: 0.0837723\ttotal: 266ms\tremaining: 300ms\n",
      "94:\tlearn: 0.0833458\ttotal: 269ms\tremaining: 297ms\n",
      "95:\tlearn: 0.0826155\ttotal: 271ms\tremaining: 294ms\n",
      "96:\tlearn: 0.0822721\ttotal: 274ms\tremaining: 291ms\n",
      "97:\tlearn: 0.0816165\ttotal: 277ms\tremaining: 288ms\n",
      "98:\tlearn: 0.0806812\ttotal: 279ms\tremaining: 285ms\n",
      "99:\tlearn: 0.0802215\ttotal: 282ms\tremaining: 282ms\n",
      "100:\tlearn: 0.0791041\ttotal: 285ms\tremaining: 279ms\n",
      "101:\tlearn: 0.0785157\ttotal: 288ms\tremaining: 276ms\n",
      "102:\tlearn: 0.0777330\ttotal: 290ms\tremaining: 274ms\n",
      "103:\tlearn: 0.0772236\ttotal: 293ms\tremaining: 271ms\n",
      "104:\tlearn: 0.0764546\ttotal: 296ms\tremaining: 268ms\n",
      "105:\tlearn: 0.0760633\ttotal: 299ms\tremaining: 265ms\n",
      "106:\tlearn: 0.0756694\ttotal: 302ms\tremaining: 263ms\n",
      "107:\tlearn: 0.0750214\ttotal: 305ms\tremaining: 260ms\n",
      "108:\tlearn: 0.0746387\ttotal: 308ms\tremaining: 257ms\n",
      "109:\tlearn: 0.0742403\ttotal: 311ms\tremaining: 254ms\n",
      "110:\tlearn: 0.0740525\ttotal: 314ms\tremaining: 252ms\n",
      "111:\tlearn: 0.0733006\ttotal: 317ms\tremaining: 249ms\n",
      "112:\tlearn: 0.0729709\ttotal: 319ms\tremaining: 246ms\n",
      "113:\tlearn: 0.0727132\ttotal: 323ms\tremaining: 244ms\n",
      "114:\tlearn: 0.0721217\ttotal: 326ms\tremaining: 241ms\n",
      "115:\tlearn: 0.0717856\ttotal: 328ms\tremaining: 238ms\n",
      "116:\tlearn: 0.0713835\ttotal: 331ms\tremaining: 235ms\n",
      "117:\tlearn: 0.0709237\ttotal: 334ms\tremaining: 232ms\n",
      "118:\tlearn: 0.0704993\ttotal: 337ms\tremaining: 229ms\n",
      "119:\tlearn: 0.0701499\ttotal: 340ms\tremaining: 227ms\n",
      "120:\tlearn: 0.0699500\ttotal: 342ms\tremaining: 224ms\n",
      "121:\tlearn: 0.0695025\ttotal: 346ms\tremaining: 221ms\n",
      "122:\tlearn: 0.0691403\ttotal: 349ms\tremaining: 218ms\n",
      "123:\tlearn: 0.0689948\ttotal: 352ms\tremaining: 215ms\n",
      "124:\tlearn: 0.0687283\ttotal: 354ms\tremaining: 213ms\n",
      "125:\tlearn: 0.0683372\ttotal: 357ms\tremaining: 210ms\n",
      "126:\tlearn: 0.0680527\ttotal: 360ms\tremaining: 207ms\n",
      "127:\tlearn: 0.0674828\ttotal: 363ms\tremaining: 204ms\n",
      "128:\tlearn: 0.0671954\ttotal: 365ms\tremaining: 201ms\n",
      "129:\tlearn: 0.0667960\ttotal: 368ms\tremaining: 198ms\n",
      "130:\tlearn: 0.0659700\ttotal: 371ms\tremaining: 196ms\n",
      "131:\tlearn: 0.0656743\ttotal: 374ms\tremaining: 193ms\n",
      "132:\tlearn: 0.0653781\ttotal: 377ms\tremaining: 190ms\n",
      "133:\tlearn: 0.0651314\ttotal: 379ms\tremaining: 187ms\n",
      "134:\tlearn: 0.0649148\ttotal: 383ms\tremaining: 185ms\n",
      "135:\tlearn: 0.0645429\ttotal: 387ms\tremaining: 182ms\n",
      "136:\tlearn: 0.0643917\ttotal: 389ms\tremaining: 179ms\n",
      "137:\tlearn: 0.0637036\ttotal: 392ms\tremaining: 176ms\n",
      "138:\tlearn: 0.0633219\ttotal: 395ms\tremaining: 173ms\n",
      "139:\tlearn: 0.0629575\ttotal: 397ms\tremaining: 170ms\n",
      "140:\tlearn: 0.0625939\ttotal: 400ms\tremaining: 167ms\n",
      "141:\tlearn: 0.0621724\ttotal: 403ms\tremaining: 165ms\n",
      "142:\tlearn: 0.0618862\ttotal: 406ms\tremaining: 162ms\n",
      "143:\tlearn: 0.0615268\ttotal: 408ms\tremaining: 159ms\n",
      "144:\tlearn: 0.0612956\ttotal: 411ms\tremaining: 156ms\n",
      "145:\tlearn: 0.0610771\ttotal: 414ms\tremaining: 153ms\n",
      "146:\tlearn: 0.0610565\ttotal: 417ms\tremaining: 150ms\n",
      "147:\tlearn: 0.0609721\ttotal: 421ms\tremaining: 148ms\n",
      "148:\tlearn: 0.0605078\ttotal: 424ms\tremaining: 145ms\n",
      "149:\tlearn: 0.0600806\ttotal: 427ms\tremaining: 142ms\n",
      "150:\tlearn: 0.0598036\ttotal: 429ms\tremaining: 139ms\n",
      "151:\tlearn: 0.0597527\ttotal: 433ms\tremaining: 137ms\n",
      "152:\tlearn: 0.0594624\ttotal: 435ms\tremaining: 134ms\n",
      "153:\tlearn: 0.0592689\ttotal: 438ms\tremaining: 131ms\n",
      "154:\tlearn: 0.0592238\ttotal: 441ms\tremaining: 128ms\n",
      "155:\tlearn: 0.0589037\ttotal: 444ms\tremaining: 125ms\n",
      "156:\tlearn: 0.0587183\ttotal: 448ms\tremaining: 123ms\n",
      "157:\tlearn: 0.0583118\ttotal: 450ms\tremaining: 120ms\n",
      "158:\tlearn: 0.0581656\ttotal: 453ms\tremaining: 117ms\n",
      "159:\tlearn: 0.0578946\ttotal: 456ms\tremaining: 114ms\n",
      "160:\tlearn: 0.0575302\ttotal: 460ms\tremaining: 111ms\n",
      "161:\tlearn: 0.0573031\ttotal: 462ms\tremaining: 108ms\n",
      "162:\tlearn: 0.0573031\ttotal: 466ms\tremaining: 106ms\n",
      "163:\tlearn: 0.0571768\ttotal: 468ms\tremaining: 103ms\n",
      "164:\tlearn: 0.0569340\ttotal: 472ms\tremaining: 100ms\n",
      "165:\tlearn: 0.0567816\ttotal: 475ms\tremaining: 97.2ms\n",
      "166:\tlearn: 0.0565357\ttotal: 478ms\tremaining: 94.4ms\n",
      "167:\tlearn: 0.0564787\ttotal: 480ms\tremaining: 91.5ms\n",
      "168:\tlearn: 0.0561586\ttotal: 483ms\tremaining: 88.5ms\n",
      "169:\tlearn: 0.0558432\ttotal: 486ms\tremaining: 85.8ms\n",
      "170:\tlearn: 0.0556797\ttotal: 489ms\tremaining: 82.9ms\n",
      "171:\tlearn: 0.0555474\ttotal: 492ms\tremaining: 80.1ms\n",
      "172:\tlearn: 0.0552667\ttotal: 494ms\tremaining: 77.1ms\n",
      "173:\tlearn: 0.0550944\ttotal: 498ms\tremaining: 74.4ms\n",
      "174:\tlearn: 0.0548881\ttotal: 500ms\tremaining: 71.5ms\n",
      "175:\tlearn: 0.0548013\ttotal: 503ms\tremaining: 68.6ms\n",
      "176:\tlearn: 0.0546934\ttotal: 506ms\tremaining: 65.7ms\n",
      "177:\tlearn: 0.0544471\ttotal: 508ms\tremaining: 62.8ms\n",
      "178:\tlearn: 0.0544422\ttotal: 511ms\tremaining: 60ms\n",
      "179:\tlearn: 0.0541710\ttotal: 514ms\tremaining: 57.1ms\n",
      "180:\tlearn: 0.0539678\ttotal: 516ms\tremaining: 54.2ms\n",
      "181:\tlearn: 0.0537712\ttotal: 519ms\tremaining: 51.4ms\n",
      "182:\tlearn: 0.0535664\ttotal: 522ms\tremaining: 48.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183:\tlearn: 0.0534374\ttotal: 526ms\tremaining: 45.7ms\n",
      "184:\tlearn: 0.0533747\ttotal: 528ms\tremaining: 42.9ms\n",
      "185:\tlearn: 0.0531840\ttotal: 531ms\tremaining: 40ms\n",
      "186:\tlearn: 0.0530335\ttotal: 534ms\tremaining: 37.2ms\n",
      "187:\tlearn: 0.0527203\ttotal: 538ms\tremaining: 34.3ms\n",
      "188:\tlearn: 0.0525482\ttotal: 541ms\tremaining: 31.5ms\n",
      "189:\tlearn: 0.0523866\ttotal: 544ms\tremaining: 28.6ms\n",
      "190:\tlearn: 0.0522578\ttotal: 546ms\tremaining: 25.7ms\n",
      "191:\tlearn: 0.0519868\ttotal: 549ms\tremaining: 22.9ms\n",
      "192:\tlearn: 0.0517681\ttotal: 552ms\tremaining: 20ms\n",
      "193:\tlearn: 0.0515533\ttotal: 555ms\tremaining: 17.2ms\n",
      "194:\tlearn: 0.0513525\ttotal: 558ms\tremaining: 14.3ms\n",
      "195:\tlearn: 0.0512989\ttotal: 560ms\tremaining: 11.4ms\n",
      "196:\tlearn: 0.0511167\ttotal: 563ms\tremaining: 8.57ms\n",
      "197:\tlearn: 0.0509837\ttotal: 567ms\tremaining: 5.72ms\n",
      "198:\tlearn: 0.0507464\ttotal: 570ms\tremaining: 2.86ms\n",
      "199:\tlearn: 0.0505794\ttotal: 572ms\tremaining: 0us\n",
      "0:\tlearn: 0.6862465\ttotal: 1.59ms\tremaining: 77.7ms\n",
      "1:\tlearn: 0.6799133\ttotal: 6.46ms\tremaining: 155ms\n",
      "2:\tlearn: 0.6735539\ttotal: 8.97ms\tremaining: 141ms\n",
      "3:\tlearn: 0.6672482\ttotal: 10.7ms\tremaining: 124ms\n",
      "4:\tlearn: 0.6612634\ttotal: 13.1ms\tremaining: 118ms\n",
      "5:\tlearn: 0.6552857\ttotal: 14.5ms\tremaining: 107ms\n",
      "6:\tlearn: 0.6493708\ttotal: 16ms\tremaining: 98.5ms\n",
      "7:\tlearn: 0.6434120\ttotal: 17.4ms\tremaining: 91.6ms\n",
      "8:\tlearn: 0.6374640\ttotal: 18.8ms\tremaining: 85.7ms\n",
      "9:\tlearn: 0.6319752\ttotal: 20.1ms\tremaining: 80.5ms\n",
      "10:\tlearn: 0.6265612\ttotal: 21.6ms\tremaining: 76.7ms\n",
      "11:\tlearn: 0.6209431\ttotal: 23.1ms\tremaining: 73.3ms\n",
      "12:\tlearn: 0.6156049\ttotal: 24.6ms\tremaining: 70.1ms\n",
      "13:\tlearn: 0.6100763\ttotal: 26.1ms\tremaining: 67.1ms\n",
      "14:\tlearn: 0.6044701\ttotal: 27.7ms\tremaining: 64.6ms\n",
      "15:\tlearn: 0.5990022\ttotal: 29ms\tremaining: 61.7ms\n",
      "16:\tlearn: 0.5937855\ttotal: 30.6ms\tremaining: 59.4ms\n",
      "17:\tlearn: 0.5886250\ttotal: 32ms\tremaining: 57ms\n",
      "18:\tlearn: 0.5838882\ttotal: 33.4ms\tremaining: 54.6ms\n",
      "19:\tlearn: 0.5787990\ttotal: 34.8ms\tremaining: 52.1ms\n",
      "20:\tlearn: 0.5739089\ttotal: 36.4ms\tremaining: 50.2ms\n",
      "21:\tlearn: 0.5692654\ttotal: 37.9ms\tremaining: 48.2ms\n",
      "22:\tlearn: 0.5645765\ttotal: 39.4ms\tremaining: 46.2ms\n",
      "23:\tlearn: 0.5602567\ttotal: 40.9ms\tremaining: 44.4ms\n",
      "24:\tlearn: 0.5558570\ttotal: 42.2ms\tremaining: 42.2ms\n",
      "25:\tlearn: 0.5513090\ttotal: 43.7ms\tremaining: 40.4ms\n",
      "26:\tlearn: 0.5471488\ttotal: 45.2ms\tremaining: 38.5ms\n",
      "27:\tlearn: 0.5426923\ttotal: 47.4ms\tremaining: 37.3ms\n",
      "28:\tlearn: 0.5385479\ttotal: 48.9ms\tremaining: 35.4ms\n",
      "29:\tlearn: 0.5343355\ttotal: 50.4ms\tremaining: 33.6ms\n",
      "30:\tlearn: 0.5303517\ttotal: 52.4ms\tremaining: 32.1ms\n",
      "31:\tlearn: 0.5261402\ttotal: 54ms\tremaining: 30.4ms\n",
      "32:\tlearn: 0.5219905\ttotal: 55.4ms\tremaining: 28.6ms\n",
      "33:\tlearn: 0.5180044\ttotal: 56.7ms\tremaining: 26.7ms\n",
      "34:\tlearn: 0.5141720\ttotal: 58.2ms\tremaining: 25ms\n",
      "35:\tlearn: 0.5102778\ttotal: 59.5ms\tremaining: 23.1ms\n",
      "36:\tlearn: 0.5064775\ttotal: 61ms\tremaining: 21.4ms\n",
      "37:\tlearn: 0.5027632\ttotal: 62.5ms\tremaining: 19.7ms\n",
      "38:\tlearn: 0.4988917\ttotal: 63.9ms\tremaining: 18ms\n",
      "39:\tlearn: 0.4949819\ttotal: 65.3ms\tremaining: 16.3ms\n",
      "40:\tlearn: 0.4913392\ttotal: 67.4ms\tremaining: 14.8ms\n",
      "41:\tlearn: 0.4875544\ttotal: 68.8ms\tremaining: 13.1ms\n",
      "42:\tlearn: 0.4839844\ttotal: 70.3ms\tremaining: 11.4ms\n",
      "43:\tlearn: 0.4805138\ttotal: 71.7ms\tremaining: 9.78ms\n",
      "44:\tlearn: 0.4772504\ttotal: 73.3ms\tremaining: 8.15ms\n",
      "45:\tlearn: 0.4739822\ttotal: 74.8ms\tremaining: 6.5ms\n",
      "46:\tlearn: 0.4707970\ttotal: 76.8ms\tremaining: 4.9ms\n",
      "47:\tlearn: 0.4677981\ttotal: 78.3ms\tremaining: 3.26ms\n",
      "48:\tlearn: 0.4647418\ttotal: 79.9ms\tremaining: 1.63ms\n",
      "49:\tlearn: 0.4615206\ttotal: 81.5ms\tremaining: 0us\n",
      "0:\tlearn: 0.6861012\ttotal: 2.38ms\tremaining: 117ms\n",
      "1:\tlearn: 0.6796885\ttotal: 3.74ms\tremaining: 89.8ms\n",
      "2:\tlearn: 0.6730329\ttotal: 5.65ms\tremaining: 88.5ms\n",
      "3:\tlearn: 0.6667040\ttotal: 7.17ms\tremaining: 82.4ms\n",
      "4:\tlearn: 0.6603975\ttotal: 8.55ms\tremaining: 76.9ms\n",
      "5:\tlearn: 0.6544670\ttotal: 10.5ms\tremaining: 77.2ms\n",
      "6:\tlearn: 0.6485852\ttotal: 12ms\tremaining: 73.4ms\n",
      "7:\tlearn: 0.6426860\ttotal: 13.3ms\tremaining: 69.6ms\n",
      "8:\tlearn: 0.6364881\ttotal: 15.4ms\tremaining: 70.3ms\n",
      "9:\tlearn: 0.6311352\ttotal: 16.7ms\tremaining: 66.9ms\n",
      "10:\tlearn: 0.6258318\ttotal: 18.2ms\tremaining: 64.5ms\n",
      "11:\tlearn: 0.6203417\ttotal: 19.6ms\tremaining: 61.9ms\n",
      "12:\tlearn: 0.6146993\ttotal: 21.1ms\tremaining: 60ms\n",
      "13:\tlearn: 0.6093489\ttotal: 22.6ms\tremaining: 58.1ms\n",
      "14:\tlearn: 0.6042416\ttotal: 24ms\tremaining: 56ms\n",
      "15:\tlearn: 0.5988572\ttotal: 25.5ms\tremaining: 54.2ms\n",
      "16:\tlearn: 0.5935328\ttotal: 27.7ms\tremaining: 53.8ms\n",
      "17:\tlearn: 0.5886189\ttotal: 29ms\tremaining: 51.6ms\n",
      "18:\tlearn: 0.5837184\ttotal: 30.5ms\tremaining: 49.8ms\n",
      "19:\tlearn: 0.5786502\ttotal: 31.8ms\tremaining: 47.7ms\n",
      "20:\tlearn: 0.5738435\ttotal: 33.2ms\tremaining: 45.9ms\n",
      "21:\tlearn: 0.5690117\ttotal: 34.7ms\tremaining: 44.2ms\n",
      "22:\tlearn: 0.5643687\ttotal: 36.9ms\tremaining: 43.4ms\n",
      "23:\tlearn: 0.5600829\ttotal: 38.4ms\tremaining: 41.6ms\n",
      "24:\tlearn: 0.5554864\ttotal: 39.8ms\tremaining: 39.8ms\n",
      "25:\tlearn: 0.5510427\ttotal: 41.2ms\tremaining: 38ms\n",
      "26:\tlearn: 0.5465989\ttotal: 42.9ms\tremaining: 36.5ms\n",
      "27:\tlearn: 0.5425121\ttotal: 44.4ms\tremaining: 34.8ms\n",
      "28:\tlearn: 0.5383885\ttotal: 45.6ms\tremaining: 33ms\n",
      "29:\tlearn: 0.5339795\ttotal: 47.1ms\tremaining: 31.4ms\n",
      "30:\tlearn: 0.5299486\ttotal: 48.5ms\tremaining: 29.7ms\n",
      "31:\tlearn: 0.5257246\ttotal: 49.8ms\tremaining: 28ms\n",
      "32:\tlearn: 0.5215871\ttotal: 51.3ms\tremaining: 26.4ms\n",
      "33:\tlearn: 0.5174545\ttotal: 52.7ms\tremaining: 24.8ms\n",
      "34:\tlearn: 0.5135276\ttotal: 54.2ms\tremaining: 23.2ms\n",
      "35:\tlearn: 0.5096693\ttotal: 56.6ms\tremaining: 22ms\n",
      "36:\tlearn: 0.5058852\ttotal: 58ms\tremaining: 20.4ms\n",
      "37:\tlearn: 0.5020666\ttotal: 59.4ms\tremaining: 18.8ms\n",
      "38:\tlearn: 0.4982690\ttotal: 60.9ms\tremaining: 17.2ms\n",
      "39:\tlearn: 0.4943629\ttotal: 62.6ms\tremaining: 15.6ms\n",
      "40:\tlearn: 0.4908071\ttotal: 63.9ms\tremaining: 14ms\n",
      "41:\tlearn: 0.4870192\ttotal: 65.4ms\tremaining: 12.4ms\n",
      "42:\tlearn: 0.4837080\ttotal: 66.7ms\tremaining: 10.9ms\n",
      "43:\tlearn: 0.4801354\ttotal: 68ms\tremaining: 9.27ms\n",
      "44:\tlearn: 0.4768667\ttotal: 69.3ms\tremaining: 7.7ms\n",
      "45:\tlearn: 0.4736211\ttotal: 70.7ms\tremaining: 6.14ms\n",
      "46:\tlearn: 0.4703554\ttotal: 72.3ms\tremaining: 4.62ms\n",
      "47:\tlearn: 0.4671676\ttotal: 73.9ms\tremaining: 3.08ms\n",
      "48:\tlearn: 0.4640859\ttotal: 75.4ms\tremaining: 1.54ms\n",
      "49:\tlearn: 0.4608458\ttotal: 76.9ms\tremaining: 0us\n",
      "0:\tlearn: 0.6861782\ttotal: 1.34ms\tremaining: 65.6ms\n",
      "1:\tlearn: 0.6797670\ttotal: 2.78ms\tremaining: 66.7ms\n",
      "2:\tlearn: 0.6733779\ttotal: 4.21ms\tremaining: 66ms\n",
      "3:\tlearn: 0.6670536\ttotal: 5.56ms\tremaining: 64ms\n",
      "4:\tlearn: 0.6606790\ttotal: 7.03ms\tremaining: 63.3ms\n",
      "5:\tlearn: 0.6545435\ttotal: 8.34ms\tremaining: 61.1ms\n",
      "6:\tlearn: 0.6486877\ttotal: 9.69ms\tremaining: 59.6ms\n",
      "7:\tlearn: 0.6424186\ttotal: 10.9ms\tremaining: 57.5ms\n",
      "8:\tlearn: 0.6364876\ttotal: 12.8ms\tremaining: 58.5ms\n",
      "9:\tlearn: 0.6310901\ttotal: 14.2ms\tremaining: 57ms\n",
      "10:\tlearn: 0.6257890\ttotal: 15.6ms\tremaining: 55.3ms\n",
      "11:\tlearn: 0.6203235\ttotal: 17.3ms\tremaining: 54.8ms\n",
      "12:\tlearn: 0.6149493\ttotal: 18.9ms\tremaining: 53.9ms\n",
      "13:\tlearn: 0.6096074\ttotal: 20.3ms\tremaining: 52.3ms\n",
      "14:\tlearn: 0.6042825\ttotal: 21.6ms\tremaining: 50.5ms\n",
      "15:\tlearn: 0.5989154\ttotal: 23.1ms\tremaining: 49ms\n",
      "16:\tlearn: 0.5936250\ttotal: 24.3ms\tremaining: 47.2ms\n",
      "17:\tlearn: 0.5884900\ttotal: 25.8ms\tremaining: 45.9ms\n",
      "18:\tlearn: 0.5836015\ttotal: 27.4ms\tremaining: 44.6ms\n",
      "19:\tlearn: 0.5785170\ttotal: 28.8ms\tremaining: 43.2ms\n",
      "20:\tlearn: 0.5736567\ttotal: 30.4ms\tremaining: 42ms\n",
      "21:\tlearn: 0.5690061\ttotal: 31.9ms\tremaining: 40.6ms\n",
      "22:\tlearn: 0.5641608\ttotal: 33.2ms\tremaining: 39ms\n",
      "23:\tlearn: 0.5597962\ttotal: 34.7ms\tremaining: 37.6ms\n",
      "24:\tlearn: 0.5550864\ttotal: 36.2ms\tremaining: 36.2ms\n",
      "25:\tlearn: 0.5506663\ttotal: 37.6ms\tremaining: 34.7ms\n",
      "26:\tlearn: 0.5461631\ttotal: 39.1ms\tremaining: 33.3ms\n",
      "27:\tlearn: 0.5418621\ttotal: 40.6ms\tremaining: 31.9ms\n",
      "28:\tlearn: 0.5376811\ttotal: 42.1ms\tremaining: 30.5ms\n",
      "29:\tlearn: 0.5332971\ttotal: 43.6ms\tremaining: 29.1ms\n",
      "30:\tlearn: 0.5290105\ttotal: 45.1ms\tremaining: 27.6ms\n",
      "31:\tlearn: 0.5247548\ttotal: 46.5ms\tremaining: 26.1ms\n",
      "32:\tlearn: 0.5207319\ttotal: 47.9ms\tremaining: 24.7ms\n",
      "33:\tlearn: 0.5167919\ttotal: 49.4ms\tremaining: 23.3ms\n",
      "34:\tlearn: 0.5128695\ttotal: 50.9ms\tremaining: 21.8ms\n",
      "35:\tlearn: 0.5089725\ttotal: 52.4ms\tremaining: 20.4ms\n",
      "36:\tlearn: 0.5051809\ttotal: 54.6ms\tremaining: 19.2ms\n",
      "37:\tlearn: 0.5013317\ttotal: 56.2ms\tremaining: 17.8ms\n",
      "38:\tlearn: 0.4974799\ttotal: 58ms\tremaining: 16.4ms\n",
      "39:\tlearn: 0.4936813\ttotal: 59.4ms\tremaining: 14.8ms\n",
      "40:\tlearn: 0.4901097\ttotal: 61.1ms\tremaining: 13.4ms\n",
      "41:\tlearn: 0.4863375\ttotal: 62.5ms\tremaining: 11.9ms\n",
      "42:\tlearn: 0.4830623\ttotal: 63.8ms\tremaining: 10.4ms\n",
      "43:\tlearn: 0.4794802\ttotal: 65.2ms\tremaining: 8.89ms\n",
      "44:\tlearn: 0.4758946\ttotal: 66.9ms\tremaining: 7.44ms\n",
      "45:\tlearn: 0.4726302\ttotal: 68.4ms\tremaining: 5.94ms\n",
      "46:\tlearn: 0.4694544\ttotal: 69.8ms\tremaining: 4.45ms\n",
      "47:\tlearn: 0.4664284\ttotal: 71.3ms\tremaining: 2.97ms\n",
      "48:\tlearn: 0.4633478\ttotal: 72.6ms\tremaining: 1.48ms\n",
      "49:\tlearn: 0.4600634\ttotal: 74.1ms\tremaining: 0us\n",
      "0:\tlearn: 0.6593054\ttotal: 1.47ms\tremaining: 72ms\n",
      "1:\tlearn: 0.6304468\ttotal: 2.94ms\tremaining: 70.6ms\n",
      "2:\tlearn: 0.6032969\ttotal: 4.29ms\tremaining: 67.3ms\n",
      "3:\tlearn: 0.5761749\ttotal: 5.63ms\tremaining: 64.8ms\n",
      "4:\tlearn: 0.5509839\ttotal: 6.95ms\tremaining: 62.6ms\n",
      "5:\tlearn: 0.5293886\ttotal: 8.21ms\tremaining: 60.2ms\n",
      "6:\tlearn: 0.5097398\ttotal: 9.52ms\tremaining: 58.5ms\n",
      "7:\tlearn: 0.4909870\ttotal: 10.8ms\tremaining: 56.8ms\n",
      "8:\tlearn: 0.4731895\ttotal: 12.5ms\tremaining: 57ms\n",
      "9:\tlearn: 0.4579934\ttotal: 14.3ms\tremaining: 57.1ms\n",
      "10:\tlearn: 0.4435989\ttotal: 15.6ms\tremaining: 55.5ms\n",
      "11:\tlearn: 0.4302929\ttotal: 17.1ms\tremaining: 54.1ms\n",
      "12:\tlearn: 0.4161944\ttotal: 18.6ms\tremaining: 53ms\n",
      "13:\tlearn: 0.4037985\ttotal: 20.2ms\tremaining: 51.8ms\n",
      "14:\tlearn: 0.3912644\ttotal: 21.6ms\tremaining: 50.4ms\n",
      "15:\tlearn: 0.3798265\ttotal: 23.1ms\tremaining: 49.1ms\n",
      "16:\tlearn: 0.3681147\ttotal: 24.5ms\tremaining: 47.5ms\n",
      "17:\tlearn: 0.3581027\ttotal: 25.9ms\tremaining: 46ms\n",
      "18:\tlearn: 0.3481382\ttotal: 27.4ms\tremaining: 44.6ms\n",
      "19:\tlearn: 0.3398070\ttotal: 28.9ms\tremaining: 43.3ms\n",
      "20:\tlearn: 0.3309286\ttotal: 30.4ms\tremaining: 41.9ms\n",
      "21:\tlearn: 0.3228007\ttotal: 31.8ms\tremaining: 40.5ms\n",
      "22:\tlearn: 0.3149672\ttotal: 33.2ms\tremaining: 38.9ms\n",
      "23:\tlearn: 0.3078934\ttotal: 34.8ms\tremaining: 37.7ms\n",
      "24:\tlearn: 0.3011138\ttotal: 36.3ms\tremaining: 36.3ms\n",
      "25:\tlearn: 0.2944643\ttotal: 37.7ms\tremaining: 34.8ms\n",
      "26:\tlearn: 0.2891970\ttotal: 39.3ms\tremaining: 33.4ms\n",
      "27:\tlearn: 0.2843389\ttotal: 40.7ms\tremaining: 32ms\n",
      "28:\tlearn: 0.2796791\ttotal: 42.2ms\tremaining: 30.6ms\n",
      "29:\tlearn: 0.2744213\ttotal: 43.6ms\tremaining: 29.1ms\n",
      "30:\tlearn: 0.2693412\ttotal: 45.1ms\tremaining: 27.6ms\n",
      "31:\tlearn: 0.2636492\ttotal: 46.5ms\tremaining: 26.1ms\n",
      "32:\tlearn: 0.2581024\ttotal: 47.8ms\tremaining: 24.6ms\n",
      "33:\tlearn: 0.2533188\ttotal: 49.3ms\tremaining: 23.2ms\n",
      "34:\tlearn: 0.2491037\ttotal: 50.8ms\tremaining: 21.8ms\n",
      "35:\tlearn: 0.2453146\ttotal: 52.1ms\tremaining: 20.3ms\n",
      "36:\tlearn: 0.2411653\ttotal: 53.5ms\tremaining: 18.8ms\n",
      "37:\tlearn: 0.2371556\ttotal: 55.1ms\tremaining: 17.4ms\n",
      "38:\tlearn: 0.2331405\ttotal: 56.5ms\tremaining: 15.9ms\n",
      "39:\tlearn: 0.2292875\ttotal: 57.9ms\tremaining: 14.5ms\n",
      "40:\tlearn: 0.2252702\ttotal: 59.3ms\tremaining: 13ms\n",
      "41:\tlearn: 0.2219303\ttotal: 60.8ms\tremaining: 11.6ms\n",
      "42:\tlearn: 0.2188010\ttotal: 62.4ms\tremaining: 10.2ms\n",
      "43:\tlearn: 0.2160384\ttotal: 64ms\tremaining: 8.72ms\n",
      "44:\tlearn: 0.2128426\ttotal: 65.6ms\tremaining: 7.29ms\n",
      "45:\tlearn: 0.2097151\ttotal: 67.1ms\tremaining: 5.84ms\n",
      "46:\tlearn: 0.2072675\ttotal: 68.7ms\tremaining: 4.39ms\n",
      "47:\tlearn: 0.2054150\ttotal: 70.2ms\tremaining: 2.92ms\n",
      "48:\tlearn: 0.2030358\ttotal: 71.7ms\tremaining: 1.46ms\n",
      "49:\tlearn: 0.2001542\ttotal: 73ms\tremaining: 0us\n",
      "0:\tlearn: 0.6585983\ttotal: 1.59ms\tremaining: 78ms\n",
      "1:\tlearn: 0.6293158\ttotal: 3.09ms\tremaining: 74.1ms\n",
      "2:\tlearn: 0.6008901\ttotal: 4.46ms\tremaining: 69.9ms\n",
      "3:\tlearn: 0.5741287\ttotal: 5.71ms\tremaining: 65.7ms\n",
      "4:\tlearn: 0.5504427\ttotal: 6.91ms\tremaining: 62.2ms\n",
      "5:\tlearn: 0.5295106\ttotal: 8.21ms\tremaining: 60.2ms\n",
      "6:\tlearn: 0.5099552\ttotal: 9.57ms\tremaining: 58.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7:\tlearn: 0.4915064\ttotal: 11.2ms\tremaining: 58.8ms\n",
      "8:\tlearn: 0.4729081\ttotal: 12.6ms\tremaining: 57.3ms\n",
      "9:\tlearn: 0.4571399\ttotal: 13.9ms\tremaining: 55.4ms\n",
      "10:\tlearn: 0.4422397\ttotal: 15.3ms\tremaining: 54.3ms\n",
      "11:\tlearn: 0.4278325\ttotal: 16.7ms\tremaining: 52.8ms\n",
      "12:\tlearn: 0.4143013\ttotal: 18.3ms\tremaining: 52ms\n",
      "13:\tlearn: 0.4018123\ttotal: 19.7ms\tremaining: 50.7ms\n",
      "14:\tlearn: 0.3906519\ttotal: 26.8ms\tremaining: 62.5ms\n",
      "15:\tlearn: 0.3793236\ttotal: 28.7ms\tremaining: 61ms\n",
      "16:\tlearn: 0.3675404\ttotal: 30.9ms\tremaining: 59.9ms\n",
      "17:\tlearn: 0.3587001\ttotal: 32.5ms\tremaining: 57.7ms\n",
      "18:\tlearn: 0.3481343\ttotal: 34ms\tremaining: 55.5ms\n",
      "19:\tlearn: 0.3400257\ttotal: 35.5ms\tremaining: 53.2ms\n",
      "20:\tlearn: 0.3311131\ttotal: 36.9ms\tremaining: 50.9ms\n",
      "21:\tlearn: 0.3228246\ttotal: 38.3ms\tremaining: 48.7ms\n",
      "22:\tlearn: 0.3153917\ttotal: 39.8ms\tremaining: 46.7ms\n",
      "23:\tlearn: 0.3085423\ttotal: 41.2ms\tremaining: 44.6ms\n",
      "24:\tlearn: 0.3015236\ttotal: 42.6ms\tremaining: 42.6ms\n",
      "25:\tlearn: 0.2948661\ttotal: 44.2ms\tremaining: 40.8ms\n",
      "26:\tlearn: 0.2896277\ttotal: 45.8ms\tremaining: 39ms\n",
      "27:\tlearn: 0.2845417\ttotal: 47.4ms\tremaining: 37.2ms\n",
      "28:\tlearn: 0.2785976\ttotal: 49ms\tremaining: 35.4ms\n",
      "29:\tlearn: 0.2739827\ttotal: 50.6ms\tremaining: 33.7ms\n",
      "30:\tlearn: 0.2680135\ttotal: 52.1ms\tremaining: 31.9ms\n",
      "31:\tlearn: 0.2630278\ttotal: 53.5ms\tremaining: 30.1ms\n",
      "32:\tlearn: 0.2574987\ttotal: 55.1ms\tremaining: 28.4ms\n",
      "33:\tlearn: 0.2530258\ttotal: 56.5ms\tremaining: 26.6ms\n",
      "34:\tlearn: 0.2488138\ttotal: 58.2ms\tremaining: 24.9ms\n",
      "35:\tlearn: 0.2443947\ttotal: 59.7ms\tremaining: 23.2ms\n",
      "36:\tlearn: 0.2404381\ttotal: 61.1ms\tremaining: 21.5ms\n",
      "37:\tlearn: 0.2364245\ttotal: 62.8ms\tremaining: 19.8ms\n",
      "38:\tlearn: 0.2324067\ttotal: 64.2ms\tremaining: 18.1ms\n",
      "39:\tlearn: 0.2286885\ttotal: 65.9ms\tremaining: 16.5ms\n",
      "40:\tlearn: 0.2253242\ttotal: 67.3ms\tremaining: 14.8ms\n",
      "41:\tlearn: 0.2219866\ttotal: 68.8ms\tremaining: 13.1ms\n",
      "42:\tlearn: 0.2188925\ttotal: 70.2ms\tremaining: 11.4ms\n",
      "43:\tlearn: 0.2156167\ttotal: 71.6ms\tremaining: 9.77ms\n",
      "44:\tlearn: 0.2135923\ttotal: 73.4ms\tremaining: 8.15ms\n",
      "45:\tlearn: 0.2108353\ttotal: 75ms\tremaining: 6.53ms\n",
      "46:\tlearn: 0.2087898\ttotal: 76.6ms\tremaining: 4.89ms\n",
      "47:\tlearn: 0.2066544\ttotal: 78.1ms\tremaining: 3.25ms\n",
      "48:\tlearn: 0.2038867\ttotal: 79.5ms\tremaining: 1.62ms\n",
      "49:\tlearn: 0.2008102\ttotal: 81ms\tremaining: 0us\n",
      "0:\tlearn: 0.6589788\ttotal: 2.18ms\tremaining: 107ms\n",
      "1:\tlearn: 0.6297143\ttotal: 3.82ms\tremaining: 91.8ms\n",
      "2:\tlearn: 0.6025131\ttotal: 5.3ms\tremaining: 83ms\n",
      "3:\tlearn: 0.5772017\ttotal: 6.67ms\tremaining: 76.8ms\n",
      "4:\tlearn: 0.5528612\ttotal: 7.96ms\tremaining: 71.7ms\n",
      "5:\tlearn: 0.5309049\ttotal: 9.48ms\tremaining: 69.5ms\n",
      "6:\tlearn: 0.5114453\ttotal: 10.8ms\tremaining: 66.4ms\n",
      "7:\tlearn: 0.4914240\ttotal: 12.3ms\tremaining: 64.3ms\n",
      "8:\tlearn: 0.4729109\ttotal: 13.7ms\tremaining: 62.6ms\n",
      "9:\tlearn: 0.4556447\ttotal: 15.3ms\tremaining: 61.1ms\n",
      "10:\tlearn: 0.4405670\ttotal: 16.7ms\tremaining: 59.2ms\n",
      "11:\tlearn: 0.4260662\ttotal: 18.2ms\tremaining: 57.5ms\n",
      "12:\tlearn: 0.4117383\ttotal: 19.8ms\tremaining: 56.2ms\n",
      "13:\tlearn: 0.3997523\ttotal: 21.1ms\tremaining: 54.2ms\n",
      "14:\tlearn: 0.3877191\ttotal: 22.5ms\tremaining: 52.5ms\n",
      "15:\tlearn: 0.3758190\ttotal: 23.9ms\tremaining: 50.8ms\n",
      "16:\tlearn: 0.3640183\ttotal: 25.4ms\tremaining: 49.3ms\n",
      "17:\tlearn: 0.3552584\ttotal: 26.8ms\tremaining: 47.6ms\n",
      "18:\tlearn: 0.3459111\ttotal: 28.1ms\tremaining: 45.9ms\n",
      "19:\tlearn: 0.3379651\ttotal: 29.8ms\tremaining: 44.6ms\n",
      "20:\tlearn: 0.3286315\ttotal: 31.3ms\tremaining: 43.2ms\n",
      "21:\tlearn: 0.3208300\ttotal: 32.8ms\tremaining: 41.7ms\n",
      "22:\tlearn: 0.3131541\ttotal: 34.2ms\tremaining: 40.2ms\n",
      "23:\tlearn: 0.3065405\ttotal: 35.8ms\tremaining: 38.8ms\n",
      "24:\tlearn: 0.2991723\ttotal: 37.3ms\tremaining: 37.3ms\n",
      "25:\tlearn: 0.2929427\ttotal: 38.9ms\tremaining: 35.9ms\n",
      "26:\tlearn: 0.2875549\ttotal: 40.3ms\tremaining: 34.3ms\n",
      "27:\tlearn: 0.2825849\ttotal: 41.7ms\tremaining: 32.7ms\n",
      "28:\tlearn: 0.2777447\ttotal: 43.1ms\tremaining: 31.2ms\n",
      "29:\tlearn: 0.2727072\ttotal: 44.8ms\tremaining: 29.8ms\n",
      "30:\tlearn: 0.2668784\ttotal: 46.2ms\tremaining: 28.3ms\n",
      "31:\tlearn: 0.2615723\ttotal: 47.8ms\tremaining: 26.9ms\n",
      "32:\tlearn: 0.2560534\ttotal: 49.2ms\tremaining: 25.3ms\n",
      "33:\tlearn: 0.2513423\ttotal: 50.6ms\tremaining: 23.8ms\n",
      "34:\tlearn: 0.2468927\ttotal: 52ms\tremaining: 22.3ms\n",
      "35:\tlearn: 0.2425590\ttotal: 53.5ms\tremaining: 20.8ms\n",
      "36:\tlearn: 0.2388094\ttotal: 55ms\tremaining: 19.3ms\n",
      "37:\tlearn: 0.2346421\ttotal: 56.4ms\tremaining: 17.8ms\n",
      "38:\tlearn: 0.2304808\ttotal: 57.9ms\tremaining: 16.3ms\n",
      "39:\tlearn: 0.2275211\ttotal: 59.4ms\tremaining: 14.8ms\n",
      "40:\tlearn: 0.2230304\ttotal: 60.6ms\tremaining: 13.3ms\n",
      "41:\tlearn: 0.2197352\ttotal: 62.2ms\tremaining: 11.9ms\n",
      "42:\tlearn: 0.2170198\ttotal: 63.8ms\tremaining: 10.4ms\n",
      "43:\tlearn: 0.2141606\ttotal: 65.2ms\tremaining: 8.89ms\n",
      "44:\tlearn: 0.2115102\ttotal: 66.7ms\tremaining: 7.41ms\n",
      "45:\tlearn: 0.2085012\ttotal: 68.7ms\tremaining: 5.98ms\n",
      "46:\tlearn: 0.2058222\ttotal: 70.3ms\tremaining: 4.49ms\n",
      "47:\tlearn: 0.2039094\ttotal: 71.8ms\tremaining: 2.99ms\n",
      "48:\tlearn: 0.2014658\ttotal: 73.5ms\tremaining: 1.5ms\n",
      "49:\tlearn: 0.1987254\ttotal: 74.8ms\tremaining: 0us\n",
      "0:\tlearn: 0.6271142\ttotal: 1.48ms\tremaining: 72.4ms\n",
      "1:\tlearn: 0.5751800\ttotal: 2.85ms\tremaining: 68.5ms\n",
      "2:\tlearn: 0.5299172\ttotal: 4.25ms\tremaining: 66.5ms\n",
      "3:\tlearn: 0.4877917\ttotal: 5.56ms\tremaining: 63.9ms\n",
      "4:\tlearn: 0.4516357\ttotal: 6.91ms\tremaining: 62.2ms\n",
      "5:\tlearn: 0.4223732\ttotal: 8.34ms\tremaining: 61.2ms\n",
      "6:\tlearn: 0.3967926\ttotal: 9.77ms\tremaining: 60ms\n",
      "7:\tlearn: 0.3745632\ttotal: 11.2ms\tremaining: 58.8ms\n",
      "8:\tlearn: 0.3533129\ttotal: 12.6ms\tremaining: 57.4ms\n",
      "9:\tlearn: 0.3358343\ttotal: 14ms\tremaining: 56.1ms\n",
      "10:\tlearn: 0.3206063\ttotal: 15.3ms\tremaining: 54.4ms\n",
      "11:\tlearn: 0.3065306\ttotal: 16.9ms\tremaining: 53.4ms\n",
      "12:\tlearn: 0.2942877\ttotal: 18.4ms\tremaining: 52.5ms\n",
      "13:\tlearn: 0.2813667\ttotal: 19.9ms\tremaining: 51.1ms\n",
      "14:\tlearn: 0.2681611\ttotal: 21.2ms\tremaining: 49.5ms\n",
      "15:\tlearn: 0.2586388\ttotal: 22.7ms\tremaining: 48.2ms\n",
      "16:\tlearn: 0.2491723\ttotal: 24.3ms\tremaining: 47.2ms\n",
      "17:\tlearn: 0.2426290\ttotal: 25.9ms\tremaining: 46ms\n",
      "18:\tlearn: 0.2367585\ttotal: 27.4ms\tremaining: 44.7ms\n",
      "19:\tlearn: 0.2276616\ttotal: 28.8ms\tremaining: 43.3ms\n",
      "20:\tlearn: 0.2203221\ttotal: 30.5ms\tremaining: 42.1ms\n",
      "21:\tlearn: 0.2141788\ttotal: 31.9ms\tremaining: 40.7ms\n",
      "22:\tlearn: 0.2069844\ttotal: 33.4ms\tremaining: 39.2ms\n",
      "23:\tlearn: 0.2034297\ttotal: 35ms\tremaining: 37.9ms\n",
      "24:\tlearn: 0.1990132\ttotal: 36.4ms\tremaining: 36.4ms\n",
      "25:\tlearn: 0.1945238\ttotal: 38ms\tremaining: 35ms\n",
      "26:\tlearn: 0.1915467\ttotal: 39.5ms\tremaining: 33.7ms\n",
      "27:\tlearn: 0.1877069\ttotal: 41.2ms\tremaining: 32.4ms\n",
      "28:\tlearn: 0.1826623\ttotal: 42.7ms\tremaining: 31ms\n",
      "29:\tlearn: 0.1796887\ttotal: 44.3ms\tremaining: 29.5ms\n",
      "30:\tlearn: 0.1758952\ttotal: 45.8ms\tremaining: 28.1ms\n",
      "31:\tlearn: 0.1719211\ttotal: 47.3ms\tremaining: 26.6ms\n",
      "32:\tlearn: 0.1680567\ttotal: 48.7ms\tremaining: 25.1ms\n",
      "33:\tlearn: 0.1649871\ttotal: 50ms\tremaining: 23.6ms\n",
      "34:\tlearn: 0.1612494\ttotal: 51.4ms\tremaining: 22ms\n",
      "35:\tlearn: 0.1579904\ttotal: 52.9ms\tremaining: 20.6ms\n",
      "36:\tlearn: 0.1558933\ttotal: 54.4ms\tremaining: 19.1ms\n",
      "37:\tlearn: 0.1532725\ttotal: 55.9ms\tremaining: 17.6ms\n",
      "38:\tlearn: 0.1504909\ttotal: 57.3ms\tremaining: 16.2ms\n",
      "39:\tlearn: 0.1476689\ttotal: 58.8ms\tremaining: 14.7ms\n",
      "40:\tlearn: 0.1450232\ttotal: 60.3ms\tremaining: 13.2ms\n",
      "41:\tlearn: 0.1430877\ttotal: 62.4ms\tremaining: 11.9ms\n",
      "42:\tlearn: 0.1412912\ttotal: 63.8ms\tremaining: 10.4ms\n",
      "43:\tlearn: 0.1389355\ttotal: 65.3ms\tremaining: 8.9ms\n",
      "44:\tlearn: 0.1368185\ttotal: 66.7ms\tremaining: 7.41ms\n",
      "45:\tlearn: 0.1355182\ttotal: 68.2ms\tremaining: 5.93ms\n",
      "46:\tlearn: 0.1338457\ttotal: 69.8ms\tremaining: 4.45ms\n",
      "47:\tlearn: 0.1327067\ttotal: 71.3ms\tremaining: 2.97ms\n",
      "48:\tlearn: 0.1312424\ttotal: 72.7ms\tremaining: 1.48ms\n",
      "49:\tlearn: 0.1301357\ttotal: 74.2ms\tremaining: 0us\n",
      "0:\tlearn: 0.6257481\ttotal: 1.48ms\tremaining: 72.4ms\n",
      "1:\tlearn: 0.5734925\ttotal: 2.94ms\tremaining: 70.6ms\n",
      "2:\tlearn: 0.5265748\ttotal: 5.13ms\tremaining: 80.3ms\n",
      "3:\tlearn: 0.4854423\ttotal: 6.28ms\tremaining: 72.2ms\n",
      "4:\tlearn: 0.4510446\ttotal: 7.59ms\tremaining: 68.3ms\n",
      "5:\tlearn: 0.4227338\ttotal: 9.63ms\tremaining: 70.6ms\n",
      "6:\tlearn: 0.3980758\ttotal: 11.2ms\tremaining: 68.6ms\n",
      "7:\tlearn: 0.3761880\ttotal: 12.6ms\tremaining: 66.2ms\n",
      "8:\tlearn: 0.3548240\ttotal: 14.2ms\tremaining: 64.7ms\n",
      "9:\tlearn: 0.3368656\ttotal: 15.7ms\tremaining: 63ms\n",
      "10:\tlearn: 0.3218865\ttotal: 17.1ms\tremaining: 60.7ms\n",
      "11:\tlearn: 0.3067874\ttotal: 18.8ms\tremaining: 59.5ms\n",
      "12:\tlearn: 0.2937084\ttotal: 20.4ms\tremaining: 57.9ms\n",
      "13:\tlearn: 0.2802523\ttotal: 21.7ms\tremaining: 55.7ms\n",
      "14:\tlearn: 0.2682218\ttotal: 23.1ms\tremaining: 54ms\n",
      "15:\tlearn: 0.2555319\ttotal: 24.7ms\tremaining: 52.6ms\n",
      "16:\tlearn: 0.2466641\ttotal: 26.2ms\tremaining: 50.8ms\n",
      "17:\tlearn: 0.2403881\ttotal: 27.8ms\tremaining: 49.4ms\n",
      "18:\tlearn: 0.2305797\ttotal: 29.2ms\tremaining: 47.6ms\n",
      "19:\tlearn: 0.2257324\ttotal: 30.7ms\tremaining: 46.1ms\n",
      "20:\tlearn: 0.2176943\ttotal: 32.4ms\tremaining: 44.8ms\n",
      "21:\tlearn: 0.2114638\ttotal: 34ms\tremaining: 43.2ms\n",
      "22:\tlearn: 0.2065547\ttotal: 35.6ms\tremaining: 41.8ms\n",
      "23:\tlearn: 0.2036422\ttotal: 37.1ms\tremaining: 40.2ms\n",
      "24:\tlearn: 0.1989717\ttotal: 38.6ms\tremaining: 38.6ms\n",
      "25:\tlearn: 0.1949551\ttotal: 40.2ms\tremaining: 37.1ms\n",
      "26:\tlearn: 0.1911894\ttotal: 41.6ms\tremaining: 35.5ms\n",
      "27:\tlearn: 0.1884051\ttotal: 43.1ms\tremaining: 33.9ms\n",
      "28:\tlearn: 0.1847674\ttotal: 44.7ms\tremaining: 32.4ms\n",
      "29:\tlearn: 0.1802244\ttotal: 46.3ms\tremaining: 30.9ms\n",
      "30:\tlearn: 0.1763076\ttotal: 47.7ms\tremaining: 29.3ms\n",
      "31:\tlearn: 0.1727682\ttotal: 49.9ms\tremaining: 28.1ms\n",
      "32:\tlearn: 0.1693651\ttotal: 51.5ms\tremaining: 26.5ms\n",
      "33:\tlearn: 0.1661636\ttotal: 53ms\tremaining: 24.9ms\n",
      "34:\tlearn: 0.1634968\ttotal: 55.1ms\tremaining: 23.6ms\n",
      "35:\tlearn: 0.1604365\ttotal: 56.6ms\tremaining: 22ms\n",
      "36:\tlearn: 0.1577175\ttotal: 57.9ms\tremaining: 20.3ms\n",
      "37:\tlearn: 0.1553138\ttotal: 59.2ms\tremaining: 18.7ms\n",
      "38:\tlearn: 0.1519979\ttotal: 60.7ms\tremaining: 17.1ms\n",
      "39:\tlearn: 0.1497945\ttotal: 62.2ms\tremaining: 15.5ms\n",
      "40:\tlearn: 0.1468118\ttotal: 63.5ms\tremaining: 13.9ms\n",
      "41:\tlearn: 0.1447341\ttotal: 65.5ms\tremaining: 12.5ms\n",
      "42:\tlearn: 0.1427129\ttotal: 67.1ms\tremaining: 10.9ms\n",
      "43:\tlearn: 0.1408133\ttotal: 68.7ms\tremaining: 9.37ms\n",
      "44:\tlearn: 0.1395334\ttotal: 70.4ms\tremaining: 7.82ms\n",
      "45:\tlearn: 0.1377172\ttotal: 71.8ms\tremaining: 6.25ms\n",
      "46:\tlearn: 0.1359064\ttotal: 73.2ms\tremaining: 4.67ms\n",
      "47:\tlearn: 0.1348858\ttotal: 74.7ms\tremaining: 3.11ms\n",
      "48:\tlearn: 0.1333230\ttotal: 76.2ms\tremaining: 1.55ms\n",
      "49:\tlearn: 0.1324951\ttotal: 77.7ms\tremaining: 0us\n",
      "0:\tlearn: 0.6264980\ttotal: 1.36ms\tremaining: 66.5ms\n",
      "1:\tlearn: 0.5743024\ttotal: 3.34ms\tremaining: 80.1ms\n",
      "2:\tlearn: 0.5304018\ttotal: 4.74ms\tremaining: 74.3ms\n",
      "3:\tlearn: 0.4912614\ttotal: 6.12ms\tremaining: 70.4ms\n",
      "4:\tlearn: 0.4542183\ttotal: 7.55ms\tremaining: 68ms\n",
      "5:\tlearn: 0.4243671\ttotal: 9ms\tremaining: 66ms\n",
      "6:\tlearn: 0.3998771\ttotal: 11.1ms\tremaining: 68.4ms\n",
      "7:\tlearn: 0.3758945\ttotal: 12.5ms\tremaining: 65.4ms\n",
      "8:\tlearn: 0.3547554\ttotal: 14ms\tremaining: 63.8ms\n",
      "9:\tlearn: 0.3371613\ttotal: 15.5ms\tremaining: 61.8ms\n",
      "10:\tlearn: 0.3216798\ttotal: 16.9ms\tremaining: 60.1ms\n",
      "11:\tlearn: 0.3066371\ttotal: 18.5ms\tremaining: 58.6ms\n",
      "12:\tlearn: 0.2925347\ttotal: 20ms\tremaining: 57ms\n",
      "13:\tlearn: 0.2794793\ttotal: 21.5ms\tremaining: 55.3ms\n",
      "14:\tlearn: 0.2673530\ttotal: 23ms\tremaining: 53.7ms\n",
      "15:\tlearn: 0.2585320\ttotal: 25.3ms\tremaining: 53.7ms\n",
      "16:\tlearn: 0.2493630\ttotal: 26.8ms\tremaining: 52ms\n",
      "17:\tlearn: 0.2412497\ttotal: 28.2ms\tremaining: 50.1ms\n",
      "18:\tlearn: 0.2327163\ttotal: 29.7ms\tremaining: 48.5ms\n",
      "19:\tlearn: 0.2279441\ttotal: 31.3ms\tremaining: 46.9ms\n",
      "20:\tlearn: 0.2197251\ttotal: 32.8ms\tremaining: 45.2ms\n",
      "21:\tlearn: 0.2138410\ttotal: 34.3ms\tremaining: 43.6ms\n",
      "22:\tlearn: 0.2077370\ttotal: 35.7ms\tremaining: 41.9ms\n",
      "23:\tlearn: 0.2035563\ttotal: 37.9ms\tremaining: 41ms\n",
      "24:\tlearn: 0.1973498\ttotal: 39.3ms\tremaining: 39.3ms\n",
      "25:\tlearn: 0.1929801\ttotal: 40.9ms\tremaining: 37.7ms\n",
      "26:\tlearn: 0.1885453\ttotal: 42.4ms\tremaining: 36.2ms\n",
      "27:\tlearn: 0.1848008\ttotal: 43.9ms\tremaining: 34.5ms\n",
      "28:\tlearn: 0.1828793\ttotal: 45.4ms\tremaining: 32.8ms\n",
      "29:\tlearn: 0.1792463\ttotal: 47ms\tremaining: 31.4ms\n",
      "30:\tlearn: 0.1751591\ttotal: 48.9ms\tremaining: 30ms\n",
      "31:\tlearn: 0.1714532\ttotal: 50.4ms\tremaining: 28.3ms\n",
      "32:\tlearn: 0.1694882\ttotal: 51.8ms\tremaining: 26.7ms\n",
      "33:\tlearn: 0.1665980\ttotal: 53.3ms\tremaining: 25.1ms\n",
      "34:\tlearn: 0.1620929\ttotal: 54.7ms\tremaining: 23.4ms\n",
      "35:\tlearn: 0.1596592\ttotal: 56.2ms\tremaining: 21.8ms\n",
      "36:\tlearn: 0.1575020\ttotal: 57.7ms\tremaining: 20.3ms\n",
      "37:\tlearn: 0.1540580\ttotal: 59.2ms\tremaining: 18.7ms\n",
      "38:\tlearn: 0.1517195\ttotal: 60.6ms\tremaining: 17.1ms\n",
      "39:\tlearn: 0.1498830\ttotal: 62.1ms\tremaining: 15.5ms\n",
      "40:\tlearn: 0.1474374\ttotal: 63.8ms\tremaining: 14ms\n",
      "41:\tlearn: 0.1458211\ttotal: 65.2ms\tremaining: 12.4ms\n",
      "42:\tlearn: 0.1444151\ttotal: 66.7ms\tremaining: 10.9ms\n",
      "43:\tlearn: 0.1426938\ttotal: 67.9ms\tremaining: 9.26ms\n",
      "44:\tlearn: 0.1410136\ttotal: 69.6ms\tremaining: 7.73ms\n",
      "45:\tlearn: 0.1394431\ttotal: 71.2ms\tremaining: 6.19ms\n",
      "46:\tlearn: 0.1376097\ttotal: 72.6ms\tremaining: 4.63ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47:\tlearn: 0.1366843\ttotal: 74.2ms\tremaining: 3.09ms\n",
      "48:\tlearn: 0.1350401\ttotal: 75.5ms\tremaining: 1.54ms\n",
      "49:\tlearn: 0.1329801\ttotal: 76.9ms\tremaining: 0us\n",
      "0:\tlearn: 0.6862465\ttotal: 1.68ms\tremaining: 167ms\n",
      "1:\tlearn: 0.6799133\ttotal: 3.08ms\tremaining: 151ms\n",
      "2:\tlearn: 0.6735539\ttotal: 4.65ms\tremaining: 150ms\n",
      "3:\tlearn: 0.6672482\ttotal: 6.15ms\tremaining: 148ms\n",
      "4:\tlearn: 0.6612634\ttotal: 7.49ms\tremaining: 142ms\n",
      "5:\tlearn: 0.6552857\ttotal: 8.78ms\tremaining: 138ms\n",
      "6:\tlearn: 0.6493708\ttotal: 10.3ms\tremaining: 136ms\n",
      "7:\tlearn: 0.6434120\ttotal: 11.6ms\tremaining: 133ms\n",
      "8:\tlearn: 0.6374640\ttotal: 13ms\tremaining: 132ms\n",
      "9:\tlearn: 0.6319752\ttotal: 14.4ms\tremaining: 130ms\n",
      "10:\tlearn: 0.6265612\ttotal: 15.8ms\tremaining: 128ms\n",
      "11:\tlearn: 0.6209431\ttotal: 17.2ms\tremaining: 126ms\n",
      "12:\tlearn: 0.6156049\ttotal: 18.6ms\tremaining: 124ms\n",
      "13:\tlearn: 0.6100763\ttotal: 19.9ms\tremaining: 122ms\n",
      "14:\tlearn: 0.6044701\ttotal: 21.3ms\tremaining: 121ms\n",
      "15:\tlearn: 0.5990022\ttotal: 22.7ms\tremaining: 119ms\n",
      "16:\tlearn: 0.5937855\ttotal: 24.2ms\tremaining: 118ms\n",
      "17:\tlearn: 0.5886250\ttotal: 25.6ms\tremaining: 116ms\n",
      "18:\tlearn: 0.5838882\ttotal: 27.1ms\tremaining: 116ms\n",
      "19:\tlearn: 0.5787990\ttotal: 28.4ms\tremaining: 114ms\n",
      "20:\tlearn: 0.5739089\ttotal: 30ms\tremaining: 113ms\n",
      "21:\tlearn: 0.5692654\ttotal: 31.4ms\tremaining: 111ms\n",
      "22:\tlearn: 0.5645765\ttotal: 32.7ms\tremaining: 110ms\n",
      "23:\tlearn: 0.5602567\ttotal: 34.2ms\tremaining: 108ms\n",
      "24:\tlearn: 0.5558570\ttotal: 35.6ms\tremaining: 107ms\n",
      "25:\tlearn: 0.5513090\ttotal: 37ms\tremaining: 105ms\n",
      "26:\tlearn: 0.5471488\ttotal: 39.2ms\tremaining: 106ms\n",
      "27:\tlearn: 0.5426923\ttotal: 40.7ms\tremaining: 105ms\n",
      "28:\tlearn: 0.5385479\ttotal: 42.3ms\tremaining: 103ms\n",
      "29:\tlearn: 0.5343355\ttotal: 43.7ms\tremaining: 102ms\n",
      "30:\tlearn: 0.5303517\ttotal: 45.3ms\tremaining: 101ms\n",
      "31:\tlearn: 0.5261402\ttotal: 46.7ms\tremaining: 99.3ms\n",
      "32:\tlearn: 0.5219905\ttotal: 48.3ms\tremaining: 98.1ms\n",
      "33:\tlearn: 0.5180044\ttotal: 49.7ms\tremaining: 96.5ms\n",
      "34:\tlearn: 0.5141720\ttotal: 51.1ms\tremaining: 94.9ms\n",
      "35:\tlearn: 0.5102778\ttotal: 52.6ms\tremaining: 93.4ms\n",
      "36:\tlearn: 0.5064775\ttotal: 54.1ms\tremaining: 92.1ms\n",
      "37:\tlearn: 0.5027632\ttotal: 55.7ms\tremaining: 90.8ms\n",
      "38:\tlearn: 0.4988917\ttotal: 57.2ms\tremaining: 89.4ms\n",
      "39:\tlearn: 0.4949819\ttotal: 58.6ms\tremaining: 87.9ms\n",
      "40:\tlearn: 0.4913392\ttotal: 60.1ms\tremaining: 86.4ms\n",
      "41:\tlearn: 0.4875544\ttotal: 61.5ms\tremaining: 85ms\n",
      "42:\tlearn: 0.4839844\ttotal: 62.9ms\tremaining: 83.4ms\n",
      "43:\tlearn: 0.4805138\ttotal: 64.6ms\tremaining: 82.2ms\n",
      "44:\tlearn: 0.4772504\ttotal: 66.1ms\tremaining: 80.8ms\n",
      "45:\tlearn: 0.4739822\ttotal: 67.6ms\tremaining: 79.3ms\n",
      "46:\tlearn: 0.4707970\ttotal: 69ms\tremaining: 77.8ms\n",
      "47:\tlearn: 0.4677981\ttotal: 70.5ms\tremaining: 76.4ms\n",
      "48:\tlearn: 0.4647418\ttotal: 72ms\tremaining: 75ms\n",
      "49:\tlearn: 0.4615206\ttotal: 73.5ms\tremaining: 73.5ms\n",
      "50:\tlearn: 0.4584376\ttotal: 75ms\tremaining: 72ms\n",
      "51:\tlearn: 0.4554064\ttotal: 77ms\tremaining: 71ms\n",
      "52:\tlearn: 0.4526441\ttotal: 79ms\tremaining: 70.1ms\n",
      "53:\tlearn: 0.4496316\ttotal: 80.5ms\tremaining: 68.6ms\n",
      "54:\tlearn: 0.4465664\ttotal: 82.1ms\tremaining: 67.1ms\n",
      "55:\tlearn: 0.4435320\ttotal: 83.7ms\tremaining: 65.8ms\n",
      "56:\tlearn: 0.4405090\ttotal: 85.2ms\tremaining: 64.3ms\n",
      "57:\tlearn: 0.4375139\ttotal: 86.7ms\tremaining: 62.8ms\n",
      "58:\tlearn: 0.4348537\ttotal: 88.2ms\tremaining: 61.3ms\n",
      "59:\tlearn: 0.4321054\ttotal: 89.8ms\tremaining: 59.9ms\n",
      "60:\tlearn: 0.4291791\ttotal: 91.3ms\tremaining: 58.4ms\n",
      "61:\tlearn: 0.4265060\ttotal: 92.7ms\tremaining: 56.8ms\n",
      "62:\tlearn: 0.4238787\ttotal: 94.2ms\tremaining: 55.3ms\n",
      "63:\tlearn: 0.4212202\ttotal: 96.4ms\tremaining: 54.2ms\n",
      "64:\tlearn: 0.4184833\ttotal: 98ms\tremaining: 52.8ms\n",
      "65:\tlearn: 0.4157974\ttotal: 99.3ms\tremaining: 51.2ms\n",
      "66:\tlearn: 0.4131394\ttotal: 101ms\tremaining: 49.6ms\n",
      "67:\tlearn: 0.4106780\ttotal: 103ms\tremaining: 48.4ms\n",
      "68:\tlearn: 0.4081480\ttotal: 104ms\tremaining: 46.9ms\n",
      "69:\tlearn: 0.4056596\ttotal: 106ms\tremaining: 45.3ms\n",
      "70:\tlearn: 0.4032222\ttotal: 107ms\tremaining: 43.8ms\n",
      "71:\tlearn: 0.4007740\ttotal: 109ms\tremaining: 42.2ms\n",
      "72:\tlearn: 0.3985403\ttotal: 110ms\tremaining: 40.7ms\n",
      "73:\tlearn: 0.3959464\ttotal: 111ms\tremaining: 39.2ms\n",
      "74:\tlearn: 0.3937821\ttotal: 113ms\tremaining: 37.6ms\n",
      "75:\tlearn: 0.3916244\ttotal: 114ms\tremaining: 36.1ms\n",
      "76:\tlearn: 0.3892685\ttotal: 116ms\tremaining: 34.6ms\n",
      "77:\tlearn: 0.3871016\ttotal: 117ms\tremaining: 33.1ms\n",
      "78:\tlearn: 0.3845838\ttotal: 119ms\tremaining: 31.6ms\n",
      "79:\tlearn: 0.3825971\ttotal: 120ms\tremaining: 30ms\n",
      "80:\tlearn: 0.3802845\ttotal: 122ms\tremaining: 28.5ms\n",
      "81:\tlearn: 0.3784682\ttotal: 123ms\tremaining: 27ms\n",
      "82:\tlearn: 0.3763081\ttotal: 125ms\tremaining: 25.5ms\n",
      "83:\tlearn: 0.3741779\ttotal: 126ms\tremaining: 24ms\n",
      "84:\tlearn: 0.3720958\ttotal: 128ms\tremaining: 22.5ms\n",
      "85:\tlearn: 0.3699629\ttotal: 129ms\tremaining: 21ms\n",
      "86:\tlearn: 0.3681582\ttotal: 131ms\tremaining: 19.5ms\n",
      "87:\tlearn: 0.3659587\ttotal: 132ms\tremaining: 18ms\n",
      "88:\tlearn: 0.3640111\ttotal: 133ms\tremaining: 16.5ms\n",
      "89:\tlearn: 0.3620470\ttotal: 135ms\tremaining: 15ms\n",
      "90:\tlearn: 0.3601675\ttotal: 136ms\tremaining: 13.5ms\n",
      "91:\tlearn: 0.3580880\ttotal: 137ms\tremaining: 11.9ms\n",
      "92:\tlearn: 0.3562733\ttotal: 139ms\tremaining: 10.5ms\n",
      "93:\tlearn: 0.3546707\ttotal: 141ms\tremaining: 8.97ms\n",
      "94:\tlearn: 0.3530158\ttotal: 142ms\tremaining: 7.47ms\n",
      "95:\tlearn: 0.3513294\ttotal: 144ms\tremaining: 5.98ms\n",
      "96:\tlearn: 0.3496957\ttotal: 145ms\tremaining: 4.49ms\n",
      "97:\tlearn: 0.3478935\ttotal: 147ms\tremaining: 2.99ms\n",
      "98:\tlearn: 0.3460571\ttotal: 148ms\tremaining: 1.5ms\n",
      "99:\tlearn: 0.3443240\ttotal: 149ms\tremaining: 0us\n",
      "0:\tlearn: 0.6861012\ttotal: 1.49ms\tremaining: 148ms\n",
      "1:\tlearn: 0.6796885\ttotal: 2.94ms\tremaining: 144ms\n",
      "2:\tlearn: 0.6730329\ttotal: 4.42ms\tremaining: 143ms\n",
      "3:\tlearn: 0.6667040\ttotal: 5.84ms\tremaining: 140ms\n",
      "4:\tlearn: 0.6603975\ttotal: 7.08ms\tremaining: 135ms\n",
      "5:\tlearn: 0.6544670\ttotal: 8.48ms\tremaining: 133ms\n",
      "6:\tlearn: 0.6485852\ttotal: 9.8ms\tremaining: 130ms\n",
      "7:\tlearn: 0.6426860\ttotal: 11.2ms\tremaining: 129ms\n",
      "8:\tlearn: 0.6364881\ttotal: 12.7ms\tremaining: 128ms\n",
      "9:\tlearn: 0.6311352\ttotal: 14.3ms\tremaining: 129ms\n",
      "10:\tlearn: 0.6258318\ttotal: 15.7ms\tremaining: 127ms\n",
      "11:\tlearn: 0.6203417\ttotal: 17.2ms\tremaining: 126ms\n",
      "12:\tlearn: 0.6146993\ttotal: 18.7ms\tremaining: 125ms\n",
      "13:\tlearn: 0.6093489\ttotal: 20.1ms\tremaining: 124ms\n",
      "14:\tlearn: 0.6042416\ttotal: 21.6ms\tremaining: 122ms\n",
      "15:\tlearn: 0.5988572\ttotal: 23.1ms\tremaining: 121ms\n",
      "16:\tlearn: 0.5935328\ttotal: 24.4ms\tremaining: 119ms\n",
      "17:\tlearn: 0.5886189\ttotal: 25.7ms\tremaining: 117ms\n",
      "18:\tlearn: 0.5837184\ttotal: 27.2ms\tremaining: 116ms\n",
      "19:\tlearn: 0.5786502\ttotal: 28.9ms\tremaining: 116ms\n",
      "20:\tlearn: 0.5738435\ttotal: 30.2ms\tremaining: 114ms\n",
      "21:\tlearn: 0.5690117\ttotal: 32ms\tremaining: 113ms\n",
      "22:\tlearn: 0.5643687\ttotal: 33.4ms\tremaining: 112ms\n",
      "23:\tlearn: 0.5600829\ttotal: 34.8ms\tremaining: 110ms\n",
      "24:\tlearn: 0.5554864\ttotal: 36.2ms\tremaining: 109ms\n",
      "25:\tlearn: 0.5510427\ttotal: 37.4ms\tremaining: 107ms\n",
      "26:\tlearn: 0.5465989\ttotal: 38.9ms\tremaining: 105ms\n",
      "27:\tlearn: 0.5425121\ttotal: 40.4ms\tremaining: 104ms\n",
      "28:\tlearn: 0.5383885\ttotal: 41.8ms\tremaining: 102ms\n",
      "29:\tlearn: 0.5339795\ttotal: 43.1ms\tremaining: 101ms\n",
      "30:\tlearn: 0.5299486\ttotal: 44.5ms\tremaining: 99ms\n",
      "31:\tlearn: 0.5257246\ttotal: 45.8ms\tremaining: 97.4ms\n",
      "32:\tlearn: 0.5215871\ttotal: 47.3ms\tremaining: 95.9ms\n",
      "33:\tlearn: 0.5174545\ttotal: 48.6ms\tremaining: 94.4ms\n",
      "34:\tlearn: 0.5135276\ttotal: 50.2ms\tremaining: 93.3ms\n",
      "35:\tlearn: 0.5096693\ttotal: 51.7ms\tremaining: 91.9ms\n",
      "36:\tlearn: 0.5058852\ttotal: 53.7ms\tremaining: 91.4ms\n",
      "37:\tlearn: 0.5020666\ttotal: 55.1ms\tremaining: 89.8ms\n",
      "38:\tlearn: 0.4982690\ttotal: 56.4ms\tremaining: 88.2ms\n",
      "39:\tlearn: 0.4943629\ttotal: 57.9ms\tremaining: 86.9ms\n",
      "40:\tlearn: 0.4908071\ttotal: 59.4ms\tremaining: 85.5ms\n",
      "41:\tlearn: 0.4870192\ttotal: 60.8ms\tremaining: 84ms\n",
      "42:\tlearn: 0.4837080\ttotal: 62.1ms\tremaining: 82.3ms\n",
      "43:\tlearn: 0.4801354\ttotal: 63.4ms\tremaining: 80.7ms\n",
      "44:\tlearn: 0.4768667\ttotal: 64.9ms\tremaining: 79.3ms\n",
      "45:\tlearn: 0.4736211\ttotal: 67ms\tremaining: 78.6ms\n",
      "46:\tlearn: 0.4703554\ttotal: 68.4ms\tremaining: 77.2ms\n",
      "47:\tlearn: 0.4671676\ttotal: 69.9ms\tremaining: 75.8ms\n",
      "48:\tlearn: 0.4640859\ttotal: 71.3ms\tremaining: 74.2ms\n",
      "49:\tlearn: 0.4608458\ttotal: 72.8ms\tremaining: 72.8ms\n",
      "50:\tlearn: 0.4577508\ttotal: 74.2ms\tremaining: 71.3ms\n",
      "51:\tlearn: 0.4547182\ttotal: 75.5ms\tremaining: 69.7ms\n",
      "52:\tlearn: 0.4519754\ttotal: 76.8ms\tremaining: 68.1ms\n",
      "53:\tlearn: 0.4488859\ttotal: 78.7ms\tremaining: 67ms\n",
      "54:\tlearn: 0.4458520\ttotal: 80.1ms\tremaining: 65.5ms\n",
      "55:\tlearn: 0.4427963\ttotal: 81.6ms\tremaining: 64.1ms\n",
      "56:\tlearn: 0.4398483\ttotal: 83.3ms\tremaining: 62.8ms\n",
      "57:\tlearn: 0.4368278\ttotal: 84.8ms\tremaining: 61.4ms\n",
      "58:\tlearn: 0.4342061\ttotal: 86.2ms\tremaining: 59.9ms\n",
      "59:\tlearn: 0.4313219\ttotal: 87.8ms\tremaining: 58.5ms\n",
      "60:\tlearn: 0.4283318\ttotal: 89.2ms\tremaining: 57ms\n",
      "61:\tlearn: 0.4256446\ttotal: 90.8ms\tremaining: 55.6ms\n",
      "62:\tlearn: 0.4230480\ttotal: 92.3ms\tremaining: 54.2ms\n",
      "63:\tlearn: 0.4201616\ttotal: 93.7ms\tremaining: 52.7ms\n",
      "64:\tlearn: 0.4173251\ttotal: 95.3ms\tremaining: 51.3ms\n",
      "65:\tlearn: 0.4145944\ttotal: 96.7ms\tremaining: 49.8ms\n",
      "66:\tlearn: 0.4117988\ttotal: 98.3ms\tremaining: 48.4ms\n",
      "67:\tlearn: 0.4093303\ttotal: 99.9ms\tremaining: 47ms\n",
      "68:\tlearn: 0.4071224\ttotal: 101ms\tremaining: 45.6ms\n",
      "69:\tlearn: 0.4046550\ttotal: 103ms\tremaining: 44.1ms\n",
      "70:\tlearn: 0.4022151\ttotal: 104ms\tremaining: 42.7ms\n",
      "71:\tlearn: 0.3995718\ttotal: 106ms\tremaining: 41.2ms\n",
      "72:\tlearn: 0.3971973\ttotal: 107ms\tremaining: 39.7ms\n",
      "73:\tlearn: 0.3947182\ttotal: 109ms\tremaining: 38.3ms\n",
      "74:\tlearn: 0.3922991\ttotal: 110ms\tremaining: 36.8ms\n",
      "75:\tlearn: 0.3901045\ttotal: 112ms\tremaining: 35.3ms\n",
      "76:\tlearn: 0.3876398\ttotal: 113ms\tremaining: 33.9ms\n",
      "77:\tlearn: 0.3853660\ttotal: 115ms\tremaining: 32.4ms\n",
      "78:\tlearn: 0.3830297\ttotal: 116ms\tremaining: 30.9ms\n",
      "79:\tlearn: 0.3808988\ttotal: 118ms\tremaining: 29.5ms\n",
      "80:\tlearn: 0.3785796\ttotal: 119ms\tremaining: 28ms\n",
      "81:\tlearn: 0.3767116\ttotal: 121ms\tremaining: 26.5ms\n",
      "82:\tlearn: 0.3745801\ttotal: 122ms\tremaining: 25ms\n",
      "83:\tlearn: 0.3725400\ttotal: 124ms\tremaining: 23.5ms\n",
      "84:\tlearn: 0.3705320\ttotal: 125ms\tremaining: 22.1ms\n",
      "85:\tlearn: 0.3684258\ttotal: 127ms\tremaining: 20.6ms\n",
      "86:\tlearn: 0.3664476\ttotal: 128ms\tremaining: 19.1ms\n",
      "87:\tlearn: 0.3642184\ttotal: 130ms\tremaining: 17.7ms\n",
      "88:\tlearn: 0.3623757\ttotal: 131ms\tremaining: 16.2ms\n",
      "89:\tlearn: 0.3604473\ttotal: 133ms\tremaining: 14.7ms\n",
      "90:\tlearn: 0.3584783\ttotal: 134ms\tremaining: 13.3ms\n",
      "91:\tlearn: 0.3564155\ttotal: 135ms\tremaining: 11.8ms\n",
      "92:\tlearn: 0.3544122\ttotal: 137ms\tremaining: 10.3ms\n",
      "93:\tlearn: 0.3526442\ttotal: 138ms\tremaining: 8.82ms\n",
      "94:\tlearn: 0.3507771\ttotal: 140ms\tremaining: 7.35ms\n",
      "95:\tlearn: 0.3490204\ttotal: 141ms\tremaining: 5.88ms\n",
      "96:\tlearn: 0.3471449\ttotal: 143ms\tremaining: 4.41ms\n",
      "97:\tlearn: 0.3453263\ttotal: 144ms\tremaining: 2.94ms\n",
      "98:\tlearn: 0.3438265\ttotal: 145ms\tremaining: 1.47ms\n",
      "99:\tlearn: 0.3417765\ttotal: 147ms\tremaining: 0us\n",
      "0:\tlearn: 0.6861782\ttotal: 1.31ms\tremaining: 129ms\n",
      "1:\tlearn: 0.6797670\ttotal: 2.9ms\tremaining: 142ms\n",
      "2:\tlearn: 0.6733779\ttotal: 4.4ms\tremaining: 142ms\n",
      "3:\tlearn: 0.6670536\ttotal: 5.84ms\tremaining: 140ms\n",
      "4:\tlearn: 0.6606790\ttotal: 7.18ms\tremaining: 136ms\n",
      "5:\tlearn: 0.6545435\ttotal: 8.51ms\tremaining: 133ms\n",
      "6:\tlearn: 0.6486877\ttotal: 9.75ms\tremaining: 130ms\n",
      "7:\tlearn: 0.6424186\ttotal: 11ms\tremaining: 127ms\n",
      "8:\tlearn: 0.6364876\ttotal: 12.3ms\tremaining: 124ms\n",
      "9:\tlearn: 0.6310901\ttotal: 13.5ms\tremaining: 121ms\n",
      "10:\tlearn: 0.6257890\ttotal: 14.9ms\tremaining: 121ms\n",
      "11:\tlearn: 0.6203235\ttotal: 16.5ms\tremaining: 121ms\n",
      "12:\tlearn: 0.6149493\ttotal: 18.7ms\tremaining: 125ms\n",
      "13:\tlearn: 0.6096074\ttotal: 20.1ms\tremaining: 124ms\n",
      "14:\tlearn: 0.6042825\ttotal: 21.6ms\tremaining: 122ms\n",
      "15:\tlearn: 0.5989154\ttotal: 23ms\tremaining: 121ms\n",
      "16:\tlearn: 0.5936250\ttotal: 24.4ms\tremaining: 119ms\n",
      "17:\tlearn: 0.5884900\ttotal: 25.7ms\tremaining: 117ms\n",
      "18:\tlearn: 0.5836015\ttotal: 27.2ms\tremaining: 116ms\n",
      "19:\tlearn: 0.5785170\ttotal: 28.9ms\tremaining: 116ms\n",
      "20:\tlearn: 0.5736567\ttotal: 30.3ms\tremaining: 114ms\n",
      "21:\tlearn: 0.5690061\ttotal: 31.8ms\tremaining: 113ms\n",
      "22:\tlearn: 0.5641608\ttotal: 33.3ms\tremaining: 111ms\n",
      "23:\tlearn: 0.5597962\ttotal: 34.7ms\tremaining: 110ms\n",
      "24:\tlearn: 0.5550864\ttotal: 36.3ms\tremaining: 109ms\n",
      "25:\tlearn: 0.5506663\ttotal: 37.6ms\tremaining: 107ms\n",
      "26:\tlearn: 0.5461631\ttotal: 39.2ms\tremaining: 106ms\n",
      "27:\tlearn: 0.5418621\ttotal: 40.6ms\tremaining: 104ms\n",
      "28:\tlearn: 0.5376811\ttotal: 42ms\tremaining: 103ms\n",
      "29:\tlearn: 0.5332971\ttotal: 43.4ms\tremaining: 101ms\n",
      "30:\tlearn: 0.5290105\ttotal: 44.8ms\tremaining: 99.7ms\n",
      "31:\tlearn: 0.5247548\ttotal: 46.3ms\tremaining: 98.5ms\n",
      "32:\tlearn: 0.5207319\ttotal: 47.7ms\tremaining: 96.9ms\n",
      "33:\tlearn: 0.5167919\ttotal: 49ms\tremaining: 95.2ms\n",
      "34:\tlearn: 0.5128695\ttotal: 50.7ms\tremaining: 94.2ms\n",
      "35:\tlearn: 0.5089725\ttotal: 52.1ms\tremaining: 92.7ms\n",
      "36:\tlearn: 0.5051809\ttotal: 53.6ms\tremaining: 91.3ms\n",
      "37:\tlearn: 0.5013317\ttotal: 55ms\tremaining: 89.7ms\n",
      "38:\tlearn: 0.4974799\ttotal: 56.4ms\tremaining: 88.2ms\n",
      "39:\tlearn: 0.4936813\ttotal: 57.9ms\tremaining: 86.8ms\n",
      "40:\tlearn: 0.4901097\ttotal: 59.5ms\tremaining: 85.5ms\n",
      "41:\tlearn: 0.4863375\ttotal: 60.9ms\tremaining: 84.1ms\n",
      "42:\tlearn: 0.4830623\ttotal: 62.4ms\tremaining: 82.7ms\n",
      "43:\tlearn: 0.4794802\ttotal: 63.8ms\tremaining: 81.2ms\n",
      "44:\tlearn: 0.4758946\ttotal: 65.5ms\tremaining: 80.1ms\n",
      "45:\tlearn: 0.4726302\ttotal: 66.9ms\tremaining: 78.5ms\n",
      "46:\tlearn: 0.4694544\ttotal: 68.4ms\tremaining: 77.1ms\n",
      "47:\tlearn: 0.4664284\ttotal: 69.8ms\tremaining: 75.6ms\n",
      "48:\tlearn: 0.4633478\ttotal: 71.2ms\tremaining: 74.1ms\n",
      "49:\tlearn: 0.4600634\ttotal: 72.8ms\tremaining: 72.8ms\n",
      "50:\tlearn: 0.4569555\ttotal: 74.1ms\tremaining: 71.2ms\n",
      "51:\tlearn: 0.4539262\ttotal: 75.6ms\tremaining: 69.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52:\tlearn: 0.4510113\ttotal: 77.2ms\tremaining: 68.5ms\n",
      "53:\tlearn: 0.4479780\ttotal: 78.6ms\tremaining: 66.9ms\n",
      "54:\tlearn: 0.4450305\ttotal: 80ms\tremaining: 65.4ms\n",
      "55:\tlearn: 0.4419735\ttotal: 81.5ms\tremaining: 64ms\n",
      "56:\tlearn: 0.4390956\ttotal: 83ms\tremaining: 62.6ms\n",
      "57:\tlearn: 0.4361496\ttotal: 84.4ms\tremaining: 61.1ms\n",
      "58:\tlearn: 0.4334680\ttotal: 85.9ms\tremaining: 59.7ms\n",
      "59:\tlearn: 0.4306007\ttotal: 87.5ms\tremaining: 58.3ms\n",
      "60:\tlearn: 0.4275172\ttotal: 88.9ms\tremaining: 56.8ms\n",
      "61:\tlearn: 0.4247714\ttotal: 90.5ms\tremaining: 55.5ms\n",
      "62:\tlearn: 0.4221651\ttotal: 91.9ms\tremaining: 54ms\n",
      "63:\tlearn: 0.4193467\ttotal: 93.5ms\tremaining: 52.6ms\n",
      "64:\tlearn: 0.4164508\ttotal: 95.1ms\tremaining: 51.2ms\n",
      "65:\tlearn: 0.4137197\ttotal: 96.4ms\tremaining: 49.7ms\n",
      "66:\tlearn: 0.4109936\ttotal: 97.9ms\tremaining: 48.2ms\n",
      "67:\tlearn: 0.4085369\ttotal: 99.4ms\tremaining: 46.8ms\n",
      "68:\tlearn: 0.4061652\ttotal: 101ms\tremaining: 45.3ms\n",
      "69:\tlearn: 0.4036451\ttotal: 102ms\tremaining: 43.8ms\n",
      "70:\tlearn: 0.4010421\ttotal: 104ms\tremaining: 42.4ms\n",
      "71:\tlearn: 0.3982802\ttotal: 105ms\tremaining: 40.9ms\n",
      "72:\tlearn: 0.3959066\ttotal: 107ms\tremaining: 39.4ms\n",
      "73:\tlearn: 0.3933106\ttotal: 108ms\tremaining: 38ms\n",
      "74:\tlearn: 0.3911020\ttotal: 109ms\tremaining: 36.5ms\n",
      "75:\tlearn: 0.3888145\ttotal: 111ms\tremaining: 35ms\n",
      "76:\tlearn: 0.3864439\ttotal: 112ms\tremaining: 33.5ms\n",
      "77:\tlearn: 0.3842358\ttotal: 114ms\tremaining: 32ms\n",
      "78:\tlearn: 0.3817666\ttotal: 115ms\tremaining: 30.5ms\n",
      "79:\tlearn: 0.3796908\ttotal: 116ms\tremaining: 29.1ms\n",
      "80:\tlearn: 0.3775404\ttotal: 118ms\tremaining: 27.6ms\n",
      "81:\tlearn: 0.3756604\ttotal: 119ms\tremaining: 26.2ms\n",
      "82:\tlearn: 0.3732693\ttotal: 121ms\tremaining: 24.7ms\n",
      "83:\tlearn: 0.3713104\ttotal: 122ms\tremaining: 23.3ms\n",
      "84:\tlearn: 0.3691886\ttotal: 124ms\tremaining: 21.8ms\n",
      "85:\tlearn: 0.3670775\ttotal: 125ms\tremaining: 20.4ms\n",
      "86:\tlearn: 0.3652119\ttotal: 127ms\tremaining: 18.9ms\n",
      "87:\tlearn: 0.3628060\ttotal: 128ms\tremaining: 17.4ms\n",
      "88:\tlearn: 0.3609894\ttotal: 129ms\tremaining: 16ms\n",
      "89:\tlearn: 0.3590440\ttotal: 131ms\tremaining: 14.5ms\n",
      "90:\tlearn: 0.3573244\ttotal: 132ms\tremaining: 13.1ms\n",
      "91:\tlearn: 0.3551969\ttotal: 134ms\tremaining: 11.6ms\n",
      "92:\tlearn: 0.3534192\ttotal: 135ms\tremaining: 10.2ms\n",
      "93:\tlearn: 0.3518460\ttotal: 137ms\tremaining: 8.73ms\n",
      "94:\tlearn: 0.3501099\ttotal: 138ms\tremaining: 7.28ms\n",
      "95:\tlearn: 0.3481978\ttotal: 140ms\tremaining: 5.83ms\n",
      "96:\tlearn: 0.3464100\ttotal: 141ms\tremaining: 4.37ms\n",
      "97:\tlearn: 0.3443558\ttotal: 143ms\tremaining: 2.91ms\n",
      "98:\tlearn: 0.3426063\ttotal: 144ms\tremaining: 1.46ms\n",
      "99:\tlearn: 0.3405828\ttotal: 146ms\tremaining: 0us\n",
      "0:\tlearn: 0.6593054\ttotal: 1.98ms\tremaining: 196ms\n",
      "1:\tlearn: 0.6304468\ttotal: 3.2ms\tremaining: 157ms\n",
      "2:\tlearn: 0.6032969\ttotal: 4.56ms\tremaining: 147ms\n",
      "3:\tlearn: 0.5761749\ttotal: 6.42ms\tremaining: 154ms\n",
      "4:\tlearn: 0.5509839\ttotal: 7.77ms\tremaining: 148ms\n",
      "5:\tlearn: 0.5293886\ttotal: 9.13ms\tremaining: 143ms\n",
      "6:\tlearn: 0.5097398\ttotal: 10.8ms\tremaining: 143ms\n",
      "7:\tlearn: 0.4909870\ttotal: 12.2ms\tremaining: 140ms\n",
      "8:\tlearn: 0.4731895\ttotal: 13.7ms\tremaining: 139ms\n",
      "9:\tlearn: 0.4579934\ttotal: 15.2ms\tremaining: 137ms\n",
      "10:\tlearn: 0.4435989\ttotal: 16.8ms\tremaining: 136ms\n",
      "11:\tlearn: 0.4302929\ttotal: 18.2ms\tremaining: 134ms\n",
      "12:\tlearn: 0.4161944\ttotal: 19.8ms\tremaining: 133ms\n",
      "13:\tlearn: 0.4037985\ttotal: 21.4ms\tremaining: 131ms\n",
      "14:\tlearn: 0.3912644\ttotal: 22.9ms\tremaining: 129ms\n",
      "15:\tlearn: 0.3798265\ttotal: 24.3ms\tremaining: 127ms\n",
      "16:\tlearn: 0.3681147\ttotal: 25.6ms\tremaining: 125ms\n",
      "17:\tlearn: 0.3581027\ttotal: 27.2ms\tremaining: 124ms\n",
      "18:\tlearn: 0.3481382\ttotal: 28.5ms\tremaining: 122ms\n",
      "19:\tlearn: 0.3398070\ttotal: 30.1ms\tremaining: 120ms\n",
      "20:\tlearn: 0.3309286\ttotal: 31.7ms\tremaining: 119ms\n",
      "21:\tlearn: 0.3228007\ttotal: 33.1ms\tremaining: 117ms\n",
      "22:\tlearn: 0.3149672\ttotal: 34.6ms\tremaining: 116ms\n",
      "23:\tlearn: 0.3078934\ttotal: 36ms\tremaining: 114ms\n",
      "24:\tlearn: 0.3011138\ttotal: 37.4ms\tremaining: 112ms\n",
      "25:\tlearn: 0.2944643\ttotal: 38.8ms\tremaining: 110ms\n",
      "26:\tlearn: 0.2891970\ttotal: 40.4ms\tremaining: 109ms\n",
      "27:\tlearn: 0.2843389\ttotal: 41.9ms\tremaining: 108ms\n",
      "28:\tlearn: 0.2796791\ttotal: 43.2ms\tremaining: 106ms\n",
      "29:\tlearn: 0.2744213\ttotal: 45.4ms\tremaining: 106ms\n",
      "30:\tlearn: 0.2693412\ttotal: 46.9ms\tremaining: 104ms\n",
      "31:\tlearn: 0.2636492\ttotal: 48.4ms\tremaining: 103ms\n",
      "32:\tlearn: 0.2581024\ttotal: 49.9ms\tremaining: 101ms\n",
      "33:\tlearn: 0.2533188\ttotal: 51.3ms\tremaining: 99.6ms\n",
      "34:\tlearn: 0.2491037\ttotal: 52.9ms\tremaining: 98.2ms\n",
      "35:\tlearn: 0.2453146\ttotal: 54.3ms\tremaining: 96.6ms\n",
      "36:\tlearn: 0.2411653\ttotal: 55.7ms\tremaining: 94.8ms\n",
      "37:\tlearn: 0.2371556\ttotal: 57.2ms\tremaining: 93.3ms\n",
      "38:\tlearn: 0.2331405\ttotal: 58.7ms\tremaining: 91.8ms\n",
      "39:\tlearn: 0.2292875\ttotal: 60.1ms\tremaining: 90.2ms\n",
      "40:\tlearn: 0.2252702\ttotal: 61.5ms\tremaining: 88.5ms\n",
      "41:\tlearn: 0.2219303\ttotal: 63ms\tremaining: 87ms\n",
      "42:\tlearn: 0.2188010\ttotal: 64.5ms\tremaining: 85.5ms\n",
      "43:\tlearn: 0.2160384\ttotal: 66.1ms\tremaining: 84.1ms\n",
      "44:\tlearn: 0.2128426\ttotal: 67.5ms\tremaining: 82.5ms\n",
      "45:\tlearn: 0.2097151\ttotal: 68.9ms\tremaining: 80.9ms\n",
      "46:\tlearn: 0.2072675\ttotal: 70.6ms\tremaining: 79.6ms\n",
      "47:\tlearn: 0.2054150\ttotal: 72.1ms\tremaining: 78.2ms\n",
      "48:\tlearn: 0.2030358\ttotal: 73.8ms\tremaining: 76.8ms\n",
      "49:\tlearn: 0.2001542\ttotal: 75.2ms\tremaining: 75.2ms\n",
      "50:\tlearn: 0.1975864\ttotal: 76.6ms\tremaining: 73.6ms\n",
      "51:\tlearn: 0.1958162\ttotal: 78.2ms\tremaining: 72.2ms\n",
      "52:\tlearn: 0.1937417\ttotal: 79.7ms\tremaining: 70.7ms\n",
      "53:\tlearn: 0.1916740\ttotal: 81.2ms\tremaining: 69.2ms\n",
      "54:\tlearn: 0.1897548\ttotal: 82.6ms\tremaining: 67.6ms\n",
      "55:\tlearn: 0.1872825\ttotal: 84ms\tremaining: 66ms\n",
      "56:\tlearn: 0.1847599\ttotal: 85.6ms\tremaining: 64.6ms\n",
      "57:\tlearn: 0.1824916\ttotal: 87ms\tremaining: 63ms\n",
      "58:\tlearn: 0.1806075\ttotal: 88.5ms\tremaining: 61.5ms\n",
      "59:\tlearn: 0.1793678\ttotal: 90.2ms\tremaining: 60.1ms\n",
      "60:\tlearn: 0.1770941\ttotal: 91.7ms\tremaining: 58.6ms\n",
      "61:\tlearn: 0.1752344\ttotal: 93.2ms\tremaining: 57.1ms\n",
      "62:\tlearn: 0.1735275\ttotal: 94.5ms\tremaining: 55.5ms\n",
      "63:\tlearn: 0.1720994\ttotal: 96.1ms\tremaining: 54.1ms\n",
      "64:\tlearn: 0.1703730\ttotal: 97.7ms\tremaining: 52.6ms\n",
      "65:\tlearn: 0.1686132\ttotal: 99.3ms\tremaining: 51.2ms\n",
      "66:\tlearn: 0.1675337\ttotal: 101ms\tremaining: 49.7ms\n",
      "67:\tlearn: 0.1654193\ttotal: 102ms\tremaining: 48.2ms\n",
      "68:\tlearn: 0.1641133\ttotal: 104ms\tremaining: 46.7ms\n",
      "69:\tlearn: 0.1623271\ttotal: 106ms\tremaining: 45.2ms\n",
      "70:\tlearn: 0.1616287\ttotal: 107ms\tremaining: 43.7ms\n",
      "71:\tlearn: 0.1596017\ttotal: 109ms\tremaining: 42.2ms\n",
      "72:\tlearn: 0.1584471\ttotal: 110ms\tremaining: 40.7ms\n",
      "73:\tlearn: 0.1568882\ttotal: 112ms\tremaining: 39.2ms\n",
      "74:\tlearn: 0.1554915\ttotal: 113ms\tremaining: 37.7ms\n",
      "75:\tlearn: 0.1536221\ttotal: 114ms\tremaining: 36.1ms\n",
      "76:\tlearn: 0.1529014\ttotal: 116ms\tremaining: 34.6ms\n",
      "77:\tlearn: 0.1522651\ttotal: 117ms\tremaining: 33.1ms\n",
      "78:\tlearn: 0.1509097\ttotal: 119ms\tremaining: 31.6ms\n",
      "79:\tlearn: 0.1497918\ttotal: 120ms\tremaining: 30.1ms\n",
      "80:\tlearn: 0.1484420\ttotal: 122ms\tremaining: 28.7ms\n",
      "81:\tlearn: 0.1477052\ttotal: 124ms\tremaining: 27.2ms\n",
      "82:\tlearn: 0.1470792\ttotal: 125ms\tremaining: 25.7ms\n",
      "83:\tlearn: 0.1458646\ttotal: 127ms\tremaining: 24.2ms\n",
      "84:\tlearn: 0.1452022\ttotal: 128ms\tremaining: 22.7ms\n",
      "85:\tlearn: 0.1442108\ttotal: 130ms\tremaining: 21.1ms\n",
      "86:\tlearn: 0.1433827\ttotal: 132ms\tremaining: 19.7ms\n",
      "87:\tlearn: 0.1416613\ttotal: 133ms\tremaining: 18.2ms\n",
      "88:\tlearn: 0.1405637\ttotal: 135ms\tremaining: 16.6ms\n",
      "89:\tlearn: 0.1394604\ttotal: 136ms\tremaining: 15.1ms\n",
      "90:\tlearn: 0.1384904\ttotal: 138ms\tremaining: 13.6ms\n",
      "91:\tlearn: 0.1376018\ttotal: 139ms\tremaining: 12.1ms\n",
      "92:\tlearn: 0.1368109\ttotal: 141ms\tremaining: 10.6ms\n",
      "93:\tlearn: 0.1359234\ttotal: 142ms\tremaining: 9.06ms\n",
      "94:\tlearn: 0.1353346\ttotal: 144ms\tremaining: 7.56ms\n",
      "95:\tlearn: 0.1346959\ttotal: 145ms\tremaining: 6.05ms\n",
      "96:\tlearn: 0.1337871\ttotal: 148ms\tremaining: 4.56ms\n",
      "97:\tlearn: 0.1323918\ttotal: 149ms\tremaining: 3.04ms\n",
      "98:\tlearn: 0.1315002\ttotal: 151ms\tremaining: 1.52ms\n",
      "99:\tlearn: 0.1307459\ttotal: 152ms\tremaining: 0us\n",
      "0:\tlearn: 0.6585983\ttotal: 1.74ms\tremaining: 172ms\n",
      "1:\tlearn: 0.6293158\ttotal: 3.1ms\tremaining: 152ms\n",
      "2:\tlearn: 0.6008901\ttotal: 4.62ms\tremaining: 149ms\n",
      "3:\tlearn: 0.5741287\ttotal: 6.04ms\tremaining: 145ms\n",
      "4:\tlearn: 0.5504427\ttotal: 7.41ms\tremaining: 141ms\n",
      "5:\tlearn: 0.5295106\ttotal: 8.93ms\tremaining: 140ms\n",
      "6:\tlearn: 0.5099552\ttotal: 10.3ms\tremaining: 136ms\n",
      "7:\tlearn: 0.4915064\ttotal: 11.5ms\tremaining: 132ms\n",
      "8:\tlearn: 0.4729081\ttotal: 13ms\tremaining: 131ms\n",
      "9:\tlearn: 0.4571399\ttotal: 14.4ms\tremaining: 129ms\n",
      "10:\tlearn: 0.4422397\ttotal: 15.9ms\tremaining: 129ms\n",
      "11:\tlearn: 0.4278325\ttotal: 17.4ms\tremaining: 127ms\n",
      "12:\tlearn: 0.4143013\ttotal: 18.8ms\tremaining: 126ms\n",
      "13:\tlearn: 0.4018123\ttotal: 20.3ms\tremaining: 125ms\n",
      "14:\tlearn: 0.3906519\ttotal: 21.9ms\tremaining: 124ms\n",
      "15:\tlearn: 0.3793236\ttotal: 23.4ms\tremaining: 123ms\n",
      "16:\tlearn: 0.3675404\ttotal: 25ms\tremaining: 122ms\n",
      "17:\tlearn: 0.3587001\ttotal: 26.5ms\tremaining: 121ms\n",
      "18:\tlearn: 0.3481343\ttotal: 27.9ms\tremaining: 119ms\n",
      "19:\tlearn: 0.3400257\ttotal: 29.3ms\tremaining: 117ms\n",
      "20:\tlearn: 0.3311131\ttotal: 30.6ms\tremaining: 115ms\n",
      "21:\tlearn: 0.3228246\ttotal: 32ms\tremaining: 113ms\n",
      "22:\tlearn: 0.3153917\ttotal: 33.6ms\tremaining: 112ms\n",
      "23:\tlearn: 0.3085423\ttotal: 35ms\tremaining: 111ms\n",
      "24:\tlearn: 0.3015236\ttotal: 36.4ms\tremaining: 109ms\n",
      "25:\tlearn: 0.2948661\ttotal: 37.8ms\tremaining: 107ms\n",
      "26:\tlearn: 0.2896277\ttotal: 39.3ms\tremaining: 106ms\n",
      "27:\tlearn: 0.2845417\ttotal: 40.9ms\tremaining: 105ms\n",
      "28:\tlearn: 0.2785976\ttotal: 42.4ms\tremaining: 104ms\n",
      "29:\tlearn: 0.2739827\ttotal: 43.8ms\tremaining: 102ms\n",
      "30:\tlearn: 0.2680135\ttotal: 45.3ms\tremaining: 101ms\n",
      "31:\tlearn: 0.2630278\ttotal: 46.8ms\tremaining: 99.4ms\n",
      "32:\tlearn: 0.2574987\ttotal: 48.3ms\tremaining: 98.1ms\n",
      "33:\tlearn: 0.2530258\ttotal: 49.7ms\tremaining: 96.4ms\n",
      "34:\tlearn: 0.2488138\ttotal: 51.2ms\tremaining: 95.1ms\n",
      "35:\tlearn: 0.2443947\ttotal: 52.6ms\tremaining: 93.4ms\n",
      "36:\tlearn: 0.2404381\ttotal: 54ms\tremaining: 92ms\n",
      "37:\tlearn: 0.2364245\ttotal: 55.5ms\tremaining: 90.5ms\n",
      "38:\tlearn: 0.2324067\ttotal: 56.9ms\tremaining: 89ms\n",
      "39:\tlearn: 0.2286885\ttotal: 58.4ms\tremaining: 87.6ms\n",
      "40:\tlearn: 0.2253242\ttotal: 59.8ms\tremaining: 86ms\n",
      "41:\tlearn: 0.2219866\ttotal: 61.3ms\tremaining: 84.6ms\n",
      "42:\tlearn: 0.2188925\ttotal: 62.7ms\tremaining: 83.1ms\n",
      "43:\tlearn: 0.2156167\ttotal: 64.1ms\tremaining: 81.6ms\n",
      "44:\tlearn: 0.2135923\ttotal: 65.6ms\tremaining: 80.2ms\n",
      "45:\tlearn: 0.2108353\ttotal: 67.1ms\tremaining: 78.8ms\n",
      "46:\tlearn: 0.2087898\ttotal: 68.6ms\tremaining: 77.4ms\n",
      "47:\tlearn: 0.2066544\ttotal: 70.3ms\tremaining: 76.1ms\n",
      "48:\tlearn: 0.2038867\ttotal: 71.9ms\tremaining: 74.8ms\n",
      "49:\tlearn: 0.2008102\ttotal: 73.3ms\tremaining: 73.3ms\n",
      "50:\tlearn: 0.1981206\ttotal: 74.7ms\tremaining: 71.8ms\n",
      "51:\tlearn: 0.1957629\ttotal: 76.3ms\tremaining: 70.5ms\n",
      "52:\tlearn: 0.1934930\ttotal: 77.9ms\tremaining: 69.1ms\n",
      "53:\tlearn: 0.1910168\ttotal: 79.4ms\tremaining: 67.7ms\n",
      "54:\tlearn: 0.1890245\ttotal: 81ms\tremaining: 66.3ms\n",
      "55:\tlearn: 0.1868014\ttotal: 82.5ms\tremaining: 64.8ms\n",
      "56:\tlearn: 0.1846318\ttotal: 84.7ms\tremaining: 63.9ms\n",
      "57:\tlearn: 0.1831181\ttotal: 86.2ms\tremaining: 62.4ms\n",
      "58:\tlearn: 0.1818761\ttotal: 87.8ms\tremaining: 61ms\n",
      "59:\tlearn: 0.1803842\ttotal: 89.9ms\tremaining: 59.9ms\n",
      "60:\tlearn: 0.1775483\ttotal: 91.3ms\tremaining: 58.4ms\n",
      "61:\tlearn: 0.1757821\ttotal: 92.8ms\tremaining: 56.9ms\n",
      "62:\tlearn: 0.1740928\ttotal: 94.3ms\tremaining: 55.4ms\n",
      "63:\tlearn: 0.1726376\ttotal: 95.8ms\tremaining: 53.9ms\n",
      "64:\tlearn: 0.1706820\ttotal: 97.4ms\tremaining: 52.4ms\n",
      "65:\tlearn: 0.1689747\ttotal: 98.8ms\tremaining: 50.9ms\n",
      "66:\tlearn: 0.1676956\ttotal: 100ms\tremaining: 49.5ms\n",
      "67:\tlearn: 0.1660602\ttotal: 102ms\tremaining: 48ms\n",
      "68:\tlearn: 0.1648157\ttotal: 103ms\tremaining: 46.4ms\n",
      "69:\tlearn: 0.1637831\ttotal: 105ms\tremaining: 45ms\n",
      "70:\tlearn: 0.1624166\ttotal: 106ms\tremaining: 43.4ms\n",
      "71:\tlearn: 0.1605734\ttotal: 108ms\tremaining: 41.9ms\n",
      "72:\tlearn: 0.1591473\ttotal: 109ms\tremaining: 40.4ms\n",
      "73:\tlearn: 0.1575170\ttotal: 111ms\tremaining: 39.1ms\n",
      "74:\tlearn: 0.1566475\ttotal: 113ms\tremaining: 37.6ms\n",
      "75:\tlearn: 0.1550319\ttotal: 114ms\tremaining: 36.1ms\n",
      "76:\tlearn: 0.1538169\ttotal: 116ms\tremaining: 34.5ms\n",
      "77:\tlearn: 0.1530504\ttotal: 117ms\tremaining: 33.1ms\n",
      "78:\tlearn: 0.1517084\ttotal: 119ms\tremaining: 31.5ms\n",
      "79:\tlearn: 0.1501597\ttotal: 120ms\tremaining: 30ms\n",
      "80:\tlearn: 0.1489294\ttotal: 122ms\tremaining: 28.5ms\n",
      "81:\tlearn: 0.1477695\ttotal: 123ms\tremaining: 27ms\n",
      "82:\tlearn: 0.1467745\ttotal: 125ms\tremaining: 25.5ms\n",
      "83:\tlearn: 0.1456493\ttotal: 126ms\tremaining: 24ms\n",
      "84:\tlearn: 0.1447978\ttotal: 128ms\tremaining: 22.5ms\n",
      "85:\tlearn: 0.1437636\ttotal: 129ms\tremaining: 21ms\n",
      "86:\tlearn: 0.1427804\ttotal: 130ms\tremaining: 19.5ms\n",
      "87:\tlearn: 0.1417543\ttotal: 132ms\tremaining: 18ms\n",
      "88:\tlearn: 0.1413619\ttotal: 133ms\tremaining: 16.5ms\n",
      "89:\tlearn: 0.1401456\ttotal: 135ms\tremaining: 15ms\n",
      "90:\tlearn: 0.1388397\ttotal: 136ms\tremaining: 13.5ms\n",
      "91:\tlearn: 0.1379331\ttotal: 138ms\tremaining: 12ms\n",
      "92:\tlearn: 0.1374008\ttotal: 139ms\tremaining: 10.5ms\n",
      "93:\tlearn: 0.1369035\ttotal: 142ms\tremaining: 9.04ms\n",
      "94:\tlearn: 0.1359668\ttotal: 143ms\tremaining: 7.53ms\n",
      "95:\tlearn: 0.1355131\ttotal: 145ms\tremaining: 6.03ms\n",
      "96:\tlearn: 0.1347682\ttotal: 146ms\tremaining: 4.52ms\n",
      "97:\tlearn: 0.1338295\ttotal: 148ms\tremaining: 3.02ms\n",
      "98:\tlearn: 0.1329964\ttotal: 150ms\tremaining: 1.51ms\n",
      "99:\tlearn: 0.1322092\ttotal: 151ms\tremaining: 0us\n",
      "0:\tlearn: 0.6589788\ttotal: 1.68ms\tremaining: 167ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\tlearn: 0.6297143\ttotal: 3.38ms\tremaining: 166ms\n",
      "2:\tlearn: 0.6025131\ttotal: 4.83ms\tremaining: 156ms\n",
      "3:\tlearn: 0.5772017\ttotal: 6.07ms\tremaining: 146ms\n",
      "4:\tlearn: 0.5528612\ttotal: 7.33ms\tremaining: 139ms\n",
      "5:\tlearn: 0.5309049\ttotal: 8.6ms\tremaining: 135ms\n",
      "6:\tlearn: 0.5114453\ttotal: 9.84ms\tremaining: 131ms\n",
      "7:\tlearn: 0.4914240\ttotal: 11.4ms\tremaining: 131ms\n",
      "8:\tlearn: 0.4729109\ttotal: 12.9ms\tremaining: 131ms\n",
      "9:\tlearn: 0.4556447\ttotal: 14.4ms\tremaining: 130ms\n",
      "10:\tlearn: 0.4405670\ttotal: 15.8ms\tremaining: 128ms\n",
      "11:\tlearn: 0.4260662\ttotal: 17.4ms\tremaining: 127ms\n",
      "12:\tlearn: 0.4117383\ttotal: 18.8ms\tremaining: 126ms\n",
      "13:\tlearn: 0.3997523\ttotal: 20.2ms\tremaining: 124ms\n",
      "14:\tlearn: 0.3877191\ttotal: 21.9ms\tremaining: 124ms\n",
      "15:\tlearn: 0.3758190\ttotal: 23.4ms\tremaining: 123ms\n",
      "16:\tlearn: 0.3640183\ttotal: 24.9ms\tremaining: 121ms\n",
      "17:\tlearn: 0.3552584\ttotal: 26.3ms\tremaining: 120ms\n",
      "18:\tlearn: 0.3459111\ttotal: 27.9ms\tremaining: 119ms\n",
      "19:\tlearn: 0.3379651\ttotal: 29.4ms\tremaining: 118ms\n",
      "20:\tlearn: 0.3286315\ttotal: 30.9ms\tremaining: 116ms\n",
      "21:\tlearn: 0.3208300\ttotal: 32.4ms\tremaining: 115ms\n",
      "22:\tlearn: 0.3131541\ttotal: 33.8ms\tremaining: 113ms\n",
      "23:\tlearn: 0.3065405\ttotal: 35.4ms\tremaining: 112ms\n",
      "24:\tlearn: 0.2991723\ttotal: 36.9ms\tremaining: 111ms\n",
      "25:\tlearn: 0.2929427\ttotal: 38.5ms\tremaining: 110ms\n",
      "26:\tlearn: 0.2875549\ttotal: 40ms\tremaining: 108ms\n",
      "27:\tlearn: 0.2825849\ttotal: 41.4ms\tremaining: 106ms\n",
      "28:\tlearn: 0.2777447\ttotal: 42.8ms\tremaining: 105ms\n",
      "29:\tlearn: 0.2727072\ttotal: 44.4ms\tremaining: 104ms\n",
      "30:\tlearn: 0.2668784\ttotal: 46.2ms\tremaining: 103ms\n",
      "31:\tlearn: 0.2615723\ttotal: 47.9ms\tremaining: 102ms\n",
      "32:\tlearn: 0.2560534\ttotal: 49.3ms\tremaining: 100ms\n",
      "33:\tlearn: 0.2513423\ttotal: 50.6ms\tremaining: 98.1ms\n",
      "34:\tlearn: 0.2468927\ttotal: 52ms\tremaining: 96.5ms\n",
      "35:\tlearn: 0.2425590\ttotal: 53.3ms\tremaining: 94.8ms\n",
      "36:\tlearn: 0.2388094\ttotal: 55ms\tremaining: 93.6ms\n",
      "37:\tlearn: 0.2346421\ttotal: 56.6ms\tremaining: 92.4ms\n",
      "38:\tlearn: 0.2304808\ttotal: 58ms\tremaining: 90.8ms\n",
      "39:\tlearn: 0.2275211\ttotal: 59.5ms\tremaining: 89.3ms\n",
      "40:\tlearn: 0.2230304\ttotal: 60.8ms\tremaining: 87.5ms\n",
      "41:\tlearn: 0.2197352\ttotal: 62.3ms\tremaining: 86ms\n",
      "42:\tlearn: 0.2170198\ttotal: 63.7ms\tremaining: 84.4ms\n",
      "43:\tlearn: 0.2141606\ttotal: 65.2ms\tremaining: 83ms\n",
      "44:\tlearn: 0.2115102\ttotal: 66.7ms\tremaining: 81.5ms\n",
      "45:\tlearn: 0.2085012\ttotal: 68.2ms\tremaining: 80.1ms\n",
      "46:\tlearn: 0.2058222\ttotal: 69.8ms\tremaining: 78.7ms\n",
      "47:\tlearn: 0.2039094\ttotal: 71.2ms\tremaining: 77.2ms\n",
      "48:\tlearn: 0.2014658\ttotal: 72.8ms\tremaining: 75.8ms\n",
      "49:\tlearn: 0.1987254\ttotal: 74.2ms\tremaining: 74.2ms\n",
      "50:\tlearn: 0.1967594\ttotal: 75.9ms\tremaining: 72.9ms\n",
      "51:\tlearn: 0.1950370\ttotal: 77.4ms\tremaining: 71.4ms\n",
      "52:\tlearn: 0.1934344\ttotal: 78.9ms\tremaining: 70ms\n",
      "53:\tlearn: 0.1910813\ttotal: 80.5ms\tremaining: 68.6ms\n",
      "54:\tlearn: 0.1883967\ttotal: 82ms\tremaining: 67.1ms\n",
      "55:\tlearn: 0.1862882\ttotal: 83.4ms\tremaining: 65.6ms\n",
      "56:\tlearn: 0.1838491\ttotal: 85ms\tremaining: 64.1ms\n",
      "57:\tlearn: 0.1822495\ttotal: 86.5ms\tremaining: 62.7ms\n",
      "58:\tlearn: 0.1808011\ttotal: 88.1ms\tremaining: 61.2ms\n",
      "59:\tlearn: 0.1793676\ttotal: 89.6ms\tremaining: 59.7ms\n",
      "60:\tlearn: 0.1776440\ttotal: 91.1ms\tremaining: 58.3ms\n",
      "61:\tlearn: 0.1754213\ttotal: 92.6ms\tremaining: 56.8ms\n",
      "62:\tlearn: 0.1729238\ttotal: 94.1ms\tremaining: 55.3ms\n",
      "63:\tlearn: 0.1717571\ttotal: 95.7ms\tremaining: 53.8ms\n",
      "64:\tlearn: 0.1698973\ttotal: 97.1ms\tremaining: 52.3ms\n",
      "65:\tlearn: 0.1677613\ttotal: 98.6ms\tremaining: 50.8ms\n",
      "66:\tlearn: 0.1663315\ttotal: 100ms\tremaining: 49.3ms\n",
      "67:\tlearn: 0.1644986\ttotal: 102ms\tremaining: 47.8ms\n",
      "68:\tlearn: 0.1632012\ttotal: 103ms\tremaining: 46.3ms\n",
      "69:\tlearn: 0.1622451\ttotal: 105ms\tremaining: 44.8ms\n",
      "70:\tlearn: 0.1609342\ttotal: 106ms\tremaining: 43.3ms\n",
      "71:\tlearn: 0.1591606\ttotal: 108ms\tremaining: 41.8ms\n",
      "72:\tlearn: 0.1578310\ttotal: 109ms\tremaining: 40.3ms\n",
      "73:\tlearn: 0.1558533\ttotal: 111ms\tremaining: 38.8ms\n",
      "74:\tlearn: 0.1547870\ttotal: 112ms\tremaining: 37.4ms\n",
      "75:\tlearn: 0.1535260\ttotal: 114ms\tremaining: 35.9ms\n",
      "76:\tlearn: 0.1523728\ttotal: 115ms\tremaining: 34.4ms\n",
      "77:\tlearn: 0.1511993\ttotal: 116ms\tremaining: 32.8ms\n",
      "78:\tlearn: 0.1498903\ttotal: 118ms\tremaining: 31.4ms\n",
      "79:\tlearn: 0.1493784\ttotal: 120ms\tremaining: 29.9ms\n",
      "80:\tlearn: 0.1481847\ttotal: 121ms\tremaining: 28.4ms\n",
      "81:\tlearn: 0.1478030\ttotal: 122ms\tremaining: 26.9ms\n",
      "82:\tlearn: 0.1473553\ttotal: 124ms\tremaining: 25.4ms\n",
      "83:\tlearn: 0.1462033\ttotal: 125ms\tremaining: 23.9ms\n",
      "84:\tlearn: 0.1457067\ttotal: 127ms\tremaining: 22.4ms\n",
      "85:\tlearn: 0.1450114\ttotal: 129ms\tremaining: 20.9ms\n",
      "86:\tlearn: 0.1439282\ttotal: 130ms\tremaining: 19.4ms\n",
      "87:\tlearn: 0.1421939\ttotal: 132ms\tremaining: 18ms\n",
      "88:\tlearn: 0.1411931\ttotal: 134ms\tremaining: 16.6ms\n",
      "89:\tlearn: 0.1408022\ttotal: 136ms\tremaining: 15.1ms\n",
      "90:\tlearn: 0.1401983\ttotal: 137ms\tremaining: 13.6ms\n",
      "91:\tlearn: 0.1392509\ttotal: 139ms\tremaining: 12.1ms\n",
      "92:\tlearn: 0.1386533\ttotal: 140ms\tremaining: 10.5ms\n",
      "93:\tlearn: 0.1380164\ttotal: 142ms\tremaining: 9.04ms\n",
      "94:\tlearn: 0.1377063\ttotal: 143ms\tremaining: 7.53ms\n",
      "95:\tlearn: 0.1372512\ttotal: 145ms\tremaining: 6.03ms\n",
      "96:\tlearn: 0.1364055\ttotal: 146ms\tremaining: 4.52ms\n",
      "97:\tlearn: 0.1351365\ttotal: 148ms\tremaining: 3.01ms\n",
      "98:\tlearn: 0.1348912\ttotal: 149ms\tremaining: 1.51ms\n",
      "99:\tlearn: 0.1341242\ttotal: 151ms\tremaining: 0us\n",
      "0:\tlearn: 0.6271142\ttotal: 1.55ms\tremaining: 154ms\n",
      "1:\tlearn: 0.5751800\ttotal: 2.96ms\tremaining: 145ms\n",
      "2:\tlearn: 0.5299172\ttotal: 4.26ms\tremaining: 138ms\n",
      "3:\tlearn: 0.4877917\ttotal: 5.58ms\tremaining: 134ms\n",
      "4:\tlearn: 0.4516357\ttotal: 6.91ms\tremaining: 131ms\n",
      "5:\tlearn: 0.4223732\ttotal: 8.22ms\tremaining: 129ms\n",
      "6:\tlearn: 0.3967926\ttotal: 9.92ms\tremaining: 132ms\n",
      "7:\tlearn: 0.3745632\ttotal: 11.3ms\tremaining: 130ms\n",
      "8:\tlearn: 0.3533129\ttotal: 12.7ms\tremaining: 128ms\n",
      "9:\tlearn: 0.3358343\ttotal: 14ms\tremaining: 126ms\n",
      "10:\tlearn: 0.3206063\ttotal: 15.6ms\tremaining: 126ms\n",
      "11:\tlearn: 0.3065306\ttotal: 17.1ms\tremaining: 125ms\n",
      "12:\tlearn: 0.2942877\ttotal: 18.4ms\tremaining: 123ms\n",
      "13:\tlearn: 0.2813667\ttotal: 19.9ms\tremaining: 122ms\n",
      "14:\tlearn: 0.2681611\ttotal: 21.4ms\tremaining: 121ms\n",
      "15:\tlearn: 0.2586388\ttotal: 22.9ms\tremaining: 120ms\n",
      "16:\tlearn: 0.2491723\ttotal: 24.5ms\tremaining: 119ms\n",
      "17:\tlearn: 0.2426290\ttotal: 26ms\tremaining: 119ms\n",
      "18:\tlearn: 0.2367585\ttotal: 27.5ms\tremaining: 117ms\n",
      "19:\tlearn: 0.2276616\ttotal: 28.9ms\tremaining: 116ms\n",
      "20:\tlearn: 0.2203221\ttotal: 30.5ms\tremaining: 115ms\n",
      "21:\tlearn: 0.2141788\ttotal: 32.1ms\tremaining: 114ms\n",
      "22:\tlearn: 0.2069844\ttotal: 33.5ms\tremaining: 112ms\n",
      "23:\tlearn: 0.2034297\ttotal: 34.9ms\tremaining: 111ms\n",
      "24:\tlearn: 0.1990132\ttotal: 36.4ms\tremaining: 109ms\n",
      "25:\tlearn: 0.1945238\ttotal: 38ms\tremaining: 108ms\n",
      "26:\tlearn: 0.1915467\ttotal: 40.4ms\tremaining: 109ms\n",
      "27:\tlearn: 0.1877069\ttotal: 41.9ms\tremaining: 108ms\n",
      "28:\tlearn: 0.1826623\ttotal: 43.2ms\tremaining: 106ms\n",
      "29:\tlearn: 0.1796887\ttotal: 45ms\tremaining: 105ms\n",
      "30:\tlearn: 0.1758952\ttotal: 46.5ms\tremaining: 103ms\n",
      "31:\tlearn: 0.1719211\ttotal: 48.1ms\tremaining: 102ms\n",
      "32:\tlearn: 0.1680567\ttotal: 49.5ms\tremaining: 100ms\n",
      "33:\tlearn: 0.1649871\ttotal: 51.3ms\tremaining: 99.6ms\n",
      "34:\tlearn: 0.1612494\ttotal: 52.7ms\tremaining: 97.9ms\n",
      "35:\tlearn: 0.1579904\ttotal: 54.4ms\tremaining: 96.6ms\n",
      "36:\tlearn: 0.1558933\ttotal: 56ms\tremaining: 95.3ms\n",
      "37:\tlearn: 0.1532725\ttotal: 58.2ms\tremaining: 94.9ms\n",
      "38:\tlearn: 0.1504909\ttotal: 59.6ms\tremaining: 93.2ms\n",
      "39:\tlearn: 0.1476689\ttotal: 61.2ms\tremaining: 91.8ms\n",
      "40:\tlearn: 0.1450232\ttotal: 62.8ms\tremaining: 90.3ms\n",
      "41:\tlearn: 0.1430877\ttotal: 64.9ms\tremaining: 89.7ms\n",
      "42:\tlearn: 0.1412912\ttotal: 66.2ms\tremaining: 87.7ms\n",
      "43:\tlearn: 0.1389355\ttotal: 67.7ms\tremaining: 86.2ms\n",
      "44:\tlearn: 0.1368185\ttotal: 69.1ms\tremaining: 84.4ms\n",
      "45:\tlearn: 0.1355182\ttotal: 70.6ms\tremaining: 82.9ms\n",
      "46:\tlearn: 0.1338457\ttotal: 72.1ms\tremaining: 81.3ms\n",
      "47:\tlearn: 0.1327067\ttotal: 73.5ms\tremaining: 79.6ms\n",
      "48:\tlearn: 0.1312424\ttotal: 75.3ms\tremaining: 78.3ms\n",
      "49:\tlearn: 0.1301357\ttotal: 76.7ms\tremaining: 76.7ms\n",
      "50:\tlearn: 0.1286557\ttotal: 78.3ms\tremaining: 75.2ms\n",
      "51:\tlearn: 0.1269418\ttotal: 79.8ms\tremaining: 73.7ms\n",
      "52:\tlearn: 0.1255667\ttotal: 81.2ms\tremaining: 72ms\n",
      "53:\tlearn: 0.1243559\ttotal: 82.6ms\tremaining: 70.4ms\n",
      "54:\tlearn: 0.1239870\ttotal: 84.2ms\tremaining: 68.9ms\n",
      "55:\tlearn: 0.1226485\ttotal: 85.5ms\tremaining: 67.2ms\n",
      "56:\tlearn: 0.1212062\ttotal: 87ms\tremaining: 65.7ms\n",
      "57:\tlearn: 0.1202870\ttotal: 88.7ms\tremaining: 64.2ms\n",
      "58:\tlearn: 0.1195178\ttotal: 90.3ms\tremaining: 62.7ms\n",
      "59:\tlearn: 0.1187770\ttotal: 91.8ms\tremaining: 61.2ms\n",
      "60:\tlearn: 0.1173654\ttotal: 93.3ms\tremaining: 59.6ms\n",
      "61:\tlearn: 0.1162732\ttotal: 94.8ms\tremaining: 58.1ms\n",
      "62:\tlearn: 0.1149996\ttotal: 96.3ms\tremaining: 56.5ms\n",
      "63:\tlearn: 0.1137850\ttotal: 97.7ms\tremaining: 55ms\n",
      "64:\tlearn: 0.1127481\ttotal: 99.4ms\tremaining: 53.5ms\n",
      "65:\tlearn: 0.1117813\ttotal: 102ms\tremaining: 52.3ms\n",
      "66:\tlearn: 0.1104114\ttotal: 103ms\tremaining: 50.7ms\n",
      "67:\tlearn: 0.1097771\ttotal: 104ms\tremaining: 49.1ms\n",
      "68:\tlearn: 0.1086831\ttotal: 106ms\tremaining: 47.5ms\n",
      "69:\tlearn: 0.1081754\ttotal: 107ms\tremaining: 46ms\n",
      "70:\tlearn: 0.1065754\ttotal: 109ms\tremaining: 44.5ms\n",
      "71:\tlearn: 0.1058252\ttotal: 110ms\tremaining: 42.9ms\n",
      "72:\tlearn: 0.1049100\ttotal: 112ms\tremaining: 41.3ms\n",
      "73:\tlearn: 0.1038713\ttotal: 113ms\tremaining: 39.7ms\n",
      "74:\tlearn: 0.1030055\ttotal: 115ms\tremaining: 38.2ms\n",
      "75:\tlearn: 0.1024374\ttotal: 116ms\tremaining: 36.7ms\n",
      "76:\tlearn: 0.1015577\ttotal: 118ms\tremaining: 35.1ms\n",
      "77:\tlearn: 0.1011340\ttotal: 119ms\tremaining: 33.6ms\n",
      "78:\tlearn: 0.1002121\ttotal: 121ms\tremaining: 32.1ms\n",
      "79:\tlearn: 0.0990752\ttotal: 122ms\tremaining: 30.5ms\n",
      "80:\tlearn: 0.0982002\ttotal: 124ms\tremaining: 29ms\n",
      "81:\tlearn: 0.0975680\ttotal: 125ms\tremaining: 27.4ms\n",
      "82:\tlearn: 0.0972409\ttotal: 126ms\tremaining: 25.9ms\n",
      "83:\tlearn: 0.0963021\ttotal: 128ms\tremaining: 24.4ms\n",
      "84:\tlearn: 0.0957972\ttotal: 129ms\tremaining: 22.8ms\n",
      "85:\tlearn: 0.0951420\ttotal: 131ms\tremaining: 21.3ms\n",
      "86:\tlearn: 0.0946616\ttotal: 133ms\tremaining: 19.8ms\n",
      "87:\tlearn: 0.0940208\ttotal: 134ms\tremaining: 18.3ms\n",
      "88:\tlearn: 0.0936152\ttotal: 136ms\tremaining: 16.8ms\n",
      "89:\tlearn: 0.0932151\ttotal: 137ms\tremaining: 15.2ms\n",
      "90:\tlearn: 0.0926300\ttotal: 139ms\tremaining: 13.7ms\n",
      "91:\tlearn: 0.0923961\ttotal: 141ms\tremaining: 12.2ms\n",
      "92:\tlearn: 0.0920956\ttotal: 142ms\tremaining: 10.7ms\n",
      "93:\tlearn: 0.0914592\ttotal: 144ms\tremaining: 9.18ms\n",
      "94:\tlearn: 0.0909149\ttotal: 145ms\tremaining: 7.65ms\n",
      "95:\tlearn: 0.0899417\ttotal: 147ms\tremaining: 6.11ms\n",
      "96:\tlearn: 0.0889802\ttotal: 148ms\tremaining: 4.59ms\n",
      "97:\tlearn: 0.0880303\ttotal: 150ms\tremaining: 3.06ms\n",
      "98:\tlearn: 0.0878233\ttotal: 151ms\tremaining: 1.53ms\n",
      "99:\tlearn: 0.0869717\ttotal: 153ms\tremaining: 0us\n",
      "0:\tlearn: 0.6257481\ttotal: 1.38ms\tremaining: 136ms\n",
      "1:\tlearn: 0.5734925\ttotal: 2.77ms\tremaining: 136ms\n",
      "2:\tlearn: 0.5265748\ttotal: 4.16ms\tremaining: 135ms\n",
      "3:\tlearn: 0.4854423\ttotal: 5.53ms\tremaining: 133ms\n",
      "4:\tlearn: 0.4510446\ttotal: 7.66ms\tremaining: 146ms\n",
      "5:\tlearn: 0.4227338\ttotal: 9.18ms\tremaining: 144ms\n",
      "6:\tlearn: 0.3980758\ttotal: 10.5ms\tremaining: 139ms\n",
      "7:\tlearn: 0.3761880\ttotal: 12.1ms\tremaining: 139ms\n",
      "8:\tlearn: 0.3548240\ttotal: 13.6ms\tremaining: 138ms\n",
      "9:\tlearn: 0.3368656\ttotal: 15.2ms\tremaining: 136ms\n",
      "10:\tlearn: 0.3218865\ttotal: 16.8ms\tremaining: 136ms\n",
      "11:\tlearn: 0.3067874\ttotal: 18.2ms\tremaining: 133ms\n",
      "12:\tlearn: 0.2937084\ttotal: 19.5ms\tremaining: 131ms\n",
      "13:\tlearn: 0.2802523\ttotal: 21.5ms\tremaining: 132ms\n",
      "14:\tlearn: 0.2682218\ttotal: 22.9ms\tremaining: 130ms\n",
      "15:\tlearn: 0.2555319\ttotal: 24.3ms\tremaining: 127ms\n",
      "16:\tlearn: 0.2466641\ttotal: 25.8ms\tremaining: 126ms\n",
      "17:\tlearn: 0.2403881\ttotal: 27.5ms\tremaining: 125ms\n",
      "18:\tlearn: 0.2305797\ttotal: 28.8ms\tremaining: 123ms\n",
      "19:\tlearn: 0.2257324\ttotal: 30.4ms\tremaining: 122ms\n",
      "20:\tlearn: 0.2176943\ttotal: 32ms\tremaining: 120ms\n",
      "21:\tlearn: 0.2114638\ttotal: 33.5ms\tremaining: 119ms\n",
      "22:\tlearn: 0.2065547\ttotal: 35ms\tremaining: 117ms\n",
      "23:\tlearn: 0.2036422\ttotal: 36.3ms\tremaining: 115ms\n",
      "24:\tlearn: 0.1989717\ttotal: 37.7ms\tremaining: 113ms\n",
      "25:\tlearn: 0.1949551\ttotal: 39.2ms\tremaining: 112ms\n",
      "26:\tlearn: 0.1911894\ttotal: 40.6ms\tremaining: 110ms\n",
      "27:\tlearn: 0.1884051\ttotal: 42.1ms\tremaining: 108ms\n",
      "28:\tlearn: 0.1847674\ttotal: 43.6ms\tremaining: 107ms\n",
      "29:\tlearn: 0.1802244\ttotal: 45ms\tremaining: 105ms\n",
      "30:\tlearn: 0.1763076\ttotal: 46.6ms\tremaining: 104ms\n",
      "31:\tlearn: 0.1727682\ttotal: 48.2ms\tremaining: 102ms\n",
      "32:\tlearn: 0.1693651\ttotal: 49.7ms\tremaining: 101ms\n",
      "33:\tlearn: 0.1661636\ttotal: 51.2ms\tremaining: 99.4ms\n",
      "34:\tlearn: 0.1634968\ttotal: 52.8ms\tremaining: 98ms\n",
      "35:\tlearn: 0.1604365\ttotal: 54.3ms\tremaining: 96.5ms\n",
      "36:\tlearn: 0.1577175\ttotal: 55.9ms\tremaining: 95.1ms\n",
      "37:\tlearn: 0.1553138\ttotal: 57.3ms\tremaining: 93.5ms\n",
      "38:\tlearn: 0.1519979\ttotal: 58.7ms\tremaining: 91.8ms\n",
      "39:\tlearn: 0.1497945\ttotal: 60.1ms\tremaining: 90.2ms\n",
      "40:\tlearn: 0.1468118\ttotal: 62.2ms\tremaining: 89.5ms\n",
      "41:\tlearn: 0.1447341\ttotal: 63.7ms\tremaining: 88ms\n",
      "42:\tlearn: 0.1427129\ttotal: 65.2ms\tremaining: 86.4ms\n",
      "43:\tlearn: 0.1408133\ttotal: 66.4ms\tremaining: 84.6ms\n",
      "44:\tlearn: 0.1395334\ttotal: 68ms\tremaining: 83.1ms\n",
      "45:\tlearn: 0.1377172\ttotal: 69.4ms\tremaining: 81.5ms\n",
      "46:\tlearn: 0.1359064\ttotal: 70.9ms\tremaining: 79.9ms\n",
      "47:\tlearn: 0.1348858\ttotal: 72.5ms\tremaining: 78.5ms\n",
      "48:\tlearn: 0.1333230\ttotal: 73.9ms\tremaining: 77ms\n",
      "49:\tlearn: 0.1324951\ttotal: 75.5ms\tremaining: 75.5ms\n",
      "50:\tlearn: 0.1307728\ttotal: 77ms\tremaining: 74ms\n",
      "51:\tlearn: 0.1290127\ttotal: 78.4ms\tremaining: 72.3ms\n",
      "52:\tlearn: 0.1275786\ttotal: 79.9ms\tremaining: 70.8ms\n",
      "53:\tlearn: 0.1263221\ttotal: 81.5ms\tremaining: 69.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54:\tlearn: 0.1249609\ttotal: 83.2ms\tremaining: 68.1ms\n",
      "55:\tlearn: 0.1238390\ttotal: 84.7ms\tremaining: 66.6ms\n",
      "56:\tlearn: 0.1220207\ttotal: 86.2ms\tremaining: 65.1ms\n",
      "57:\tlearn: 0.1212601\ttotal: 87.7ms\tremaining: 63.5ms\n",
      "58:\tlearn: 0.1206341\ttotal: 89.1ms\tremaining: 61.9ms\n",
      "59:\tlearn: 0.1197868\ttotal: 90.5ms\tremaining: 60.4ms\n",
      "60:\tlearn: 0.1184941\ttotal: 91.9ms\tremaining: 58.7ms\n",
      "61:\tlearn: 0.1173968\ttotal: 93.4ms\tremaining: 57.2ms\n",
      "62:\tlearn: 0.1162142\ttotal: 100ms\tremaining: 58.8ms\n",
      "63:\tlearn: 0.1153604\ttotal: 103ms\tremaining: 57.7ms\n",
      "64:\tlearn: 0.1144395\ttotal: 104ms\tremaining: 56.2ms\n",
      "65:\tlearn: 0.1132013\ttotal: 106ms\tremaining: 54.5ms\n",
      "66:\tlearn: 0.1116311\ttotal: 108ms\tremaining: 53ms\n",
      "67:\tlearn: 0.1110080\ttotal: 109ms\tremaining: 51.3ms\n",
      "68:\tlearn: 0.1101243\ttotal: 110ms\tremaining: 49.6ms\n",
      "69:\tlearn: 0.1091576\ttotal: 112ms\tremaining: 47.9ms\n",
      "70:\tlearn: 0.1083550\ttotal: 113ms\tremaining: 46.3ms\n",
      "71:\tlearn: 0.1077576\ttotal: 116ms\tremaining: 45ms\n",
      "72:\tlearn: 0.1074401\ttotal: 117ms\tremaining: 43.4ms\n",
      "73:\tlearn: 0.1064293\ttotal: 119ms\tremaining: 41.8ms\n",
      "74:\tlearn: 0.1057359\ttotal: 120ms\tremaining: 40.1ms\n",
      "75:\tlearn: 0.1050062\ttotal: 122ms\tremaining: 38.5ms\n",
      "76:\tlearn: 0.1040188\ttotal: 124ms\tremaining: 37ms\n",
      "77:\tlearn: 0.1033405\ttotal: 125ms\tremaining: 35.3ms\n",
      "78:\tlearn: 0.1025023\ttotal: 127ms\tremaining: 33.7ms\n",
      "79:\tlearn: 0.1013281\ttotal: 128ms\tremaining: 32.1ms\n",
      "80:\tlearn: 0.1005905\ttotal: 130ms\tremaining: 30.4ms\n",
      "81:\tlearn: 0.0996933\ttotal: 131ms\tremaining: 28.8ms\n",
      "82:\tlearn: 0.0989979\ttotal: 133ms\tremaining: 27.2ms\n",
      "83:\tlearn: 0.0981237\ttotal: 134ms\tremaining: 25.5ms\n",
      "84:\tlearn: 0.0977291\ttotal: 135ms\tremaining: 23.9ms\n",
      "85:\tlearn: 0.0973649\ttotal: 137ms\tremaining: 22.3ms\n",
      "86:\tlearn: 0.0966386\ttotal: 138ms\tremaining: 20.6ms\n",
      "87:\tlearn: 0.0955903\ttotal: 140ms\tremaining: 19ms\n",
      "88:\tlearn: 0.0953524\ttotal: 141ms\tremaining: 17.5ms\n",
      "89:\tlearn: 0.0950895\ttotal: 143ms\tremaining: 15.9ms\n",
      "90:\tlearn: 0.0943194\ttotal: 144ms\tremaining: 14.3ms\n",
      "91:\tlearn: 0.0936655\ttotal: 146ms\tremaining: 12.7ms\n",
      "92:\tlearn: 0.0934570\ttotal: 147ms\tremaining: 11.1ms\n",
      "93:\tlearn: 0.0931171\ttotal: 149ms\tremaining: 9.48ms\n",
      "94:\tlearn: 0.0923584\ttotal: 150ms\tremaining: 7.91ms\n",
      "95:\tlearn: 0.0920917\ttotal: 152ms\tremaining: 6.32ms\n",
      "96:\tlearn: 0.0919239\ttotal: 153ms\tremaining: 4.73ms\n",
      "97:\tlearn: 0.0911844\ttotal: 155ms\tremaining: 3.16ms\n",
      "98:\tlearn: 0.0907557\ttotal: 156ms\tremaining: 1.58ms\n",
      "99:\tlearn: 0.0904447\ttotal: 158ms\tremaining: 0us\n",
      "0:\tlearn: 0.6264980\ttotal: 1.47ms\tremaining: 146ms\n",
      "1:\tlearn: 0.5743024\ttotal: 2.92ms\tremaining: 143ms\n",
      "2:\tlearn: 0.5304018\ttotal: 4.31ms\tremaining: 139ms\n",
      "3:\tlearn: 0.4912614\ttotal: 5.56ms\tremaining: 133ms\n",
      "4:\tlearn: 0.4542183\ttotal: 7.05ms\tremaining: 134ms\n",
      "5:\tlearn: 0.4243671\ttotal: 8.24ms\tremaining: 129ms\n",
      "6:\tlearn: 0.3998771\ttotal: 9.42ms\tremaining: 125ms\n",
      "7:\tlearn: 0.3758945\ttotal: 10.7ms\tremaining: 124ms\n",
      "8:\tlearn: 0.3547554\ttotal: 12.1ms\tremaining: 122ms\n",
      "9:\tlearn: 0.3371613\ttotal: 14.5ms\tremaining: 130ms\n",
      "10:\tlearn: 0.3216798\ttotal: 16ms\tremaining: 130ms\n",
      "11:\tlearn: 0.3066371\ttotal: 17.5ms\tremaining: 129ms\n",
      "12:\tlearn: 0.2925347\ttotal: 19ms\tremaining: 127ms\n",
      "13:\tlearn: 0.2794793\ttotal: 20.4ms\tremaining: 126ms\n",
      "14:\tlearn: 0.2673530\ttotal: 22ms\tremaining: 124ms\n",
      "15:\tlearn: 0.2585320\ttotal: 23.5ms\tremaining: 124ms\n",
      "16:\tlearn: 0.2493630\ttotal: 25ms\tremaining: 122ms\n",
      "17:\tlearn: 0.2412497\ttotal: 26.4ms\tremaining: 120ms\n",
      "18:\tlearn: 0.2327163\ttotal: 28.1ms\tremaining: 120ms\n",
      "19:\tlearn: 0.2279441\ttotal: 30.2ms\tremaining: 121ms\n",
      "20:\tlearn: 0.2197251\ttotal: 31.9ms\tremaining: 120ms\n",
      "21:\tlearn: 0.2138410\ttotal: 33.3ms\tremaining: 118ms\n",
      "22:\tlearn: 0.2077370\ttotal: 34.8ms\tremaining: 117ms\n",
      "23:\tlearn: 0.2035563\ttotal: 36.2ms\tremaining: 115ms\n",
      "24:\tlearn: 0.1973498\ttotal: 38.1ms\tremaining: 114ms\n",
      "25:\tlearn: 0.1929801\ttotal: 39.6ms\tremaining: 113ms\n",
      "26:\tlearn: 0.1885453\ttotal: 41.1ms\tremaining: 111ms\n",
      "27:\tlearn: 0.1848008\ttotal: 42.6ms\tremaining: 110ms\n",
      "28:\tlearn: 0.1828793\ttotal: 44.1ms\tremaining: 108ms\n",
      "29:\tlearn: 0.1792463\ttotal: 45.6ms\tremaining: 106ms\n",
      "30:\tlearn: 0.1751591\ttotal: 47.1ms\tremaining: 105ms\n",
      "31:\tlearn: 0.1714532\ttotal: 48.4ms\tremaining: 103ms\n",
      "32:\tlearn: 0.1694882\ttotal: 50ms\tremaining: 102ms\n",
      "33:\tlearn: 0.1665980\ttotal: 51.5ms\tremaining: 100ms\n",
      "34:\tlearn: 0.1620929\ttotal: 53ms\tremaining: 98.4ms\n",
      "35:\tlearn: 0.1596592\ttotal: 54.6ms\tremaining: 97.1ms\n",
      "36:\tlearn: 0.1575020\ttotal: 56.9ms\tremaining: 96.8ms\n",
      "37:\tlearn: 0.1540580\ttotal: 58.3ms\tremaining: 95.1ms\n",
      "38:\tlearn: 0.1517195\ttotal: 59.7ms\tremaining: 93.4ms\n",
      "39:\tlearn: 0.1498830\ttotal: 61.1ms\tremaining: 91.7ms\n",
      "40:\tlearn: 0.1474374\ttotal: 62.8ms\tremaining: 90.3ms\n",
      "41:\tlearn: 0.1458211\ttotal: 64.2ms\tremaining: 88.6ms\n",
      "42:\tlearn: 0.1444151\ttotal: 65.6ms\tremaining: 87ms\n",
      "43:\tlearn: 0.1426938\ttotal: 67ms\tremaining: 85.3ms\n",
      "44:\tlearn: 0.1410136\ttotal: 68.5ms\tremaining: 83.7ms\n",
      "45:\tlearn: 0.1394431\ttotal: 70ms\tremaining: 82.1ms\n",
      "46:\tlearn: 0.1376097\ttotal: 71.5ms\tremaining: 80.6ms\n",
      "47:\tlearn: 0.1366843\ttotal: 72.9ms\tremaining: 79ms\n",
      "48:\tlearn: 0.1350401\ttotal: 74.4ms\tremaining: 77.4ms\n",
      "49:\tlearn: 0.1329801\ttotal: 75.8ms\tremaining: 75.8ms\n",
      "50:\tlearn: 0.1315285\ttotal: 77.4ms\tremaining: 74.4ms\n",
      "51:\tlearn: 0.1302728\ttotal: 79.1ms\tremaining: 73ms\n",
      "52:\tlearn: 0.1290086\ttotal: 80.7ms\tremaining: 71.6ms\n",
      "53:\tlearn: 0.1275564\ttotal: 82.2ms\tremaining: 70ms\n",
      "54:\tlearn: 0.1260601\ttotal: 83.7ms\tremaining: 68.4ms\n",
      "55:\tlearn: 0.1247933\ttotal: 85.2ms\tremaining: 66.9ms\n",
      "56:\tlearn: 0.1234415\ttotal: 86.6ms\tremaining: 65.3ms\n",
      "57:\tlearn: 0.1224112\ttotal: 88.1ms\tremaining: 63.8ms\n",
      "58:\tlearn: 0.1218273\ttotal: 89.5ms\tremaining: 62.2ms\n",
      "59:\tlearn: 0.1209710\ttotal: 90.9ms\tremaining: 60.6ms\n",
      "60:\tlearn: 0.1198055\ttotal: 92.6ms\tremaining: 59.2ms\n",
      "61:\tlearn: 0.1180432\ttotal: 94ms\tremaining: 57.6ms\n",
      "62:\tlearn: 0.1168980\ttotal: 95.4ms\tremaining: 56.1ms\n",
      "63:\tlearn: 0.1160155\ttotal: 96.8ms\tremaining: 54.5ms\n",
      "64:\tlearn: 0.1147434\ttotal: 98.4ms\tremaining: 53ms\n",
      "65:\tlearn: 0.1137032\ttotal: 99.9ms\tremaining: 51.5ms\n",
      "66:\tlearn: 0.1120154\ttotal: 101ms\tremaining: 50ms\n",
      "67:\tlearn: 0.1114169\ttotal: 103ms\tremaining: 48.5ms\n",
      "68:\tlearn: 0.1110686\ttotal: 104ms\tremaining: 46.9ms\n",
      "69:\tlearn: 0.1103818\ttotal: 106ms\tremaining: 45.3ms\n",
      "70:\tlearn: 0.1092194\ttotal: 107ms\tremaining: 43.7ms\n",
      "71:\tlearn: 0.1080379\ttotal: 109ms\tremaining: 42.2ms\n",
      "72:\tlearn: 0.1071883\ttotal: 110ms\tremaining: 40.8ms\n",
      "73:\tlearn: 0.1061923\ttotal: 112ms\tremaining: 39.3ms\n",
      "74:\tlearn: 0.1055538\ttotal: 113ms\tremaining: 37.8ms\n",
      "75:\tlearn: 0.1053326\ttotal: 115ms\tremaining: 36.3ms\n",
      "76:\tlearn: 0.1045825\ttotal: 116ms\tremaining: 34.8ms\n",
      "77:\tlearn: 0.1030369\ttotal: 119ms\tremaining: 33.5ms\n",
      "78:\tlearn: 0.1020053\ttotal: 120ms\tremaining: 31.9ms\n",
      "79:\tlearn: 0.1012971\ttotal: 122ms\tremaining: 30.4ms\n",
      "80:\tlearn: 0.1009091\ttotal: 123ms\tremaining: 28.8ms\n",
      "81:\tlearn: 0.1002462\ttotal: 124ms\tremaining: 27.3ms\n",
      "82:\tlearn: 0.0992805\ttotal: 126ms\tremaining: 25.8ms\n",
      "83:\tlearn: 0.0986109\ttotal: 127ms\tremaining: 24.3ms\n",
      "84:\tlearn: 0.0982407\ttotal: 129ms\tremaining: 22.7ms\n",
      "85:\tlearn: 0.0974236\ttotal: 130ms\tremaining: 21.2ms\n",
      "86:\tlearn: 0.0970357\ttotal: 132ms\tremaining: 19.7ms\n",
      "87:\tlearn: 0.0962057\ttotal: 133ms\tremaining: 18.2ms\n",
      "88:\tlearn: 0.0958744\ttotal: 135ms\tremaining: 16.6ms\n",
      "89:\tlearn: 0.0955219\ttotal: 136ms\tremaining: 15.1ms\n",
      "90:\tlearn: 0.0950559\ttotal: 138ms\tremaining: 13.6ms\n",
      "91:\tlearn: 0.0947280\ttotal: 139ms\tremaining: 12.1ms\n",
      "92:\tlearn: 0.0944033\ttotal: 140ms\tremaining: 10.6ms\n",
      "93:\tlearn: 0.0942027\ttotal: 142ms\tremaining: 9.05ms\n",
      "94:\tlearn: 0.0937959\ttotal: 143ms\tremaining: 7.55ms\n",
      "95:\tlearn: 0.0931717\ttotal: 145ms\tremaining: 6.03ms\n",
      "96:\tlearn: 0.0927090\ttotal: 146ms\tremaining: 4.53ms\n",
      "97:\tlearn: 0.0920989\ttotal: 148ms\tremaining: 3.02ms\n",
      "98:\tlearn: 0.0917506\ttotal: 149ms\tremaining: 1.51ms\n",
      "99:\tlearn: 0.0910112\ttotal: 151ms\tremaining: 0us\n",
      "0:\tlearn: 0.6789518\ttotal: 3.16ms\tremaining: 629ms\n",
      "1:\tlearn: 0.6670285\ttotal: 6.48ms\tremaining: 642ms\n",
      "2:\tlearn: 0.6533137\ttotal: 9.76ms\tremaining: 641ms\n",
      "3:\tlearn: 0.6396220\ttotal: 13.8ms\tremaining: 674ms\n",
      "4:\tlearn: 0.6254746\ttotal: 17.5ms\tremaining: 681ms\n",
      "5:\tlearn: 0.6144270\ttotal: 21.5ms\tremaining: 695ms\n",
      "6:\tlearn: 0.6042494\ttotal: 25ms\tremaining: 689ms\n",
      "7:\tlearn: 0.5912920\ttotal: 28.4ms\tremaining: 681ms\n",
      "8:\tlearn: 0.5817386\ttotal: 31.7ms\tremaining: 673ms\n",
      "9:\tlearn: 0.5719080\ttotal: 35.7ms\tremaining: 678ms\n",
      "10:\tlearn: 0.5610016\ttotal: 38.9ms\tremaining: 669ms\n",
      "11:\tlearn: 0.5509429\ttotal: 43.2ms\tremaining: 677ms\n",
      "12:\tlearn: 0.5412665\ttotal: 46.7ms\tremaining: 672ms\n",
      "13:\tlearn: 0.5319315\ttotal: 49.8ms\tremaining: 662ms\n",
      "14:\tlearn: 0.5233063\ttotal: 53.6ms\tremaining: 662ms\n",
      "15:\tlearn: 0.5164080\ttotal: 56.4ms\tremaining: 648ms\n",
      "16:\tlearn: 0.5079142\ttotal: 59.8ms\tremaining: 644ms\n",
      "17:\tlearn: 0.4996210\ttotal: 63.2ms\tremaining: 639ms\n",
      "18:\tlearn: 0.4917776\ttotal: 67.4ms\tremaining: 642ms\n",
      "19:\tlearn: 0.4843881\ttotal: 71.1ms\tremaining: 640ms\n",
      "20:\tlearn: 0.4773925\ttotal: 74.4ms\tremaining: 635ms\n",
      "21:\tlearn: 0.4702145\ttotal: 77.8ms\tremaining: 629ms\n",
      "22:\tlearn: 0.4644370\ttotal: 80.2ms\tremaining: 617ms\n",
      "23:\tlearn: 0.4579948\ttotal: 83.6ms\tremaining: 613ms\n",
      "24:\tlearn: 0.4517501\ttotal: 87.2ms\tremaining: 611ms\n",
      "25:\tlearn: 0.4444222\ttotal: 90.5ms\tremaining: 606ms\n",
      "26:\tlearn: 0.4392799\ttotal: 94.1ms\tremaining: 603ms\n",
      "27:\tlearn: 0.4335719\ttotal: 97.7ms\tremaining: 600ms\n",
      "28:\tlearn: 0.4285245\ttotal: 102ms\tremaining: 600ms\n",
      "29:\tlearn: 0.4221669\ttotal: 105ms\tremaining: 596ms\n",
      "30:\tlearn: 0.4158560\ttotal: 109ms\tremaining: 592ms\n",
      "31:\tlearn: 0.4099678\ttotal: 112ms\tremaining: 588ms\n",
      "32:\tlearn: 0.4051254\ttotal: 115ms\tremaining: 582ms\n",
      "33:\tlearn: 0.3992289\ttotal: 119ms\tremaining: 579ms\n",
      "34:\tlearn: 0.3941149\ttotal: 122ms\tremaining: 575ms\n",
      "35:\tlearn: 0.3873660\ttotal: 125ms\tremaining: 571ms\n",
      "36:\tlearn: 0.3821792\ttotal: 129ms\tremaining: 568ms\n",
      "37:\tlearn: 0.3768389\ttotal: 133ms\tremaining: 565ms\n",
      "38:\tlearn: 0.3719376\ttotal: 136ms\tremaining: 563ms\n",
      "39:\tlearn: 0.3658578\ttotal: 140ms\tremaining: 560ms\n",
      "40:\tlearn: 0.3615909\ttotal: 144ms\tremaining: 557ms\n",
      "41:\tlearn: 0.3579715\ttotal: 147ms\tremaining: 553ms\n",
      "42:\tlearn: 0.3538418\ttotal: 150ms\tremaining: 548ms\n",
      "43:\tlearn: 0.3482957\ttotal: 154ms\tremaining: 544ms\n",
      "44:\tlearn: 0.3443145\ttotal: 157ms\tremaining: 541ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45:\tlearn: 0.3412739\ttotal: 161ms\tremaining: 538ms\n",
      "46:\tlearn: 0.3377184\ttotal: 164ms\tremaining: 535ms\n",
      "47:\tlearn: 0.3344860\ttotal: 168ms\tremaining: 532ms\n",
      "48:\tlearn: 0.3310263\ttotal: 171ms\tremaining: 528ms\n",
      "49:\tlearn: 0.3272307\ttotal: 175ms\tremaining: 524ms\n",
      "50:\tlearn: 0.3226634\ttotal: 178ms\tremaining: 520ms\n",
      "51:\tlearn: 0.3197516\ttotal: 182ms\tremaining: 517ms\n",
      "52:\tlearn: 0.3170968\ttotal: 185ms\tremaining: 513ms\n",
      "53:\tlearn: 0.3132773\ttotal: 188ms\tremaining: 510ms\n",
      "54:\tlearn: 0.3105721\ttotal: 193ms\tremaining: 508ms\n",
      "55:\tlearn: 0.3076867\ttotal: 196ms\tremaining: 504ms\n",
      "56:\tlearn: 0.3048352\ttotal: 199ms\tremaining: 500ms\n",
      "57:\tlearn: 0.3015737\ttotal: 203ms\tremaining: 498ms\n",
      "58:\tlearn: 0.2980927\ttotal: 207ms\tremaining: 494ms\n",
      "59:\tlearn: 0.2947155\ttotal: 211ms\tremaining: 491ms\n",
      "60:\tlearn: 0.2930171\ttotal: 214ms\tremaining: 488ms\n",
      "61:\tlearn: 0.2897196\ttotal: 218ms\tremaining: 484ms\n",
      "62:\tlearn: 0.2878513\ttotal: 221ms\tremaining: 480ms\n",
      "63:\tlearn: 0.2860122\ttotal: 224ms\tremaining: 477ms\n",
      "64:\tlearn: 0.2839339\ttotal: 228ms\tremaining: 473ms\n",
      "65:\tlearn: 0.2805684\ttotal: 231ms\tremaining: 469ms\n",
      "66:\tlearn: 0.2785406\ttotal: 235ms\tremaining: 466ms\n",
      "67:\tlearn: 0.2759002\ttotal: 238ms\tremaining: 463ms\n",
      "68:\tlearn: 0.2754240\ttotal: 240ms\tremaining: 456ms\n",
      "69:\tlearn: 0.2734813\ttotal: 243ms\tremaining: 452ms\n",
      "70:\tlearn: 0.2716804\ttotal: 248ms\tremaining: 450ms\n",
      "71:\tlearn: 0.2694490\ttotal: 251ms\tremaining: 447ms\n",
      "72:\tlearn: 0.2679474\ttotal: 255ms\tremaining: 444ms\n",
      "73:\tlearn: 0.2662209\ttotal: 259ms\tremaining: 440ms\n",
      "74:\tlearn: 0.2646871\ttotal: 262ms\tremaining: 436ms\n",
      "75:\tlearn: 0.2616475\ttotal: 265ms\tremaining: 433ms\n",
      "76:\tlearn: 0.2596475\ttotal: 269ms\tremaining: 429ms\n",
      "77:\tlearn: 0.2578769\ttotal: 272ms\tremaining: 426ms\n",
      "78:\tlearn: 0.2561898\ttotal: 275ms\tremaining: 422ms\n",
      "79:\tlearn: 0.2544242\ttotal: 279ms\tremaining: 418ms\n",
      "80:\tlearn: 0.2521646\ttotal: 282ms\tremaining: 415ms\n",
      "81:\tlearn: 0.2497360\ttotal: 286ms\tremaining: 412ms\n",
      "82:\tlearn: 0.2482108\ttotal: 289ms\tremaining: 408ms\n",
      "83:\tlearn: 0.2468288\ttotal: 293ms\tremaining: 405ms\n",
      "84:\tlearn: 0.2455811\ttotal: 297ms\tremaining: 401ms\n",
      "85:\tlearn: 0.2445527\ttotal: 300ms\tremaining: 398ms\n",
      "86:\tlearn: 0.2425029\ttotal: 304ms\tremaining: 394ms\n",
      "87:\tlearn: 0.2411328\ttotal: 307ms\tremaining: 391ms\n",
      "88:\tlearn: 0.2395611\ttotal: 311ms\tremaining: 387ms\n",
      "89:\tlearn: 0.2374430\ttotal: 314ms\tremaining: 384ms\n",
      "90:\tlearn: 0.2358488\ttotal: 318ms\tremaining: 380ms\n",
      "91:\tlearn: 0.2345330\ttotal: 321ms\tremaining: 377ms\n",
      "92:\tlearn: 0.2326822\ttotal: 325ms\tremaining: 373ms\n",
      "93:\tlearn: 0.2306726\ttotal: 328ms\tremaining: 370ms\n",
      "94:\tlearn: 0.2299967\ttotal: 332ms\tremaining: 367ms\n",
      "95:\tlearn: 0.2288985\ttotal: 337ms\tremaining: 365ms\n",
      "96:\tlearn: 0.2280294\ttotal: 340ms\tremaining: 361ms\n",
      "97:\tlearn: 0.2265722\ttotal: 344ms\tremaining: 358ms\n",
      "98:\tlearn: 0.2248552\ttotal: 347ms\tremaining: 354ms\n",
      "99:\tlearn: 0.2238302\ttotal: 351ms\tremaining: 351ms\n",
      "100:\tlearn: 0.2228659\ttotal: 355ms\tremaining: 348ms\n",
      "101:\tlearn: 0.2219987\ttotal: 359ms\tremaining: 345ms\n",
      "102:\tlearn: 0.2211051\ttotal: 362ms\tremaining: 341ms\n",
      "103:\tlearn: 0.2202906\ttotal: 366ms\tremaining: 338ms\n",
      "104:\tlearn: 0.2189922\ttotal: 369ms\tremaining: 334ms\n",
      "105:\tlearn: 0.2175018\ttotal: 373ms\tremaining: 330ms\n",
      "106:\tlearn: 0.2165306\ttotal: 376ms\tremaining: 327ms\n",
      "107:\tlearn: 0.2156891\ttotal: 379ms\tremaining: 323ms\n",
      "108:\tlearn: 0.2147764\ttotal: 383ms\tremaining: 319ms\n",
      "109:\tlearn: 0.2138431\ttotal: 386ms\tremaining: 316ms\n",
      "110:\tlearn: 0.2129276\ttotal: 389ms\tremaining: 312ms\n",
      "111:\tlearn: 0.2119915\ttotal: 393ms\tremaining: 308ms\n",
      "112:\tlearn: 0.2105464\ttotal: 396ms\tremaining: 305ms\n",
      "113:\tlearn: 0.2096330\ttotal: 400ms\tremaining: 302ms\n",
      "114:\tlearn: 0.2085619\ttotal: 403ms\tremaining: 298ms\n",
      "115:\tlearn: 0.2076172\ttotal: 407ms\tremaining: 295ms\n",
      "116:\tlearn: 0.2073526\ttotal: 410ms\tremaining: 291ms\n",
      "117:\tlearn: 0.2065700\ttotal: 414ms\tremaining: 288ms\n",
      "118:\tlearn: 0.2053210\ttotal: 418ms\tremaining: 285ms\n",
      "119:\tlearn: 0.2044389\ttotal: 422ms\tremaining: 281ms\n",
      "120:\tlearn: 0.2036695\ttotal: 425ms\tremaining: 278ms\n",
      "121:\tlearn: 0.2029033\ttotal: 429ms\tremaining: 274ms\n",
      "122:\tlearn: 0.2021955\ttotal: 432ms\tremaining: 271ms\n",
      "123:\tlearn: 0.2009902\ttotal: 436ms\tremaining: 267ms\n",
      "124:\tlearn: 0.2002115\ttotal: 440ms\tremaining: 264ms\n",
      "125:\tlearn: 0.1994149\ttotal: 443ms\tremaining: 260ms\n",
      "126:\tlearn: 0.1978452\ttotal: 447ms\tremaining: 257ms\n",
      "127:\tlearn: 0.1971314\ttotal: 451ms\tremaining: 254ms\n",
      "128:\tlearn: 0.1962924\ttotal: 454ms\tremaining: 250ms\n",
      "129:\tlearn: 0.1957510\ttotal: 459ms\tremaining: 247ms\n",
      "130:\tlearn: 0.1949494\ttotal: 463ms\tremaining: 244ms\n",
      "131:\tlearn: 0.1944504\ttotal: 467ms\tremaining: 241ms\n",
      "132:\tlearn: 0.1930674\ttotal: 470ms\tremaining: 237ms\n",
      "133:\tlearn: 0.1924419\ttotal: 474ms\tremaining: 233ms\n",
      "134:\tlearn: 0.1915517\ttotal: 477ms\tremaining: 230ms\n",
      "135:\tlearn: 0.1905503\ttotal: 481ms\tremaining: 226ms\n",
      "136:\tlearn: 0.1896542\ttotal: 484ms\tremaining: 223ms\n",
      "137:\tlearn: 0.1888734\ttotal: 488ms\tremaining: 219ms\n",
      "138:\tlearn: 0.1883561\ttotal: 491ms\tremaining: 216ms\n",
      "139:\tlearn: 0.1873868\ttotal: 494ms\tremaining: 212ms\n",
      "140:\tlearn: 0.1866450\ttotal: 498ms\tremaining: 208ms\n",
      "141:\tlearn: 0.1859119\ttotal: 501ms\tremaining: 205ms\n",
      "142:\tlearn: 0.1849543\ttotal: 505ms\tremaining: 201ms\n",
      "143:\tlearn: 0.1837539\ttotal: 509ms\tremaining: 198ms\n",
      "144:\tlearn: 0.1832433\ttotal: 512ms\tremaining: 194ms\n",
      "145:\tlearn: 0.1821515\ttotal: 515ms\tremaining: 191ms\n",
      "146:\tlearn: 0.1814712\ttotal: 519ms\tremaining: 187ms\n",
      "147:\tlearn: 0.1808062\ttotal: 523ms\tremaining: 184ms\n",
      "148:\tlearn: 0.1802421\ttotal: 526ms\tremaining: 180ms\n",
      "149:\tlearn: 0.1796285\ttotal: 530ms\tremaining: 177ms\n",
      "150:\tlearn: 0.1785290\ttotal: 533ms\tremaining: 173ms\n",
      "151:\tlearn: 0.1775954\ttotal: 537ms\tremaining: 169ms\n",
      "152:\tlearn: 0.1768503\ttotal: 540ms\tremaining: 166ms\n",
      "153:\tlearn: 0.1760329\ttotal: 544ms\tremaining: 162ms\n",
      "154:\tlearn: 0.1754942\ttotal: 548ms\tremaining: 159ms\n",
      "155:\tlearn: 0.1750794\ttotal: 551ms\tremaining: 155ms\n",
      "156:\tlearn: 0.1740781\ttotal: 554ms\tremaining: 152ms\n",
      "157:\tlearn: 0.1734738\ttotal: 558ms\tremaining: 148ms\n",
      "158:\tlearn: 0.1727832\ttotal: 561ms\tremaining: 145ms\n",
      "159:\tlearn: 0.1724551\ttotal: 565ms\tremaining: 141ms\n",
      "160:\tlearn: 0.1715099\ttotal: 568ms\tremaining: 138ms\n",
      "161:\tlearn: 0.1708834\ttotal: 572ms\tremaining: 134ms\n",
      "162:\tlearn: 0.1703037\ttotal: 575ms\tremaining: 131ms\n",
      "163:\tlearn: 0.1699061\ttotal: 579ms\tremaining: 127ms\n",
      "164:\tlearn: 0.1692888\ttotal: 582ms\tremaining: 124ms\n",
      "165:\tlearn: 0.1687798\ttotal: 586ms\tremaining: 120ms\n",
      "166:\tlearn: 0.1683847\ttotal: 589ms\tremaining: 116ms\n",
      "167:\tlearn: 0.1680296\ttotal: 593ms\tremaining: 113ms\n",
      "168:\tlearn: 0.1675669\ttotal: 597ms\tremaining: 109ms\n",
      "169:\tlearn: 0.1671052\ttotal: 600ms\tremaining: 106ms\n",
      "170:\tlearn: 0.1667544\ttotal: 604ms\tremaining: 102ms\n",
      "171:\tlearn: 0.1663536\ttotal: 607ms\tremaining: 98.9ms\n",
      "172:\tlearn: 0.1658431\ttotal: 611ms\tremaining: 95.4ms\n",
      "173:\tlearn: 0.1652502\ttotal: 615ms\tremaining: 91.9ms\n",
      "174:\tlearn: 0.1647375\ttotal: 618ms\tremaining: 88.3ms\n",
      "175:\tlearn: 0.1641658\ttotal: 622ms\tremaining: 84.8ms\n",
      "176:\tlearn: 0.1634082\ttotal: 625ms\tremaining: 81.3ms\n",
      "177:\tlearn: 0.1628337\ttotal: 629ms\tremaining: 77.7ms\n",
      "178:\tlearn: 0.1623959\ttotal: 633ms\tremaining: 74.2ms\n",
      "179:\tlearn: 0.1618909\ttotal: 636ms\tremaining: 70.7ms\n",
      "180:\tlearn: 0.1615910\ttotal: 639ms\tremaining: 67.1ms\n",
      "181:\tlearn: 0.1611557\ttotal: 643ms\tremaining: 63.6ms\n",
      "182:\tlearn: 0.1607931\ttotal: 647ms\tremaining: 60.1ms\n",
      "183:\tlearn: 0.1600525\ttotal: 650ms\tremaining: 56.5ms\n",
      "184:\tlearn: 0.1596247\ttotal: 653ms\tremaining: 53ms\n",
      "185:\tlearn: 0.1590795\ttotal: 657ms\tremaining: 49.5ms\n",
      "186:\tlearn: 0.1586522\ttotal: 661ms\tremaining: 45.9ms\n",
      "187:\tlearn: 0.1584042\ttotal: 664ms\tremaining: 42.4ms\n",
      "188:\tlearn: 0.1579632\ttotal: 668ms\tremaining: 38.9ms\n",
      "189:\tlearn: 0.1572995\ttotal: 671ms\tremaining: 35.3ms\n",
      "190:\tlearn: 0.1568641\ttotal: 674ms\tremaining: 31.8ms\n",
      "191:\tlearn: 0.1560883\ttotal: 679ms\tremaining: 28.3ms\n",
      "192:\tlearn: 0.1554140\ttotal: 682ms\tremaining: 24.7ms\n",
      "193:\tlearn: 0.1550301\ttotal: 686ms\tremaining: 21.2ms\n",
      "194:\tlearn: 0.1544859\ttotal: 690ms\tremaining: 17.7ms\n",
      "195:\tlearn: 0.1539170\ttotal: 694ms\tremaining: 14.2ms\n",
      "196:\tlearn: 0.1536594\ttotal: 698ms\tremaining: 10.6ms\n",
      "197:\tlearn: 0.1531634\ttotal: 701ms\tremaining: 7.08ms\n",
      "198:\tlearn: 0.1527682\ttotal: 705ms\tremaining: 3.54ms\n",
      "199:\tlearn: 0.1524607\ttotal: 709ms\tremaining: 0us\n",
      "0:\tlearn: 0.6802163\ttotal: 2.99ms\tremaining: 594ms\n",
      "1:\tlearn: 0.6669334\ttotal: 6.18ms\tremaining: 612ms\n",
      "2:\tlearn: 0.6533873\ttotal: 9.89ms\tremaining: 649ms\n",
      "3:\tlearn: 0.6395287\ttotal: 13.4ms\tremaining: 657ms\n",
      "4:\tlearn: 0.6262109\ttotal: 16.8ms\tremaining: 655ms\n",
      "5:\tlearn: 0.6152355\ttotal: 20.3ms\tremaining: 655ms\n",
      "6:\tlearn: 0.6042564\ttotal: 23.8ms\tremaining: 655ms\n",
      "7:\tlearn: 0.5913170\ttotal: 26.9ms\tremaining: 646ms\n",
      "8:\tlearn: 0.5818168\ttotal: 30.4ms\tremaining: 644ms\n",
      "9:\tlearn: 0.5703185\ttotal: 33.4ms\tremaining: 634ms\n",
      "10:\tlearn: 0.5603926\ttotal: 36.7ms\tremaining: 631ms\n",
      "11:\tlearn: 0.5504244\ttotal: 40.9ms\tremaining: 640ms\n",
      "12:\tlearn: 0.5394000\ttotal: 44.8ms\tremaining: 644ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:\tlearn: 0.5288645\ttotal: 47.9ms\tremaining: 637ms\n",
      "14:\tlearn: 0.5201289\ttotal: 51ms\tremaining: 629ms\n",
      "15:\tlearn: 0.5115289\ttotal: 54ms\tremaining: 621ms\n",
      "16:\tlearn: 0.5021670\ttotal: 57.7ms\tremaining: 622ms\n",
      "17:\tlearn: 0.4937037\ttotal: 62.3ms\tremaining: 630ms\n",
      "18:\tlearn: 0.4858532\ttotal: 65.7ms\tremaining: 626ms\n",
      "19:\tlearn: 0.4779519\ttotal: 69.2ms\tremaining: 623ms\n",
      "20:\tlearn: 0.4701961\ttotal: 72.6ms\tremaining: 619ms\n",
      "21:\tlearn: 0.4622683\ttotal: 76.2ms\tremaining: 617ms\n",
      "22:\tlearn: 0.4537668\ttotal: 79.8ms\tremaining: 614ms\n",
      "23:\tlearn: 0.4472568\ttotal: 83.3ms\tremaining: 611ms\n",
      "24:\tlearn: 0.4389571\ttotal: 86.5ms\tremaining: 605ms\n",
      "25:\tlearn: 0.4317785\ttotal: 89.7ms\tremaining: 600ms\n",
      "26:\tlearn: 0.4257404\ttotal: 93ms\tremaining: 596ms\n",
      "27:\tlearn: 0.4197587\ttotal: 96.6ms\tremaining: 593ms\n",
      "28:\tlearn: 0.4137970\ttotal: 100ms\tremaining: 590ms\n",
      "29:\tlearn: 0.4076070\ttotal: 103ms\tremaining: 586ms\n",
      "30:\tlearn: 0.4022885\ttotal: 107ms\tremaining: 582ms\n",
      "31:\tlearn: 0.3972214\ttotal: 111ms\tremaining: 585ms\n",
      "32:\tlearn: 0.3895259\ttotal: 115ms\tremaining: 580ms\n",
      "33:\tlearn: 0.3846727\ttotal: 118ms\tremaining: 577ms\n",
      "34:\tlearn: 0.3803936\ttotal: 121ms\tremaining: 572ms\n",
      "35:\tlearn: 0.3752256\ttotal: 125ms\tremaining: 570ms\n",
      "36:\tlearn: 0.3693109\ttotal: 128ms\tremaining: 565ms\n",
      "37:\tlearn: 0.3644562\ttotal: 132ms\tremaining: 561ms\n",
      "38:\tlearn: 0.3601790\ttotal: 135ms\tremaining: 556ms\n",
      "39:\tlearn: 0.3561118\ttotal: 138ms\tremaining: 552ms\n",
      "40:\tlearn: 0.3514268\ttotal: 141ms\tremaining: 547ms\n",
      "41:\tlearn: 0.3476200\ttotal: 145ms\tremaining: 544ms\n",
      "42:\tlearn: 0.3434154\ttotal: 148ms\tremaining: 540ms\n",
      "43:\tlearn: 0.3396335\ttotal: 151ms\tremaining: 537ms\n",
      "44:\tlearn: 0.3363435\ttotal: 155ms\tremaining: 533ms\n",
      "45:\tlearn: 0.3331791\ttotal: 158ms\tremaining: 531ms\n",
      "46:\tlearn: 0.3292625\ttotal: 162ms\tremaining: 527ms\n",
      "47:\tlearn: 0.3241761\ttotal: 166ms\tremaining: 525ms\n",
      "48:\tlearn: 0.3195841\ttotal: 169ms\tremaining: 522ms\n",
      "49:\tlearn: 0.3164985\ttotal: 173ms\tremaining: 519ms\n",
      "50:\tlearn: 0.3127160\ttotal: 176ms\tremaining: 515ms\n",
      "51:\tlearn: 0.3096801\ttotal: 180ms\tremaining: 512ms\n",
      "52:\tlearn: 0.3074859\ttotal: 184ms\tremaining: 509ms\n",
      "53:\tlearn: 0.3031081\ttotal: 187ms\tremaining: 505ms\n",
      "54:\tlearn: 0.3003988\ttotal: 190ms\tremaining: 502ms\n",
      "55:\tlearn: 0.2976498\ttotal: 194ms\tremaining: 498ms\n",
      "56:\tlearn: 0.2948661\ttotal: 198ms\tremaining: 497ms\n",
      "57:\tlearn: 0.2924748\ttotal: 202ms\tremaining: 494ms\n",
      "58:\tlearn: 0.2893276\ttotal: 205ms\tremaining: 490ms\n",
      "59:\tlearn: 0.2870869\ttotal: 209ms\tremaining: 487ms\n",
      "60:\tlearn: 0.2849102\ttotal: 212ms\tremaining: 484ms\n",
      "61:\tlearn: 0.2831101\ttotal: 216ms\tremaining: 480ms\n",
      "62:\tlearn: 0.2810937\ttotal: 219ms\tremaining: 477ms\n",
      "63:\tlearn: 0.2781127\ttotal: 223ms\tremaining: 473ms\n",
      "64:\tlearn: 0.2752806\ttotal: 226ms\tremaining: 469ms\n",
      "65:\tlearn: 0.2720284\ttotal: 229ms\tremaining: 466ms\n",
      "66:\tlearn: 0.2688900\ttotal: 233ms\tremaining: 462ms\n",
      "67:\tlearn: 0.2664619\ttotal: 236ms\tremaining: 459ms\n",
      "68:\tlearn: 0.2642604\ttotal: 240ms\tremaining: 455ms\n",
      "69:\tlearn: 0.2627419\ttotal: 244ms\tremaining: 452ms\n",
      "70:\tlearn: 0.2609923\ttotal: 247ms\tremaining: 449ms\n",
      "71:\tlearn: 0.2577301\ttotal: 251ms\tremaining: 446ms\n",
      "72:\tlearn: 0.2557678\ttotal: 255ms\tremaining: 443ms\n",
      "73:\tlearn: 0.2533859\ttotal: 259ms\tremaining: 441ms\n",
      "74:\tlearn: 0.2520430\ttotal: 263ms\tremaining: 438ms\n",
      "75:\tlearn: 0.2497568\ttotal: 266ms\tremaining: 434ms\n",
      "76:\tlearn: 0.2485473\ttotal: 269ms\tremaining: 430ms\n",
      "77:\tlearn: 0.2470199\ttotal: 273ms\tremaining: 427ms\n",
      "78:\tlearn: 0.2459706\ttotal: 277ms\tremaining: 424ms\n",
      "79:\tlearn: 0.2443635\ttotal: 281ms\tremaining: 421ms\n",
      "80:\tlearn: 0.2429332\ttotal: 284ms\tremaining: 418ms\n",
      "81:\tlearn: 0.2404556\ttotal: 288ms\tremaining: 414ms\n",
      "82:\tlearn: 0.2390351\ttotal: 291ms\tremaining: 411ms\n",
      "83:\tlearn: 0.2377224\ttotal: 295ms\tremaining: 407ms\n",
      "84:\tlearn: 0.2355675\ttotal: 298ms\tremaining: 403ms\n",
      "85:\tlearn: 0.2343796\ttotal: 302ms\tremaining: 400ms\n",
      "86:\tlearn: 0.2332409\ttotal: 305ms\tremaining: 396ms\n",
      "87:\tlearn: 0.2319869\ttotal: 309ms\tremaining: 393ms\n",
      "88:\tlearn: 0.2307290\ttotal: 312ms\tremaining: 390ms\n",
      "89:\tlearn: 0.2295479\ttotal: 316ms\tremaining: 386ms\n",
      "90:\tlearn: 0.2278601\ttotal: 320ms\tremaining: 383ms\n",
      "91:\tlearn: 0.2266954\ttotal: 324ms\tremaining: 380ms\n",
      "92:\tlearn: 0.2254909\ttotal: 327ms\tremaining: 376ms\n",
      "93:\tlearn: 0.2246281\ttotal: 331ms\tremaining: 373ms\n",
      "94:\tlearn: 0.2229290\ttotal: 334ms\tremaining: 369ms\n",
      "95:\tlearn: 0.2218609\ttotal: 338ms\tremaining: 366ms\n",
      "96:\tlearn: 0.2206262\ttotal: 341ms\tremaining: 362ms\n",
      "97:\tlearn: 0.2197588\ttotal: 345ms\tremaining: 359ms\n",
      "98:\tlearn: 0.2180095\ttotal: 348ms\tremaining: 355ms\n",
      "99:\tlearn: 0.2171390\ttotal: 352ms\tremaining: 352ms\n",
      "100:\tlearn: 0.2160850\ttotal: 355ms\tremaining: 348ms\n",
      "101:\tlearn: 0.2152034\ttotal: 359ms\tremaining: 345ms\n",
      "102:\tlearn: 0.2142730\ttotal: 362ms\tremaining: 341ms\n",
      "103:\tlearn: 0.2133868\ttotal: 366ms\tremaining: 338ms\n",
      "104:\tlearn: 0.2123482\ttotal: 369ms\tremaining: 334ms\n",
      "105:\tlearn: 0.2111295\ttotal: 373ms\tremaining: 331ms\n",
      "106:\tlearn: 0.2097982\ttotal: 377ms\tremaining: 328ms\n",
      "107:\tlearn: 0.2081117\ttotal: 380ms\tremaining: 324ms\n",
      "108:\tlearn: 0.2072950\ttotal: 384ms\tremaining: 320ms\n",
      "109:\tlearn: 0.2063943\ttotal: 388ms\tremaining: 317ms\n",
      "110:\tlearn: 0.2049372\ttotal: 391ms\tremaining: 314ms\n",
      "111:\tlearn: 0.2041823\ttotal: 395ms\tremaining: 310ms\n",
      "112:\tlearn: 0.2034633\ttotal: 398ms\tremaining: 307ms\n",
      "113:\tlearn: 0.2027022\ttotal: 402ms\tremaining: 303ms\n",
      "114:\tlearn: 0.2012198\ttotal: 405ms\tremaining: 300ms\n",
      "115:\tlearn: 0.2005525\ttotal: 409ms\tremaining: 296ms\n",
      "116:\tlearn: 0.1997571\ttotal: 413ms\tremaining: 293ms\n",
      "117:\tlearn: 0.1987591\ttotal: 416ms\tremaining: 289ms\n",
      "118:\tlearn: 0.1977791\ttotal: 420ms\tremaining: 286ms\n",
      "119:\tlearn: 0.1962776\ttotal: 423ms\tremaining: 282ms\n",
      "120:\tlearn: 0.1956602\ttotal: 427ms\tremaining: 279ms\n",
      "121:\tlearn: 0.1943630\ttotal: 431ms\tremaining: 275ms\n",
      "122:\tlearn: 0.1932306\ttotal: 434ms\tremaining: 272ms\n",
      "123:\tlearn: 0.1925200\ttotal: 437ms\tremaining: 268ms\n",
      "124:\tlearn: 0.1916796\ttotal: 441ms\tremaining: 264ms\n",
      "125:\tlearn: 0.1907374\ttotal: 444ms\tremaining: 261ms\n",
      "126:\tlearn: 0.1897194\ttotal: 448ms\tremaining: 257ms\n",
      "127:\tlearn: 0.1884111\ttotal: 451ms\tremaining: 254ms\n",
      "128:\tlearn: 0.1871788\ttotal: 454ms\tremaining: 250ms\n",
      "129:\tlearn: 0.1861680\ttotal: 458ms\tremaining: 247ms\n",
      "130:\tlearn: 0.1852901\ttotal: 462ms\tremaining: 243ms\n",
      "131:\tlearn: 0.1844332\ttotal: 465ms\tremaining: 240ms\n",
      "132:\tlearn: 0.1830893\ttotal: 469ms\tremaining: 236ms\n",
      "133:\tlearn: 0.1824613\ttotal: 472ms\tremaining: 233ms\n",
      "134:\tlearn: 0.1818194\ttotal: 476ms\tremaining: 229ms\n",
      "135:\tlearn: 0.1811655\ttotal: 480ms\tremaining: 226ms\n",
      "136:\tlearn: 0.1802890\ttotal: 484ms\tremaining: 222ms\n",
      "137:\tlearn: 0.1795595\ttotal: 487ms\tremaining: 219ms\n",
      "138:\tlearn: 0.1790328\ttotal: 492ms\tremaining: 216ms\n",
      "139:\tlearn: 0.1783907\ttotal: 495ms\tremaining: 212ms\n",
      "140:\tlearn: 0.1776743\ttotal: 498ms\tremaining: 209ms\n",
      "141:\tlearn: 0.1767820\ttotal: 503ms\tremaining: 205ms\n",
      "142:\tlearn: 0.1762728\ttotal: 506ms\tremaining: 202ms\n",
      "143:\tlearn: 0.1754100\ttotal: 510ms\tremaining: 198ms\n",
      "144:\tlearn: 0.1747391\ttotal: 513ms\tremaining: 195ms\n",
      "145:\tlearn: 0.1741837\ttotal: 517ms\tremaining: 191ms\n",
      "146:\tlearn: 0.1735567\ttotal: 521ms\tremaining: 188ms\n",
      "147:\tlearn: 0.1728760\ttotal: 524ms\tremaining: 184ms\n",
      "148:\tlearn: 0.1723783\ttotal: 528ms\tremaining: 181ms\n",
      "149:\tlearn: 0.1713525\ttotal: 531ms\tremaining: 177ms\n",
      "150:\tlearn: 0.1702075\ttotal: 534ms\tremaining: 173ms\n",
      "151:\tlearn: 0.1695126\ttotal: 538ms\tremaining: 170ms\n",
      "152:\tlearn: 0.1689885\ttotal: 541ms\tremaining: 166ms\n",
      "153:\tlearn: 0.1685470\ttotal: 544ms\tremaining: 163ms\n",
      "154:\tlearn: 0.1677978\ttotal: 548ms\tremaining: 159ms\n",
      "155:\tlearn: 0.1673191\ttotal: 552ms\tremaining: 156ms\n",
      "156:\tlearn: 0.1669800\ttotal: 556ms\tremaining: 152ms\n",
      "157:\tlearn: 0.1662862\ttotal: 560ms\tremaining: 149ms\n",
      "158:\tlearn: 0.1659107\ttotal: 563ms\tremaining: 145ms\n",
      "159:\tlearn: 0.1655424\ttotal: 567ms\tremaining: 142ms\n",
      "160:\tlearn: 0.1650368\ttotal: 570ms\tremaining: 138ms\n",
      "161:\tlearn: 0.1642673\ttotal: 574ms\tremaining: 135ms\n",
      "162:\tlearn: 0.1635995\ttotal: 578ms\tremaining: 131ms\n",
      "163:\tlearn: 0.1633106\ttotal: 582ms\tremaining: 128ms\n",
      "164:\tlearn: 0.1625566\ttotal: 585ms\tremaining: 124ms\n",
      "165:\tlearn: 0.1622259\ttotal: 589ms\tremaining: 121ms\n",
      "166:\tlearn: 0.1617652\ttotal: 592ms\tremaining: 117ms\n",
      "167:\tlearn: 0.1613216\ttotal: 596ms\tremaining: 114ms\n",
      "168:\tlearn: 0.1607502\ttotal: 600ms\tremaining: 110ms\n",
      "169:\tlearn: 0.1603249\ttotal: 603ms\tremaining: 106ms\n",
      "170:\tlearn: 0.1599330\ttotal: 607ms\tremaining: 103ms\n",
      "171:\tlearn: 0.1596297\ttotal: 611ms\tremaining: 99.5ms\n",
      "172:\tlearn: 0.1590587\ttotal: 615ms\tremaining: 96ms\n",
      "173:\tlearn: 0.1587006\ttotal: 618ms\tremaining: 92.4ms\n",
      "174:\tlearn: 0.1582635\ttotal: 622ms\tremaining: 88.8ms\n",
      "175:\tlearn: 0.1577299\ttotal: 625ms\tremaining: 85.3ms\n",
      "176:\tlearn: 0.1570977\ttotal: 629ms\tremaining: 81.8ms\n",
      "177:\tlearn: 0.1562514\ttotal: 633ms\tremaining: 78.3ms\n",
      "178:\tlearn: 0.1556055\ttotal: 637ms\tremaining: 74.7ms\n",
      "179:\tlearn: 0.1552245\ttotal: 641ms\tremaining: 71.2ms\n",
      "180:\tlearn: 0.1548293\ttotal: 644ms\tremaining: 67.6ms\n",
      "181:\tlearn: 0.1543567\ttotal: 648ms\tremaining: 64ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182:\tlearn: 0.1537481\ttotal: 651ms\tremaining: 60.5ms\n",
      "183:\tlearn: 0.1533054\ttotal: 655ms\tremaining: 56.9ms\n",
      "184:\tlearn: 0.1528847\ttotal: 658ms\tremaining: 53.3ms\n",
      "185:\tlearn: 0.1525738\ttotal: 661ms\tremaining: 49.8ms\n",
      "186:\tlearn: 0.1522377\ttotal: 665ms\tremaining: 46.2ms\n",
      "187:\tlearn: 0.1518344\ttotal: 669ms\tremaining: 42.7ms\n",
      "188:\tlearn: 0.1511614\ttotal: 672ms\tremaining: 39.1ms\n",
      "189:\tlearn: 0.1506468\ttotal: 676ms\tremaining: 35.6ms\n",
      "190:\tlearn: 0.1500866\ttotal: 680ms\tremaining: 32ms\n",
      "191:\tlearn: 0.1498312\ttotal: 683ms\tremaining: 28.5ms\n",
      "192:\tlearn: 0.1494025\ttotal: 687ms\tremaining: 24.9ms\n",
      "193:\tlearn: 0.1489859\ttotal: 690ms\tremaining: 21.3ms\n",
      "194:\tlearn: 0.1486725\ttotal: 694ms\tremaining: 17.8ms\n",
      "195:\tlearn: 0.1482029\ttotal: 697ms\tremaining: 14.2ms\n",
      "196:\tlearn: 0.1476356\ttotal: 701ms\tremaining: 10.7ms\n",
      "197:\tlearn: 0.1472538\ttotal: 705ms\tremaining: 7.12ms\n",
      "198:\tlearn: 0.1468717\ttotal: 708ms\tremaining: 3.56ms\n",
      "199:\tlearn: 0.1465020\ttotal: 712ms\tremaining: 0us\n",
      "0:\tlearn: 0.6794121\ttotal: 3.58ms\tremaining: 713ms\n",
      "1:\tlearn: 0.6659920\ttotal: 6.93ms\tremaining: 686ms\n",
      "2:\tlearn: 0.6525795\ttotal: 10.6ms\tremaining: 697ms\n",
      "3:\tlearn: 0.6401182\ttotal: 14ms\tremaining: 688ms\n",
      "4:\tlearn: 0.6267372\ttotal: 17.5ms\tremaining: 681ms\n",
      "5:\tlearn: 0.6151469\ttotal: 20.6ms\tremaining: 667ms\n",
      "6:\tlearn: 0.6034866\ttotal: 24.3ms\tremaining: 669ms\n",
      "7:\tlearn: 0.5911156\ttotal: 27.7ms\tremaining: 665ms\n",
      "8:\tlearn: 0.5818408\ttotal: 30.2ms\tremaining: 640ms\n",
      "9:\tlearn: 0.5728677\ttotal: 33.8ms\tremaining: 642ms\n",
      "10:\tlearn: 0.5629476\ttotal: 37.1ms\tremaining: 637ms\n",
      "11:\tlearn: 0.5533093\ttotal: 40.6ms\tremaining: 636ms\n",
      "12:\tlearn: 0.5435169\ttotal: 44.6ms\tremaining: 642ms\n",
      "13:\tlearn: 0.5349220\ttotal: 48.4ms\tremaining: 643ms\n",
      "14:\tlearn: 0.5265798\ttotal: 51.7ms\tremaining: 638ms\n",
      "15:\tlearn: 0.5172019\ttotal: 55.1ms\tremaining: 633ms\n",
      "16:\tlearn: 0.5086352\ttotal: 58.4ms\tremaining: 628ms\n",
      "17:\tlearn: 0.4993027\ttotal: 61.9ms\tremaining: 626ms\n",
      "18:\tlearn: 0.4918672\ttotal: 65.5ms\tremaining: 624ms\n",
      "19:\tlearn: 0.4840758\ttotal: 68.8ms\tremaining: 619ms\n",
      "20:\tlearn: 0.4759264\ttotal: 72.1ms\tremaining: 615ms\n",
      "21:\tlearn: 0.4684547\ttotal: 75.7ms\tremaining: 613ms\n",
      "22:\tlearn: 0.4623573\ttotal: 79.6ms\tremaining: 613ms\n",
      "23:\tlearn: 0.4546489\ttotal: 82.8ms\tremaining: 607ms\n",
      "24:\tlearn: 0.4472959\ttotal: 86.4ms\tremaining: 605ms\n",
      "25:\tlearn: 0.4401918\ttotal: 89.8ms\tremaining: 601ms\n",
      "26:\tlearn: 0.4326385\ttotal: 93.1ms\tremaining: 596ms\n",
      "27:\tlearn: 0.4265673\ttotal: 97.3ms\tremaining: 598ms\n",
      "28:\tlearn: 0.4199114\ttotal: 101ms\tremaining: 595ms\n",
      "29:\tlearn: 0.4140022\ttotal: 105ms\tremaining: 592ms\n",
      "30:\tlearn: 0.4064359\ttotal: 108ms\tremaining: 589ms\n",
      "31:\tlearn: 0.4007448\ttotal: 111ms\tremaining: 585ms\n",
      "32:\tlearn: 0.3950855\ttotal: 115ms\tremaining: 584ms\n",
      "33:\tlearn: 0.3900226\ttotal: 119ms\tremaining: 580ms\n",
      "34:\tlearn: 0.3849603\ttotal: 122ms\tremaining: 576ms\n",
      "35:\tlearn: 0.3799777\ttotal: 125ms\tremaining: 571ms\n",
      "36:\tlearn: 0.3734363\ttotal: 129ms\tremaining: 568ms\n",
      "37:\tlearn: 0.3690948\ttotal: 133ms\tremaining: 565ms\n",
      "38:\tlearn: 0.3634142\ttotal: 136ms\tremaining: 561ms\n",
      "39:\tlearn: 0.3587049\ttotal: 139ms\tremaining: 557ms\n",
      "40:\tlearn: 0.3540684\ttotal: 143ms\tremaining: 553ms\n",
      "41:\tlearn: 0.3497195\ttotal: 146ms\tremaining: 550ms\n",
      "42:\tlearn: 0.3457571\ttotal: 149ms\tremaining: 545ms\n",
      "43:\tlearn: 0.3417662\ttotal: 153ms\tremaining: 542ms\n",
      "44:\tlearn: 0.3378925\ttotal: 157ms\tremaining: 539ms\n",
      "45:\tlearn: 0.3341121\ttotal: 160ms\tremaining: 535ms\n",
      "46:\tlearn: 0.3311004\ttotal: 163ms\tremaining: 531ms\n",
      "47:\tlearn: 0.3276512\ttotal: 167ms\tremaining: 529ms\n",
      "48:\tlearn: 0.3243329\ttotal: 170ms\tremaining: 525ms\n",
      "49:\tlearn: 0.3193136\ttotal: 174ms\tremaining: 521ms\n",
      "50:\tlearn: 0.3161285\ttotal: 177ms\tremaining: 518ms\n",
      "51:\tlearn: 0.3127803\ttotal: 181ms\tremaining: 514ms\n",
      "52:\tlearn: 0.3102821\ttotal: 184ms\tremaining: 511ms\n",
      "53:\tlearn: 0.3074757\ttotal: 188ms\tremaining: 508ms\n",
      "54:\tlearn: 0.3049488\ttotal: 192ms\tremaining: 505ms\n",
      "55:\tlearn: 0.3025731\ttotal: 196ms\tremaining: 504ms\n",
      "56:\tlearn: 0.2996721\ttotal: 200ms\tremaining: 501ms\n",
      "57:\tlearn: 0.2982628\ttotal: 203ms\tremaining: 498ms\n",
      "58:\tlearn: 0.2957285\ttotal: 207ms\tremaining: 495ms\n",
      "59:\tlearn: 0.2931950\ttotal: 211ms\tremaining: 491ms\n",
      "60:\tlearn: 0.2897170\ttotal: 214ms\tremaining: 488ms\n",
      "61:\tlearn: 0.2877676\ttotal: 218ms\tremaining: 486ms\n",
      "62:\tlearn: 0.2845801\ttotal: 221ms\tremaining: 481ms\n",
      "63:\tlearn: 0.2822862\ttotal: 225ms\tremaining: 478ms\n",
      "64:\tlearn: 0.2804687\ttotal: 229ms\tremaining: 476ms\n",
      "65:\tlearn: 0.2786964\ttotal: 233ms\tremaining: 473ms\n",
      "66:\tlearn: 0.2754834\ttotal: 236ms\tremaining: 469ms\n",
      "67:\tlearn: 0.2732097\ttotal: 240ms\tremaining: 466ms\n",
      "68:\tlearn: 0.2712840\ttotal: 244ms\tremaining: 463ms\n",
      "69:\tlearn: 0.2695672\ttotal: 247ms\tremaining: 459ms\n",
      "70:\tlearn: 0.2679198\ttotal: 251ms\tremaining: 456ms\n",
      "71:\tlearn: 0.2662178\ttotal: 254ms\tremaining: 452ms\n",
      "72:\tlearn: 0.2634224\ttotal: 258ms\tremaining: 448ms\n",
      "73:\tlearn: 0.2616192\ttotal: 261ms\tremaining: 445ms\n",
      "74:\tlearn: 0.2594554\ttotal: 265ms\tremaining: 441ms\n",
      "75:\tlearn: 0.2578458\ttotal: 269ms\tremaining: 439ms\n",
      "76:\tlearn: 0.2565097\ttotal: 273ms\tremaining: 436ms\n",
      "77:\tlearn: 0.2542761\ttotal: 276ms\tremaining: 432ms\n",
      "78:\tlearn: 0.2526419\ttotal: 280ms\tremaining: 429ms\n",
      "79:\tlearn: 0.2497863\ttotal: 284ms\tremaining: 425ms\n",
      "80:\tlearn: 0.2483750\ttotal: 287ms\tremaining: 422ms\n",
      "81:\tlearn: 0.2467351\ttotal: 291ms\tremaining: 419ms\n",
      "82:\tlearn: 0.2454153\ttotal: 294ms\tremaining: 415ms\n",
      "83:\tlearn: 0.2435226\ttotal: 298ms\tremaining: 412ms\n",
      "84:\tlearn: 0.2419759\ttotal: 302ms\tremaining: 408ms\n",
      "85:\tlearn: 0.2407144\ttotal: 306ms\tremaining: 405ms\n",
      "86:\tlearn: 0.2394866\ttotal: 309ms\tremaining: 402ms\n",
      "87:\tlearn: 0.2384069\ttotal: 313ms\tremaining: 398ms\n",
      "88:\tlearn: 0.2369365\ttotal: 316ms\tremaining: 394ms\n",
      "89:\tlearn: 0.2354639\ttotal: 319ms\tremaining: 390ms\n",
      "90:\tlearn: 0.2344473\ttotal: 323ms\tremaining: 387ms\n",
      "91:\tlearn: 0.2325717\ttotal: 326ms\tremaining: 383ms\n",
      "92:\tlearn: 0.2311424\ttotal: 330ms\tremaining: 380ms\n",
      "93:\tlearn: 0.2299742\ttotal: 334ms\tremaining: 376ms\n",
      "94:\tlearn: 0.2289122\ttotal: 337ms\tremaining: 373ms\n",
      "95:\tlearn: 0.2279290\ttotal: 340ms\tremaining: 369ms\n",
      "96:\tlearn: 0.2270244\ttotal: 344ms\tremaining: 366ms\n",
      "97:\tlearn: 0.2258313\ttotal: 348ms\tremaining: 362ms\n",
      "98:\tlearn: 0.2251035\ttotal: 351ms\tremaining: 358ms\n",
      "99:\tlearn: 0.2238770\ttotal: 355ms\tremaining: 355ms\n",
      "100:\tlearn: 0.2230085\ttotal: 358ms\tremaining: 351ms\n",
      "101:\tlearn: 0.2214378\ttotal: 362ms\tremaining: 348ms\n",
      "102:\tlearn: 0.2199300\ttotal: 365ms\tremaining: 344ms\n",
      "103:\tlearn: 0.2183460\ttotal: 369ms\tremaining: 341ms\n",
      "104:\tlearn: 0.2178408\ttotal: 373ms\tremaining: 337ms\n",
      "105:\tlearn: 0.2163257\ttotal: 376ms\tremaining: 333ms\n",
      "106:\tlearn: 0.2153743\ttotal: 379ms\tremaining: 330ms\n",
      "107:\tlearn: 0.2145074\ttotal: 383ms\tremaining: 326ms\n",
      "108:\tlearn: 0.2135438\ttotal: 386ms\tremaining: 322ms\n",
      "109:\tlearn: 0.2124123\ttotal: 390ms\tremaining: 319ms\n",
      "110:\tlearn: 0.2105687\ttotal: 393ms\tremaining: 315ms\n",
      "111:\tlearn: 0.2091611\ttotal: 397ms\tremaining: 312ms\n",
      "112:\tlearn: 0.2081678\ttotal: 401ms\tremaining: 309ms\n",
      "113:\tlearn: 0.2070829\ttotal: 405ms\tremaining: 305ms\n",
      "114:\tlearn: 0.2060677\ttotal: 408ms\tremaining: 302ms\n",
      "115:\tlearn: 0.2053653\ttotal: 411ms\tremaining: 298ms\n",
      "116:\tlearn: 0.2042915\ttotal: 415ms\tremaining: 294ms\n",
      "117:\tlearn: 0.2034668\ttotal: 418ms\tremaining: 291ms\n",
      "118:\tlearn: 0.2028401\ttotal: 422ms\tremaining: 287ms\n",
      "119:\tlearn: 0.2015888\ttotal: 425ms\tremaining: 283ms\n",
      "120:\tlearn: 0.2007815\ttotal: 429ms\tremaining: 280ms\n",
      "121:\tlearn: 0.2002214\ttotal: 433ms\tremaining: 277ms\n",
      "122:\tlearn: 0.1989854\ttotal: 436ms\tremaining: 273ms\n",
      "123:\tlearn: 0.1975384\ttotal: 439ms\tremaining: 269ms\n",
      "124:\tlearn: 0.1968448\ttotal: 443ms\tremaining: 266ms\n",
      "125:\tlearn: 0.1961864\ttotal: 446ms\tremaining: 262ms\n",
      "126:\tlearn: 0.1949401\ttotal: 450ms\tremaining: 259ms\n",
      "127:\tlearn: 0.1942458\ttotal: 454ms\tremaining: 255ms\n",
      "128:\tlearn: 0.1933783\ttotal: 457ms\tremaining: 252ms\n",
      "129:\tlearn: 0.1926260\ttotal: 461ms\tremaining: 248ms\n",
      "130:\tlearn: 0.1919860\ttotal: 464ms\tremaining: 244ms\n",
      "131:\tlearn: 0.1905037\ttotal: 467ms\tremaining: 241ms\n",
      "132:\tlearn: 0.1893510\ttotal: 470ms\tremaining: 237ms\n",
      "133:\tlearn: 0.1888335\ttotal: 474ms\tremaining: 233ms\n",
      "134:\tlearn: 0.1876627\ttotal: 477ms\tremaining: 230ms\n",
      "135:\tlearn: 0.1864778\ttotal: 481ms\tremaining: 226ms\n",
      "136:\tlearn: 0.1855623\ttotal: 484ms\tremaining: 223ms\n",
      "137:\tlearn: 0.1850928\ttotal: 488ms\tremaining: 219ms\n",
      "138:\tlearn: 0.1844509\ttotal: 491ms\tremaining: 216ms\n",
      "139:\tlearn: 0.1839153\ttotal: 494ms\tremaining: 212ms\n",
      "140:\tlearn: 0.1833003\ttotal: 499ms\tremaining: 209ms\n",
      "141:\tlearn: 0.1827777\ttotal: 503ms\tremaining: 205ms\n",
      "142:\tlearn: 0.1822246\ttotal: 506ms\tremaining: 202ms\n",
      "143:\tlearn: 0.1811325\ttotal: 510ms\tremaining: 198ms\n",
      "144:\tlearn: 0.1804360\ttotal: 513ms\tremaining: 195ms\n",
      "145:\tlearn: 0.1793489\ttotal: 517ms\tremaining: 191ms\n",
      "146:\tlearn: 0.1788199\ttotal: 521ms\tremaining: 188ms\n",
      "147:\tlearn: 0.1777942\ttotal: 524ms\tremaining: 184ms\n",
      "148:\tlearn: 0.1776300\ttotal: 527ms\tremaining: 180ms\n",
      "149:\tlearn: 0.1772036\ttotal: 530ms\tremaining: 177ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150:\tlearn: 0.1765754\ttotal: 535ms\tremaining: 173ms\n",
      "151:\tlearn: 0.1762321\ttotal: 538ms\tremaining: 170ms\n",
      "152:\tlearn: 0.1753448\ttotal: 541ms\tremaining: 166ms\n",
      "153:\tlearn: 0.1745082\ttotal: 545ms\tremaining: 163ms\n",
      "154:\tlearn: 0.1737473\ttotal: 548ms\tremaining: 159ms\n",
      "155:\tlearn: 0.1729504\ttotal: 551ms\tremaining: 155ms\n",
      "156:\tlearn: 0.1720733\ttotal: 555ms\tremaining: 152ms\n",
      "157:\tlearn: 0.1714331\ttotal: 559ms\tremaining: 149ms\n",
      "158:\tlearn: 0.1709291\ttotal: 562ms\tremaining: 145ms\n",
      "159:\tlearn: 0.1704246\ttotal: 566ms\tremaining: 141ms\n",
      "160:\tlearn: 0.1699629\ttotal: 569ms\tremaining: 138ms\n",
      "161:\tlearn: 0.1691270\ttotal: 572ms\tremaining: 134ms\n",
      "162:\tlearn: 0.1687370\ttotal: 576ms\tremaining: 131ms\n",
      "163:\tlearn: 0.1684166\ttotal: 580ms\tremaining: 127ms\n",
      "164:\tlearn: 0.1676395\ttotal: 583ms\tremaining: 124ms\n",
      "165:\tlearn: 0.1666698\ttotal: 587ms\tremaining: 120ms\n",
      "166:\tlearn: 0.1658720\ttotal: 591ms\tremaining: 117ms\n",
      "167:\tlearn: 0.1655101\ttotal: 594ms\tremaining: 113ms\n",
      "168:\tlearn: 0.1646386\ttotal: 597ms\tremaining: 110ms\n",
      "169:\tlearn: 0.1638329\ttotal: 601ms\tremaining: 106ms\n",
      "170:\tlearn: 0.1633907\ttotal: 604ms\tremaining: 102ms\n",
      "171:\tlearn: 0.1628028\ttotal: 608ms\tremaining: 98.9ms\n",
      "172:\tlearn: 0.1624223\ttotal: 611ms\tremaining: 95.4ms\n",
      "173:\tlearn: 0.1619704\ttotal: 615ms\tremaining: 91.9ms\n",
      "174:\tlearn: 0.1616051\ttotal: 619ms\tremaining: 88.4ms\n",
      "175:\tlearn: 0.1611617\ttotal: 622ms\tremaining: 84.8ms\n",
      "176:\tlearn: 0.1608226\ttotal: 626ms\tremaining: 81.4ms\n",
      "177:\tlearn: 0.1603130\ttotal: 630ms\tremaining: 77.9ms\n",
      "178:\tlearn: 0.1599212\ttotal: 634ms\tremaining: 74.4ms\n",
      "179:\tlearn: 0.1591811\ttotal: 638ms\tremaining: 70.8ms\n",
      "180:\tlearn: 0.1585808\ttotal: 641ms\tremaining: 67.3ms\n",
      "181:\tlearn: 0.1581749\ttotal: 644ms\tremaining: 63.7ms\n",
      "182:\tlearn: 0.1576990\ttotal: 648ms\tremaining: 60.2ms\n",
      "183:\tlearn: 0.1572103\ttotal: 652ms\tremaining: 56.7ms\n",
      "184:\tlearn: 0.1565922\ttotal: 655ms\tremaining: 53.1ms\n",
      "185:\tlearn: 0.1559492\ttotal: 658ms\tremaining: 49.6ms\n",
      "186:\tlearn: 0.1555668\ttotal: 662ms\tremaining: 46ms\n",
      "187:\tlearn: 0.1552291\ttotal: 665ms\tremaining: 42.5ms\n",
      "188:\tlearn: 0.1546835\ttotal: 669ms\tremaining: 38.9ms\n",
      "189:\tlearn: 0.1542628\ttotal: 673ms\tremaining: 35.4ms\n",
      "190:\tlearn: 0.1540026\ttotal: 676ms\tremaining: 31.9ms\n",
      "191:\tlearn: 0.1537163\ttotal: 680ms\tremaining: 28.3ms\n",
      "192:\tlearn: 0.1534053\ttotal: 684ms\tremaining: 24.8ms\n",
      "193:\tlearn: 0.1527416\ttotal: 687ms\tremaining: 21.3ms\n",
      "194:\tlearn: 0.1524078\ttotal: 691ms\tremaining: 17.7ms\n",
      "195:\tlearn: 0.1519582\ttotal: 694ms\tremaining: 14.2ms\n",
      "196:\tlearn: 0.1515926\ttotal: 697ms\tremaining: 10.6ms\n",
      "197:\tlearn: 0.1511797\ttotal: 701ms\tremaining: 7.08ms\n",
      "198:\tlearn: 0.1508799\ttotal: 705ms\tremaining: 3.54ms\n",
      "199:\tlearn: 0.1505482\ttotal: 708ms\tremaining: 0us\n",
      "0:\tlearn: 0.6250389\ttotal: 3.1ms\tremaining: 618ms\n",
      "1:\tlearn: 0.5744381\ttotal: 6.49ms\tremaining: 643ms\n",
      "2:\tlearn: 0.5221696\ttotal: 9.89ms\tremaining: 649ms\n",
      "3:\tlearn: 0.4763858\ttotal: 13.3ms\tremaining: 653ms\n",
      "4:\tlearn: 0.4363342\ttotal: 17.4ms\tremaining: 679ms\n",
      "5:\tlearn: 0.4067585\ttotal: 21ms\tremaining: 677ms\n",
      "6:\tlearn: 0.3780226\ttotal: 24.9ms\tremaining: 686ms\n",
      "7:\tlearn: 0.3499508\ttotal: 28.2ms\tremaining: 677ms\n",
      "8:\tlearn: 0.3327867\ttotal: 31.6ms\tremaining: 671ms\n",
      "9:\tlearn: 0.3162044\ttotal: 35ms\tremaining: 665ms\n",
      "10:\tlearn: 0.3010341\ttotal: 38.8ms\tremaining: 666ms\n",
      "11:\tlearn: 0.2853533\ttotal: 42.8ms\tremaining: 670ms\n",
      "12:\tlearn: 0.2753188\ttotal: 46.8ms\tremaining: 673ms\n",
      "13:\tlearn: 0.2662428\ttotal: 50.2ms\tremaining: 667ms\n",
      "14:\tlearn: 0.2597706\ttotal: 54.7ms\tremaining: 674ms\n",
      "15:\tlearn: 0.2461431\ttotal: 58ms\tremaining: 668ms\n",
      "16:\tlearn: 0.2340826\ttotal: 62.2ms\tremaining: 669ms\n",
      "17:\tlearn: 0.2285149\ttotal: 66ms\tremaining: 668ms\n",
      "18:\tlearn: 0.2182900\ttotal: 69.9ms\tremaining: 666ms\n",
      "19:\tlearn: 0.2138757\ttotal: 73.3ms\tremaining: 660ms\n",
      "20:\tlearn: 0.2096011\ttotal: 76.7ms\tremaining: 654ms\n",
      "21:\tlearn: 0.2056711\ttotal: 80.3ms\tremaining: 649ms\n",
      "22:\tlearn: 0.2025296\ttotal: 83.9ms\tremaining: 646ms\n",
      "23:\tlearn: 0.1963272\ttotal: 87.4ms\tremaining: 641ms\n",
      "24:\tlearn: 0.1934422\ttotal: 91ms\tremaining: 637ms\n",
      "25:\tlearn: 0.1910856\ttotal: 95ms\tremaining: 636ms\n",
      "26:\tlearn: 0.1878285\ttotal: 98.8ms\tremaining: 633ms\n",
      "27:\tlearn: 0.1843269\ttotal: 103ms\tremaining: 633ms\n",
      "28:\tlearn: 0.1819657\ttotal: 107ms\tremaining: 630ms\n",
      "29:\tlearn: 0.1791284\ttotal: 111ms\tremaining: 630ms\n",
      "30:\tlearn: 0.1742401\ttotal: 114ms\tremaining: 623ms\n",
      "31:\tlearn: 0.1714719\ttotal: 118ms\tremaining: 618ms\n",
      "32:\tlearn: 0.1684420\ttotal: 121ms\tremaining: 614ms\n",
      "33:\tlearn: 0.1660878\ttotal: 125ms\tremaining: 610ms\n",
      "34:\tlearn: 0.1612281\ttotal: 128ms\tremaining: 605ms\n",
      "35:\tlearn: 0.1562848\ttotal: 132ms\tremaining: 603ms\n",
      "36:\tlearn: 0.1541005\ttotal: 136ms\tremaining: 598ms\n",
      "37:\tlearn: 0.1511966\ttotal: 139ms\tremaining: 594ms\n",
      "38:\tlearn: 0.1494794\ttotal: 143ms\tremaining: 589ms\n",
      "39:\tlearn: 0.1475679\ttotal: 146ms\tremaining: 585ms\n",
      "40:\tlearn: 0.1445187\ttotal: 150ms\tremaining: 582ms\n",
      "41:\tlearn: 0.1434300\ttotal: 154ms\tremaining: 578ms\n",
      "42:\tlearn: 0.1414125\ttotal: 157ms\tremaining: 573ms\n",
      "43:\tlearn: 0.1405405\ttotal: 160ms\tremaining: 568ms\n",
      "44:\tlearn: 0.1390599\ttotal: 164ms\tremaining: 564ms\n",
      "45:\tlearn: 0.1363333\ttotal: 167ms\tremaining: 560ms\n",
      "46:\tlearn: 0.1354825\ttotal: 170ms\tremaining: 555ms\n",
      "47:\tlearn: 0.1335436\ttotal: 174ms\tremaining: 551ms\n",
      "48:\tlearn: 0.1316477\ttotal: 178ms\tremaining: 548ms\n",
      "49:\tlearn: 0.1295523\ttotal: 181ms\tremaining: 544ms\n",
      "50:\tlearn: 0.1282691\ttotal: 185ms\tremaining: 540ms\n",
      "51:\tlearn: 0.1267211\ttotal: 189ms\tremaining: 538ms\n",
      "52:\tlearn: 0.1256637\ttotal: 193ms\tremaining: 535ms\n",
      "53:\tlearn: 0.1242264\ttotal: 196ms\tremaining: 530ms\n",
      "54:\tlearn: 0.1227866\ttotal: 200ms\tremaining: 527ms\n",
      "55:\tlearn: 0.1209679\ttotal: 203ms\tremaining: 523ms\n",
      "56:\tlearn: 0.1192891\ttotal: 207ms\tremaining: 519ms\n",
      "57:\tlearn: 0.1175981\ttotal: 210ms\tremaining: 515ms\n",
      "58:\tlearn: 0.1169080\ttotal: 214ms\tremaining: 511ms\n",
      "59:\tlearn: 0.1156023\ttotal: 217ms\tremaining: 507ms\n",
      "60:\tlearn: 0.1138702\ttotal: 221ms\tremaining: 503ms\n",
      "61:\tlearn: 0.1122761\ttotal: 224ms\tremaining: 498ms\n",
      "62:\tlearn: 0.1113543\ttotal: 234ms\tremaining: 508ms\n",
      "63:\tlearn: 0.1104435\ttotal: 238ms\tremaining: 506ms\n",
      "64:\tlearn: 0.1097594\ttotal: 241ms\tremaining: 501ms\n",
      "65:\tlearn: 0.1086492\ttotal: 245ms\tremaining: 497ms\n",
      "66:\tlearn: 0.1075525\ttotal: 248ms\tremaining: 493ms\n",
      "67:\tlearn: 0.1065911\ttotal: 252ms\tremaining: 489ms\n",
      "68:\tlearn: 0.1057046\ttotal: 255ms\tremaining: 485ms\n",
      "69:\tlearn: 0.1050449\ttotal: 259ms\tremaining: 482ms\n",
      "70:\tlearn: 0.1040330\ttotal: 263ms\tremaining: 478ms\n",
      "71:\tlearn: 0.1032790\ttotal: 267ms\tremaining: 474ms\n",
      "72:\tlearn: 0.1028197\ttotal: 270ms\tremaining: 470ms\n",
      "73:\tlearn: 0.1019519\ttotal: 274ms\tremaining: 466ms\n",
      "74:\tlearn: 0.1010593\ttotal: 277ms\tremaining: 462ms\n",
      "75:\tlearn: 0.0999999\ttotal: 280ms\tremaining: 458ms\n",
      "76:\tlearn: 0.0993645\ttotal: 284ms\tremaining: 454ms\n",
      "77:\tlearn: 0.0988814\ttotal: 288ms\tremaining: 451ms\n",
      "78:\tlearn: 0.0980921\ttotal: 291ms\tremaining: 446ms\n",
      "79:\tlearn: 0.0973931\ttotal: 295ms\tremaining: 443ms\n",
      "80:\tlearn: 0.0964788\ttotal: 299ms\tremaining: 439ms\n",
      "81:\tlearn: 0.0960990\ttotal: 302ms\tremaining: 435ms\n",
      "82:\tlearn: 0.0955445\ttotal: 306ms\tremaining: 431ms\n",
      "83:\tlearn: 0.0950925\ttotal: 309ms\tremaining: 427ms\n",
      "84:\tlearn: 0.0943873\ttotal: 313ms\tremaining: 424ms\n",
      "85:\tlearn: 0.0937362\ttotal: 316ms\tremaining: 419ms\n",
      "86:\tlearn: 0.0929057\ttotal: 320ms\tremaining: 415ms\n",
      "87:\tlearn: 0.0923011\ttotal: 323ms\tremaining: 412ms\n",
      "88:\tlearn: 0.0921432\ttotal: 327ms\tremaining: 408ms\n",
      "89:\tlearn: 0.0912476\ttotal: 330ms\tremaining: 404ms\n",
      "90:\tlearn: 0.0902790\ttotal: 334ms\tremaining: 400ms\n",
      "91:\tlearn: 0.0894963\ttotal: 337ms\tremaining: 396ms\n",
      "92:\tlearn: 0.0893000\ttotal: 341ms\tremaining: 392ms\n",
      "93:\tlearn: 0.0889254\ttotal: 344ms\tremaining: 388ms\n",
      "94:\tlearn: 0.0884041\ttotal: 348ms\tremaining: 384ms\n",
      "95:\tlearn: 0.0872288\ttotal: 351ms\tremaining: 380ms\n",
      "96:\tlearn: 0.0864055\ttotal: 355ms\tremaining: 377ms\n",
      "97:\tlearn: 0.0859740\ttotal: 359ms\tremaining: 373ms\n",
      "98:\tlearn: 0.0854581\ttotal: 363ms\tremaining: 370ms\n",
      "99:\tlearn: 0.0851441\ttotal: 366ms\tremaining: 366ms\n",
      "100:\tlearn: 0.0847116\ttotal: 370ms\tremaining: 362ms\n",
      "101:\tlearn: 0.0840366\ttotal: 374ms\tremaining: 359ms\n",
      "102:\tlearn: 0.0837063\ttotal: 377ms\tremaining: 355ms\n",
      "103:\tlearn: 0.0832425\ttotal: 381ms\tremaining: 351ms\n",
      "104:\tlearn: 0.0829374\ttotal: 384ms\tremaining: 347ms\n",
      "105:\tlearn: 0.0825879\ttotal: 387ms\tremaining: 343ms\n",
      "106:\tlearn: 0.0823971\ttotal: 391ms\tremaining: 340ms\n",
      "107:\tlearn: 0.0821964\ttotal: 394ms\tremaining: 336ms\n",
      "108:\tlearn: 0.0820374\ttotal: 398ms\tremaining: 332ms\n",
      "109:\tlearn: 0.0814815\ttotal: 401ms\tremaining: 328ms\n",
      "110:\tlearn: 0.0806605\ttotal: 405ms\tremaining: 325ms\n",
      "111:\tlearn: 0.0801397\ttotal: 409ms\tremaining: 321ms\n",
      "112:\tlearn: 0.0794724\ttotal: 413ms\tremaining: 318ms\n",
      "113:\tlearn: 0.0791045\ttotal: 416ms\tremaining: 314ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114:\tlearn: 0.0789417\ttotal: 420ms\tremaining: 310ms\n",
      "115:\tlearn: 0.0784187\ttotal: 424ms\tremaining: 307ms\n",
      "116:\tlearn: 0.0782045\ttotal: 428ms\tremaining: 304ms\n",
      "117:\tlearn: 0.0777401\ttotal: 431ms\tremaining: 300ms\n",
      "118:\tlearn: 0.0773978\ttotal: 435ms\tremaining: 296ms\n",
      "119:\tlearn: 0.0771620\ttotal: 439ms\tremaining: 293ms\n",
      "120:\tlearn: 0.0767214\ttotal: 442ms\tremaining: 289ms\n",
      "121:\tlearn: 0.0761471\ttotal: 446ms\tremaining: 285ms\n",
      "122:\tlearn: 0.0755687\ttotal: 450ms\tremaining: 282ms\n",
      "123:\tlearn: 0.0753883\ttotal: 453ms\tremaining: 278ms\n",
      "124:\tlearn: 0.0751318\ttotal: 457ms\tremaining: 274ms\n",
      "125:\tlearn: 0.0745912\ttotal: 460ms\tremaining: 270ms\n",
      "126:\tlearn: 0.0741971\ttotal: 464ms\tremaining: 267ms\n",
      "127:\tlearn: 0.0738961\ttotal: 469ms\tremaining: 264ms\n",
      "128:\tlearn: 0.0733819\ttotal: 472ms\tremaining: 260ms\n",
      "129:\tlearn: 0.0728413\ttotal: 476ms\tremaining: 256ms\n",
      "130:\tlearn: 0.0728132\ttotal: 478ms\tremaining: 252ms\n",
      "131:\tlearn: 0.0726939\ttotal: 482ms\tremaining: 248ms\n",
      "132:\tlearn: 0.0722731\ttotal: 485ms\tremaining: 244ms\n",
      "133:\tlearn: 0.0721130\ttotal: 489ms\tremaining: 241ms\n",
      "134:\tlearn: 0.0718413\ttotal: 493ms\tremaining: 237ms\n",
      "135:\tlearn: 0.0715319\ttotal: 496ms\tremaining: 234ms\n",
      "136:\tlearn: 0.0711117\ttotal: 500ms\tremaining: 230ms\n",
      "137:\tlearn: 0.0708030\ttotal: 503ms\tremaining: 226ms\n",
      "138:\tlearn: 0.0706946\ttotal: 507ms\tremaining: 222ms\n",
      "139:\tlearn: 0.0702372\ttotal: 510ms\tremaining: 219ms\n",
      "140:\tlearn: 0.0697874\ttotal: 514ms\tremaining: 215ms\n",
      "141:\tlearn: 0.0694713\ttotal: 517ms\tremaining: 211ms\n",
      "142:\tlearn: 0.0692463\ttotal: 521ms\tremaining: 208ms\n",
      "143:\tlearn: 0.0689319\ttotal: 524ms\tremaining: 204ms\n",
      "144:\tlearn: 0.0684627\ttotal: 528ms\tremaining: 200ms\n",
      "145:\tlearn: 0.0684623\ttotal: 531ms\tremaining: 196ms\n",
      "146:\tlearn: 0.0682773\ttotal: 534ms\tremaining: 193ms\n",
      "147:\tlearn: 0.0679289\ttotal: 538ms\tremaining: 189ms\n",
      "148:\tlearn: 0.0676285\ttotal: 541ms\tremaining: 185ms\n",
      "149:\tlearn: 0.0674798\ttotal: 545ms\tremaining: 182ms\n",
      "150:\tlearn: 0.0673586\ttotal: 548ms\tremaining: 178ms\n",
      "151:\tlearn: 0.0670926\ttotal: 551ms\tremaining: 174ms\n",
      "152:\tlearn: 0.0664919\ttotal: 554ms\tremaining: 170ms\n",
      "153:\tlearn: 0.0659288\ttotal: 559ms\tremaining: 167ms\n",
      "154:\tlearn: 0.0654252\ttotal: 562ms\tremaining: 163ms\n",
      "155:\tlearn: 0.0652106\ttotal: 567ms\tremaining: 160ms\n",
      "156:\tlearn: 0.0646541\ttotal: 570ms\tremaining: 156ms\n",
      "157:\tlearn: 0.0644749\ttotal: 573ms\tremaining: 152ms\n",
      "158:\tlearn: 0.0643330\ttotal: 577ms\tremaining: 149ms\n",
      "159:\tlearn: 0.0641208\ttotal: 580ms\tremaining: 145ms\n",
      "160:\tlearn: 0.0638997\ttotal: 584ms\tremaining: 141ms\n",
      "161:\tlearn: 0.0635289\ttotal: 587ms\tremaining: 138ms\n",
      "162:\tlearn: 0.0632082\ttotal: 591ms\tremaining: 134ms\n",
      "163:\tlearn: 0.0627421\ttotal: 595ms\tremaining: 131ms\n",
      "164:\tlearn: 0.0624719\ttotal: 598ms\tremaining: 127ms\n",
      "165:\tlearn: 0.0622598\ttotal: 601ms\tremaining: 123ms\n",
      "166:\tlearn: 0.0618192\ttotal: 605ms\tremaining: 120ms\n",
      "167:\tlearn: 0.0615483\ttotal: 608ms\tremaining: 116ms\n",
      "168:\tlearn: 0.0615053\ttotal: 612ms\tremaining: 112ms\n",
      "169:\tlearn: 0.0612523\ttotal: 616ms\tremaining: 109ms\n",
      "170:\tlearn: 0.0610526\ttotal: 620ms\tremaining: 105ms\n",
      "171:\tlearn: 0.0608971\ttotal: 624ms\tremaining: 102ms\n",
      "172:\tlearn: 0.0608685\ttotal: 627ms\tremaining: 97.9ms\n",
      "173:\tlearn: 0.0606951\ttotal: 631ms\tremaining: 94.2ms\n",
      "174:\tlearn: 0.0604190\ttotal: 634ms\tremaining: 90.6ms\n",
      "175:\tlearn: 0.0601218\ttotal: 638ms\tremaining: 87ms\n",
      "176:\tlearn: 0.0597931\ttotal: 641ms\tremaining: 83.4ms\n",
      "177:\tlearn: 0.0596372\ttotal: 645ms\tremaining: 79.7ms\n",
      "178:\tlearn: 0.0592341\ttotal: 649ms\tremaining: 76.1ms\n",
      "179:\tlearn: 0.0589378\ttotal: 653ms\tremaining: 72.5ms\n",
      "180:\tlearn: 0.0588742\ttotal: 656ms\tremaining: 68.9ms\n",
      "181:\tlearn: 0.0587299\ttotal: 660ms\tremaining: 65.3ms\n",
      "182:\tlearn: 0.0584186\ttotal: 664ms\tremaining: 61.6ms\n",
      "183:\tlearn: 0.0580418\ttotal: 668ms\tremaining: 58.1ms\n",
      "184:\tlearn: 0.0577169\ttotal: 671ms\tremaining: 54.4ms\n",
      "185:\tlearn: 0.0574943\ttotal: 675ms\tremaining: 50.8ms\n",
      "186:\tlearn: 0.0573633\ttotal: 678ms\tremaining: 47.1ms\n",
      "187:\tlearn: 0.0570586\ttotal: 681ms\tremaining: 43.5ms\n",
      "188:\tlearn: 0.0568545\ttotal: 685ms\tremaining: 39.9ms\n",
      "189:\tlearn: 0.0567015\ttotal: 688ms\tremaining: 36.2ms\n",
      "190:\tlearn: 0.0566382\ttotal: 692ms\tremaining: 32.6ms\n",
      "191:\tlearn: 0.0565601\ttotal: 695ms\tremaining: 29ms\n",
      "192:\tlearn: 0.0562020\ttotal: 699ms\tremaining: 25.4ms\n",
      "193:\tlearn: 0.0556745\ttotal: 703ms\tremaining: 21.7ms\n",
      "194:\tlearn: 0.0554034\ttotal: 707ms\tremaining: 18.1ms\n",
      "195:\tlearn: 0.0553487\ttotal: 710ms\tremaining: 14.5ms\n",
      "196:\tlearn: 0.0552120\ttotal: 713ms\tremaining: 10.9ms\n",
      "197:\tlearn: 0.0550919\ttotal: 716ms\tremaining: 7.24ms\n",
      "198:\tlearn: 0.0547253\ttotal: 720ms\tremaining: 3.62ms\n",
      "199:\tlearn: 0.0543804\ttotal: 723ms\tremaining: 0us\n",
      "0:\tlearn: 0.6308687\ttotal: 3.12ms\tremaining: 620ms\n",
      "1:\tlearn: 0.5739381\ttotal: 6.36ms\tremaining: 630ms\n",
      "2:\tlearn: 0.5198942\ttotal: 9.75ms\tremaining: 640ms\n",
      "3:\tlearn: 0.4775523\ttotal: 13.5ms\tremaining: 660ms\n",
      "4:\tlearn: 0.4377273\ttotal: 16.9ms\tremaining: 659ms\n",
      "5:\tlearn: 0.4091673\ttotal: 20.2ms\tremaining: 654ms\n",
      "6:\tlearn: 0.3827383\ttotal: 23.6ms\tremaining: 651ms\n",
      "7:\tlearn: 0.3599789\ttotal: 26.8ms\tremaining: 644ms\n",
      "8:\tlearn: 0.3321173\ttotal: 30ms\tremaining: 636ms\n",
      "9:\tlearn: 0.3074918\ttotal: 33.3ms\tremaining: 632ms\n",
      "10:\tlearn: 0.2931055\ttotal: 36.7ms\tremaining: 630ms\n",
      "11:\tlearn: 0.2803945\ttotal: 40.7ms\tremaining: 638ms\n",
      "12:\tlearn: 0.2690446\ttotal: 44.1ms\tremaining: 634ms\n",
      "13:\tlearn: 0.2589034\ttotal: 47.3ms\tremaining: 628ms\n",
      "14:\tlearn: 0.2528247\ttotal: 50.8ms\tremaining: 626ms\n",
      "15:\tlearn: 0.2391422\ttotal: 54.1ms\tremaining: 622ms\n",
      "16:\tlearn: 0.2331410\ttotal: 57.6ms\tremaining: 620ms\n",
      "17:\tlearn: 0.2277675\ttotal: 61.1ms\tremaining: 618ms\n",
      "18:\tlearn: 0.2182349\ttotal: 65.4ms\tremaining: 623ms\n",
      "19:\tlearn: 0.2140624\ttotal: 68.6ms\tremaining: 617ms\n",
      "20:\tlearn: 0.2068664\ttotal: 72ms\tremaining: 614ms\n",
      "21:\tlearn: 0.2023012\ttotal: 75.5ms\tremaining: 611ms\n",
      "22:\tlearn: 0.1947816\ttotal: 79ms\tremaining: 608ms\n",
      "23:\tlearn: 0.1916474\ttotal: 82.8ms\tremaining: 607ms\n",
      "24:\tlearn: 0.1887785\ttotal: 86.1ms\tremaining: 603ms\n",
      "25:\tlearn: 0.1867150\ttotal: 90.5ms\tremaining: 606ms\n",
      "26:\tlearn: 0.1826038\ttotal: 93.8ms\tremaining: 601ms\n",
      "27:\tlearn: 0.1791031\ttotal: 97.1ms\tremaining: 596ms\n",
      "28:\tlearn: 0.1745055\ttotal: 100ms\tremaining: 593ms\n",
      "29:\tlearn: 0.1717092\ttotal: 104ms\tremaining: 591ms\n",
      "30:\tlearn: 0.1691580\ttotal: 107ms\tremaining: 586ms\n",
      "31:\tlearn: 0.1656956\ttotal: 112ms\tremaining: 586ms\n",
      "32:\tlearn: 0.1634480\ttotal: 116ms\tremaining: 587ms\n",
      "33:\tlearn: 0.1615794\ttotal: 120ms\tremaining: 584ms\n",
      "34:\tlearn: 0.1580887\ttotal: 124ms\tremaining: 584ms\n",
      "35:\tlearn: 0.1546624\ttotal: 128ms\tremaining: 583ms\n",
      "36:\tlearn: 0.1530632\ttotal: 132ms\tremaining: 579ms\n",
      "37:\tlearn: 0.1510574\ttotal: 135ms\tremaining: 576ms\n",
      "38:\tlearn: 0.1491649\ttotal: 138ms\tremaining: 571ms\n",
      "39:\tlearn: 0.1470850\ttotal: 143ms\tremaining: 571ms\n",
      "40:\tlearn: 0.1440561\ttotal: 146ms\tremaining: 566ms\n",
      "41:\tlearn: 0.1426536\ttotal: 149ms\tremaining: 561ms\n",
      "42:\tlearn: 0.1417755\ttotal: 152ms\tremaining: 557ms\n",
      "43:\tlearn: 0.1406057\ttotal: 156ms\tremaining: 555ms\n",
      "44:\tlearn: 0.1385662\ttotal: 161ms\tremaining: 553ms\n",
      "45:\tlearn: 0.1368979\ttotal: 164ms\tremaining: 550ms\n",
      "46:\tlearn: 0.1356106\ttotal: 167ms\tremaining: 545ms\n",
      "47:\tlearn: 0.1337946\ttotal: 171ms\tremaining: 542ms\n",
      "48:\tlearn: 0.1320524\ttotal: 175ms\tremaining: 539ms\n",
      "49:\tlearn: 0.1307374\ttotal: 178ms\tremaining: 535ms\n",
      "50:\tlearn: 0.1297818\ttotal: 182ms\tremaining: 532ms\n",
      "51:\tlearn: 0.1289193\ttotal: 186ms\tremaining: 528ms\n",
      "52:\tlearn: 0.1279809\ttotal: 189ms\tremaining: 524ms\n",
      "53:\tlearn: 0.1264246\ttotal: 193ms\tremaining: 521ms\n",
      "54:\tlearn: 0.1251082\ttotal: 196ms\tremaining: 517ms\n",
      "55:\tlearn: 0.1230040\ttotal: 199ms\tremaining: 513ms\n",
      "56:\tlearn: 0.1215387\ttotal: 203ms\tremaining: 509ms\n",
      "57:\tlearn: 0.1203405\ttotal: 206ms\tremaining: 504ms\n",
      "58:\tlearn: 0.1190908\ttotal: 210ms\tremaining: 502ms\n",
      "59:\tlearn: 0.1177056\ttotal: 214ms\tremaining: 499ms\n",
      "60:\tlearn: 0.1164640\ttotal: 218ms\tremaining: 497ms\n",
      "61:\tlearn: 0.1149492\ttotal: 222ms\tremaining: 493ms\n",
      "62:\tlearn: 0.1141303\ttotal: 225ms\tremaining: 489ms\n",
      "63:\tlearn: 0.1130916\ttotal: 229ms\tremaining: 486ms\n",
      "64:\tlearn: 0.1117377\ttotal: 232ms\tremaining: 483ms\n",
      "65:\tlearn: 0.1109051\ttotal: 236ms\tremaining: 478ms\n",
      "66:\tlearn: 0.1099606\ttotal: 239ms\tremaining: 474ms\n",
      "67:\tlearn: 0.1088442\ttotal: 242ms\tremaining: 471ms\n",
      "68:\tlearn: 0.1076465\ttotal: 246ms\tremaining: 467ms\n",
      "69:\tlearn: 0.1070734\ttotal: 249ms\tremaining: 463ms\n",
      "70:\tlearn: 0.1063150\ttotal: 253ms\tremaining: 459ms\n",
      "71:\tlearn: 0.1057313\ttotal: 257ms\tremaining: 456ms\n",
      "72:\tlearn: 0.1050113\ttotal: 260ms\tremaining: 452ms\n",
      "73:\tlearn: 0.1043148\ttotal: 264ms\tremaining: 449ms\n",
      "74:\tlearn: 0.1040504\ttotal: 267ms\tremaining: 445ms\n",
      "75:\tlearn: 0.1031509\ttotal: 270ms\tremaining: 441ms\n",
      "76:\tlearn: 0.1027008\ttotal: 274ms\tremaining: 438ms\n",
      "77:\tlearn: 0.1022932\ttotal: 278ms\tremaining: 434ms\n",
      "78:\tlearn: 0.1014407\ttotal: 281ms\tremaining: 431ms\n",
      "79:\tlearn: 0.1010258\ttotal: 285ms\tremaining: 428ms\n",
      "80:\tlearn: 0.1002153\ttotal: 289ms\tremaining: 424ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81:\tlearn: 0.0999048\ttotal: 292ms\tremaining: 420ms\n",
      "82:\tlearn: 0.0987565\ttotal: 295ms\tremaining: 416ms\n",
      "83:\tlearn: 0.0981567\ttotal: 300ms\tremaining: 414ms\n",
      "84:\tlearn: 0.0973818\ttotal: 304ms\tremaining: 411ms\n",
      "85:\tlearn: 0.0965847\ttotal: 307ms\tremaining: 408ms\n",
      "86:\tlearn: 0.0960434\ttotal: 311ms\tremaining: 404ms\n",
      "87:\tlearn: 0.0956435\ttotal: 315ms\tremaining: 400ms\n",
      "88:\tlearn: 0.0948589\ttotal: 318ms\tremaining: 397ms\n",
      "89:\tlearn: 0.0945654\ttotal: 321ms\tremaining: 393ms\n",
      "90:\tlearn: 0.0937743\ttotal: 325ms\tremaining: 389ms\n",
      "91:\tlearn: 0.0935864\ttotal: 328ms\tremaining: 385ms\n",
      "92:\tlearn: 0.0930945\ttotal: 332ms\tremaining: 382ms\n",
      "93:\tlearn: 0.0924301\ttotal: 336ms\tremaining: 379ms\n",
      "94:\tlearn: 0.0917653\ttotal: 340ms\tremaining: 375ms\n",
      "95:\tlearn: 0.0914029\ttotal: 343ms\tremaining: 372ms\n",
      "96:\tlearn: 0.0914020\ttotal: 345ms\tremaining: 367ms\n",
      "97:\tlearn: 0.0910467\ttotal: 349ms\tremaining: 363ms\n",
      "98:\tlearn: 0.0906540\ttotal: 352ms\tremaining: 360ms\n",
      "99:\tlearn: 0.0902352\ttotal: 356ms\tremaining: 356ms\n",
      "100:\tlearn: 0.0898316\ttotal: 359ms\tremaining: 352ms\n",
      "101:\tlearn: 0.0898309\ttotal: 361ms\tremaining: 347ms\n",
      "102:\tlearn: 0.0895565\ttotal: 365ms\tremaining: 344ms\n",
      "103:\tlearn: 0.0887854\ttotal: 369ms\tremaining: 341ms\n",
      "104:\tlearn: 0.0883984\ttotal: 372ms\tremaining: 337ms\n",
      "105:\tlearn: 0.0879468\ttotal: 376ms\tremaining: 333ms\n",
      "106:\tlearn: 0.0874446\ttotal: 379ms\tremaining: 329ms\n",
      "107:\tlearn: 0.0870599\ttotal: 382ms\tremaining: 326ms\n",
      "108:\tlearn: 0.0863684\ttotal: 386ms\tremaining: 322ms\n",
      "109:\tlearn: 0.0863197\ttotal: 389ms\tremaining: 318ms\n",
      "110:\tlearn: 0.0861705\ttotal: 392ms\tremaining: 314ms\n",
      "111:\tlearn: 0.0859682\ttotal: 395ms\tremaining: 311ms\n",
      "112:\tlearn: 0.0855818\ttotal: 399ms\tremaining: 307ms\n",
      "113:\tlearn: 0.0850766\ttotal: 402ms\tremaining: 303ms\n",
      "114:\tlearn: 0.0846301\ttotal: 406ms\tremaining: 300ms\n",
      "115:\tlearn: 0.0845113\ttotal: 410ms\tremaining: 297ms\n",
      "116:\tlearn: 0.0841652\ttotal: 413ms\tremaining: 293ms\n",
      "117:\tlearn: 0.0838410\ttotal: 416ms\tremaining: 289ms\n",
      "118:\tlearn: 0.0832036\ttotal: 420ms\tremaining: 286ms\n",
      "119:\tlearn: 0.0829375\ttotal: 424ms\tremaining: 283ms\n",
      "120:\tlearn: 0.0825149\ttotal: 428ms\tremaining: 279ms\n",
      "121:\tlearn: 0.0822758\ttotal: 431ms\tremaining: 276ms\n",
      "122:\tlearn: 0.0821056\ttotal: 435ms\tremaining: 272ms\n",
      "123:\tlearn: 0.0819899\ttotal: 438ms\tremaining: 268ms\n",
      "124:\tlearn: 0.0817011\ttotal: 441ms\tremaining: 265ms\n",
      "125:\tlearn: 0.0814104\ttotal: 445ms\tremaining: 261ms\n",
      "126:\tlearn: 0.0812207\ttotal: 448ms\tremaining: 257ms\n",
      "127:\tlearn: 0.0808850\ttotal: 451ms\tremaining: 254ms\n",
      "128:\tlearn: 0.0803914\ttotal: 455ms\tremaining: 250ms\n",
      "129:\tlearn: 0.0802277\ttotal: 459ms\tremaining: 247ms\n",
      "130:\tlearn: 0.0799541\ttotal: 462ms\tremaining: 244ms\n",
      "131:\tlearn: 0.0797230\ttotal: 466ms\tremaining: 240ms\n",
      "132:\tlearn: 0.0796761\ttotal: 470ms\tremaining: 237ms\n",
      "133:\tlearn: 0.0790054\ttotal: 473ms\tremaining: 233ms\n",
      "134:\tlearn: 0.0788429\ttotal: 477ms\tremaining: 230ms\n",
      "135:\tlearn: 0.0784427\ttotal: 481ms\tremaining: 226ms\n",
      "136:\tlearn: 0.0782136\ttotal: 484ms\tremaining: 223ms\n",
      "137:\tlearn: 0.0777834\ttotal: 487ms\tremaining: 219ms\n",
      "138:\tlearn: 0.0773076\ttotal: 490ms\tremaining: 215ms\n",
      "139:\tlearn: 0.0769274\ttotal: 494ms\tremaining: 212ms\n",
      "140:\tlearn: 0.0763736\ttotal: 498ms\tremaining: 208ms\n",
      "141:\tlearn: 0.0760492\ttotal: 501ms\tremaining: 205ms\n",
      "142:\tlearn: 0.0753482\ttotal: 505ms\tremaining: 201ms\n",
      "143:\tlearn: 0.0749851\ttotal: 508ms\tremaining: 198ms\n",
      "144:\tlearn: 0.0749839\ttotal: 510ms\tremaining: 193ms\n",
      "145:\tlearn: 0.0747645\ttotal: 514ms\tremaining: 190ms\n",
      "146:\tlearn: 0.0747630\ttotal: 516ms\tremaining: 186ms\n",
      "147:\tlearn: 0.0745456\ttotal: 520ms\tremaining: 183ms\n",
      "148:\tlearn: 0.0744255\ttotal: 524ms\tremaining: 179ms\n",
      "149:\tlearn: 0.0742335\ttotal: 528ms\tremaining: 176ms\n",
      "150:\tlearn: 0.0739649\ttotal: 531ms\tremaining: 172ms\n",
      "151:\tlearn: 0.0735571\ttotal: 534ms\tremaining: 169ms\n",
      "152:\tlearn: 0.0731175\ttotal: 539ms\tremaining: 166ms\n",
      "153:\tlearn: 0.0728569\ttotal: 544ms\tremaining: 162ms\n",
      "154:\tlearn: 0.0725901\ttotal: 547ms\tremaining: 159ms\n",
      "155:\tlearn: 0.0725892\ttotal: 550ms\tremaining: 155ms\n",
      "156:\tlearn: 0.0723600\ttotal: 553ms\tremaining: 152ms\n",
      "157:\tlearn: 0.0718388\ttotal: 557ms\tremaining: 148ms\n",
      "158:\tlearn: 0.0718386\ttotal: 559ms\tremaining: 144ms\n",
      "159:\tlearn: 0.0714477\ttotal: 562ms\tremaining: 141ms\n",
      "160:\tlearn: 0.0709978\ttotal: 566ms\tremaining: 137ms\n",
      "161:\tlearn: 0.0709975\ttotal: 568ms\tremaining: 133ms\n",
      "162:\tlearn: 0.0706681\ttotal: 572ms\tremaining: 130ms\n",
      "163:\tlearn: 0.0706628\ttotal: 574ms\tremaining: 126ms\n",
      "164:\tlearn: 0.0703522\ttotal: 577ms\tremaining: 122ms\n",
      "165:\tlearn: 0.0701602\ttotal: 581ms\tremaining: 119ms\n",
      "166:\tlearn: 0.0698057\ttotal: 584ms\tremaining: 115ms\n",
      "167:\tlearn: 0.0695625\ttotal: 587ms\tremaining: 112ms\n",
      "168:\tlearn: 0.0693148\ttotal: 590ms\tremaining: 108ms\n",
      "169:\tlearn: 0.0693101\ttotal: 593ms\tremaining: 105ms\n",
      "170:\tlearn: 0.0690486\ttotal: 596ms\tremaining: 101ms\n",
      "171:\tlearn: 0.0687466\ttotal: 600ms\tremaining: 97.6ms\n",
      "172:\tlearn: 0.0684422\ttotal: 603ms\tremaining: 94.2ms\n",
      "173:\tlearn: 0.0682011\ttotal: 607ms\tremaining: 90.6ms\n",
      "174:\tlearn: 0.0677405\ttotal: 611ms\tremaining: 87.3ms\n",
      "175:\tlearn: 0.0677390\ttotal: 614ms\tremaining: 83.7ms\n",
      "176:\tlearn: 0.0672981\ttotal: 617ms\tremaining: 80.2ms\n",
      "177:\tlearn: 0.0672591\ttotal: 621ms\tremaining: 76.8ms\n",
      "178:\tlearn: 0.0668393\ttotal: 625ms\tremaining: 73.3ms\n",
      "179:\tlearn: 0.0665028\ttotal: 628ms\tremaining: 69.8ms\n",
      "180:\tlearn: 0.0665002\ttotal: 630ms\tremaining: 66.2ms\n",
      "181:\tlearn: 0.0662982\ttotal: 634ms\tremaining: 62.7ms\n",
      "182:\tlearn: 0.0660072\ttotal: 637ms\tremaining: 59.2ms\n",
      "183:\tlearn: 0.0660030\ttotal: 640ms\tremaining: 55.7ms\n",
      "184:\tlearn: 0.0659793\ttotal: 643ms\tremaining: 52.1ms\n",
      "185:\tlearn: 0.0656831\ttotal: 646ms\tremaining: 48.6ms\n",
      "186:\tlearn: 0.0654088\ttotal: 650ms\tremaining: 45.2ms\n",
      "187:\tlearn: 0.0651454\ttotal: 654ms\tremaining: 41.7ms\n",
      "188:\tlearn: 0.0649008\ttotal: 657ms\tremaining: 38.2ms\n",
      "189:\tlearn: 0.0643312\ttotal: 660ms\tremaining: 34.7ms\n",
      "190:\tlearn: 0.0639659\ttotal: 664ms\tremaining: 31.3ms\n",
      "191:\tlearn: 0.0636680\ttotal: 667ms\tremaining: 27.8ms\n",
      "192:\tlearn: 0.0635521\ttotal: 671ms\tremaining: 24.3ms\n",
      "193:\tlearn: 0.0632858\ttotal: 674ms\tremaining: 20.8ms\n",
      "194:\tlearn: 0.0630613\ttotal: 677ms\tremaining: 17.4ms\n",
      "195:\tlearn: 0.0630596\ttotal: 679ms\tremaining: 13.9ms\n",
      "196:\tlearn: 0.0628986\ttotal: 683ms\tremaining: 10.4ms\n",
      "197:\tlearn: 0.0625727\ttotal: 687ms\tremaining: 6.94ms\n",
      "198:\tlearn: 0.0621044\ttotal: 690ms\tremaining: 3.47ms\n",
      "199:\tlearn: 0.0618935\ttotal: 695ms\tremaining: 0us\n",
      "0:\tlearn: 0.6271446\ttotal: 3.89ms\tremaining: 775ms\n",
      "1:\tlearn: 0.5698713\ttotal: 6.99ms\tremaining: 692ms\n",
      "2:\tlearn: 0.5182519\ttotal: 10.3ms\tremaining: 677ms\n",
      "3:\tlearn: 0.4754737\ttotal: 13.3ms\tremaining: 652ms\n",
      "4:\tlearn: 0.4350932\ttotal: 16.7ms\tremaining: 650ms\n",
      "5:\tlearn: 0.4060177\ttotal: 19.7ms\tremaining: 636ms\n",
      "6:\tlearn: 0.3797951\ttotal: 22.8ms\tremaining: 628ms\n",
      "7:\tlearn: 0.3598643\ttotal: 26.1ms\tremaining: 627ms\n",
      "8:\tlearn: 0.3312458\ttotal: 29.5ms\tremaining: 626ms\n",
      "9:\tlearn: 0.3151467\ttotal: 32.8ms\tremaining: 623ms\n",
      "10:\tlearn: 0.2945902\ttotal: 36.3ms\tremaining: 624ms\n",
      "11:\tlearn: 0.2815087\ttotal: 40.3ms\tremaining: 631ms\n",
      "12:\tlearn: 0.2712600\ttotal: 43.8ms\tremaining: 630ms\n",
      "13:\tlearn: 0.2611873\ttotal: 47.3ms\tremaining: 628ms\n",
      "14:\tlearn: 0.2541814\ttotal: 51.2ms\tremaining: 632ms\n",
      "15:\tlearn: 0.2407856\ttotal: 54.8ms\tremaining: 630ms\n",
      "16:\tlearn: 0.2344542\ttotal: 58.3ms\tremaining: 628ms\n",
      "17:\tlearn: 0.2294103\ttotal: 61.8ms\tremaining: 625ms\n",
      "18:\tlearn: 0.2247233\ttotal: 65.2ms\tremaining: 622ms\n",
      "19:\tlearn: 0.2200510\ttotal: 69.3ms\tremaining: 624ms\n",
      "20:\tlearn: 0.2114728\ttotal: 72.8ms\tremaining: 621ms\n",
      "21:\tlearn: 0.2067216\ttotal: 76.5ms\tremaining: 619ms\n",
      "22:\tlearn: 0.2033708\ttotal: 80.3ms\tremaining: 618ms\n",
      "23:\tlearn: 0.1978990\ttotal: 83.7ms\tremaining: 614ms\n",
      "24:\tlearn: 0.1946136\ttotal: 87.9ms\tremaining: 615ms\n",
      "25:\tlearn: 0.1891196\ttotal: 91.8ms\tremaining: 614ms\n",
      "26:\tlearn: 0.1854104\ttotal: 95.1ms\tremaining: 610ms\n",
      "27:\tlearn: 0.1818917\ttotal: 98.6ms\tremaining: 606ms\n",
      "28:\tlearn: 0.1789785\ttotal: 102ms\tremaining: 601ms\n",
      "29:\tlearn: 0.1732860\ttotal: 106ms\tremaining: 598ms\n",
      "30:\tlearn: 0.1705485\ttotal: 109ms\tremaining: 595ms\n",
      "31:\tlearn: 0.1663435\ttotal: 113ms\tremaining: 591ms\n",
      "32:\tlearn: 0.1643213\ttotal: 116ms\tremaining: 587ms\n",
      "33:\tlearn: 0.1624867\ttotal: 120ms\tremaining: 584ms\n",
      "34:\tlearn: 0.1598037\ttotal: 123ms\tremaining: 579ms\n",
      "35:\tlearn: 0.1578389\ttotal: 126ms\tremaining: 574ms\n",
      "36:\tlearn: 0.1563246\ttotal: 129ms\tremaining: 570ms\n",
      "37:\tlearn: 0.1532039\ttotal: 133ms\tremaining: 567ms\n",
      "38:\tlearn: 0.1516289\ttotal: 137ms\tremaining: 567ms\n",
      "39:\tlearn: 0.1502057\ttotal: 142ms\tremaining: 566ms\n",
      "40:\tlearn: 0.1480249\ttotal: 146ms\tremaining: 565ms\n",
      "41:\tlearn: 0.1454227\ttotal: 150ms\tremaining: 563ms\n",
      "42:\tlearn: 0.1435066\ttotal: 153ms\tremaining: 559ms\n",
      "43:\tlearn: 0.1410748\ttotal: 157ms\tremaining: 556ms\n",
      "44:\tlearn: 0.1402428\ttotal: 160ms\tremaining: 552ms\n",
      "45:\tlearn: 0.1387377\ttotal: 164ms\tremaining: 548ms\n",
      "46:\tlearn: 0.1365976\ttotal: 167ms\tremaining: 544ms\n",
      "47:\tlearn: 0.1352611\ttotal: 171ms\tremaining: 542ms\n",
      "48:\tlearn: 0.1341323\ttotal: 174ms\tremaining: 538ms\n",
      "49:\tlearn: 0.1320754\ttotal: 178ms\tremaining: 534ms\n",
      "50:\tlearn: 0.1311014\ttotal: 182ms\tremaining: 531ms\n",
      "51:\tlearn: 0.1296203\ttotal: 185ms\tremaining: 527ms\n",
      "52:\tlearn: 0.1274900\ttotal: 189ms\tremaining: 523ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53:\tlearn: 0.1259904\ttotal: 192ms\tremaining: 520ms\n",
      "54:\tlearn: 0.1246545\ttotal: 196ms\tremaining: 516ms\n",
      "55:\tlearn: 0.1232093\ttotal: 199ms\tremaining: 511ms\n",
      "56:\tlearn: 0.1224351\ttotal: 202ms\tremaining: 508ms\n",
      "57:\tlearn: 0.1210814\ttotal: 206ms\tremaining: 504ms\n",
      "58:\tlearn: 0.1195579\ttotal: 209ms\tremaining: 500ms\n",
      "59:\tlearn: 0.1183323\ttotal: 214ms\tremaining: 500ms\n",
      "60:\tlearn: 0.1174106\ttotal: 217ms\tremaining: 495ms\n",
      "61:\tlearn: 0.1160271\ttotal: 221ms\tremaining: 491ms\n",
      "62:\tlearn: 0.1146259\ttotal: 224ms\tremaining: 488ms\n",
      "63:\tlearn: 0.1138433\ttotal: 228ms\tremaining: 485ms\n",
      "64:\tlearn: 0.1126027\ttotal: 233ms\tremaining: 483ms\n",
      "65:\tlearn: 0.1120205\ttotal: 237ms\tremaining: 481ms\n",
      "66:\tlearn: 0.1109262\ttotal: 240ms\tremaining: 477ms\n",
      "67:\tlearn: 0.1099882\ttotal: 244ms\tremaining: 473ms\n",
      "68:\tlearn: 0.1096242\ttotal: 247ms\tremaining: 470ms\n",
      "69:\tlearn: 0.1091477\ttotal: 251ms\tremaining: 465ms\n",
      "70:\tlearn: 0.1086662\ttotal: 254ms\tremaining: 461ms\n",
      "71:\tlearn: 0.1080988\ttotal: 257ms\tremaining: 458ms\n",
      "72:\tlearn: 0.1074507\ttotal: 261ms\tremaining: 454ms\n",
      "73:\tlearn: 0.1068257\ttotal: 264ms\tremaining: 450ms\n",
      "74:\tlearn: 0.1056777\ttotal: 267ms\tremaining: 446ms\n",
      "75:\tlearn: 0.1049045\ttotal: 271ms\tremaining: 443ms\n",
      "76:\tlearn: 0.1034396\ttotal: 275ms\tremaining: 439ms\n",
      "77:\tlearn: 0.1026195\ttotal: 278ms\tremaining: 435ms\n",
      "78:\tlearn: 0.1019766\ttotal: 282ms\tremaining: 431ms\n",
      "79:\tlearn: 0.1009758\ttotal: 285ms\tremaining: 427ms\n",
      "80:\tlearn: 0.1004393\ttotal: 288ms\tremaining: 424ms\n",
      "81:\tlearn: 0.0995959\ttotal: 292ms\tremaining: 420ms\n",
      "82:\tlearn: 0.0991764\ttotal: 295ms\tremaining: 416ms\n",
      "83:\tlearn: 0.0987003\ttotal: 299ms\tremaining: 413ms\n",
      "84:\tlearn: 0.0980918\ttotal: 303ms\tremaining: 409ms\n",
      "85:\tlearn: 0.0977701\ttotal: 306ms\tremaining: 405ms\n",
      "86:\tlearn: 0.0970917\ttotal: 309ms\tremaining: 402ms\n",
      "87:\tlearn: 0.0966112\ttotal: 313ms\tremaining: 399ms\n",
      "88:\tlearn: 0.0958315\ttotal: 317ms\tremaining: 396ms\n",
      "89:\tlearn: 0.0954652\ttotal: 320ms\tremaining: 392ms\n",
      "90:\tlearn: 0.0949816\ttotal: 324ms\tremaining: 388ms\n",
      "91:\tlearn: 0.0945440\ttotal: 328ms\tremaining: 385ms\n",
      "92:\tlearn: 0.0938580\ttotal: 331ms\tremaining: 381ms\n",
      "93:\tlearn: 0.0935952\ttotal: 335ms\tremaining: 377ms\n",
      "94:\tlearn: 0.0932343\ttotal: 338ms\tremaining: 373ms\n",
      "95:\tlearn: 0.0924767\ttotal: 342ms\tremaining: 370ms\n",
      "96:\tlearn: 0.0918288\ttotal: 345ms\tremaining: 366ms\n",
      "97:\tlearn: 0.0914375\ttotal: 348ms\tremaining: 362ms\n",
      "98:\tlearn: 0.0905889\ttotal: 351ms\tremaining: 358ms\n",
      "99:\tlearn: 0.0901976\ttotal: 355ms\tremaining: 355ms\n",
      "100:\tlearn: 0.0897105\ttotal: 358ms\tremaining: 351ms\n",
      "101:\tlearn: 0.0889706\ttotal: 362ms\tremaining: 348ms\n",
      "102:\tlearn: 0.0884164\ttotal: 365ms\tremaining: 344ms\n",
      "103:\tlearn: 0.0881449\ttotal: 369ms\tremaining: 340ms\n",
      "104:\tlearn: 0.0876238\ttotal: 372ms\tremaining: 337ms\n",
      "105:\tlearn: 0.0872387\ttotal: 375ms\tremaining: 333ms\n",
      "106:\tlearn: 0.0866038\ttotal: 379ms\tremaining: 329ms\n",
      "107:\tlearn: 0.0863611\ttotal: 383ms\tremaining: 326ms\n",
      "108:\tlearn: 0.0860219\ttotal: 386ms\tremaining: 322ms\n",
      "109:\tlearn: 0.0854636\ttotal: 389ms\tremaining: 318ms\n",
      "110:\tlearn: 0.0853481\ttotal: 392ms\tremaining: 314ms\n",
      "111:\tlearn: 0.0845544\ttotal: 395ms\tremaining: 311ms\n",
      "112:\tlearn: 0.0841030\ttotal: 398ms\tremaining: 307ms\n",
      "113:\tlearn: 0.0839562\ttotal: 401ms\tremaining: 303ms\n",
      "114:\tlearn: 0.0836289\ttotal: 405ms\tremaining: 299ms\n",
      "115:\tlearn: 0.0829034\ttotal: 408ms\tremaining: 295ms\n",
      "116:\tlearn: 0.0824401\ttotal: 411ms\tremaining: 292ms\n",
      "117:\tlearn: 0.0820040\ttotal: 416ms\tremaining: 289ms\n",
      "118:\tlearn: 0.0817883\ttotal: 419ms\tremaining: 285ms\n",
      "119:\tlearn: 0.0815993\ttotal: 423ms\tremaining: 282ms\n",
      "120:\tlearn: 0.0813649\ttotal: 426ms\tremaining: 278ms\n",
      "121:\tlearn: 0.0811688\ttotal: 430ms\tremaining: 275ms\n",
      "122:\tlearn: 0.0809859\ttotal: 434ms\tremaining: 271ms\n",
      "123:\tlearn: 0.0805418\ttotal: 437ms\tremaining: 268ms\n",
      "124:\tlearn: 0.0799336\ttotal: 441ms\tremaining: 264ms\n",
      "125:\tlearn: 0.0793647\ttotal: 444ms\tremaining: 261ms\n",
      "126:\tlearn: 0.0789539\ttotal: 448ms\tremaining: 257ms\n",
      "127:\tlearn: 0.0783096\ttotal: 451ms\tremaining: 254ms\n",
      "128:\tlearn: 0.0779067\ttotal: 455ms\tremaining: 251ms\n",
      "129:\tlearn: 0.0775049\ttotal: 459ms\tremaining: 247ms\n",
      "130:\tlearn: 0.0772920\ttotal: 462ms\tremaining: 243ms\n",
      "131:\tlearn: 0.0770011\ttotal: 466ms\tremaining: 240ms\n",
      "132:\tlearn: 0.0765121\ttotal: 470ms\tremaining: 237ms\n",
      "133:\tlearn: 0.0758424\ttotal: 473ms\tremaining: 233ms\n",
      "134:\tlearn: 0.0756510\ttotal: 477ms\tremaining: 230ms\n",
      "135:\tlearn: 0.0755450\ttotal: 481ms\tremaining: 226ms\n",
      "136:\tlearn: 0.0754575\ttotal: 484ms\tremaining: 223ms\n",
      "137:\tlearn: 0.0751480\ttotal: 488ms\tremaining: 219ms\n",
      "138:\tlearn: 0.0749265\ttotal: 492ms\tremaining: 216ms\n",
      "139:\tlearn: 0.0748682\ttotal: 495ms\tremaining: 212ms\n",
      "140:\tlearn: 0.0745139\ttotal: 498ms\tremaining: 208ms\n",
      "141:\tlearn: 0.0740940\ttotal: 502ms\tremaining: 205ms\n",
      "142:\tlearn: 0.0739092\ttotal: 505ms\tremaining: 201ms\n",
      "143:\tlearn: 0.0735800\ttotal: 508ms\tremaining: 198ms\n",
      "144:\tlearn: 0.0731250\ttotal: 513ms\tremaining: 194ms\n",
      "145:\tlearn: 0.0727627\ttotal: 517ms\tremaining: 191ms\n",
      "146:\tlearn: 0.0724572\ttotal: 520ms\tremaining: 188ms\n",
      "147:\tlearn: 0.0723512\ttotal: 524ms\tremaining: 184ms\n",
      "148:\tlearn: 0.0722067\ttotal: 527ms\tremaining: 180ms\n",
      "149:\tlearn: 0.0717415\ttotal: 530ms\tremaining: 177ms\n",
      "150:\tlearn: 0.0713775\ttotal: 534ms\tremaining: 173ms\n",
      "151:\tlearn: 0.0711026\ttotal: 537ms\tremaining: 170ms\n",
      "152:\tlearn: 0.0709658\ttotal: 541ms\tremaining: 166ms\n",
      "153:\tlearn: 0.0704694\ttotal: 544ms\tremaining: 163ms\n",
      "154:\tlearn: 0.0703712\ttotal: 548ms\tremaining: 159ms\n",
      "155:\tlearn: 0.0698760\ttotal: 551ms\tremaining: 155ms\n",
      "156:\tlearn: 0.0695593\ttotal: 555ms\tremaining: 152ms\n",
      "157:\tlearn: 0.0695267\ttotal: 558ms\tremaining: 148ms\n",
      "158:\tlearn: 0.0693985\ttotal: 561ms\tremaining: 145ms\n",
      "159:\tlearn: 0.0691294\ttotal: 565ms\tremaining: 141ms\n",
      "160:\tlearn: 0.0689115\ttotal: 569ms\tremaining: 138ms\n",
      "161:\tlearn: 0.0685824\ttotal: 572ms\tremaining: 134ms\n",
      "162:\tlearn: 0.0684212\ttotal: 575ms\tremaining: 131ms\n",
      "163:\tlearn: 0.0681242\ttotal: 579ms\tremaining: 127ms\n",
      "164:\tlearn: 0.0680058\ttotal: 582ms\tremaining: 123ms\n",
      "165:\tlearn: 0.0677929\ttotal: 586ms\tremaining: 120ms\n",
      "166:\tlearn: 0.0672335\ttotal: 589ms\tremaining: 116ms\n",
      "167:\tlearn: 0.0667247\ttotal: 592ms\tremaining: 113ms\n",
      "168:\tlearn: 0.0663424\ttotal: 596ms\tremaining: 109ms\n",
      "169:\tlearn: 0.0661948\ttotal: 599ms\tremaining: 106ms\n",
      "170:\tlearn: 0.0660991\ttotal: 603ms\tremaining: 102ms\n",
      "171:\tlearn: 0.0659027\ttotal: 606ms\tremaining: 98.7ms\n",
      "172:\tlearn: 0.0657371\ttotal: 610ms\tremaining: 95.2ms\n",
      "173:\tlearn: 0.0654548\ttotal: 614ms\tremaining: 91.7ms\n",
      "174:\tlearn: 0.0650631\ttotal: 618ms\tremaining: 88.3ms\n",
      "175:\tlearn: 0.0647380\ttotal: 621ms\tremaining: 84.7ms\n",
      "176:\tlearn: 0.0643677\ttotal: 625ms\tremaining: 81.2ms\n",
      "177:\tlearn: 0.0642222\ttotal: 628ms\tremaining: 77.7ms\n",
      "178:\tlearn: 0.0638490\ttotal: 632ms\tremaining: 74.1ms\n",
      "179:\tlearn: 0.0635100\ttotal: 636ms\tremaining: 70.6ms\n",
      "180:\tlearn: 0.0631480\ttotal: 639ms\tremaining: 67.1ms\n",
      "181:\tlearn: 0.0629148\ttotal: 644ms\tremaining: 63.7ms\n",
      "182:\tlearn: 0.0628910\ttotal: 646ms\tremaining: 60ms\n",
      "183:\tlearn: 0.0626847\ttotal: 650ms\tremaining: 56.5ms\n",
      "184:\tlearn: 0.0623726\ttotal: 654ms\tremaining: 53ms\n",
      "185:\tlearn: 0.0621972\ttotal: 658ms\tremaining: 49.5ms\n",
      "186:\tlearn: 0.0618233\ttotal: 661ms\tremaining: 46ms\n",
      "187:\tlearn: 0.0613751\ttotal: 665ms\tremaining: 42.4ms\n",
      "188:\tlearn: 0.0612858\ttotal: 669ms\tremaining: 38.9ms\n",
      "189:\tlearn: 0.0609716\ttotal: 673ms\tremaining: 35.4ms\n",
      "190:\tlearn: 0.0606016\ttotal: 676ms\tremaining: 31.9ms\n",
      "191:\tlearn: 0.0601963\ttotal: 680ms\tremaining: 28.3ms\n",
      "192:\tlearn: 0.0598353\ttotal: 683ms\tremaining: 24.8ms\n",
      "193:\tlearn: 0.0596869\ttotal: 687ms\tremaining: 21.2ms\n",
      "194:\tlearn: 0.0594034\ttotal: 690ms\tremaining: 17.7ms\n",
      "195:\tlearn: 0.0592341\ttotal: 694ms\tremaining: 14.2ms\n",
      "196:\tlearn: 0.0589763\ttotal: 697ms\tremaining: 10.6ms\n",
      "197:\tlearn: 0.0589318\ttotal: 700ms\tremaining: 7.08ms\n",
      "198:\tlearn: 0.0588176\ttotal: 704ms\tremaining: 3.54ms\n",
      "199:\tlearn: 0.0587375\ttotal: 708ms\tremaining: 0us\n",
      "0:\tlearn: 0.5640324\ttotal: 3.17ms\tremaining: 630ms\n",
      "1:\tlearn: 0.4826348\ttotal: 6.7ms\tremaining: 664ms\n",
      "2:\tlearn: 0.4095816\ttotal: 10.4ms\tremaining: 682ms\n",
      "3:\tlearn: 0.3454679\ttotal: 13.9ms\tremaining: 680ms\n",
      "4:\tlearn: 0.3200541\ttotal: 17.4ms\tremaining: 677ms\n",
      "5:\tlearn: 0.2906512\ttotal: 20.8ms\tremaining: 674ms\n",
      "6:\tlearn: 0.2662785\ttotal: 24.8ms\tremaining: 684ms\n",
      "7:\tlearn: 0.2491929\ttotal: 28.9ms\tremaining: 695ms\n",
      "8:\tlearn: 0.2319030\ttotal: 33.4ms\tremaining: 708ms\n",
      "9:\tlearn: 0.2198319\ttotal: 36.8ms\tremaining: 700ms\n",
      "10:\tlearn: 0.2101869\ttotal: 40.4ms\tremaining: 695ms\n",
      "11:\tlearn: 0.2008937\ttotal: 44.5ms\tremaining: 697ms\n",
      "12:\tlearn: 0.1860351\ttotal: 47.8ms\tremaining: 687ms\n",
      "13:\tlearn: 0.1791512\ttotal: 51.7ms\tremaining: 687ms\n",
      "14:\tlearn: 0.1682981\ttotal: 55.1ms\tremaining: 679ms\n",
      "15:\tlearn: 0.1598761\ttotal: 58.5ms\tremaining: 673ms\n",
      "16:\tlearn: 0.1525782\ttotal: 62.5ms\tremaining: 673ms\n",
      "17:\tlearn: 0.1486175\ttotal: 66.1ms\tremaining: 669ms\n",
      "18:\tlearn: 0.1457431\ttotal: 69.4ms\tremaining: 661ms\n",
      "19:\tlearn: 0.1420951\ttotal: 72.7ms\tremaining: 654ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:\tlearn: 0.1397941\ttotal: 76.1ms\tremaining: 649ms\n",
      "21:\tlearn: 0.1361909\ttotal: 79.7ms\tremaining: 645ms\n",
      "22:\tlearn: 0.1334995\ttotal: 83ms\tremaining: 639ms\n",
      "23:\tlearn: 0.1294634\ttotal: 86.6ms\tremaining: 635ms\n",
      "24:\tlearn: 0.1258872\ttotal: 89.8ms\tremaining: 628ms\n",
      "25:\tlearn: 0.1245815\ttotal: 94.1ms\tremaining: 630ms\n",
      "26:\tlearn: 0.1217693\ttotal: 97.5ms\tremaining: 625ms\n",
      "27:\tlearn: 0.1195988\ttotal: 101ms\tremaining: 621ms\n",
      "28:\tlearn: 0.1166771\ttotal: 105ms\tremaining: 617ms\n",
      "29:\tlearn: 0.1149600\ttotal: 108ms\tremaining: 614ms\n",
      "30:\tlearn: 0.1120057\ttotal: 112ms\tremaining: 609ms\n",
      "31:\tlearn: 0.1098038\ttotal: 116ms\tremaining: 609ms\n",
      "32:\tlearn: 0.1073083\ttotal: 120ms\tremaining: 605ms\n",
      "33:\tlearn: 0.1053083\ttotal: 123ms\tremaining: 602ms\n",
      "34:\tlearn: 0.1040173\ttotal: 127ms\tremaining: 598ms\n",
      "35:\tlearn: 0.1017340\ttotal: 130ms\tremaining: 594ms\n",
      "36:\tlearn: 0.0994821\ttotal: 134ms\tremaining: 591ms\n",
      "37:\tlearn: 0.0975368\ttotal: 138ms\tremaining: 588ms\n",
      "38:\tlearn: 0.0963443\ttotal: 142ms\tremaining: 584ms\n",
      "39:\tlearn: 0.0944003\ttotal: 145ms\tremaining: 581ms\n",
      "40:\tlearn: 0.0926833\ttotal: 150ms\tremaining: 580ms\n",
      "41:\tlearn: 0.0912075\ttotal: 153ms\tremaining: 575ms\n",
      "42:\tlearn: 0.0901123\ttotal: 156ms\tremaining: 571ms\n",
      "43:\tlearn: 0.0891431\ttotal: 160ms\tremaining: 567ms\n",
      "44:\tlearn: 0.0880530\ttotal: 163ms\tremaining: 563ms\n",
      "45:\tlearn: 0.0867123\ttotal: 167ms\tremaining: 559ms\n",
      "46:\tlearn: 0.0858816\ttotal: 171ms\tremaining: 555ms\n",
      "47:\tlearn: 0.0853134\ttotal: 174ms\tremaining: 552ms\n",
      "48:\tlearn: 0.0842982\ttotal: 178ms\tremaining: 548ms\n",
      "49:\tlearn: 0.0836863\ttotal: 181ms\tremaining: 544ms\n",
      "50:\tlearn: 0.0827177\ttotal: 185ms\tremaining: 539ms\n",
      "51:\tlearn: 0.0820187\ttotal: 189ms\tremaining: 537ms\n",
      "52:\tlearn: 0.0811366\ttotal: 192ms\tremaining: 533ms\n",
      "53:\tlearn: 0.0806939\ttotal: 196ms\tremaining: 529ms\n",
      "54:\tlearn: 0.0797361\ttotal: 199ms\tremaining: 525ms\n",
      "55:\tlearn: 0.0792365\ttotal: 202ms\tremaining: 520ms\n",
      "56:\tlearn: 0.0784891\ttotal: 206ms\tremaining: 516ms\n",
      "57:\tlearn: 0.0778493\ttotal: 209ms\tremaining: 512ms\n",
      "58:\tlearn: 0.0770393\ttotal: 214ms\tremaining: 510ms\n",
      "59:\tlearn: 0.0766222\ttotal: 218ms\tremaining: 508ms\n",
      "60:\tlearn: 0.0758602\ttotal: 221ms\tremaining: 504ms\n",
      "61:\tlearn: 0.0755841\ttotal: 224ms\tremaining: 500ms\n",
      "62:\tlearn: 0.0746667\ttotal: 228ms\tremaining: 496ms\n",
      "63:\tlearn: 0.0746065\ttotal: 230ms\tremaining: 489ms\n",
      "64:\tlearn: 0.0735583\ttotal: 234ms\tremaining: 487ms\n",
      "65:\tlearn: 0.0724811\ttotal: 238ms\tremaining: 483ms\n",
      "66:\tlearn: 0.0717388\ttotal: 241ms\tremaining: 479ms\n",
      "67:\tlearn: 0.0710425\ttotal: 245ms\tremaining: 475ms\n",
      "68:\tlearn: 0.0706445\ttotal: 248ms\tremaining: 471ms\n",
      "69:\tlearn: 0.0698398\ttotal: 252ms\tremaining: 467ms\n",
      "70:\tlearn: 0.0696848\ttotal: 256ms\tremaining: 464ms\n",
      "71:\tlearn: 0.0691592\ttotal: 260ms\tremaining: 462ms\n",
      "72:\tlearn: 0.0686393\ttotal: 263ms\tremaining: 458ms\n",
      "73:\tlearn: 0.0684122\ttotal: 267ms\tremaining: 454ms\n",
      "74:\tlearn: 0.0677980\ttotal: 271ms\tremaining: 451ms\n",
      "75:\tlearn: 0.0669134\ttotal: 274ms\tremaining: 447ms\n",
      "76:\tlearn: 0.0664272\ttotal: 278ms\tremaining: 444ms\n",
      "77:\tlearn: 0.0654512\ttotal: 281ms\tremaining: 439ms\n",
      "78:\tlearn: 0.0652575\ttotal: 284ms\tremaining: 435ms\n",
      "79:\tlearn: 0.0649437\ttotal: 289ms\tremaining: 433ms\n",
      "80:\tlearn: 0.0643813\ttotal: 292ms\tremaining: 429ms\n",
      "81:\tlearn: 0.0634949\ttotal: 296ms\tremaining: 426ms\n",
      "82:\tlearn: 0.0633058\ttotal: 299ms\tremaining: 422ms\n",
      "83:\tlearn: 0.0625593\ttotal: 303ms\tremaining: 418ms\n",
      "84:\tlearn: 0.0617284\ttotal: 306ms\tremaining: 415ms\n",
      "85:\tlearn: 0.0607281\ttotal: 310ms\tremaining: 411ms\n",
      "86:\tlearn: 0.0604004\ttotal: 314ms\tremaining: 408ms\n",
      "87:\tlearn: 0.0597950\ttotal: 318ms\tremaining: 404ms\n",
      "88:\tlearn: 0.0592473\ttotal: 321ms\tremaining: 400ms\n",
      "89:\tlearn: 0.0585361\ttotal: 324ms\tremaining: 396ms\n",
      "90:\tlearn: 0.0579289\ttotal: 328ms\tremaining: 393ms\n",
      "91:\tlearn: 0.0576739\ttotal: 331ms\tremaining: 388ms\n",
      "92:\tlearn: 0.0571499\ttotal: 334ms\tremaining: 384ms\n",
      "93:\tlearn: 0.0569020\ttotal: 338ms\tremaining: 381ms\n",
      "94:\tlearn: 0.0565733\ttotal: 341ms\tremaining: 377ms\n",
      "95:\tlearn: 0.0563289\ttotal: 346ms\tremaining: 374ms\n",
      "96:\tlearn: 0.0557464\ttotal: 349ms\tremaining: 371ms\n",
      "97:\tlearn: 0.0551781\ttotal: 353ms\tremaining: 367ms\n",
      "98:\tlearn: 0.0550246\ttotal: 356ms\tremaining: 363ms\n",
      "99:\tlearn: 0.0546508\ttotal: 360ms\tremaining: 360ms\n",
      "100:\tlearn: 0.0543668\ttotal: 364ms\tremaining: 356ms\n",
      "101:\tlearn: 0.0535165\ttotal: 367ms\tremaining: 353ms\n",
      "102:\tlearn: 0.0534753\ttotal: 371ms\tremaining: 349ms\n",
      "103:\tlearn: 0.0531581\ttotal: 374ms\tremaining: 345ms\n",
      "104:\tlearn: 0.0524251\ttotal: 378ms\tremaining: 342ms\n",
      "105:\tlearn: 0.0522082\ttotal: 381ms\tremaining: 338ms\n",
      "106:\tlearn: 0.0520649\ttotal: 386ms\tremaining: 335ms\n",
      "107:\tlearn: 0.0513378\ttotal: 389ms\tremaining: 331ms\n",
      "108:\tlearn: 0.0505858\ttotal: 392ms\tremaining: 327ms\n",
      "109:\tlearn: 0.0503341\ttotal: 396ms\tremaining: 324ms\n",
      "110:\tlearn: 0.0498671\ttotal: 400ms\tremaining: 320ms\n",
      "111:\tlearn: 0.0494006\ttotal: 403ms\tremaining: 317ms\n",
      "112:\tlearn: 0.0491241\ttotal: 407ms\tremaining: 313ms\n",
      "113:\tlearn: 0.0486857\ttotal: 410ms\tremaining: 310ms\n",
      "114:\tlearn: 0.0486013\ttotal: 414ms\tremaining: 306ms\n",
      "115:\tlearn: 0.0482020\ttotal: 417ms\tremaining: 302ms\n",
      "116:\tlearn: 0.0475168\ttotal: 421ms\tremaining: 298ms\n",
      "117:\tlearn: 0.0474096\ttotal: 424ms\tremaining: 295ms\n",
      "118:\tlearn: 0.0468591\ttotal: 428ms\tremaining: 291ms\n",
      "119:\tlearn: 0.0465430\ttotal: 432ms\tremaining: 288ms\n",
      "120:\tlearn: 0.0460190\ttotal: 435ms\tremaining: 284ms\n",
      "121:\tlearn: 0.0454898\ttotal: 439ms\tremaining: 280ms\n",
      "122:\tlearn: 0.0454300\ttotal: 442ms\tremaining: 277ms\n",
      "123:\tlearn: 0.0452131\ttotal: 446ms\tremaining: 273ms\n",
      "124:\tlearn: 0.0449328\ttotal: 450ms\tremaining: 270ms\n",
      "125:\tlearn: 0.0449082\ttotal: 453ms\tremaining: 266ms\n",
      "126:\tlearn: 0.0448950\ttotal: 457ms\tremaining: 263ms\n",
      "127:\tlearn: 0.0446015\ttotal: 461ms\tremaining: 259ms\n",
      "128:\tlearn: 0.0444097\ttotal: 464ms\tremaining: 256ms\n",
      "129:\tlearn: 0.0437676\ttotal: 468ms\tremaining: 252ms\n",
      "130:\tlearn: 0.0432486\ttotal: 472ms\tremaining: 248ms\n",
      "131:\tlearn: 0.0428424\ttotal: 475ms\tremaining: 245ms\n",
      "132:\tlearn: 0.0424856\ttotal: 479ms\tremaining: 241ms\n",
      "133:\tlearn: 0.0421453\ttotal: 483ms\tremaining: 238ms\n",
      "134:\tlearn: 0.0419346\ttotal: 486ms\tremaining: 234ms\n",
      "135:\tlearn: 0.0416662\ttotal: 490ms\tremaining: 231ms\n",
      "136:\tlearn: 0.0415285\ttotal: 494ms\tremaining: 227ms\n",
      "137:\tlearn: 0.0412367\ttotal: 498ms\tremaining: 224ms\n",
      "138:\tlearn: 0.0409231\ttotal: 501ms\tremaining: 220ms\n",
      "139:\tlearn: 0.0407941\ttotal: 504ms\tremaining: 216ms\n",
      "140:\tlearn: 0.0403653\ttotal: 509ms\tremaining: 213ms\n",
      "141:\tlearn: 0.0402380\ttotal: 513ms\tremaining: 210ms\n",
      "142:\tlearn: 0.0397131\ttotal: 517ms\tremaining: 206ms\n",
      "143:\tlearn: 0.0394491\ttotal: 520ms\tremaining: 202ms\n",
      "144:\tlearn: 0.0392456\ttotal: 524ms\tremaining: 199ms\n",
      "145:\tlearn: 0.0388372\ttotal: 528ms\tremaining: 195ms\n",
      "146:\tlearn: 0.0388299\ttotal: 532ms\tremaining: 192ms\n",
      "147:\tlearn: 0.0386696\ttotal: 535ms\tremaining: 188ms\n",
      "148:\tlearn: 0.0382041\ttotal: 538ms\tremaining: 184ms\n",
      "149:\tlearn: 0.0379198\ttotal: 542ms\tremaining: 181ms\n",
      "150:\tlearn: 0.0374992\ttotal: 546ms\tremaining: 177ms\n",
      "151:\tlearn: 0.0374416\ttotal: 549ms\tremaining: 173ms\n",
      "152:\tlearn: 0.0371736\ttotal: 552ms\tremaining: 170ms\n",
      "153:\tlearn: 0.0371714\ttotal: 556ms\tremaining: 166ms\n",
      "154:\tlearn: 0.0369741\ttotal: 559ms\tremaining: 162ms\n",
      "155:\tlearn: 0.0367238\ttotal: 563ms\tremaining: 159ms\n",
      "156:\tlearn: 0.0364195\ttotal: 566ms\tremaining: 155ms\n",
      "157:\tlearn: 0.0362926\ttotal: 570ms\tremaining: 151ms\n",
      "158:\tlearn: 0.0362470\ttotal: 573ms\tremaining: 148ms\n",
      "159:\tlearn: 0.0359248\ttotal: 577ms\tremaining: 144ms\n",
      "160:\tlearn: 0.0355434\ttotal: 580ms\tremaining: 141ms\n",
      "161:\tlearn: 0.0353444\ttotal: 583ms\tremaining: 137ms\n",
      "162:\tlearn: 0.0350622\ttotal: 587ms\tremaining: 133ms\n",
      "163:\tlearn: 0.0349816\ttotal: 590ms\tremaining: 130ms\n",
      "164:\tlearn: 0.0346140\ttotal: 594ms\tremaining: 126ms\n",
      "165:\tlearn: 0.0344097\ttotal: 597ms\tremaining: 122ms\n",
      "166:\tlearn: 0.0341583\ttotal: 601ms\tremaining: 119ms\n",
      "167:\tlearn: 0.0338633\ttotal: 605ms\tremaining: 115ms\n",
      "168:\tlearn: 0.0337240\ttotal: 608ms\tremaining: 112ms\n",
      "169:\tlearn: 0.0335474\ttotal: 612ms\tremaining: 108ms\n",
      "170:\tlearn: 0.0334290\ttotal: 616ms\tremaining: 104ms\n",
      "171:\tlearn: 0.0333561\ttotal: 620ms\tremaining: 101ms\n",
      "172:\tlearn: 0.0332295\ttotal: 623ms\tremaining: 97.3ms\n",
      "173:\tlearn: 0.0331951\ttotal: 627ms\tremaining: 93.7ms\n",
      "174:\tlearn: 0.0328954\ttotal: 631ms\tremaining: 90.1ms\n",
      "175:\tlearn: 0.0325815\ttotal: 634ms\tremaining: 86.4ms\n",
      "176:\tlearn: 0.0324666\ttotal: 637ms\tremaining: 82.8ms\n",
      "177:\tlearn: 0.0321648\ttotal: 641ms\tremaining: 79.2ms\n",
      "178:\tlearn: 0.0319402\ttotal: 644ms\tremaining: 75.6ms\n",
      "179:\tlearn: 0.0319035\ttotal: 648ms\tremaining: 72ms\n",
      "180:\tlearn: 0.0317070\ttotal: 652ms\tremaining: 68.4ms\n",
      "181:\tlearn: 0.0314547\ttotal: 655ms\tremaining: 64.8ms\n",
      "182:\tlearn: 0.0313894\ttotal: 659ms\tremaining: 61.2ms\n",
      "183:\tlearn: 0.0311160\ttotal: 663ms\tremaining: 57.6ms\n",
      "184:\tlearn: 0.0306501\ttotal: 666ms\tremaining: 54ms\n",
      "185:\tlearn: 0.0305546\ttotal: 670ms\tremaining: 50.4ms\n",
      "186:\tlearn: 0.0304309\ttotal: 673ms\tremaining: 46.8ms\n",
      "187:\tlearn: 0.0302086\ttotal: 677ms\tremaining: 43.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188:\tlearn: 0.0300168\ttotal: 681ms\tremaining: 39.6ms\n",
      "189:\tlearn: 0.0296700\ttotal: 684ms\tremaining: 36ms\n",
      "190:\tlearn: 0.0293078\ttotal: 688ms\tremaining: 32.4ms\n",
      "191:\tlearn: 0.0292568\ttotal: 697ms\tremaining: 29ms\n",
      "192:\tlearn: 0.0289728\ttotal: 701ms\tremaining: 25.4ms\n",
      "193:\tlearn: 0.0288826\ttotal: 704ms\tremaining: 21.8ms\n",
      "194:\tlearn: 0.0287487\ttotal: 708ms\tremaining: 18.1ms\n",
      "195:\tlearn: 0.0284106\ttotal: 711ms\tremaining: 14.5ms\n",
      "196:\tlearn: 0.0281685\ttotal: 715ms\tremaining: 10.9ms\n",
      "197:\tlearn: 0.0279546\ttotal: 719ms\tremaining: 7.26ms\n",
      "198:\tlearn: 0.0277791\ttotal: 722ms\tremaining: 3.63ms\n",
      "199:\tlearn: 0.0276644\ttotal: 725ms\tremaining: 0us\n",
      "0:\tlearn: 0.5744853\ttotal: 3.3ms\tremaining: 658ms\n",
      "1:\tlearn: 0.4816982\ttotal: 6.35ms\tremaining: 629ms\n",
      "2:\tlearn: 0.4061825\ttotal: 9.8ms\tremaining: 644ms\n",
      "3:\tlearn: 0.3439336\ttotal: 13.2ms\tremaining: 648ms\n",
      "4:\tlearn: 0.3151981\ttotal: 16.9ms\tremaining: 659ms\n",
      "5:\tlearn: 0.2869387\ttotal: 20.8ms\tremaining: 672ms\n",
      "6:\tlearn: 0.2526745\ttotal: 24ms\tremaining: 661ms\n",
      "7:\tlearn: 0.2348784\ttotal: 27.2ms\tremaining: 654ms\n",
      "8:\tlearn: 0.2225687\ttotal: 30.9ms\tremaining: 656ms\n",
      "9:\tlearn: 0.2096403\ttotal: 34.3ms\tremaining: 653ms\n",
      "10:\tlearn: 0.1999635\ttotal: 37.9ms\tremaining: 651ms\n",
      "11:\tlearn: 0.1903886\ttotal: 41.5ms\tremaining: 651ms\n",
      "12:\tlearn: 0.1811510\ttotal: 45.1ms\tremaining: 649ms\n",
      "13:\tlearn: 0.1745683\ttotal: 49.4ms\tremaining: 656ms\n",
      "14:\tlearn: 0.1678919\ttotal: 53.1ms\tremaining: 656ms\n",
      "15:\tlearn: 0.1591766\ttotal: 56.7ms\tremaining: 652ms\n",
      "16:\tlearn: 0.1556246\ttotal: 60.2ms\tremaining: 648ms\n",
      "17:\tlearn: 0.1521641\ttotal: 64ms\tremaining: 647ms\n",
      "18:\tlearn: 0.1453621\ttotal: 67.3ms\tremaining: 642ms\n",
      "19:\tlearn: 0.1420658\ttotal: 71.3ms\tremaining: 642ms\n",
      "20:\tlearn: 0.1405039\ttotal: 75.5ms\tremaining: 643ms\n",
      "21:\tlearn: 0.1362785\ttotal: 79.7ms\tremaining: 645ms\n",
      "22:\tlearn: 0.1333676\ttotal: 83.8ms\tremaining: 645ms\n",
      "23:\tlearn: 0.1316854\ttotal: 87.5ms\tremaining: 641ms\n",
      "24:\tlearn: 0.1293620\ttotal: 90.9ms\tremaining: 636ms\n",
      "25:\tlearn: 0.1269984\ttotal: 94.4ms\tremaining: 631ms\n",
      "26:\tlearn: 0.1236519\ttotal: 98.2ms\tremaining: 629ms\n",
      "27:\tlearn: 0.1199682\ttotal: 102ms\tremaining: 626ms\n",
      "28:\tlearn: 0.1185584\ttotal: 106ms\tremaining: 624ms\n",
      "29:\tlearn: 0.1154627\ttotal: 110ms\tremaining: 621ms\n",
      "30:\tlearn: 0.1128556\ttotal: 113ms\tremaining: 618ms\n",
      "31:\tlearn: 0.1109474\ttotal: 117ms\tremaining: 616ms\n",
      "32:\tlearn: 0.1087687\ttotal: 121ms\tremaining: 611ms\n",
      "33:\tlearn: 0.1072830\ttotal: 124ms\tremaining: 608ms\n",
      "34:\tlearn: 0.1054082\ttotal: 128ms\tremaining: 602ms\n",
      "35:\tlearn: 0.1043945\ttotal: 131ms\tremaining: 597ms\n",
      "36:\tlearn: 0.1019815\ttotal: 135ms\tremaining: 593ms\n",
      "37:\tlearn: 0.1001119\ttotal: 138ms\tremaining: 589ms\n",
      "38:\tlearn: 0.0986255\ttotal: 142ms\tremaining: 585ms\n",
      "39:\tlearn: 0.0973748\ttotal: 146ms\tremaining: 582ms\n",
      "40:\tlearn: 0.0962176\ttotal: 149ms\tremaining: 579ms\n",
      "41:\tlearn: 0.0952253\ttotal: 153ms\tremaining: 577ms\n",
      "42:\tlearn: 0.0945683\ttotal: 157ms\tremaining: 572ms\n",
      "43:\tlearn: 0.0935106\ttotal: 161ms\tremaining: 569ms\n",
      "44:\tlearn: 0.0926987\ttotal: 164ms\tremaining: 565ms\n",
      "45:\tlearn: 0.0918719\ttotal: 167ms\tremaining: 560ms\n",
      "46:\tlearn: 0.0909026\ttotal: 171ms\tremaining: 557ms\n",
      "47:\tlearn: 0.0903232\ttotal: 175ms\tremaining: 555ms\n",
      "48:\tlearn: 0.0891540\ttotal: 178ms\tremaining: 550ms\n",
      "49:\tlearn: 0.0889263\ttotal: 183ms\tremaining: 548ms\n",
      "50:\tlearn: 0.0876993\ttotal: 186ms\tremaining: 544ms\n",
      "51:\tlearn: 0.0869308\ttotal: 189ms\tremaining: 539ms\n",
      "52:\tlearn: 0.0868541\ttotal: 191ms\tremaining: 531ms\n",
      "53:\tlearn: 0.0858723\ttotal: 195ms\tremaining: 526ms\n",
      "54:\tlearn: 0.0855231\ttotal: 198ms\tremaining: 521ms\n",
      "55:\tlearn: 0.0844517\ttotal: 201ms\tremaining: 517ms\n",
      "56:\tlearn: 0.0836969\ttotal: 205ms\tremaining: 513ms\n",
      "57:\tlearn: 0.0828643\ttotal: 208ms\tremaining: 509ms\n",
      "58:\tlearn: 0.0819470\ttotal: 211ms\tremaining: 505ms\n",
      "59:\tlearn: 0.0804598\ttotal: 215ms\tremaining: 501ms\n",
      "60:\tlearn: 0.0799272\ttotal: 219ms\tremaining: 498ms\n",
      "61:\tlearn: 0.0787666\ttotal: 222ms\tremaining: 495ms\n",
      "62:\tlearn: 0.0779828\ttotal: 226ms\tremaining: 491ms\n",
      "63:\tlearn: 0.0778647\ttotal: 228ms\tremaining: 485ms\n",
      "64:\tlearn: 0.0768662\ttotal: 232ms\tremaining: 481ms\n",
      "65:\tlearn: 0.0759352\ttotal: 235ms\tremaining: 477ms\n",
      "66:\tlearn: 0.0759317\ttotal: 238ms\tremaining: 472ms\n",
      "67:\tlearn: 0.0756389\ttotal: 241ms\tremaining: 468ms\n",
      "68:\tlearn: 0.0751197\ttotal: 244ms\tremaining: 464ms\n",
      "69:\tlearn: 0.0750437\ttotal: 248ms\tremaining: 461ms\n",
      "70:\tlearn: 0.0738539\ttotal: 252ms\tremaining: 457ms\n",
      "71:\tlearn: 0.0729610\ttotal: 255ms\tremaining: 453ms\n",
      "72:\tlearn: 0.0722348\ttotal: 258ms\tremaining: 449ms\n",
      "73:\tlearn: 0.0722332\ttotal: 260ms\tremaining: 443ms\n",
      "74:\tlearn: 0.0722318\ttotal: 263ms\tremaining: 438ms\n",
      "75:\tlearn: 0.0715605\ttotal: 266ms\tremaining: 434ms\n",
      "76:\tlearn: 0.0711837\ttotal: 269ms\tremaining: 430ms\n",
      "77:\tlearn: 0.0711825\ttotal: 271ms\tremaining: 424ms\n",
      "78:\tlearn: 0.0702509\ttotal: 275ms\tremaining: 421ms\n",
      "79:\tlearn: 0.0702352\ttotal: 278ms\tremaining: 417ms\n",
      "80:\tlearn: 0.0695764\ttotal: 282ms\tremaining: 414ms\n",
      "81:\tlearn: 0.0690218\ttotal: 285ms\tremaining: 410ms\n",
      "82:\tlearn: 0.0682936\ttotal: 288ms\tremaining: 406ms\n",
      "83:\tlearn: 0.0681593\ttotal: 291ms\tremaining: 403ms\n",
      "84:\tlearn: 0.0671574\ttotal: 295ms\tremaining: 399ms\n",
      "85:\tlearn: 0.0668019\ttotal: 298ms\tremaining: 395ms\n",
      "86:\tlearn: 0.0658991\ttotal: 302ms\tremaining: 392ms\n",
      "87:\tlearn: 0.0658781\ttotal: 305ms\tremaining: 388ms\n",
      "88:\tlearn: 0.0648586\ttotal: 308ms\tremaining: 385ms\n",
      "89:\tlearn: 0.0642882\ttotal: 313ms\tremaining: 382ms\n",
      "90:\tlearn: 0.0642844\ttotal: 316ms\tremaining: 378ms\n",
      "91:\tlearn: 0.0636045\ttotal: 319ms\tremaining: 374ms\n",
      "92:\tlearn: 0.0628976\ttotal: 322ms\tremaining: 371ms\n",
      "93:\tlearn: 0.0628964\ttotal: 325ms\tremaining: 366ms\n",
      "94:\tlearn: 0.0624810\ttotal: 328ms\tremaining: 363ms\n",
      "95:\tlearn: 0.0619316\ttotal: 332ms\tremaining: 360ms\n",
      "96:\tlearn: 0.0617635\ttotal: 335ms\tremaining: 356ms\n",
      "97:\tlearn: 0.0612735\ttotal: 339ms\tremaining: 352ms\n",
      "98:\tlearn: 0.0612570\ttotal: 342ms\tremaining: 349ms\n",
      "99:\tlearn: 0.0607638\ttotal: 345ms\tremaining: 345ms\n",
      "100:\tlearn: 0.0606163\ttotal: 349ms\tremaining: 342ms\n",
      "101:\tlearn: 0.0603555\ttotal: 353ms\tremaining: 339ms\n",
      "102:\tlearn: 0.0595764\ttotal: 356ms\tremaining: 335ms\n",
      "103:\tlearn: 0.0595745\ttotal: 359ms\tremaining: 332ms\n",
      "104:\tlearn: 0.0592609\ttotal: 362ms\tremaining: 328ms\n",
      "105:\tlearn: 0.0588830\ttotal: 366ms\tremaining: 325ms\n",
      "106:\tlearn: 0.0585349\ttotal: 369ms\tremaining: 321ms\n",
      "107:\tlearn: 0.0579512\ttotal: 373ms\tremaining: 318ms\n",
      "108:\tlearn: 0.0574283\ttotal: 377ms\tremaining: 315ms\n",
      "109:\tlearn: 0.0568034\ttotal: 381ms\tremaining: 312ms\n",
      "110:\tlearn: 0.0565166\ttotal: 385ms\tremaining: 309ms\n",
      "111:\tlearn: 0.0563466\ttotal: 389ms\tremaining: 306ms\n",
      "112:\tlearn: 0.0557039\ttotal: 392ms\tremaining: 302ms\n",
      "113:\tlearn: 0.0553583\ttotal: 396ms\tremaining: 298ms\n",
      "114:\tlearn: 0.0548474\ttotal: 400ms\tremaining: 295ms\n",
      "115:\tlearn: 0.0540196\ttotal: 403ms\tremaining: 292ms\n",
      "116:\tlearn: 0.0539174\ttotal: 407ms\tremaining: 289ms\n",
      "117:\tlearn: 0.0533330\ttotal: 410ms\tremaining: 285ms\n",
      "118:\tlearn: 0.0529740\ttotal: 414ms\tremaining: 282ms\n",
      "119:\tlearn: 0.0526839\ttotal: 417ms\tremaining: 278ms\n",
      "120:\tlearn: 0.0522243\ttotal: 421ms\tremaining: 275ms\n",
      "121:\tlearn: 0.0521345\ttotal: 424ms\tremaining: 271ms\n",
      "122:\tlearn: 0.0518497\ttotal: 427ms\tremaining: 267ms\n",
      "123:\tlearn: 0.0517381\ttotal: 431ms\tremaining: 264ms\n",
      "124:\tlearn: 0.0512744\ttotal: 435ms\tremaining: 261ms\n",
      "125:\tlearn: 0.0512744\ttotal: 437ms\tremaining: 256ms\n",
      "126:\tlearn: 0.0506737\ttotal: 440ms\tremaining: 253ms\n",
      "127:\tlearn: 0.0506315\ttotal: 443ms\tremaining: 249ms\n",
      "128:\tlearn: 0.0501376\ttotal: 447ms\tremaining: 246ms\n",
      "129:\tlearn: 0.0498663\ttotal: 450ms\tremaining: 242ms\n",
      "130:\tlearn: 0.0494819\ttotal: 454ms\tremaining: 239ms\n",
      "131:\tlearn: 0.0490635\ttotal: 457ms\tremaining: 235ms\n",
      "132:\tlearn: 0.0490200\ttotal: 460ms\tremaining: 232ms\n",
      "133:\tlearn: 0.0486416\ttotal: 463ms\tremaining: 228ms\n",
      "134:\tlearn: 0.0486416\ttotal: 465ms\tremaining: 224ms\n",
      "135:\tlearn: 0.0481983\ttotal: 468ms\tremaining: 220ms\n",
      "136:\tlearn: 0.0477599\ttotal: 472ms\tremaining: 217ms\n",
      "137:\tlearn: 0.0474394\ttotal: 475ms\tremaining: 214ms\n",
      "138:\tlearn: 0.0470303\ttotal: 478ms\tremaining: 210ms\n",
      "139:\tlearn: 0.0467032\ttotal: 482ms\tremaining: 206ms\n",
      "140:\tlearn: 0.0460275\ttotal: 485ms\tremaining: 203ms\n",
      "141:\tlearn: 0.0454727\ttotal: 489ms\tremaining: 200ms\n",
      "142:\tlearn: 0.0453626\ttotal: 492ms\tremaining: 196ms\n",
      "143:\tlearn: 0.0451292\ttotal: 496ms\tremaining: 193ms\n",
      "144:\tlearn: 0.0450005\ttotal: 499ms\tremaining: 189ms\n",
      "145:\tlearn: 0.0447834\ttotal: 503ms\tremaining: 186ms\n",
      "146:\tlearn: 0.0444312\ttotal: 506ms\tremaining: 183ms\n",
      "147:\tlearn: 0.0443487\ttotal: 509ms\tremaining: 179ms\n",
      "148:\tlearn: 0.0441462\ttotal: 513ms\tremaining: 175ms\n",
      "149:\tlearn: 0.0441404\ttotal: 516ms\tremaining: 172ms\n",
      "150:\tlearn: 0.0439785\ttotal: 519ms\tremaining: 168ms\n",
      "151:\tlearn: 0.0436983\ttotal: 522ms\tremaining: 165ms\n",
      "152:\tlearn: 0.0433533\ttotal: 526ms\tremaining: 162ms\n",
      "153:\tlearn: 0.0429172\ttotal: 529ms\tremaining: 158ms\n",
      "154:\tlearn: 0.0425692\ttotal: 533ms\tremaining: 155ms\n",
      "155:\tlearn: 0.0421530\ttotal: 536ms\tremaining: 151ms\n",
      "156:\tlearn: 0.0420378\ttotal: 540ms\tremaining: 148ms\n",
      "157:\tlearn: 0.0416854\ttotal: 544ms\tremaining: 145ms\n",
      "158:\tlearn: 0.0413773\ttotal: 548ms\tremaining: 141ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 0.0413070\ttotal: 551ms\tremaining: 138ms\n",
      "160:\tlearn: 0.0409279\ttotal: 555ms\tremaining: 134ms\n",
      "161:\tlearn: 0.0405743\ttotal: 558ms\tremaining: 131ms\n",
      "162:\tlearn: 0.0400702\ttotal: 561ms\tremaining: 127ms\n",
      "163:\tlearn: 0.0400508\ttotal: 565ms\tremaining: 124ms\n",
      "164:\tlearn: 0.0397689\ttotal: 568ms\tremaining: 121ms\n",
      "165:\tlearn: 0.0393807\ttotal: 572ms\tremaining: 117ms\n",
      "166:\tlearn: 0.0390617\ttotal: 575ms\tremaining: 114ms\n",
      "167:\tlearn: 0.0389383\ttotal: 579ms\tremaining: 110ms\n",
      "168:\tlearn: 0.0385899\ttotal: 582ms\tremaining: 107ms\n",
      "169:\tlearn: 0.0383002\ttotal: 586ms\tremaining: 103ms\n",
      "170:\tlearn: 0.0380458\ttotal: 589ms\tremaining: 99.9ms\n",
      "171:\tlearn: 0.0380431\ttotal: 593ms\tremaining: 96.6ms\n",
      "172:\tlearn: 0.0378367\ttotal: 597ms\tremaining: 93.2ms\n",
      "173:\tlearn: 0.0376651\ttotal: 601ms\tremaining: 89.8ms\n",
      "174:\tlearn: 0.0374762\ttotal: 605ms\tremaining: 86.4ms\n",
      "175:\tlearn: 0.0373086\ttotal: 609ms\tremaining: 83ms\n",
      "176:\tlearn: 0.0370410\ttotal: 613ms\tremaining: 79.6ms\n",
      "177:\tlearn: 0.0367603\ttotal: 616ms\tremaining: 76.1ms\n",
      "178:\tlearn: 0.0365076\ttotal: 619ms\tremaining: 72.7ms\n",
      "179:\tlearn: 0.0361925\ttotal: 623ms\tremaining: 69.3ms\n",
      "180:\tlearn: 0.0360231\ttotal: 626ms\tremaining: 65.8ms\n",
      "181:\tlearn: 0.0356983\ttotal: 630ms\tremaining: 62.3ms\n",
      "182:\tlearn: 0.0354886\ttotal: 633ms\tremaining: 58.8ms\n",
      "183:\tlearn: 0.0353061\ttotal: 637ms\tremaining: 55.4ms\n",
      "184:\tlearn: 0.0350522\ttotal: 640ms\tremaining: 51.9ms\n",
      "185:\tlearn: 0.0348067\ttotal: 644ms\tremaining: 48.4ms\n",
      "186:\tlearn: 0.0345587\ttotal: 647ms\tremaining: 45ms\n",
      "187:\tlearn: 0.0343160\ttotal: 650ms\tremaining: 41.5ms\n",
      "188:\tlearn: 0.0343038\ttotal: 654ms\tremaining: 38.1ms\n",
      "189:\tlearn: 0.0342118\ttotal: 658ms\tremaining: 34.6ms\n",
      "190:\tlearn: 0.0342058\ttotal: 661ms\tremaining: 31.2ms\n",
      "191:\tlearn: 0.0339260\ttotal: 665ms\tremaining: 27.7ms\n",
      "192:\tlearn: 0.0338595\ttotal: 668ms\tremaining: 24.2ms\n",
      "193:\tlearn: 0.0336567\ttotal: 672ms\tremaining: 20.8ms\n",
      "194:\tlearn: 0.0335317\ttotal: 675ms\tremaining: 17.3ms\n",
      "195:\tlearn: 0.0332848\ttotal: 679ms\tremaining: 13.9ms\n",
      "196:\tlearn: 0.0330933\ttotal: 682ms\tremaining: 10.4ms\n",
      "197:\tlearn: 0.0330929\ttotal: 685ms\tremaining: 6.92ms\n",
      "198:\tlearn: 0.0329437\ttotal: 689ms\tremaining: 3.46ms\n",
      "199:\tlearn: 0.0328650\ttotal: 692ms\tremaining: 0us\n",
      "0:\tlearn: 0.5677650\ttotal: 3.56ms\tremaining: 709ms\n",
      "1:\tlearn: 0.4749437\ttotal: 7.31ms\tremaining: 724ms\n",
      "2:\tlearn: 0.4037239\ttotal: 10.6ms\tremaining: 694ms\n",
      "3:\tlearn: 0.3476545\ttotal: 14.1ms\tremaining: 689ms\n",
      "4:\tlearn: 0.3049478\ttotal: 18.1ms\tremaining: 705ms\n",
      "5:\tlearn: 0.2706588\ttotal: 22ms\tremaining: 710ms\n",
      "6:\tlearn: 0.2497271\ttotal: 25.4ms\tremaining: 701ms\n",
      "7:\tlearn: 0.2358121\ttotal: 28.7ms\tremaining: 689ms\n",
      "8:\tlearn: 0.2229564\ttotal: 32.2ms\tremaining: 684ms\n",
      "9:\tlearn: 0.2132170\ttotal: 35.9ms\tremaining: 681ms\n",
      "10:\tlearn: 0.2051124\ttotal: 39.5ms\tremaining: 678ms\n",
      "11:\tlearn: 0.1991315\ttotal: 43ms\tremaining: 674ms\n",
      "12:\tlearn: 0.1856937\ttotal: 46.6ms\tremaining: 671ms\n",
      "13:\tlearn: 0.1768557\ttotal: 50.1ms\tremaining: 665ms\n",
      "14:\tlearn: 0.1723856\ttotal: 53.4ms\tremaining: 659ms\n",
      "15:\tlearn: 0.1679035\ttotal: 57ms\tremaining: 656ms\n",
      "16:\tlearn: 0.1612012\ttotal: 60.1ms\tremaining: 647ms\n",
      "17:\tlearn: 0.1569337\ttotal: 63.5ms\tremaining: 642ms\n",
      "18:\tlearn: 0.1532634\ttotal: 67.4ms\tremaining: 642ms\n",
      "19:\tlearn: 0.1484674\ttotal: 70.9ms\tremaining: 638ms\n",
      "20:\tlearn: 0.1463016\ttotal: 74.6ms\tremaining: 636ms\n",
      "21:\tlearn: 0.1398900\ttotal: 77.9ms\tremaining: 630ms\n",
      "22:\tlearn: 0.1369592\ttotal: 82.3ms\tremaining: 634ms\n",
      "23:\tlearn: 0.1336753\ttotal: 85.8ms\tremaining: 629ms\n",
      "24:\tlearn: 0.1297703\ttotal: 89.8ms\tremaining: 629ms\n",
      "25:\tlearn: 0.1281933\ttotal: 93.3ms\tremaining: 625ms\n",
      "26:\tlearn: 0.1251432\ttotal: 96.7ms\tremaining: 620ms\n",
      "27:\tlearn: 0.1217096\ttotal: 100ms\tremaining: 616ms\n",
      "28:\tlearn: 0.1198868\ttotal: 104ms\tremaining: 616ms\n",
      "29:\tlearn: 0.1174595\ttotal: 108ms\tremaining: 614ms\n",
      "30:\tlearn: 0.1155094\ttotal: 111ms\tremaining: 608ms\n",
      "31:\tlearn: 0.1142718\ttotal: 115ms\tremaining: 604ms\n",
      "32:\tlearn: 0.1116303\ttotal: 119ms\tremaining: 601ms\n",
      "33:\tlearn: 0.1102691\ttotal: 122ms\tremaining: 597ms\n",
      "34:\tlearn: 0.1083623\ttotal: 127ms\tremaining: 596ms\n",
      "35:\tlearn: 0.1063611\ttotal: 130ms\tremaining: 592ms\n",
      "36:\tlearn: 0.1043244\ttotal: 133ms\tremaining: 587ms\n",
      "37:\tlearn: 0.1025546\ttotal: 137ms\tremaining: 584ms\n",
      "38:\tlearn: 0.1019671\ttotal: 141ms\tremaining: 581ms\n",
      "39:\tlearn: 0.1006896\ttotal: 144ms\tremaining: 576ms\n",
      "40:\tlearn: 0.0997244\ttotal: 148ms\tremaining: 572ms\n",
      "41:\tlearn: 0.0986901\ttotal: 152ms\tremaining: 570ms\n",
      "42:\tlearn: 0.0965897\ttotal: 155ms\tremaining: 568ms\n",
      "43:\tlearn: 0.0953519\ttotal: 159ms\tremaining: 564ms\n",
      "44:\tlearn: 0.0938077\ttotal: 163ms\tremaining: 560ms\n",
      "45:\tlearn: 0.0926338\ttotal: 166ms\tremaining: 556ms\n",
      "46:\tlearn: 0.0906491\ttotal: 169ms\tremaining: 552ms\n",
      "47:\tlearn: 0.0898308\ttotal: 173ms\tremaining: 547ms\n",
      "48:\tlearn: 0.0892106\ttotal: 176ms\tremaining: 543ms\n",
      "49:\tlearn: 0.0878248\ttotal: 181ms\tremaining: 542ms\n",
      "50:\tlearn: 0.0871263\ttotal: 184ms\tremaining: 539ms\n",
      "51:\tlearn: 0.0863911\ttotal: 188ms\tremaining: 535ms\n",
      "52:\tlearn: 0.0855943\ttotal: 192ms\tremaining: 532ms\n",
      "53:\tlearn: 0.0850208\ttotal: 195ms\tremaining: 528ms\n",
      "54:\tlearn: 0.0845774\ttotal: 199ms\tremaining: 525ms\n",
      "55:\tlearn: 0.0830868\ttotal: 203ms\tremaining: 523ms\n",
      "56:\tlearn: 0.0823984\ttotal: 207ms\tremaining: 519ms\n",
      "57:\tlearn: 0.0817204\ttotal: 210ms\tremaining: 515ms\n",
      "58:\tlearn: 0.0809366\ttotal: 214ms\tremaining: 512ms\n",
      "59:\tlearn: 0.0802220\ttotal: 218ms\tremaining: 508ms\n",
      "60:\tlearn: 0.0790754\ttotal: 222ms\tremaining: 505ms\n",
      "61:\tlearn: 0.0784058\ttotal: 225ms\tremaining: 502ms\n",
      "62:\tlearn: 0.0777266\ttotal: 229ms\tremaining: 498ms\n",
      "63:\tlearn: 0.0770739\ttotal: 233ms\tremaining: 494ms\n",
      "64:\tlearn: 0.0760866\ttotal: 236ms\tremaining: 490ms\n",
      "65:\tlearn: 0.0755239\ttotal: 239ms\tremaining: 486ms\n",
      "66:\tlearn: 0.0748977\ttotal: 243ms\tremaining: 482ms\n",
      "67:\tlearn: 0.0739634\ttotal: 246ms\tremaining: 478ms\n",
      "68:\tlearn: 0.0727341\ttotal: 250ms\tremaining: 474ms\n",
      "69:\tlearn: 0.0719283\ttotal: 253ms\tremaining: 470ms\n",
      "70:\tlearn: 0.0718542\ttotal: 255ms\tremaining: 464ms\n",
      "71:\tlearn: 0.0716533\ttotal: 258ms\tremaining: 459ms\n",
      "72:\tlearn: 0.0714536\ttotal: 261ms\tremaining: 455ms\n",
      "73:\tlearn: 0.0709431\ttotal: 265ms\tremaining: 451ms\n",
      "74:\tlearn: 0.0700416\ttotal: 268ms\tremaining: 447ms\n",
      "75:\tlearn: 0.0694110\ttotal: 271ms\tremaining: 443ms\n",
      "76:\tlearn: 0.0691550\ttotal: 276ms\tremaining: 441ms\n",
      "77:\tlearn: 0.0687254\ttotal: 280ms\tremaining: 437ms\n",
      "78:\tlearn: 0.0682536\ttotal: 283ms\tremaining: 433ms\n",
      "79:\tlearn: 0.0675193\ttotal: 286ms\tremaining: 429ms\n",
      "80:\tlearn: 0.0671575\ttotal: 290ms\tremaining: 426ms\n",
      "81:\tlearn: 0.0662136\ttotal: 293ms\tremaining: 422ms\n",
      "82:\tlearn: 0.0654591\ttotal: 297ms\tremaining: 418ms\n",
      "83:\tlearn: 0.0649197\ttotal: 300ms\tremaining: 414ms\n",
      "84:\tlearn: 0.0646377\ttotal: 304ms\tremaining: 411ms\n",
      "85:\tlearn: 0.0643096\ttotal: 308ms\tremaining: 408ms\n",
      "86:\tlearn: 0.0638908\ttotal: 311ms\tremaining: 404ms\n",
      "87:\tlearn: 0.0632348\ttotal: 315ms\tremaining: 401ms\n",
      "88:\tlearn: 0.0623608\ttotal: 319ms\tremaining: 397ms\n",
      "89:\tlearn: 0.0616678\ttotal: 322ms\tremaining: 394ms\n",
      "90:\tlearn: 0.0608351\ttotal: 326ms\tremaining: 390ms\n",
      "91:\tlearn: 0.0603586\ttotal: 329ms\tremaining: 386ms\n",
      "92:\tlearn: 0.0595620\ttotal: 333ms\tremaining: 383ms\n",
      "93:\tlearn: 0.0590574\ttotal: 336ms\tremaining: 379ms\n",
      "94:\tlearn: 0.0588329\ttotal: 339ms\tremaining: 375ms\n",
      "95:\tlearn: 0.0585804\ttotal: 343ms\tremaining: 372ms\n",
      "96:\tlearn: 0.0582845\ttotal: 347ms\tremaining: 369ms\n",
      "97:\tlearn: 0.0573447\ttotal: 351ms\tremaining: 365ms\n",
      "98:\tlearn: 0.0565440\ttotal: 354ms\tremaining: 361ms\n",
      "99:\tlearn: 0.0558733\ttotal: 358ms\tremaining: 358ms\n",
      "100:\tlearn: 0.0553546\ttotal: 361ms\tremaining: 354ms\n",
      "101:\tlearn: 0.0547985\ttotal: 365ms\tremaining: 350ms\n",
      "102:\tlearn: 0.0543972\ttotal: 369ms\tremaining: 347ms\n",
      "103:\tlearn: 0.0536445\ttotal: 372ms\tremaining: 344ms\n",
      "104:\tlearn: 0.0532819\ttotal: 376ms\tremaining: 340ms\n",
      "105:\tlearn: 0.0526507\ttotal: 379ms\tremaining: 336ms\n",
      "106:\tlearn: 0.0523750\ttotal: 383ms\tremaining: 333ms\n",
      "107:\tlearn: 0.0517539\ttotal: 386ms\tremaining: 329ms\n",
      "108:\tlearn: 0.0512408\ttotal: 390ms\tremaining: 326ms\n",
      "109:\tlearn: 0.0507789\ttotal: 393ms\tremaining: 322ms\n",
      "110:\tlearn: 0.0502671\ttotal: 397ms\tremaining: 318ms\n",
      "111:\tlearn: 0.0501259\ttotal: 400ms\tremaining: 315ms\n",
      "112:\tlearn: 0.0499203\ttotal: 404ms\tremaining: 311ms\n",
      "113:\tlearn: 0.0494458\ttotal: 407ms\tremaining: 307ms\n",
      "114:\tlearn: 0.0492409\ttotal: 410ms\tremaining: 303ms\n",
      "115:\tlearn: 0.0486374\ttotal: 414ms\tremaining: 300ms\n",
      "116:\tlearn: 0.0479976\ttotal: 417ms\tremaining: 296ms\n",
      "117:\tlearn: 0.0474480\ttotal: 421ms\tremaining: 292ms\n",
      "118:\tlearn: 0.0470278\ttotal: 425ms\tremaining: 289ms\n",
      "119:\tlearn: 0.0466442\ttotal: 428ms\tremaining: 286ms\n",
      "120:\tlearn: 0.0463527\ttotal: 432ms\tremaining: 282ms\n",
      "121:\tlearn: 0.0462425\ttotal: 435ms\tremaining: 278ms\n",
      "122:\tlearn: 0.0459314\ttotal: 439ms\tremaining: 275ms\n",
      "123:\tlearn: 0.0455620\ttotal: 443ms\tremaining: 271ms\n",
      "124:\tlearn: 0.0453925\ttotal: 447ms\tremaining: 268ms\n",
      "125:\tlearn: 0.0450102\ttotal: 451ms\tremaining: 265ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126:\tlearn: 0.0448511\ttotal: 454ms\tremaining: 261ms\n",
      "127:\tlearn: 0.0443936\ttotal: 458ms\tremaining: 258ms\n",
      "128:\tlearn: 0.0441791\ttotal: 461ms\tremaining: 254ms\n",
      "129:\tlearn: 0.0438604\ttotal: 465ms\tremaining: 250ms\n",
      "130:\tlearn: 0.0434630\ttotal: 469ms\tremaining: 247ms\n",
      "131:\tlearn: 0.0432511\ttotal: 472ms\tremaining: 243ms\n",
      "132:\tlearn: 0.0427614\ttotal: 476ms\tremaining: 240ms\n",
      "133:\tlearn: 0.0426389\ttotal: 480ms\tremaining: 236ms\n",
      "134:\tlearn: 0.0423261\ttotal: 483ms\tremaining: 233ms\n",
      "135:\tlearn: 0.0420575\ttotal: 487ms\tremaining: 229ms\n",
      "136:\tlearn: 0.0417473\ttotal: 490ms\tremaining: 226ms\n",
      "137:\tlearn: 0.0414565\ttotal: 494ms\tremaining: 222ms\n",
      "138:\tlearn: 0.0411382\ttotal: 498ms\tremaining: 218ms\n",
      "139:\tlearn: 0.0409857\ttotal: 502ms\tremaining: 215ms\n",
      "140:\tlearn: 0.0407414\ttotal: 506ms\tremaining: 212ms\n",
      "141:\tlearn: 0.0406121\ttotal: 510ms\tremaining: 208ms\n",
      "142:\tlearn: 0.0405427\ttotal: 513ms\tremaining: 205ms\n",
      "143:\tlearn: 0.0402794\ttotal: 517ms\tremaining: 201ms\n",
      "144:\tlearn: 0.0402115\ttotal: 521ms\tremaining: 197ms\n",
      "145:\tlearn: 0.0400320\ttotal: 524ms\tremaining: 194ms\n",
      "146:\tlearn: 0.0396608\ttotal: 528ms\tremaining: 190ms\n",
      "147:\tlearn: 0.0394810\ttotal: 531ms\tremaining: 187ms\n",
      "148:\tlearn: 0.0391735\ttotal: 535ms\tremaining: 183ms\n",
      "149:\tlearn: 0.0389631\ttotal: 538ms\tremaining: 179ms\n",
      "150:\tlearn: 0.0385916\ttotal: 542ms\tremaining: 176ms\n",
      "151:\tlearn: 0.0382100\ttotal: 545ms\tremaining: 172ms\n",
      "152:\tlearn: 0.0381419\ttotal: 548ms\tremaining: 168ms\n",
      "153:\tlearn: 0.0378253\ttotal: 552ms\tremaining: 165ms\n",
      "154:\tlearn: 0.0374388\ttotal: 555ms\tremaining: 161ms\n",
      "155:\tlearn: 0.0373392\ttotal: 560ms\tremaining: 158ms\n",
      "156:\tlearn: 0.0371004\ttotal: 563ms\tremaining: 154ms\n",
      "157:\tlearn: 0.0369075\ttotal: 566ms\tremaining: 151ms\n",
      "158:\tlearn: 0.0367011\ttotal: 570ms\tremaining: 147ms\n",
      "159:\tlearn: 0.0363002\ttotal: 574ms\tremaining: 143ms\n",
      "160:\tlearn: 0.0361268\ttotal: 578ms\tremaining: 140ms\n",
      "161:\tlearn: 0.0357363\ttotal: 582ms\tremaining: 136ms\n",
      "162:\tlearn: 0.0356128\ttotal: 585ms\tremaining: 133ms\n",
      "163:\tlearn: 0.0353398\ttotal: 589ms\tremaining: 129ms\n",
      "164:\tlearn: 0.0352671\ttotal: 593ms\tremaining: 126ms\n",
      "165:\tlearn: 0.0350306\ttotal: 597ms\tremaining: 122ms\n",
      "166:\tlearn: 0.0349872\ttotal: 600ms\tremaining: 119ms\n",
      "167:\tlearn: 0.0348522\ttotal: 604ms\tremaining: 115ms\n",
      "168:\tlearn: 0.0347672\ttotal: 608ms\tremaining: 111ms\n",
      "169:\tlearn: 0.0346089\ttotal: 612ms\tremaining: 108ms\n",
      "170:\tlearn: 0.0344003\ttotal: 615ms\tremaining: 104ms\n",
      "171:\tlearn: 0.0341996\ttotal: 618ms\tremaining: 101ms\n",
      "172:\tlearn: 0.0340913\ttotal: 621ms\tremaining: 97ms\n",
      "173:\tlearn: 0.0340605\ttotal: 625ms\tremaining: 93.4ms\n",
      "174:\tlearn: 0.0338458\ttotal: 629ms\tremaining: 89.9ms\n",
      "175:\tlearn: 0.0334707\ttotal: 632ms\tremaining: 86.2ms\n",
      "176:\tlearn: 0.0332419\ttotal: 636ms\tremaining: 82.6ms\n",
      "177:\tlearn: 0.0330414\ttotal: 639ms\tremaining: 79ms\n",
      "178:\tlearn: 0.0327964\ttotal: 643ms\tremaining: 75.4ms\n",
      "179:\tlearn: 0.0326201\ttotal: 646ms\tremaining: 71.8ms\n",
      "180:\tlearn: 0.0323702\ttotal: 650ms\tremaining: 68.2ms\n",
      "181:\tlearn: 0.0322317\ttotal: 653ms\tremaining: 64.6ms\n",
      "182:\tlearn: 0.0319898\ttotal: 657ms\tremaining: 61ms\n",
      "183:\tlearn: 0.0318473\ttotal: 660ms\tremaining: 57.4ms\n",
      "184:\tlearn: 0.0316996\ttotal: 664ms\tremaining: 53.9ms\n",
      "185:\tlearn: 0.0314637\ttotal: 668ms\tremaining: 50.3ms\n",
      "186:\tlearn: 0.0313135\ttotal: 672ms\tremaining: 46.7ms\n",
      "187:\tlearn: 0.0310168\ttotal: 675ms\tremaining: 43.1ms\n",
      "188:\tlearn: 0.0309854\ttotal: 679ms\tremaining: 39.5ms\n",
      "189:\tlearn: 0.0308160\ttotal: 683ms\tremaining: 35.9ms\n",
      "190:\tlearn: 0.0306308\ttotal: 686ms\tremaining: 32.3ms\n",
      "191:\tlearn: 0.0305811\ttotal: 689ms\tremaining: 28.7ms\n",
      "192:\tlearn: 0.0303548\ttotal: 693ms\tremaining: 25.1ms\n",
      "193:\tlearn: 0.0301690\ttotal: 697ms\tremaining: 21.5ms\n",
      "194:\tlearn: 0.0300810\ttotal: 700ms\tremaining: 18ms\n",
      "195:\tlearn: 0.0299391\ttotal: 704ms\tremaining: 14.4ms\n",
      "196:\tlearn: 0.0297478\ttotal: 708ms\tremaining: 10.8ms\n",
      "197:\tlearn: 0.0294973\ttotal: 711ms\tremaining: 7.18ms\n",
      "198:\tlearn: 0.0293331\ttotal: 715ms\tremaining: 3.59ms\n",
      "199:\tlearn: 0.0292458\ttotal: 718ms\tremaining: 0us\n",
      "0:\tlearn: 0.6862465\ttotal: 1.58ms\tremaining: 77.6ms\n",
      "1:\tlearn: 0.6800288\ttotal: 3.68ms\tremaining: 88.3ms\n",
      "2:\tlearn: 0.6737208\ttotal: 6.66ms\tremaining: 104ms\n",
      "3:\tlearn: 0.6675232\ttotal: 8.95ms\tremaining: 103ms\n",
      "4:\tlearn: 0.6619713\ttotal: 11.2ms\tremaining: 101ms\n",
      "5:\tlearn: 0.6558108\ttotal: 12.4ms\tremaining: 91.2ms\n",
      "6:\tlearn: 0.6502206\ttotal: 14.6ms\tremaining: 89.9ms\n",
      "7:\tlearn: 0.6442342\ttotal: 16.9ms\tremaining: 88.6ms\n",
      "8:\tlearn: 0.6392838\ttotal: 19.2ms\tremaining: 87.3ms\n",
      "9:\tlearn: 0.6336706\ttotal: 21.5ms\tremaining: 85.9ms\n",
      "10:\tlearn: 0.6279715\ttotal: 23.8ms\tremaining: 84.3ms\n",
      "11:\tlearn: 0.6224709\ttotal: 26ms\tremaining: 82.4ms\n",
      "12:\tlearn: 0.6169614\ttotal: 28.4ms\tremaining: 80.9ms\n",
      "13:\tlearn: 0.6116428\ttotal: 30.5ms\tremaining: 78.5ms\n",
      "14:\tlearn: 0.6063673\ttotal: 32.7ms\tremaining: 76.2ms\n",
      "15:\tlearn: 0.6015985\ttotal: 34.9ms\tremaining: 74.2ms\n",
      "16:\tlearn: 0.5966820\ttotal: 37ms\tremaining: 71.9ms\n",
      "17:\tlearn: 0.5919107\ttotal: 39.3ms\tremaining: 70ms\n",
      "18:\tlearn: 0.5870104\ttotal: 41.5ms\tremaining: 67.8ms\n",
      "19:\tlearn: 0.5824297\ttotal: 43.9ms\tremaining: 65.9ms\n",
      "20:\tlearn: 0.5778384\ttotal: 46.1ms\tremaining: 63.7ms\n",
      "21:\tlearn: 0.5729241\ttotal: 48.5ms\tremaining: 61.7ms\n",
      "22:\tlearn: 0.5682597\ttotal: 51.6ms\tremaining: 60.6ms\n",
      "23:\tlearn: 0.5637475\ttotal: 53.9ms\tremaining: 58.3ms\n",
      "24:\tlearn: 0.5593827\ttotal: 56.1ms\tremaining: 56.1ms\n",
      "25:\tlearn: 0.5552732\ttotal: 58.4ms\tremaining: 53.9ms\n",
      "26:\tlearn: 0.5507952\ttotal: 60.8ms\tremaining: 51.8ms\n",
      "27:\tlearn: 0.5464636\ttotal: 63.1ms\tremaining: 49.6ms\n",
      "28:\tlearn: 0.5424471\ttotal: 65.6ms\tremaining: 47.5ms\n",
      "29:\tlearn: 0.5384969\ttotal: 68ms\tremaining: 45.3ms\n",
      "30:\tlearn: 0.5347301\ttotal: 70.9ms\tremaining: 43.5ms\n",
      "31:\tlearn: 0.5303606\ttotal: 73.3ms\tremaining: 41.2ms\n",
      "32:\tlearn: 0.5265335\ttotal: 75.5ms\tremaining: 38.9ms\n",
      "33:\tlearn: 0.5223459\ttotal: 78.7ms\tremaining: 37ms\n",
      "34:\tlearn: 0.5184427\ttotal: 80.9ms\tremaining: 34.7ms\n",
      "35:\tlearn: 0.5144810\ttotal: 83.1ms\tremaining: 32.3ms\n",
      "36:\tlearn: 0.5102032\ttotal: 85.3ms\tremaining: 30ms\n",
      "37:\tlearn: 0.5064519\ttotal: 87.3ms\tremaining: 27.6ms\n",
      "38:\tlearn: 0.5029112\ttotal: 90.2ms\tremaining: 25.4ms\n",
      "39:\tlearn: 0.4991977\ttotal: 92.5ms\tremaining: 23.1ms\n",
      "40:\tlearn: 0.4955731\ttotal: 94.7ms\tremaining: 20.8ms\n",
      "41:\tlearn: 0.4921373\ttotal: 96.9ms\tremaining: 18.5ms\n",
      "42:\tlearn: 0.4886631\ttotal: 99.2ms\tremaining: 16.1ms\n",
      "43:\tlearn: 0.4851428\ttotal: 102ms\tremaining: 13.8ms\n",
      "44:\tlearn: 0.4816377\ttotal: 104ms\tremaining: 11.5ms\n",
      "45:\tlearn: 0.4782961\ttotal: 107ms\tremaining: 9.29ms\n",
      "46:\tlearn: 0.4748210\ttotal: 110ms\tremaining: 7ms\n",
      "47:\tlearn: 0.4714994\ttotal: 112ms\tremaining: 4.68ms\n",
      "48:\tlearn: 0.4684302\ttotal: 115ms\tremaining: 2.35ms\n",
      "49:\tlearn: 0.4652623\ttotal: 118ms\tremaining: 0us\n",
      "0:\tlearn: 0.6860899\ttotal: 2.23ms\tremaining: 109ms\n",
      "1:\tlearn: 0.6793130\ttotal: 4.61ms\tremaining: 111ms\n",
      "2:\tlearn: 0.6734430\ttotal: 6.87ms\tremaining: 108ms\n",
      "3:\tlearn: 0.6675745\ttotal: 8.87ms\tremaining: 102ms\n",
      "4:\tlearn: 0.6615878\ttotal: 10.9ms\tremaining: 98.5ms\n",
      "5:\tlearn: 0.6556114\ttotal: 13ms\tremaining: 95.6ms\n",
      "6:\tlearn: 0.6499470\ttotal: 15.4ms\tremaining: 94.3ms\n",
      "7:\tlearn: 0.6441324\ttotal: 17.6ms\tremaining: 92.6ms\n",
      "8:\tlearn: 0.6383721\ttotal: 20.2ms\tremaining: 92.1ms\n",
      "9:\tlearn: 0.6327614\ttotal: 22.5ms\tremaining: 90.1ms\n",
      "10:\tlearn: 0.6271179\ttotal: 23.6ms\tremaining: 83.7ms\n",
      "11:\tlearn: 0.6215042\ttotal: 25.8ms\tremaining: 81.8ms\n",
      "12:\tlearn: 0.6163936\ttotal: 28.3ms\tremaining: 80.5ms\n",
      "13:\tlearn: 0.6108643\ttotal: 30.6ms\tremaining: 78.6ms\n",
      "14:\tlearn: 0.6059164\ttotal: 32.7ms\tremaining: 76.4ms\n",
      "15:\tlearn: 0.6006790\ttotal: 35.7ms\tremaining: 75.8ms\n",
      "16:\tlearn: 0.5957002\ttotal: 37.9ms\tremaining: 73.6ms\n",
      "17:\tlearn: 0.5905492\ttotal: 40.2ms\tremaining: 71.5ms\n",
      "18:\tlearn: 0.5858462\ttotal: 43.2ms\tremaining: 70.4ms\n",
      "19:\tlearn: 0.5812597\ttotal: 45.4ms\tremaining: 68.1ms\n",
      "20:\tlearn: 0.5767754\ttotal: 47.7ms\tremaining: 65.8ms\n",
      "21:\tlearn: 0.5719220\ttotal: 49.9ms\tremaining: 63.4ms\n",
      "22:\tlearn: 0.5673582\ttotal: 52.2ms\tremaining: 61.3ms\n",
      "23:\tlearn: 0.5630790\ttotal: 54ms\tremaining: 58.5ms\n",
      "24:\tlearn: 0.5585616\ttotal: 56.3ms\tremaining: 56.3ms\n",
      "25:\tlearn: 0.5540444\ttotal: 58.4ms\tremaining: 54ms\n",
      "26:\tlearn: 0.5496615\ttotal: 60.7ms\tremaining: 51.7ms\n",
      "27:\tlearn: 0.5457394\ttotal: 62.9ms\tremaining: 49.5ms\n",
      "28:\tlearn: 0.5413615\ttotal: 65.3ms\tremaining: 47.3ms\n",
      "29:\tlearn: 0.5374409\ttotal: 67.6ms\tremaining: 45.1ms\n",
      "30:\tlearn: 0.5331692\ttotal: 70.5ms\tremaining: 43.2ms\n",
      "31:\tlearn: 0.5291912\ttotal: 72.7ms\tremaining: 40.9ms\n",
      "32:\tlearn: 0.5254107\ttotal: 75ms\tremaining: 38.7ms\n",
      "33:\tlearn: 0.5214309\ttotal: 78ms\tremaining: 36.7ms\n",
      "34:\tlearn: 0.5177121\ttotal: 80ms\tremaining: 34.3ms\n",
      "35:\tlearn: 0.5140227\ttotal: 82.9ms\tremaining: 32.2ms\n",
      "36:\tlearn: 0.5102675\ttotal: 85.3ms\tremaining: 30ms\n",
      "37:\tlearn: 0.5067211\ttotal: 87.9ms\tremaining: 27.7ms\n",
      "38:\tlearn: 0.5027523\ttotal: 89.9ms\tremaining: 25.4ms\n",
      "39:\tlearn: 0.4990921\ttotal: 92ms\tremaining: 23ms\n",
      "40:\tlearn: 0.4954921\ttotal: 94.2ms\tremaining: 20.7ms\n",
      "41:\tlearn: 0.4918964\ttotal: 96.5ms\tremaining: 18.4ms\n",
      "42:\tlearn: 0.4882223\ttotal: 98.8ms\tremaining: 16.1ms\n",
      "43:\tlearn: 0.4844639\ttotal: 101ms\tremaining: 13.8ms\n",
      "44:\tlearn: 0.4808891\ttotal: 103ms\tremaining: 11.5ms\n",
      "45:\tlearn: 0.4773684\ttotal: 105ms\tremaining: 9.17ms\n",
      "46:\tlearn: 0.4741019\ttotal: 108ms\tremaining: 6.88ms\n",
      "47:\tlearn: 0.4705823\ttotal: 110ms\tremaining: 4.58ms\n",
      "48:\tlearn: 0.4676850\ttotal: 112ms\tremaining: 2.29ms\n",
      "49:\tlearn: 0.4647567\ttotal: 115ms\tremaining: 0us\n",
      "0:\tlearn: 0.6861343\ttotal: 2.25ms\tremaining: 110ms\n",
      "1:\tlearn: 0.6793919\ttotal: 4.35ms\tremaining: 104ms\n",
      "2:\tlearn: 0.6734481\ttotal: 6.57ms\tremaining: 103ms\n",
      "3:\tlearn: 0.6676918\ttotal: 8.77ms\tremaining: 101ms\n",
      "4:\tlearn: 0.6618046\ttotal: 10.9ms\tremaining: 98.3ms\n",
      "5:\tlearn: 0.6558412\ttotal: 13ms\tremaining: 95.2ms\n",
      "6:\tlearn: 0.6500463\ttotal: 15.4ms\tremaining: 94.7ms\n",
      "7:\tlearn: 0.6439136\ttotal: 17.6ms\tremaining: 92.3ms\n",
      "8:\tlearn: 0.6382547\ttotal: 19.8ms\tremaining: 90.4ms\n",
      "9:\tlearn: 0.6325391\ttotal: 22.1ms\tremaining: 88.3ms\n",
      "10:\tlearn: 0.6269709\ttotal: 23.1ms\tremaining: 82ms\n",
      "11:\tlearn: 0.6218358\ttotal: 25.2ms\tremaining: 79.7ms\n",
      "12:\tlearn: 0.6167415\ttotal: 27.4ms\tremaining: 78ms\n",
      "13:\tlearn: 0.6111140\ttotal: 30.1ms\tremaining: 77.5ms\n",
      "14:\tlearn: 0.6059562\ttotal: 32.6ms\tremaining: 76.1ms\n",
      "15:\tlearn: 0.6006331\ttotal: 35.6ms\tremaining: 75.6ms\n",
      "16:\tlearn: 0.5954944\ttotal: 37.9ms\tremaining: 73.5ms\n",
      "17:\tlearn: 0.5901443\ttotal: 40.1ms\tremaining: 71.3ms\n",
      "18:\tlearn: 0.5851572\ttotal: 42.3ms\tremaining: 69ms\n",
      "19:\tlearn: 0.5803863\ttotal: 44.6ms\tremaining: 66.9ms\n",
      "20:\tlearn: 0.5756928\ttotal: 46.9ms\tremaining: 64.8ms\n",
      "21:\tlearn: 0.5706426\ttotal: 49.1ms\tremaining: 62.5ms\n",
      "22:\tlearn: 0.5660743\ttotal: 52ms\tremaining: 61.1ms\n",
      "23:\tlearn: 0.5617769\ttotal: 53.6ms\tremaining: 58.1ms\n",
      "24:\tlearn: 0.5572030\ttotal: 55.9ms\tremaining: 55.9ms\n",
      "25:\tlearn: 0.5531634\ttotal: 57.9ms\tremaining: 53.4ms\n",
      "26:\tlearn: 0.5487930\ttotal: 60.1ms\tremaining: 51.2ms\n",
      "27:\tlearn: 0.5445559\ttotal: 62.7ms\tremaining: 49.2ms\n",
      "28:\tlearn: 0.5401919\ttotal: 65ms\tremaining: 47ms\n",
      "29:\tlearn: 0.5359377\ttotal: 67.3ms\tremaining: 44.9ms\n",
      "30:\tlearn: 0.5318799\ttotal: 69.6ms\tremaining: 42.6ms\n",
      "31:\tlearn: 0.5280130\ttotal: 72ms\tremaining: 40.5ms\n",
      "32:\tlearn: 0.5241710\ttotal: 74.2ms\tremaining: 38.2ms\n",
      "33:\tlearn: 0.5201742\ttotal: 76.4ms\tremaining: 36ms\n",
      "34:\tlearn: 0.5163647\ttotal: 78.5ms\tremaining: 33.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35:\tlearn: 0.5127074\ttotal: 80.8ms\tremaining: 31.4ms\n",
      "36:\tlearn: 0.5085491\ttotal: 83.3ms\tremaining: 29.3ms\n",
      "37:\tlearn: 0.5047086\ttotal: 85.6ms\tremaining: 27ms\n",
      "38:\tlearn: 0.5007771\ttotal: 88.4ms\tremaining: 24.9ms\n",
      "39:\tlearn: 0.4971625\ttotal: 91.5ms\tremaining: 22.9ms\n",
      "40:\tlearn: 0.4936249\ttotal: 93.9ms\tremaining: 20.6ms\n",
      "41:\tlearn: 0.4900292\ttotal: 96.1ms\tremaining: 18.3ms\n",
      "42:\tlearn: 0.4863241\ttotal: 98.4ms\tremaining: 16ms\n",
      "43:\tlearn: 0.4825842\ttotal: 101ms\tremaining: 13.7ms\n",
      "44:\tlearn: 0.4788724\ttotal: 103ms\tremaining: 11.4ms\n",
      "45:\tlearn: 0.4754534\ttotal: 106ms\tremaining: 9.21ms\n",
      "46:\tlearn: 0.4724018\ttotal: 108ms\tremaining: 6.9ms\n",
      "47:\tlearn: 0.4689811\ttotal: 110ms\tremaining: 4.6ms\n",
      "48:\tlearn: 0.4658977\ttotal: 112ms\tremaining: 2.29ms\n",
      "49:\tlearn: 0.4628520\ttotal: 115ms\tremaining: 0us\n",
      "0:\tlearn: 0.6593054\ttotal: 1.57ms\tremaining: 76.9ms\n",
      "1:\tlearn: 0.6309429\ttotal: 3.79ms\tremaining: 90.9ms\n",
      "2:\tlearn: 0.6039985\ttotal: 5.88ms\tremaining: 92.1ms\n",
      "3:\tlearn: 0.5800866\ttotal: 7.98ms\tremaining: 91.8ms\n",
      "4:\tlearn: 0.5586421\ttotal: 10ms\tremaining: 90.3ms\n",
      "5:\tlearn: 0.5373816\ttotal: 12.4ms\tremaining: 90.6ms\n",
      "6:\tlearn: 0.5162916\ttotal: 14.6ms\tremaining: 89.6ms\n",
      "7:\tlearn: 0.4980395\ttotal: 17ms\tremaining: 89.2ms\n",
      "8:\tlearn: 0.4809877\ttotal: 19.5ms\tremaining: 89ms\n",
      "9:\tlearn: 0.4645617\ttotal: 21.3ms\tremaining: 85.1ms\n",
      "10:\tlearn: 0.4489201\ttotal: 23.6ms\tremaining: 83.5ms\n",
      "11:\tlearn: 0.4344166\ttotal: 25.8ms\tremaining: 81.8ms\n",
      "12:\tlearn: 0.4210810\ttotal: 28ms\tremaining: 79.6ms\n",
      "13:\tlearn: 0.4071946\ttotal: 30.2ms\tremaining: 77.6ms\n",
      "14:\tlearn: 0.3946361\ttotal: 32.6ms\tremaining: 76ms\n",
      "15:\tlearn: 0.3824853\ttotal: 34.8ms\tremaining: 73.9ms\n",
      "16:\tlearn: 0.3706711\ttotal: 36.9ms\tremaining: 71.6ms\n",
      "17:\tlearn: 0.3597038\ttotal: 39.1ms\tremaining: 69.4ms\n",
      "18:\tlearn: 0.3512110\ttotal: 41.4ms\tremaining: 67.6ms\n",
      "19:\tlearn: 0.3417171\ttotal: 43.6ms\tremaining: 65.5ms\n",
      "20:\tlearn: 0.3335921\ttotal: 46ms\tremaining: 63.5ms\n",
      "21:\tlearn: 0.3246580\ttotal: 48.3ms\tremaining: 61.4ms\n",
      "22:\tlearn: 0.3172125\ttotal: 50.5ms\tremaining: 59.3ms\n",
      "23:\tlearn: 0.3107614\ttotal: 52.8ms\tremaining: 57.2ms\n",
      "24:\tlearn: 0.3031342\ttotal: 55.4ms\tremaining: 55.4ms\n",
      "25:\tlearn: 0.2960356\ttotal: 57.7ms\tremaining: 53.3ms\n",
      "26:\tlearn: 0.2892554\ttotal: 60.1ms\tremaining: 51.2ms\n",
      "27:\tlearn: 0.2824743\ttotal: 62.3ms\tremaining: 49ms\n",
      "28:\tlearn: 0.2762719\ttotal: 64.7ms\tremaining: 46.8ms\n",
      "29:\tlearn: 0.2705776\ttotal: 66.9ms\tremaining: 44.6ms\n",
      "30:\tlearn: 0.2651965\ttotal: 69.1ms\tremaining: 42.3ms\n",
      "31:\tlearn: 0.2601832\ttotal: 71.5ms\tremaining: 40.2ms\n",
      "32:\tlearn: 0.2543914\ttotal: 73.8ms\tremaining: 38ms\n",
      "33:\tlearn: 0.2493058\ttotal: 77.1ms\tremaining: 36.3ms\n",
      "34:\tlearn: 0.2447318\ttotal: 79.2ms\tremaining: 33.9ms\n",
      "35:\tlearn: 0.2391245\ttotal: 81.4ms\tremaining: 31.6ms\n",
      "36:\tlearn: 0.2355614\ttotal: 83.7ms\tremaining: 29.4ms\n",
      "37:\tlearn: 0.2302538\ttotal: 86.1ms\tremaining: 27.2ms\n",
      "38:\tlearn: 0.2264421\ttotal: 88.6ms\tremaining: 25ms\n",
      "39:\tlearn: 0.2227293\ttotal: 90.8ms\tremaining: 22.7ms\n",
      "40:\tlearn: 0.2197457\ttotal: 93.2ms\tremaining: 20.5ms\n",
      "41:\tlearn: 0.2161603\ttotal: 95.6ms\tremaining: 18.2ms\n",
      "42:\tlearn: 0.2126614\ttotal: 98ms\tremaining: 15.9ms\n",
      "43:\tlearn: 0.2090448\ttotal: 100ms\tremaining: 13.7ms\n",
      "44:\tlearn: 0.2057844\ttotal: 103ms\tremaining: 11.4ms\n",
      "45:\tlearn: 0.2029529\ttotal: 105ms\tremaining: 9.11ms\n",
      "46:\tlearn: 0.1998490\ttotal: 108ms\tremaining: 6.87ms\n",
      "47:\tlearn: 0.1967153\ttotal: 110ms\tremaining: 4.58ms\n",
      "48:\tlearn: 0.1935647\ttotal: 112ms\tremaining: 2.29ms\n",
      "49:\tlearn: 0.1907406\ttotal: 115ms\tremaining: 0us\n",
      "0:\tlearn: 0.6585370\ttotal: 2.13ms\tremaining: 104ms\n",
      "1:\tlearn: 0.6275753\ttotal: 4.41ms\tremaining: 106ms\n",
      "2:\tlearn: 0.6031652\ttotal: 6.61ms\tremaining: 104ms\n",
      "3:\tlearn: 0.5799435\ttotal: 8.84ms\tremaining: 102ms\n",
      "4:\tlearn: 0.5568821\ttotal: 10.9ms\tremaining: 98.5ms\n",
      "5:\tlearn: 0.5353139\ttotal: 14ms\tremaining: 103ms\n",
      "6:\tlearn: 0.5156367\ttotal: 16.3ms\tremaining: 100ms\n",
      "7:\tlearn: 0.4960020\ttotal: 18.8ms\tremaining: 98.8ms\n",
      "8:\tlearn: 0.4766158\ttotal: 21ms\tremaining: 95.8ms\n",
      "9:\tlearn: 0.4605583\ttotal: 23.4ms\tremaining: 93.4ms\n",
      "10:\tlearn: 0.4453540\ttotal: 24.8ms\tremaining: 88.1ms\n",
      "11:\tlearn: 0.4297533\ttotal: 27.1ms\tremaining: 85.7ms\n",
      "12:\tlearn: 0.4173227\ttotal: 29.5ms\tremaining: 84ms\n",
      "13:\tlearn: 0.4039737\ttotal: 31.9ms\tremaining: 82ms\n",
      "14:\tlearn: 0.3913493\ttotal: 35ms\tremaining: 81.7ms\n",
      "15:\tlearn: 0.3794527\ttotal: 37.3ms\tremaining: 79.4ms\n",
      "16:\tlearn: 0.3685044\ttotal: 39.6ms\tremaining: 76.8ms\n",
      "17:\tlearn: 0.3582197\ttotal: 41.8ms\tremaining: 74.3ms\n",
      "18:\tlearn: 0.3492587\ttotal: 44ms\tremaining: 71.8ms\n",
      "19:\tlearn: 0.3398207\ttotal: 46.1ms\tremaining: 69.2ms\n",
      "20:\tlearn: 0.3320855\ttotal: 48.3ms\tremaining: 66.7ms\n",
      "21:\tlearn: 0.3230730\ttotal: 50.6ms\tremaining: 64.4ms\n",
      "22:\tlearn: 0.3152235\ttotal: 53.3ms\tremaining: 62.5ms\n",
      "23:\tlearn: 0.3083440\ttotal: 55.9ms\tremaining: 60.5ms\n",
      "24:\tlearn: 0.3012182\ttotal: 58.2ms\tremaining: 58.2ms\n",
      "25:\tlearn: 0.2960920\ttotal: 60.5ms\tremaining: 55.8ms\n",
      "26:\tlearn: 0.2897770\ttotal: 62.7ms\tremaining: 53.4ms\n",
      "27:\tlearn: 0.2825965\ttotal: 65ms\tremaining: 51.1ms\n",
      "28:\tlearn: 0.2769480\ttotal: 67.6ms\tremaining: 48.9ms\n",
      "29:\tlearn: 0.2707530\ttotal: 69.7ms\tremaining: 46.5ms\n",
      "30:\tlearn: 0.2650175\ttotal: 72.1ms\tremaining: 44.2ms\n",
      "31:\tlearn: 0.2597695\ttotal: 74.3ms\tremaining: 41.8ms\n",
      "32:\tlearn: 0.2549556\ttotal: 76.6ms\tremaining: 39.5ms\n",
      "33:\tlearn: 0.2494529\ttotal: 78.9ms\tremaining: 37.1ms\n",
      "34:\tlearn: 0.2448184\ttotal: 81.2ms\tremaining: 34.8ms\n",
      "35:\tlearn: 0.2397445\ttotal: 83.3ms\tremaining: 32.4ms\n",
      "36:\tlearn: 0.2355043\ttotal: 85.8ms\tremaining: 30.2ms\n",
      "37:\tlearn: 0.2311705\ttotal: 88.2ms\tremaining: 27.9ms\n",
      "38:\tlearn: 0.2267152\ttotal: 90.4ms\tremaining: 25.5ms\n",
      "39:\tlearn: 0.2230304\ttotal: 92.8ms\tremaining: 23.2ms\n",
      "40:\tlearn: 0.2195623\ttotal: 95.7ms\tremaining: 21ms\n",
      "41:\tlearn: 0.2151360\ttotal: 98.2ms\tremaining: 18.7ms\n",
      "42:\tlearn: 0.2111207\ttotal: 100ms\tremaining: 16.4ms\n",
      "43:\tlearn: 0.2077864\ttotal: 103ms\tremaining: 14ms\n",
      "44:\tlearn: 0.2045965\ttotal: 106ms\tremaining: 11.7ms\n",
      "45:\tlearn: 0.2016280\ttotal: 108ms\tremaining: 9.39ms\n",
      "46:\tlearn: 0.1986525\ttotal: 111ms\tremaining: 7.08ms\n",
      "47:\tlearn: 0.1958867\ttotal: 113ms\tremaining: 4.71ms\n",
      "48:\tlearn: 0.1928690\ttotal: 115ms\tremaining: 2.35ms\n",
      "49:\tlearn: 0.1899933\ttotal: 118ms\tremaining: 0us\n",
      "0:\tlearn: 0.6587585\ttotal: 2.39ms\tremaining: 117ms\n",
      "1:\tlearn: 0.6280080\ttotal: 4.7ms\tremaining: 113ms\n",
      "2:\tlearn: 0.6027066\ttotal: 6.85ms\tremaining: 107ms\n",
      "3:\tlearn: 0.5790613\ttotal: 9.03ms\tremaining: 104ms\n",
      "4:\tlearn: 0.5565316\ttotal: 11.2ms\tremaining: 101ms\n",
      "5:\tlearn: 0.5354625\ttotal: 13.5ms\tremaining: 99.2ms\n",
      "6:\tlearn: 0.5157042\ttotal: 15.9ms\tremaining: 97.4ms\n",
      "7:\tlearn: 0.4958100\ttotal: 18.2ms\tremaining: 95.7ms\n",
      "8:\tlearn: 0.4764543\ttotal: 20.4ms\tremaining: 92.8ms\n",
      "9:\tlearn: 0.4598402\ttotal: 22.7ms\tremaining: 90.6ms\n",
      "10:\tlearn: 0.4448855\ttotal: 23.8ms\tremaining: 84.4ms\n",
      "11:\tlearn: 0.4307588\ttotal: 26.2ms\tremaining: 83ms\n",
      "12:\tlearn: 0.4172202\ttotal: 28.4ms\tremaining: 80.9ms\n",
      "13:\tlearn: 0.4026939\ttotal: 30.6ms\tremaining: 78.7ms\n",
      "14:\tlearn: 0.3901896\ttotal: 33.2ms\tremaining: 77.4ms\n",
      "15:\tlearn: 0.3778814\ttotal: 35.3ms\tremaining: 75.1ms\n",
      "16:\tlearn: 0.3667769\ttotal: 37.6ms\tremaining: 73ms\n",
      "17:\tlearn: 0.3559213\ttotal: 39.9ms\tremaining: 70.9ms\n",
      "18:\tlearn: 0.3464933\ttotal: 42ms\tremaining: 68.6ms\n",
      "19:\tlearn: 0.3357407\ttotal: 44ms\tremaining: 66.1ms\n",
      "20:\tlearn: 0.3276080\ttotal: 46.2ms\tremaining: 63.9ms\n",
      "21:\tlearn: 0.3187401\ttotal: 48.5ms\tremaining: 61.7ms\n",
      "22:\tlearn: 0.3114792\ttotal: 50.8ms\tremaining: 59.7ms\n",
      "23:\tlearn: 0.3038816\ttotal: 53ms\tremaining: 57.4ms\n",
      "24:\tlearn: 0.2966029\ttotal: 55.3ms\tremaining: 55.3ms\n",
      "25:\tlearn: 0.2909022\ttotal: 57.7ms\tremaining: 53.2ms\n",
      "26:\tlearn: 0.2840729\ttotal: 59.9ms\tremaining: 51.1ms\n",
      "27:\tlearn: 0.2766774\ttotal: 62.1ms\tremaining: 48.8ms\n",
      "28:\tlearn: 0.2714162\ttotal: 64.4ms\tremaining: 46.7ms\n",
      "29:\tlearn: 0.2663837\ttotal: 66.7ms\tremaining: 44.5ms\n",
      "30:\tlearn: 0.2620768\ttotal: 69.2ms\tremaining: 42.4ms\n",
      "31:\tlearn: 0.2567518\ttotal: 71.4ms\tremaining: 40.2ms\n",
      "32:\tlearn: 0.2521032\ttotal: 73.8ms\tremaining: 38ms\n",
      "33:\tlearn: 0.2470670\ttotal: 76ms\tremaining: 35.8ms\n",
      "34:\tlearn: 0.2424098\ttotal: 78.3ms\tremaining: 33.6ms\n",
      "35:\tlearn: 0.2371652\ttotal: 80.8ms\tremaining: 31.4ms\n",
      "36:\tlearn: 0.2336595\ttotal: 83.9ms\tremaining: 29.5ms\n",
      "37:\tlearn: 0.2284589\ttotal: 86.3ms\tremaining: 27.2ms\n",
      "38:\tlearn: 0.2253314\ttotal: 88.5ms\tremaining: 25ms\n",
      "39:\tlearn: 0.2214486\ttotal: 90.8ms\tremaining: 22.7ms\n",
      "40:\tlearn: 0.2181124\ttotal: 93ms\tremaining: 20.4ms\n",
      "41:\tlearn: 0.2143048\ttotal: 95.3ms\tremaining: 18.2ms\n",
      "42:\tlearn: 0.2097484\ttotal: 98.2ms\tremaining: 16ms\n",
      "43:\tlearn: 0.2066050\ttotal: 100ms\tremaining: 13.7ms\n",
      "44:\tlearn: 0.2035410\ttotal: 104ms\tremaining: 11.5ms\n",
      "45:\tlearn: 0.2006039\ttotal: 106ms\tremaining: 9.2ms\n",
      "46:\tlearn: 0.1979171\ttotal: 108ms\tremaining: 6.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47:\tlearn: 0.1949509\ttotal: 111ms\tremaining: 4.61ms\n",
      "48:\tlearn: 0.1918820\ttotal: 113ms\tremaining: 2.31ms\n",
      "49:\tlearn: 0.1892070\ttotal: 115ms\tremaining: 0us\n",
      "0:\tlearn: 0.6271142\ttotal: 1.37ms\tremaining: 67.1ms\n",
      "1:\tlearn: 0.5776311\ttotal: 3.79ms\tremaining: 91ms\n",
      "2:\tlearn: 0.5315137\ttotal: 5.46ms\tremaining: 85.6ms\n",
      "3:\tlearn: 0.4924283\ttotal: 7.76ms\tremaining: 89.3ms\n",
      "4:\tlearn: 0.4626219\ttotal: 9.85ms\tremaining: 88.7ms\n",
      "5:\tlearn: 0.4332794\ttotal: 12.2ms\tremaining: 89.5ms\n",
      "6:\tlearn: 0.4075966\ttotal: 14.4ms\tremaining: 88.7ms\n",
      "7:\tlearn: 0.3812579\ttotal: 17.2ms\tremaining: 90.4ms\n",
      "8:\tlearn: 0.3623644\ttotal: 19.2ms\tremaining: 87.7ms\n",
      "9:\tlearn: 0.3428616\ttotal: 21.7ms\tremaining: 86.7ms\n",
      "10:\tlearn: 0.3248749\ttotal: 24.1ms\tremaining: 85.5ms\n",
      "11:\tlearn: 0.3085911\ttotal: 26.4ms\tremaining: 83.5ms\n",
      "12:\tlearn: 0.2952599\ttotal: 28.8ms\tremaining: 81.9ms\n",
      "13:\tlearn: 0.2819475\ttotal: 30.9ms\tremaining: 79.5ms\n",
      "14:\tlearn: 0.2698514\ttotal: 33.3ms\tremaining: 77.8ms\n",
      "15:\tlearn: 0.2577639\ttotal: 35.6ms\tremaining: 75.6ms\n",
      "16:\tlearn: 0.2477691\ttotal: 37.9ms\tremaining: 73.6ms\n",
      "17:\tlearn: 0.2368901\ttotal: 40.1ms\tremaining: 71.3ms\n",
      "18:\tlearn: 0.2313193\ttotal: 42.8ms\tremaining: 69.9ms\n",
      "19:\tlearn: 0.2238663\ttotal: 45ms\tremaining: 67.6ms\n",
      "20:\tlearn: 0.2163441\ttotal: 47.4ms\tremaining: 65.4ms\n",
      "21:\tlearn: 0.2092454\ttotal: 49.6ms\tremaining: 63.1ms\n",
      "22:\tlearn: 0.2016965\ttotal: 51.8ms\tremaining: 60.8ms\n",
      "23:\tlearn: 0.1969208\ttotal: 54.3ms\tremaining: 58.8ms\n",
      "24:\tlearn: 0.1928095\ttotal: 56.6ms\tremaining: 56.6ms\n",
      "25:\tlearn: 0.1859084\ttotal: 58.9ms\tremaining: 54.4ms\n",
      "26:\tlearn: 0.1809503\ttotal: 61.3ms\tremaining: 52.2ms\n",
      "27:\tlearn: 0.1766041\ttotal: 63.5ms\tremaining: 49.9ms\n",
      "28:\tlearn: 0.1728243\ttotal: 65.9ms\tremaining: 47.7ms\n",
      "29:\tlearn: 0.1668831\ttotal: 68.8ms\tremaining: 45.9ms\n",
      "30:\tlearn: 0.1618556\ttotal: 71.1ms\tremaining: 43.6ms\n",
      "31:\tlearn: 0.1579373\ttotal: 73.3ms\tremaining: 41.3ms\n",
      "32:\tlearn: 0.1546037\ttotal: 75.6ms\tremaining: 39ms\n",
      "33:\tlearn: 0.1520818\ttotal: 77.9ms\tremaining: 36.7ms\n",
      "34:\tlearn: 0.1490788\ttotal: 80.2ms\tremaining: 34.4ms\n",
      "35:\tlearn: 0.1457416\ttotal: 82.5ms\tremaining: 32.1ms\n",
      "36:\tlearn: 0.1441172\ttotal: 84.8ms\tremaining: 29.8ms\n",
      "37:\tlearn: 0.1408894\ttotal: 87ms\tremaining: 27.5ms\n",
      "38:\tlearn: 0.1392358\ttotal: 89.3ms\tremaining: 25.2ms\n",
      "39:\tlearn: 0.1367689\ttotal: 91.5ms\tremaining: 22.9ms\n",
      "40:\tlearn: 0.1346231\ttotal: 93.8ms\tremaining: 20.6ms\n",
      "41:\tlearn: 0.1328557\ttotal: 96ms\tremaining: 18.3ms\n",
      "42:\tlearn: 0.1310678\ttotal: 99.1ms\tremaining: 16.1ms\n",
      "43:\tlearn: 0.1291080\ttotal: 101ms\tremaining: 13.8ms\n",
      "44:\tlearn: 0.1272884\ttotal: 104ms\tremaining: 11.5ms\n",
      "45:\tlearn: 0.1261459\ttotal: 106ms\tremaining: 9.22ms\n",
      "46:\tlearn: 0.1243388\ttotal: 108ms\tremaining: 6.91ms\n",
      "47:\tlearn: 0.1220812\ttotal: 111ms\tremaining: 4.62ms\n",
      "48:\tlearn: 0.1205234\ttotal: 113ms\tremaining: 2.31ms\n",
      "49:\tlearn: 0.1187428\ttotal: 116ms\tremaining: 0us\n",
      "0:\tlearn: 0.6256143\ttotal: 2.69ms\tremaining: 132ms\n",
      "1:\tlearn: 0.5704489\ttotal: 5.56ms\tremaining: 134ms\n",
      "2:\tlearn: 0.5302243\ttotal: 7.79ms\tremaining: 122ms\n",
      "3:\tlearn: 0.4942758\ttotal: 9.9ms\tremaining: 114ms\n",
      "4:\tlearn: 0.4604304\ttotal: 12.2ms\tremaining: 110ms\n",
      "5:\tlearn: 0.4309161\ttotal: 14.5ms\tremaining: 106ms\n",
      "6:\tlearn: 0.4054040\ttotal: 16.7ms\tremaining: 102ms\n",
      "7:\tlearn: 0.3815432\ttotal: 18.8ms\tremaining: 98.8ms\n",
      "8:\tlearn: 0.3576101\ttotal: 21.1ms\tremaining: 96.3ms\n",
      "9:\tlearn: 0.3393478\ttotal: 23.5ms\tremaining: 93.9ms\n",
      "10:\tlearn: 0.3200697\ttotal: 25.9ms\tremaining: 91.9ms\n",
      "11:\tlearn: 0.3022505\ttotal: 28.2ms\tremaining: 89.4ms\n",
      "12:\tlearn: 0.2876923\ttotal: 30.5ms\tremaining: 86.8ms\n",
      "13:\tlearn: 0.2753845\ttotal: 33.6ms\tremaining: 86.3ms\n",
      "14:\tlearn: 0.2627363\ttotal: 36.6ms\tremaining: 85.3ms\n",
      "15:\tlearn: 0.2540804\ttotal: 38.9ms\tremaining: 82.6ms\n",
      "16:\tlearn: 0.2437959\ttotal: 41ms\tremaining: 79.6ms\n",
      "17:\tlearn: 0.2344740\ttotal: 43.5ms\tremaining: 77.3ms\n",
      "18:\tlearn: 0.2270679\ttotal: 45.7ms\tremaining: 74.5ms\n",
      "19:\tlearn: 0.2210634\ttotal: 48ms\tremaining: 72ms\n",
      "20:\tlearn: 0.2144580\ttotal: 51.1ms\tremaining: 70.5ms\n",
      "21:\tlearn: 0.2082488\ttotal: 53.3ms\tremaining: 67.8ms\n",
      "22:\tlearn: 0.2024804\ttotal: 55.5ms\tremaining: 65.2ms\n",
      "23:\tlearn: 0.1963387\ttotal: 57.9ms\tremaining: 62.7ms\n",
      "24:\tlearn: 0.1906472\ttotal: 60.2ms\tremaining: 60.2ms\n",
      "25:\tlearn: 0.1856819\ttotal: 62.5ms\tremaining: 57.7ms\n",
      "26:\tlearn: 0.1813116\ttotal: 65.2ms\tremaining: 55.5ms\n",
      "27:\tlearn: 0.1754721\ttotal: 67.4ms\tremaining: 52.9ms\n",
      "28:\tlearn: 0.1713243\ttotal: 69.6ms\tremaining: 50.4ms\n",
      "29:\tlearn: 0.1665220\ttotal: 71.9ms\tremaining: 47.9ms\n",
      "30:\tlearn: 0.1627580\ttotal: 74ms\tremaining: 45.4ms\n",
      "31:\tlearn: 0.1597594\ttotal: 81.2ms\tremaining: 45.7ms\n",
      "32:\tlearn: 0.1559158\ttotal: 85.2ms\tremaining: 43.9ms\n",
      "33:\tlearn: 0.1538269\ttotal: 87.6ms\tremaining: 41.2ms\n",
      "34:\tlearn: 0.1507994\ttotal: 89.8ms\tremaining: 38.5ms\n",
      "35:\tlearn: 0.1480769\ttotal: 92.2ms\tremaining: 35.9ms\n",
      "36:\tlearn: 0.1454253\ttotal: 94.6ms\tremaining: 33.2ms\n",
      "37:\tlearn: 0.1435197\ttotal: 97ms\tremaining: 30.6ms\n",
      "38:\tlearn: 0.1406557\ttotal: 99.4ms\tremaining: 28ms\n",
      "39:\tlearn: 0.1375213\ttotal: 102ms\tremaining: 25.6ms\n",
      "40:\tlearn: 0.1350927\ttotal: 105ms\tremaining: 23ms\n",
      "41:\tlearn: 0.1320323\ttotal: 107ms\tremaining: 20.3ms\n",
      "42:\tlearn: 0.1302738\ttotal: 110ms\tremaining: 17.8ms\n",
      "43:\tlearn: 0.1279907\ttotal: 112ms\tremaining: 15.2ms\n",
      "44:\tlearn: 0.1262496\ttotal: 114ms\tremaining: 12.6ms\n",
      "45:\tlearn: 0.1239598\ttotal: 116ms\tremaining: 10.1ms\n",
      "46:\tlearn: 0.1225089\ttotal: 118ms\tremaining: 7.55ms\n",
      "47:\tlearn: 0.1208122\ttotal: 121ms\tremaining: 5.02ms\n",
      "48:\tlearn: 0.1200406\ttotal: 123ms\tremaining: 2.51ms\n",
      "49:\tlearn: 0.1182186\ttotal: 125ms\tremaining: 0us\n",
      "0:\tlearn: 0.6260552\ttotal: 2.2ms\tremaining: 108ms\n",
      "1:\tlearn: 0.5712674\ttotal: 4.39ms\tremaining: 105ms\n",
      "2:\tlearn: 0.5295628\ttotal: 6.75ms\tremaining: 106ms\n",
      "3:\tlearn: 0.4930433\ttotal: 8.71ms\tremaining: 100ms\n",
      "4:\tlearn: 0.4603491\ttotal: 11ms\tremaining: 99.1ms\n",
      "5:\tlearn: 0.4312578\ttotal: 13.2ms\tremaining: 96.8ms\n",
      "6:\tlearn: 0.4054381\ttotal: 15.6ms\tremaining: 95.7ms\n",
      "7:\tlearn: 0.3807159\ttotal: 18ms\tremaining: 94.6ms\n",
      "8:\tlearn: 0.3563650\ttotal: 20.4ms\tremaining: 92.8ms\n",
      "9:\tlearn: 0.3365614\ttotal: 22.6ms\tremaining: 90.3ms\n",
      "10:\tlearn: 0.3182448\ttotal: 24.8ms\tremaining: 87.9ms\n",
      "11:\tlearn: 0.3021835\ttotal: 27.1ms\tremaining: 85.7ms\n",
      "12:\tlearn: 0.2879721\ttotal: 29.4ms\tremaining: 83.7ms\n",
      "13:\tlearn: 0.2764793\ttotal: 31.8ms\tremaining: 81.7ms\n",
      "14:\tlearn: 0.2653904\ttotal: 34.1ms\tremaining: 79.5ms\n",
      "15:\tlearn: 0.2555651\ttotal: 36.5ms\tremaining: 77.6ms\n",
      "16:\tlearn: 0.2447383\ttotal: 38.7ms\tremaining: 75.1ms\n",
      "17:\tlearn: 0.2356304\ttotal: 41ms\tremaining: 72.9ms\n",
      "18:\tlearn: 0.2272268\ttotal: 43.4ms\tremaining: 70.9ms\n",
      "19:\tlearn: 0.2204892\ttotal: 45.7ms\tremaining: 68.6ms\n",
      "20:\tlearn: 0.2123663\ttotal: 47.9ms\tremaining: 66.1ms\n",
      "21:\tlearn: 0.2079614\ttotal: 50.2ms\tremaining: 64ms\n",
      "22:\tlearn: 0.2027151\ttotal: 52.5ms\tremaining: 61.6ms\n",
      "23:\tlearn: 0.1968645\ttotal: 54.8ms\tremaining: 59.4ms\n",
      "24:\tlearn: 0.1912361\ttotal: 57.1ms\tremaining: 57.1ms\n",
      "25:\tlearn: 0.1861829\ttotal: 59.4ms\tremaining: 54.8ms\n",
      "26:\tlearn: 0.1818745\ttotal: 61.7ms\tremaining: 52.5ms\n",
      "27:\tlearn: 0.1770800\ttotal: 64ms\tremaining: 50.3ms\n",
      "28:\tlearn: 0.1731373\ttotal: 66.2ms\tremaining: 48ms\n",
      "29:\tlearn: 0.1682575\ttotal: 68.8ms\tremaining: 45.9ms\n",
      "30:\tlearn: 0.1638260\ttotal: 71.2ms\tremaining: 43.7ms\n",
      "31:\tlearn: 0.1611567\ttotal: 74.1ms\tremaining: 41.7ms\n",
      "32:\tlearn: 0.1569225\ttotal: 76.2ms\tremaining: 39.3ms\n",
      "33:\tlearn: 0.1548774\ttotal: 78.5ms\tremaining: 36.9ms\n",
      "34:\tlearn: 0.1522495\ttotal: 80.9ms\tremaining: 34.7ms\n",
      "35:\tlearn: 0.1494951\ttotal: 83.2ms\tremaining: 32.4ms\n",
      "36:\tlearn: 0.1466880\ttotal: 85.5ms\tremaining: 30ms\n",
      "37:\tlearn: 0.1429074\ttotal: 87.8ms\tremaining: 27.7ms\n",
      "38:\tlearn: 0.1400885\ttotal: 90.1ms\tremaining: 25.4ms\n",
      "39:\tlearn: 0.1377791\ttotal: 92.4ms\tremaining: 23.1ms\n",
      "40:\tlearn: 0.1359086\ttotal: 94.6ms\tremaining: 20.8ms\n",
      "41:\tlearn: 0.1346784\ttotal: 96.9ms\tremaining: 18.5ms\n",
      "42:\tlearn: 0.1319116\ttotal: 99.2ms\tremaining: 16.1ms\n",
      "43:\tlearn: 0.1294421\ttotal: 101ms\tremaining: 13.8ms\n",
      "44:\tlearn: 0.1279441\ttotal: 104ms\tremaining: 11.5ms\n",
      "45:\tlearn: 0.1264493\ttotal: 106ms\tremaining: 9.24ms\n",
      "46:\tlearn: 0.1253683\ttotal: 109ms\tremaining: 6.93ms\n",
      "47:\tlearn: 0.1238981\ttotal: 111ms\tremaining: 4.62ms\n",
      "48:\tlearn: 0.1231252\ttotal: 113ms\tremaining: 2.31ms\n",
      "49:\tlearn: 0.1217578\ttotal: 116ms\tremaining: 0us\n",
      "0:\tlearn: 0.6862465\ttotal: 1.53ms\tremaining: 152ms\n",
      "1:\tlearn: 0.6800288\ttotal: 3.78ms\tremaining: 185ms\n",
      "2:\tlearn: 0.6737208\ttotal: 6.19ms\tremaining: 200ms\n",
      "3:\tlearn: 0.6675232\ttotal: 8.52ms\tremaining: 204ms\n",
      "4:\tlearn: 0.6619713\ttotal: 10.7ms\tremaining: 203ms\n",
      "5:\tlearn: 0.6558108\ttotal: 11.8ms\tremaining: 184ms\n",
      "6:\tlearn: 0.6502206\ttotal: 14ms\tremaining: 186ms\n",
      "7:\tlearn: 0.6442342\ttotal: 16ms\tremaining: 184ms\n",
      "8:\tlearn: 0.6392838\ttotal: 18.1ms\tremaining: 183ms\n",
      "9:\tlearn: 0.6336706\ttotal: 21.7ms\tremaining: 195ms\n",
      "10:\tlearn: 0.6279715\ttotal: 23.8ms\tremaining: 193ms\n",
      "11:\tlearn: 0.6224709\ttotal: 26.1ms\tremaining: 191ms\n",
      "12:\tlearn: 0.6169614\ttotal: 28.4ms\tremaining: 190ms\n",
      "13:\tlearn: 0.6116428\ttotal: 30.7ms\tremaining: 188ms\n",
      "14:\tlearn: 0.6063673\ttotal: 33.7ms\tremaining: 191ms\n",
      "15:\tlearn: 0.6015985\ttotal: 35.8ms\tremaining: 188ms\n",
      "16:\tlearn: 0.5966820\ttotal: 38.1ms\tremaining: 186ms\n",
      "17:\tlearn: 0.5919107\ttotal: 40.2ms\tremaining: 183ms\n",
      "18:\tlearn: 0.5870104\ttotal: 42.4ms\tremaining: 181ms\n",
      "19:\tlearn: 0.5824297\ttotal: 44.7ms\tremaining: 179ms\n",
      "20:\tlearn: 0.5778384\ttotal: 47.3ms\tremaining: 178ms\n",
      "21:\tlearn: 0.5729241\ttotal: 49.6ms\tremaining: 176ms\n",
      "22:\tlearn: 0.5682597\ttotal: 51.8ms\tremaining: 174ms\n",
      "23:\tlearn: 0.5637475\ttotal: 54.5ms\tremaining: 172ms\n",
      "24:\tlearn: 0.5593827\ttotal: 56.8ms\tremaining: 170ms\n",
      "25:\tlearn: 0.5552732\ttotal: 59.1ms\tremaining: 168ms\n",
      "26:\tlearn: 0.5507952\ttotal: 61.5ms\tremaining: 166ms\n",
      "27:\tlearn: 0.5464636\ttotal: 63.5ms\tremaining: 163ms\n",
      "28:\tlearn: 0.5424471\ttotal: 65.6ms\tremaining: 161ms\n",
      "29:\tlearn: 0.5384969\ttotal: 67.8ms\tremaining: 158ms\n",
      "30:\tlearn: 0.5347301\ttotal: 70ms\tremaining: 156ms\n",
      "31:\tlearn: 0.5303606\ttotal: 72.4ms\tremaining: 154ms\n",
      "32:\tlearn: 0.5265335\ttotal: 74.6ms\tremaining: 151ms\n",
      "33:\tlearn: 0.5223459\ttotal: 77ms\tremaining: 149ms\n",
      "34:\tlearn: 0.5184427\ttotal: 79.4ms\tremaining: 147ms\n",
      "35:\tlearn: 0.5144810\ttotal: 81.8ms\tremaining: 145ms\n",
      "36:\tlearn: 0.5102032\ttotal: 84.7ms\tremaining: 144ms\n",
      "37:\tlearn: 0.5064519\ttotal: 87ms\tremaining: 142ms\n",
      "38:\tlearn: 0.5029112\ttotal: 90.1ms\tremaining: 141ms\n",
      "39:\tlearn: 0.4991977\ttotal: 92.4ms\tremaining: 139ms\n",
      "40:\tlearn: 0.4955731\ttotal: 94.7ms\tremaining: 136ms\n",
      "41:\tlearn: 0.4921373\ttotal: 96.9ms\tremaining: 134ms\n",
      "42:\tlearn: 0.4886631\ttotal: 99.2ms\tremaining: 131ms\n",
      "43:\tlearn: 0.4851428\ttotal: 102ms\tremaining: 129ms\n",
      "44:\tlearn: 0.4816377\ttotal: 104ms\tremaining: 127ms\n",
      "45:\tlearn: 0.4782961\ttotal: 106ms\tremaining: 125ms\n",
      "46:\tlearn: 0.4748210\ttotal: 108ms\tremaining: 122ms\n",
      "47:\tlearn: 0.4714994\ttotal: 111ms\tremaining: 120ms\n",
      "48:\tlearn: 0.4684302\ttotal: 113ms\tremaining: 118ms\n",
      "49:\tlearn: 0.4652623\ttotal: 115ms\tremaining: 115ms\n",
      "50:\tlearn: 0.4621369\ttotal: 118ms\tremaining: 113ms\n",
      "51:\tlearn: 0.4589616\ttotal: 120ms\tremaining: 111ms\n",
      "52:\tlearn: 0.4558525\ttotal: 122ms\tremaining: 108ms\n",
      "53:\tlearn: 0.4528924\ttotal: 125ms\tremaining: 106ms\n",
      "54:\tlearn: 0.4495640\ttotal: 127ms\tremaining: 104ms\n",
      "55:\tlearn: 0.4462400\ttotal: 129ms\tremaining: 101ms\n",
      "56:\tlearn: 0.4435628\ttotal: 131ms\tremaining: 99ms\n",
      "57:\tlearn: 0.4405534\ttotal: 134ms\tremaining: 96.7ms\n",
      "58:\tlearn: 0.4375236\ttotal: 136ms\tremaining: 94.3ms\n",
      "59:\tlearn: 0.4346304\ttotal: 138ms\tremaining: 92ms\n",
      "60:\tlearn: 0.4318478\ttotal: 140ms\tremaining: 89.7ms\n",
      "61:\tlearn: 0.4291626\ttotal: 142ms\tremaining: 87.3ms\n",
      "62:\tlearn: 0.4265483\ttotal: 145ms\tremaining: 85ms\n",
      "63:\tlearn: 0.4241635\ttotal: 147ms\tremaining: 82.7ms\n",
      "64:\tlearn: 0.4216367\ttotal: 149ms\tremaining: 80.4ms\n",
      "65:\tlearn: 0.4185545\ttotal: 152ms\tremaining: 78.1ms\n",
      "66:\tlearn: 0.4160765\ttotal: 154ms\tremaining: 75.7ms\n",
      "67:\tlearn: 0.4137690\ttotal: 156ms\tremaining: 73.6ms\n",
      "68:\tlearn: 0.4113742\ttotal: 159ms\tremaining: 71.4ms\n",
      "69:\tlearn: 0.4086368\ttotal: 161ms\tremaining: 69ms\n",
      "70:\tlearn: 0.4065426\ttotal: 163ms\tremaining: 66.6ms\n",
      "71:\tlearn: 0.4040228\ttotal: 166ms\tremaining: 64.4ms\n",
      "72:\tlearn: 0.4013641\ttotal: 168ms\tremaining: 62.2ms\n",
      "73:\tlearn: 0.3990311\ttotal: 170ms\tremaining: 59.8ms\n",
      "74:\tlearn: 0.3967514\ttotal: 173ms\tremaining: 57.5ms\n",
      "75:\tlearn: 0.3945921\ttotal: 175ms\tremaining: 55.3ms\n",
      "76:\tlearn: 0.3924720\ttotal: 177ms\tremaining: 52.9ms\n",
      "77:\tlearn: 0.3899918\ttotal: 180ms\tremaining: 50.6ms\n",
      "78:\tlearn: 0.3877766\ttotal: 182ms\tremaining: 48.3ms\n",
      "79:\tlearn: 0.3854460\ttotal: 184ms\tremaining: 46ms\n",
      "80:\tlearn: 0.3832072\ttotal: 186ms\tremaining: 43.7ms\n",
      "81:\tlearn: 0.3807473\ttotal: 189ms\tremaining: 41.4ms\n",
      "82:\tlearn: 0.3784305\ttotal: 192ms\tremaining: 39.3ms\n",
      "83:\tlearn: 0.3760086\ttotal: 194ms\tremaining: 37ms\n",
      "84:\tlearn: 0.3738563\ttotal: 196ms\tremaining: 34.6ms\n",
      "85:\tlearn: 0.3720287\ttotal: 199ms\tremaining: 32.3ms\n",
      "86:\tlearn: 0.3700289\ttotal: 201ms\tremaining: 30ms\n",
      "87:\tlearn: 0.3681698\ttotal: 204ms\tremaining: 27.8ms\n",
      "88:\tlearn: 0.3658150\ttotal: 206ms\tremaining: 25.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89:\tlearn: 0.3639283\ttotal: 208ms\tremaining: 23.1ms\n",
      "90:\tlearn: 0.3616361\ttotal: 210ms\tremaining: 20.8ms\n",
      "91:\tlearn: 0.3597144\ttotal: 212ms\tremaining: 18.5ms\n",
      "92:\tlearn: 0.3578588\ttotal: 215ms\tremaining: 16.2ms\n",
      "93:\tlearn: 0.3557728\ttotal: 217ms\tremaining: 13.9ms\n",
      "94:\tlearn: 0.3537851\ttotal: 220ms\tremaining: 11.6ms\n",
      "95:\tlearn: 0.3516687\ttotal: 222ms\tremaining: 9.24ms\n",
      "96:\tlearn: 0.3499245\ttotal: 224ms\tremaining: 6.93ms\n",
      "97:\tlearn: 0.3478577\ttotal: 226ms\tremaining: 4.62ms\n",
      "98:\tlearn: 0.3459126\ttotal: 229ms\tremaining: 2.31ms\n",
      "99:\tlearn: 0.3441700\ttotal: 232ms\tremaining: 0us\n",
      "0:\tlearn: 0.6860899\ttotal: 2.17ms\tremaining: 215ms\n",
      "1:\tlearn: 0.6793130\ttotal: 4.43ms\tremaining: 217ms\n",
      "2:\tlearn: 0.6734430\ttotal: 6.57ms\tremaining: 212ms\n",
      "3:\tlearn: 0.6675745\ttotal: 8.58ms\tremaining: 206ms\n",
      "4:\tlearn: 0.6615878\ttotal: 10.7ms\tremaining: 204ms\n",
      "5:\tlearn: 0.6556114\ttotal: 13ms\tremaining: 204ms\n",
      "6:\tlearn: 0.6499470\ttotal: 15.3ms\tremaining: 204ms\n",
      "7:\tlearn: 0.6441324\ttotal: 17.4ms\tremaining: 200ms\n",
      "8:\tlearn: 0.6383721\ttotal: 19.7ms\tremaining: 199ms\n",
      "9:\tlearn: 0.6327614\ttotal: 21.9ms\tremaining: 197ms\n",
      "10:\tlearn: 0.6271179\ttotal: 23ms\tremaining: 186ms\n",
      "11:\tlearn: 0.6215042\ttotal: 25.2ms\tremaining: 185ms\n",
      "12:\tlearn: 0.6163936\ttotal: 27.3ms\tremaining: 183ms\n",
      "13:\tlearn: 0.6108643\ttotal: 29.6ms\tremaining: 182ms\n",
      "14:\tlearn: 0.6059164\ttotal: 32.1ms\tremaining: 182ms\n",
      "15:\tlearn: 0.6006790\ttotal: 34.2ms\tremaining: 179ms\n",
      "16:\tlearn: 0.5957002\ttotal: 36.2ms\tremaining: 177ms\n",
      "17:\tlearn: 0.5905492\ttotal: 38.5ms\tremaining: 175ms\n",
      "18:\tlearn: 0.5858462\ttotal: 40.6ms\tremaining: 173ms\n",
      "19:\tlearn: 0.5812597\ttotal: 42.8ms\tremaining: 171ms\n",
      "20:\tlearn: 0.5767754\ttotal: 44.9ms\tremaining: 169ms\n",
      "21:\tlearn: 0.5719220\ttotal: 46.9ms\tremaining: 166ms\n",
      "22:\tlearn: 0.5673582\ttotal: 49.1ms\tremaining: 164ms\n",
      "23:\tlearn: 0.5630790\ttotal: 50.9ms\tremaining: 161ms\n",
      "24:\tlearn: 0.5585616\ttotal: 53.4ms\tremaining: 160ms\n",
      "25:\tlearn: 0.5540444\ttotal: 55.7ms\tremaining: 158ms\n",
      "26:\tlearn: 0.5496615\ttotal: 57.9ms\tremaining: 156ms\n",
      "27:\tlearn: 0.5457394\ttotal: 60.2ms\tremaining: 155ms\n",
      "28:\tlearn: 0.5413615\ttotal: 62.4ms\tremaining: 153ms\n",
      "29:\tlearn: 0.5374409\ttotal: 64.8ms\tremaining: 151ms\n",
      "30:\tlearn: 0.5331692\ttotal: 66.9ms\tremaining: 149ms\n",
      "31:\tlearn: 0.5291912\ttotal: 69ms\tremaining: 147ms\n",
      "32:\tlearn: 0.5254107\ttotal: 71.2ms\tremaining: 145ms\n",
      "33:\tlearn: 0.5214309\ttotal: 73.4ms\tremaining: 143ms\n",
      "34:\tlearn: 0.5177121\ttotal: 75.5ms\tremaining: 140ms\n",
      "35:\tlearn: 0.5140227\ttotal: 77.6ms\tremaining: 138ms\n",
      "36:\tlearn: 0.5102675\ttotal: 79.8ms\tremaining: 136ms\n",
      "37:\tlearn: 0.5067211\ttotal: 82ms\tremaining: 134ms\n",
      "38:\tlearn: 0.5027523\ttotal: 84.4ms\tremaining: 132ms\n",
      "39:\tlearn: 0.4990921\ttotal: 86.6ms\tremaining: 130ms\n",
      "40:\tlearn: 0.4954921\ttotal: 89.1ms\tremaining: 128ms\n",
      "41:\tlearn: 0.4918964\ttotal: 91.3ms\tremaining: 126ms\n",
      "42:\tlearn: 0.4882223\ttotal: 93.4ms\tremaining: 124ms\n",
      "43:\tlearn: 0.4844639\ttotal: 95.8ms\tremaining: 122ms\n",
      "44:\tlearn: 0.4808891\ttotal: 97.9ms\tremaining: 120ms\n",
      "45:\tlearn: 0.4773684\ttotal: 100ms\tremaining: 118ms\n",
      "46:\tlearn: 0.4741019\ttotal: 102ms\tremaining: 115ms\n",
      "47:\tlearn: 0.4705823\ttotal: 105ms\tremaining: 114ms\n",
      "48:\tlearn: 0.4676850\ttotal: 108ms\tremaining: 112ms\n",
      "49:\tlearn: 0.4647567\ttotal: 110ms\tremaining: 110ms\n",
      "50:\tlearn: 0.4616489\ttotal: 112ms\tremaining: 108ms\n",
      "51:\tlearn: 0.4584640\ttotal: 114ms\tremaining: 106ms\n",
      "52:\tlearn: 0.4552511\ttotal: 117ms\tremaining: 103ms\n",
      "53:\tlearn: 0.4521164\ttotal: 119ms\tremaining: 102ms\n",
      "54:\tlearn: 0.4487053\ttotal: 121ms\tremaining: 99.3ms\n",
      "55:\tlearn: 0.4457342\ttotal: 124ms\tremaining: 97.5ms\n",
      "56:\tlearn: 0.4430570\ttotal: 127ms\tremaining: 96ms\n",
      "57:\tlearn: 0.4399730\ttotal: 130ms\tremaining: 93.9ms\n",
      "58:\tlearn: 0.4371578\ttotal: 132ms\tremaining: 91.7ms\n",
      "59:\tlearn: 0.4342932\ttotal: 134ms\tremaining: 89.5ms\n",
      "60:\tlearn: 0.4313124\ttotal: 137ms\tremaining: 87.3ms\n",
      "61:\tlearn: 0.4283701\ttotal: 139ms\tremaining: 85.1ms\n",
      "62:\tlearn: 0.4257191\ttotal: 141ms\tremaining: 82.9ms\n",
      "63:\tlearn: 0.4233053\ttotal: 143ms\tremaining: 80.6ms\n",
      "64:\tlearn: 0.4206035\ttotal: 145ms\tremaining: 78.3ms\n",
      "65:\tlearn: 0.4177061\ttotal: 148ms\tremaining: 76.1ms\n",
      "66:\tlearn: 0.4152554\ttotal: 150ms\tremaining: 74ms\n",
      "67:\tlearn: 0.4128509\ttotal: 153ms\tremaining: 71.8ms\n",
      "68:\tlearn: 0.4102920\ttotal: 155ms\tremaining: 69.6ms\n",
      "69:\tlearn: 0.4075948\ttotal: 157ms\tremaining: 67.3ms\n",
      "70:\tlearn: 0.4053619\ttotal: 160ms\tremaining: 65.2ms\n",
      "71:\tlearn: 0.4028584\ttotal: 163ms\tremaining: 63.3ms\n",
      "72:\tlearn: 0.4003088\ttotal: 165ms\tremaining: 61ms\n",
      "73:\tlearn: 0.3977469\ttotal: 168ms\tremaining: 58.9ms\n",
      "74:\tlearn: 0.3952514\ttotal: 170ms\tremaining: 56.7ms\n",
      "75:\tlearn: 0.3931275\ttotal: 173ms\tremaining: 54.7ms\n",
      "76:\tlearn: 0.3911209\ttotal: 176ms\tremaining: 52.5ms\n",
      "77:\tlearn: 0.3887334\ttotal: 178ms\tremaining: 50.2ms\n",
      "78:\tlearn: 0.3863113\ttotal: 180ms\tremaining: 47.9ms\n",
      "79:\tlearn: 0.3839159\ttotal: 182ms\tremaining: 45.6ms\n",
      "80:\tlearn: 0.3816348\ttotal: 185ms\tremaining: 43.3ms\n",
      "81:\tlearn: 0.3794523\ttotal: 187ms\tremaining: 41ms\n",
      "82:\tlearn: 0.3771788\ttotal: 189ms\tremaining: 38.7ms\n",
      "83:\tlearn: 0.3748380\ttotal: 191ms\tremaining: 36.5ms\n",
      "84:\tlearn: 0.3727348\ttotal: 194ms\tremaining: 34.2ms\n",
      "85:\tlearn: 0.3706072\ttotal: 196ms\tremaining: 31.9ms\n",
      "86:\tlearn: 0.3684430\ttotal: 198ms\tremaining: 29.6ms\n",
      "87:\tlearn: 0.3665853\ttotal: 201ms\tremaining: 27.4ms\n",
      "88:\tlearn: 0.3644949\ttotal: 203ms\tremaining: 25.1ms\n",
      "89:\tlearn: 0.3624416\ttotal: 206ms\tremaining: 22.8ms\n",
      "90:\tlearn: 0.3603787\ttotal: 208ms\tremaining: 20.6ms\n",
      "91:\tlearn: 0.3584773\ttotal: 210ms\tremaining: 18.3ms\n",
      "92:\tlearn: 0.3565561\ttotal: 213ms\tremaining: 16ms\n",
      "93:\tlearn: 0.3544571\ttotal: 215ms\tremaining: 13.7ms\n",
      "94:\tlearn: 0.3526362\ttotal: 218ms\tremaining: 11.4ms\n",
      "95:\tlearn: 0.3504841\ttotal: 220ms\tremaining: 9.16ms\n",
      "96:\tlearn: 0.3485793\ttotal: 222ms\tremaining: 6.87ms\n",
      "97:\tlearn: 0.3466588\ttotal: 224ms\tremaining: 4.58ms\n",
      "98:\tlearn: 0.3446815\ttotal: 227ms\tremaining: 2.29ms\n",
      "99:\tlearn: 0.3430151\ttotal: 229ms\tremaining: 0us\n",
      "0:\tlearn: 0.6861343\ttotal: 2.29ms\tremaining: 226ms\n",
      "1:\tlearn: 0.6793919\ttotal: 4.78ms\tremaining: 234ms\n",
      "2:\tlearn: 0.6734481\ttotal: 6.86ms\tremaining: 222ms\n",
      "3:\tlearn: 0.6676918\ttotal: 9.78ms\tremaining: 235ms\n",
      "4:\tlearn: 0.6618046\ttotal: 11.9ms\tremaining: 226ms\n",
      "5:\tlearn: 0.6558412\ttotal: 14.3ms\tremaining: 224ms\n",
      "6:\tlearn: 0.6500463\ttotal: 16.7ms\tremaining: 222ms\n",
      "7:\tlearn: 0.6439136\ttotal: 19.2ms\tremaining: 221ms\n",
      "8:\tlearn: 0.6382547\ttotal: 21.3ms\tremaining: 215ms\n",
      "9:\tlearn: 0.6325391\ttotal: 23.5ms\tremaining: 212ms\n",
      "10:\tlearn: 0.6269709\ttotal: 24.8ms\tremaining: 201ms\n",
      "11:\tlearn: 0.6218358\ttotal: 27.1ms\tremaining: 199ms\n",
      "12:\tlearn: 0.6167415\ttotal: 29.3ms\tremaining: 196ms\n",
      "13:\tlearn: 0.6111140\ttotal: 32.2ms\tremaining: 198ms\n",
      "14:\tlearn: 0.6059562\ttotal: 34.7ms\tremaining: 196ms\n",
      "15:\tlearn: 0.6006331\ttotal: 36.8ms\tremaining: 193ms\n",
      "16:\tlearn: 0.5954944\ttotal: 39ms\tremaining: 191ms\n",
      "17:\tlearn: 0.5901443\ttotal: 41.2ms\tremaining: 188ms\n",
      "18:\tlearn: 0.5851572\ttotal: 43.3ms\tremaining: 185ms\n",
      "19:\tlearn: 0.5803863\ttotal: 45.4ms\tremaining: 182ms\n",
      "20:\tlearn: 0.5756928\ttotal: 47.4ms\tremaining: 178ms\n",
      "21:\tlearn: 0.5706426\ttotal: 49.6ms\tremaining: 176ms\n",
      "22:\tlearn: 0.5660743\ttotal: 51.8ms\tremaining: 173ms\n",
      "23:\tlearn: 0.5617769\ttotal: 53.4ms\tremaining: 169ms\n",
      "24:\tlearn: 0.5572030\ttotal: 56.2ms\tremaining: 169ms\n",
      "25:\tlearn: 0.5531634\ttotal: 58.3ms\tremaining: 166ms\n",
      "26:\tlearn: 0.5487930\ttotal: 60.4ms\tremaining: 163ms\n",
      "27:\tlearn: 0.5445559\ttotal: 62.6ms\tremaining: 161ms\n",
      "28:\tlearn: 0.5401919\ttotal: 64.8ms\tremaining: 159ms\n",
      "29:\tlearn: 0.5359377\ttotal: 67.1ms\tremaining: 156ms\n",
      "30:\tlearn: 0.5318799\ttotal: 69.4ms\tremaining: 154ms\n",
      "31:\tlearn: 0.5280130\ttotal: 71.5ms\tremaining: 152ms\n",
      "32:\tlearn: 0.5241710\ttotal: 73.6ms\tremaining: 149ms\n",
      "33:\tlearn: 0.5201742\ttotal: 76.4ms\tremaining: 148ms\n",
      "34:\tlearn: 0.5163647\ttotal: 78.5ms\tremaining: 146ms\n",
      "35:\tlearn: 0.5127074\ttotal: 80.5ms\tremaining: 143ms\n",
      "36:\tlearn: 0.5085491\ttotal: 83.4ms\tremaining: 142ms\n",
      "37:\tlearn: 0.5047086\ttotal: 85.9ms\tremaining: 140ms\n",
      "38:\tlearn: 0.5007771\ttotal: 88.2ms\tremaining: 138ms\n",
      "39:\tlearn: 0.4971625\ttotal: 90.4ms\tremaining: 136ms\n",
      "40:\tlearn: 0.4936249\ttotal: 92.7ms\tremaining: 133ms\n",
      "41:\tlearn: 0.4900292\ttotal: 94.9ms\tremaining: 131ms\n",
      "42:\tlearn: 0.4863241\ttotal: 97.2ms\tremaining: 129ms\n",
      "43:\tlearn: 0.4825842\ttotal: 99.3ms\tremaining: 126ms\n",
      "44:\tlearn: 0.4788724\ttotal: 102ms\tremaining: 124ms\n",
      "45:\tlearn: 0.4754534\ttotal: 104ms\tremaining: 122ms\n",
      "46:\tlearn: 0.4724018\ttotal: 107ms\tremaining: 121ms\n",
      "47:\tlearn: 0.4689811\ttotal: 109ms\tremaining: 118ms\n",
      "48:\tlearn: 0.4658977\ttotal: 112ms\tremaining: 116ms\n",
      "49:\tlearn: 0.4628520\ttotal: 114ms\tremaining: 114ms\n",
      "50:\tlearn: 0.4596544\ttotal: 116ms\tremaining: 112ms\n",
      "51:\tlearn: 0.4564637\ttotal: 118ms\tremaining: 109ms\n",
      "52:\tlearn: 0.4533200\ttotal: 121ms\tremaining: 107ms\n",
      "53:\tlearn: 0.4501575\ttotal: 123ms\tremaining: 105ms\n",
      "54:\tlearn: 0.4467252\ttotal: 126ms\tremaining: 103ms\n",
      "55:\tlearn: 0.4434253\ttotal: 128ms\tremaining: 101ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56:\tlearn: 0.4406830\ttotal: 131ms\tremaining: 98.6ms\n",
      "57:\tlearn: 0.4377014\ttotal: 133ms\tremaining: 96.3ms\n",
      "58:\tlearn: 0.4347007\ttotal: 135ms\tremaining: 93.9ms\n",
      "59:\tlearn: 0.4318401\ttotal: 137ms\tremaining: 91.6ms\n",
      "60:\tlearn: 0.4291104\ttotal: 140ms\tremaining: 89.4ms\n",
      "61:\tlearn: 0.4265164\ttotal: 142ms\tremaining: 87.2ms\n",
      "62:\tlearn: 0.4237690\ttotal: 145ms\tremaining: 84.9ms\n",
      "63:\tlearn: 0.4213694\ttotal: 147ms\tremaining: 82.5ms\n",
      "64:\tlearn: 0.4188928\ttotal: 149ms\tremaining: 80.2ms\n",
      "65:\tlearn: 0.4158896\ttotal: 151ms\tremaining: 77.8ms\n",
      "66:\tlearn: 0.4128656\ttotal: 154ms\tremaining: 75.8ms\n",
      "67:\tlearn: 0.4106175\ttotal: 156ms\tremaining: 73.5ms\n",
      "68:\tlearn: 0.4081068\ttotal: 158ms\tremaining: 71.1ms\n",
      "69:\tlearn: 0.4053526\ttotal: 161ms\tremaining: 68.8ms\n",
      "70:\tlearn: 0.4031798\ttotal: 163ms\tremaining: 66.5ms\n",
      "71:\tlearn: 0.4006751\ttotal: 165ms\tremaining: 64.2ms\n",
      "72:\tlearn: 0.3980065\ttotal: 167ms\tremaining: 61.9ms\n",
      "73:\tlearn: 0.3955135\ttotal: 170ms\tremaining: 59.7ms\n",
      "74:\tlearn: 0.3931801\ttotal: 172ms\tremaining: 57.5ms\n",
      "75:\tlearn: 0.3910357\ttotal: 175ms\tremaining: 55.1ms\n",
      "76:\tlearn: 0.3888049\ttotal: 177ms\tremaining: 52.9ms\n",
      "77:\tlearn: 0.3864314\ttotal: 180ms\tremaining: 50.8ms\n",
      "78:\tlearn: 0.3841529\ttotal: 182ms\tremaining: 48.5ms\n",
      "79:\tlearn: 0.3818067\ttotal: 185ms\tremaining: 46.2ms\n",
      "80:\tlearn: 0.3795760\ttotal: 188ms\tremaining: 44ms\n",
      "81:\tlearn: 0.3771341\ttotal: 190ms\tremaining: 41.7ms\n",
      "82:\tlearn: 0.3748428\ttotal: 192ms\tremaining: 39.4ms\n",
      "83:\tlearn: 0.3726905\ttotal: 195ms\tremaining: 37.1ms\n",
      "84:\tlearn: 0.3705994\ttotal: 197ms\tremaining: 34.8ms\n",
      "85:\tlearn: 0.3684336\ttotal: 199ms\tremaining: 32.5ms\n",
      "86:\tlearn: 0.3665067\ttotal: 202ms\tremaining: 30.1ms\n",
      "87:\tlearn: 0.3646702\ttotal: 204ms\tremaining: 27.8ms\n",
      "88:\tlearn: 0.3625356\ttotal: 206ms\tremaining: 25.5ms\n",
      "89:\tlearn: 0.3602877\ttotal: 209ms\tremaining: 23.2ms\n",
      "90:\tlearn: 0.3581598\ttotal: 211ms\tremaining: 20.9ms\n",
      "91:\tlearn: 0.3561508\ttotal: 213ms\tremaining: 18.6ms\n",
      "92:\tlearn: 0.3541523\ttotal: 216ms\tremaining: 16.2ms\n",
      "93:\tlearn: 0.3520767\ttotal: 218ms\tremaining: 13.9ms\n",
      "94:\tlearn: 0.3502694\ttotal: 220ms\tremaining: 11.6ms\n",
      "95:\tlearn: 0.3480987\ttotal: 222ms\tremaining: 9.26ms\n",
      "96:\tlearn: 0.3465003\ttotal: 224ms\tremaining: 6.94ms\n",
      "97:\tlearn: 0.3445299\ttotal: 227ms\tremaining: 4.63ms\n",
      "98:\tlearn: 0.3425336\ttotal: 229ms\tremaining: 2.31ms\n",
      "99:\tlearn: 0.3408922\ttotal: 231ms\tremaining: 0us\n",
      "0:\tlearn: 0.6593054\ttotal: 1.55ms\tremaining: 154ms\n",
      "1:\tlearn: 0.6309429\ttotal: 3.8ms\tremaining: 186ms\n",
      "2:\tlearn: 0.6039985\ttotal: 5.66ms\tremaining: 183ms\n",
      "3:\tlearn: 0.5800866\ttotal: 7.88ms\tremaining: 189ms\n",
      "4:\tlearn: 0.5586421\ttotal: 10.7ms\tremaining: 204ms\n",
      "5:\tlearn: 0.5373816\ttotal: 13ms\tremaining: 204ms\n",
      "6:\tlearn: 0.5162916\ttotal: 15.9ms\tremaining: 211ms\n",
      "7:\tlearn: 0.4980395\ttotal: 18.2ms\tremaining: 209ms\n",
      "8:\tlearn: 0.4809877\ttotal: 20.5ms\tremaining: 208ms\n",
      "9:\tlearn: 0.4645617\ttotal: 22.3ms\tremaining: 201ms\n",
      "10:\tlearn: 0.4489201\ttotal: 24.7ms\tremaining: 200ms\n",
      "11:\tlearn: 0.4344166\ttotal: 26.9ms\tremaining: 197ms\n",
      "12:\tlearn: 0.4210810\ttotal: 29.1ms\tremaining: 195ms\n",
      "13:\tlearn: 0.4071946\ttotal: 31.4ms\tremaining: 193ms\n",
      "14:\tlearn: 0.3946361\ttotal: 33.9ms\tremaining: 192ms\n",
      "15:\tlearn: 0.3824853\ttotal: 36.1ms\tremaining: 190ms\n",
      "16:\tlearn: 0.3706711\ttotal: 38.5ms\tremaining: 188ms\n",
      "17:\tlearn: 0.3597038\ttotal: 40.8ms\tremaining: 186ms\n",
      "18:\tlearn: 0.3512110\ttotal: 43ms\tremaining: 183ms\n",
      "19:\tlearn: 0.3417171\ttotal: 45.2ms\tremaining: 181ms\n",
      "20:\tlearn: 0.3335921\ttotal: 47.6ms\tremaining: 179ms\n",
      "21:\tlearn: 0.3246580\ttotal: 50.3ms\tremaining: 178ms\n",
      "22:\tlearn: 0.3172125\ttotal: 52.6ms\tremaining: 176ms\n",
      "23:\tlearn: 0.3107614\ttotal: 54.8ms\tremaining: 173ms\n",
      "24:\tlearn: 0.3031342\ttotal: 57.1ms\tremaining: 171ms\n",
      "25:\tlearn: 0.2960356\ttotal: 59.5ms\tremaining: 169ms\n",
      "26:\tlearn: 0.2892554\ttotal: 61.6ms\tremaining: 167ms\n",
      "27:\tlearn: 0.2824743\ttotal: 63.9ms\tremaining: 164ms\n",
      "28:\tlearn: 0.2762719\ttotal: 66.1ms\tremaining: 162ms\n",
      "29:\tlearn: 0.2705776\ttotal: 68.4ms\tremaining: 160ms\n",
      "30:\tlearn: 0.2651965\ttotal: 70.7ms\tremaining: 157ms\n",
      "31:\tlearn: 0.2601832\ttotal: 73ms\tremaining: 155ms\n",
      "32:\tlearn: 0.2543914\ttotal: 75.4ms\tremaining: 153ms\n",
      "33:\tlearn: 0.2493058\ttotal: 77.8ms\tremaining: 151ms\n",
      "34:\tlearn: 0.2447318\ttotal: 80.1ms\tremaining: 149ms\n",
      "35:\tlearn: 0.2391245\ttotal: 82.4ms\tremaining: 146ms\n",
      "36:\tlearn: 0.2355614\ttotal: 84.6ms\tremaining: 144ms\n",
      "37:\tlearn: 0.2302538\ttotal: 86.9ms\tremaining: 142ms\n",
      "38:\tlearn: 0.2264421\ttotal: 89.2ms\tremaining: 139ms\n",
      "39:\tlearn: 0.2227293\ttotal: 91.6ms\tremaining: 137ms\n",
      "40:\tlearn: 0.2197457\ttotal: 94.1ms\tremaining: 135ms\n",
      "41:\tlearn: 0.2161603\ttotal: 96.5ms\tremaining: 133ms\n",
      "42:\tlearn: 0.2126614\ttotal: 99.4ms\tremaining: 132ms\n",
      "43:\tlearn: 0.2090448\ttotal: 102ms\tremaining: 129ms\n",
      "44:\tlearn: 0.2057844\ttotal: 104ms\tremaining: 127ms\n",
      "45:\tlearn: 0.2029529\ttotal: 106ms\tremaining: 124ms\n",
      "46:\tlearn: 0.1998490\ttotal: 108ms\tremaining: 122ms\n",
      "47:\tlearn: 0.1967153\ttotal: 110ms\tremaining: 120ms\n",
      "48:\tlearn: 0.1935647\ttotal: 113ms\tremaining: 118ms\n",
      "49:\tlearn: 0.1907406\ttotal: 115ms\tremaining: 115ms\n",
      "50:\tlearn: 0.1880107\ttotal: 118ms\tremaining: 113ms\n",
      "51:\tlearn: 0.1853218\ttotal: 120ms\tremaining: 111ms\n",
      "52:\tlearn: 0.1831841\ttotal: 123ms\tremaining: 109ms\n",
      "53:\tlearn: 0.1812494\ttotal: 126ms\tremaining: 108ms\n",
      "54:\tlearn: 0.1785001\ttotal: 129ms\tremaining: 105ms\n",
      "55:\tlearn: 0.1766290\ttotal: 131ms\tremaining: 103ms\n",
      "56:\tlearn: 0.1751819\ttotal: 134ms\tremaining: 101ms\n",
      "57:\tlearn: 0.1727936\ttotal: 137ms\tremaining: 98.9ms\n",
      "58:\tlearn: 0.1708552\ttotal: 139ms\tremaining: 96.5ms\n",
      "59:\tlearn: 0.1688895\ttotal: 141ms\tremaining: 94.1ms\n",
      "60:\tlearn: 0.1670867\ttotal: 144ms\tremaining: 91.8ms\n",
      "61:\tlearn: 0.1646699\ttotal: 146ms\tremaining: 89.4ms\n",
      "62:\tlearn: 0.1632343\ttotal: 148ms\tremaining: 87ms\n",
      "63:\tlearn: 0.1616432\ttotal: 150ms\tremaining: 84.6ms\n",
      "64:\tlearn: 0.1603640\ttotal: 153ms\tremaining: 82.3ms\n",
      "65:\tlearn: 0.1584905\ttotal: 155ms\tremaining: 79.9ms\n",
      "66:\tlearn: 0.1571636\ttotal: 157ms\tremaining: 77.6ms\n",
      "67:\tlearn: 0.1561008\ttotal: 160ms\tremaining: 75.3ms\n",
      "68:\tlearn: 0.1545398\ttotal: 162ms\tremaining: 72.9ms\n",
      "69:\tlearn: 0.1528211\ttotal: 165ms\tremaining: 70.9ms\n",
      "70:\tlearn: 0.1514628\ttotal: 168ms\tremaining: 68.6ms\n",
      "71:\tlearn: 0.1501483\ttotal: 170ms\tremaining: 66.2ms\n",
      "72:\tlearn: 0.1484054\ttotal: 173ms\tremaining: 63.8ms\n",
      "73:\tlearn: 0.1469601\ttotal: 175ms\tremaining: 61.4ms\n",
      "74:\tlearn: 0.1455691\ttotal: 177ms\tremaining: 59ms\n",
      "75:\tlearn: 0.1437686\ttotal: 179ms\tremaining: 56.6ms\n",
      "76:\tlearn: 0.1424973\ttotal: 181ms\tremaining: 54.2ms\n",
      "77:\tlearn: 0.1412412\ttotal: 184ms\tremaining: 51.8ms\n",
      "78:\tlearn: 0.1407099\ttotal: 186ms\tremaining: 49.5ms\n",
      "79:\tlearn: 0.1393990\ttotal: 189ms\tremaining: 47.1ms\n",
      "80:\tlearn: 0.1383502\ttotal: 191ms\tremaining: 44.8ms\n",
      "81:\tlearn: 0.1372962\ttotal: 193ms\tremaining: 42.4ms\n",
      "82:\tlearn: 0.1360779\ttotal: 195ms\tremaining: 40ms\n",
      "83:\tlearn: 0.1345809\ttotal: 198ms\tremaining: 37.7ms\n",
      "84:\tlearn: 0.1337674\ttotal: 201ms\tremaining: 35.4ms\n",
      "85:\tlearn: 0.1326968\ttotal: 203ms\tremaining: 33ms\n",
      "86:\tlearn: 0.1319790\ttotal: 205ms\tremaining: 30.7ms\n",
      "87:\tlearn: 0.1309791\ttotal: 208ms\tremaining: 28.3ms\n",
      "88:\tlearn: 0.1302970\ttotal: 210ms\tremaining: 25.9ms\n",
      "89:\tlearn: 0.1294794\ttotal: 212ms\tremaining: 23.6ms\n",
      "90:\tlearn: 0.1284828\ttotal: 215ms\tremaining: 21.2ms\n",
      "91:\tlearn: 0.1276377\ttotal: 217ms\tremaining: 18.8ms\n",
      "92:\tlearn: 0.1267367\ttotal: 219ms\tremaining: 16.5ms\n",
      "93:\tlearn: 0.1258785\ttotal: 221ms\tremaining: 14.1ms\n",
      "94:\tlearn: 0.1246958\ttotal: 224ms\tremaining: 11.8ms\n",
      "95:\tlearn: 0.1236789\ttotal: 226ms\tremaining: 9.43ms\n",
      "96:\tlearn: 0.1228465\ttotal: 229ms\tremaining: 7.07ms\n",
      "97:\tlearn: 0.1221343\ttotal: 231ms\tremaining: 4.71ms\n",
      "98:\tlearn: 0.1210770\ttotal: 233ms\tremaining: 2.36ms\n",
      "99:\tlearn: 0.1201747\ttotal: 236ms\tremaining: 0us\n",
      "0:\tlearn: 0.6585370\ttotal: 2.14ms\tremaining: 212ms\n",
      "1:\tlearn: 0.6275753\ttotal: 4.36ms\tremaining: 214ms\n",
      "2:\tlearn: 0.6031652\ttotal: 6.61ms\tremaining: 214ms\n",
      "3:\tlearn: 0.5799435\ttotal: 8.86ms\tremaining: 213ms\n",
      "4:\tlearn: 0.5568821\ttotal: 11ms\tremaining: 209ms\n",
      "5:\tlearn: 0.5353139\ttotal: 13.8ms\tremaining: 216ms\n",
      "6:\tlearn: 0.5156367\ttotal: 16.1ms\tremaining: 214ms\n",
      "7:\tlearn: 0.4960020\ttotal: 18.4ms\tremaining: 212ms\n",
      "8:\tlearn: 0.4766158\ttotal: 20.6ms\tremaining: 208ms\n",
      "9:\tlearn: 0.4605583\ttotal: 22.8ms\tremaining: 205ms\n",
      "10:\tlearn: 0.4453540\ttotal: 24ms\tremaining: 194ms\n",
      "11:\tlearn: 0.4297533\ttotal: 26.3ms\tremaining: 193ms\n",
      "12:\tlearn: 0.4173227\ttotal: 28.6ms\tremaining: 191ms\n",
      "13:\tlearn: 0.4039737\ttotal: 30.9ms\tremaining: 190ms\n",
      "14:\tlearn: 0.3913493\ttotal: 33.1ms\tremaining: 187ms\n",
      "15:\tlearn: 0.3794527\ttotal: 35.2ms\tremaining: 185ms\n",
      "16:\tlearn: 0.3685044\ttotal: 37.6ms\tremaining: 183ms\n",
      "17:\tlearn: 0.3582197\ttotal: 39.9ms\tremaining: 182ms\n",
      "18:\tlearn: 0.3492587\ttotal: 42ms\tremaining: 179ms\n",
      "19:\tlearn: 0.3398207\ttotal: 44.2ms\tremaining: 177ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:\tlearn: 0.3320855\ttotal: 46.5ms\tremaining: 175ms\n",
      "21:\tlearn: 0.3230730\ttotal: 48.7ms\tremaining: 173ms\n",
      "22:\tlearn: 0.3152235\ttotal: 51.1ms\tremaining: 171ms\n",
      "23:\tlearn: 0.3083440\ttotal: 53.4ms\tremaining: 169ms\n",
      "24:\tlearn: 0.3012182\ttotal: 55.5ms\tremaining: 167ms\n",
      "25:\tlearn: 0.2960920\ttotal: 57.8ms\tremaining: 164ms\n",
      "26:\tlearn: 0.2897770\ttotal: 60.2ms\tremaining: 163ms\n",
      "27:\tlearn: 0.2825965\ttotal: 62.6ms\tremaining: 161ms\n",
      "28:\tlearn: 0.2769480\ttotal: 65.3ms\tremaining: 160ms\n",
      "29:\tlearn: 0.2707530\ttotal: 67.6ms\tremaining: 158ms\n",
      "30:\tlearn: 0.2650175\ttotal: 70.1ms\tremaining: 156ms\n",
      "31:\tlearn: 0.2597695\ttotal: 72.4ms\tremaining: 154ms\n",
      "32:\tlearn: 0.2549556\ttotal: 74.6ms\tremaining: 151ms\n",
      "33:\tlearn: 0.2494529\ttotal: 77.6ms\tremaining: 151ms\n",
      "34:\tlearn: 0.2448184\ttotal: 79.9ms\tremaining: 148ms\n",
      "35:\tlearn: 0.2397445\ttotal: 82ms\tremaining: 146ms\n",
      "36:\tlearn: 0.2355043\ttotal: 84.5ms\tremaining: 144ms\n",
      "37:\tlearn: 0.2311705\ttotal: 86.9ms\tremaining: 142ms\n",
      "38:\tlearn: 0.2267152\ttotal: 89ms\tremaining: 139ms\n",
      "39:\tlearn: 0.2230304\ttotal: 91.3ms\tremaining: 137ms\n",
      "40:\tlearn: 0.2195623\ttotal: 93.7ms\tremaining: 135ms\n",
      "41:\tlearn: 0.2151360\ttotal: 96ms\tremaining: 133ms\n",
      "42:\tlearn: 0.2111207\ttotal: 98.3ms\tremaining: 130ms\n",
      "43:\tlearn: 0.2077864\ttotal: 101ms\tremaining: 128ms\n",
      "44:\tlearn: 0.2045965\ttotal: 103ms\tremaining: 126ms\n",
      "45:\tlearn: 0.2016280\ttotal: 105ms\tremaining: 123ms\n",
      "46:\tlearn: 0.1986525\ttotal: 108ms\tremaining: 121ms\n",
      "47:\tlearn: 0.1958867\ttotal: 110ms\tremaining: 119ms\n",
      "48:\tlearn: 0.1928690\ttotal: 112ms\tremaining: 117ms\n",
      "49:\tlearn: 0.1899933\ttotal: 114ms\tremaining: 114ms\n",
      "50:\tlearn: 0.1884265\ttotal: 117ms\tremaining: 112ms\n",
      "51:\tlearn: 0.1856057\ttotal: 119ms\tremaining: 110ms\n",
      "52:\tlearn: 0.1829521\ttotal: 121ms\tremaining: 108ms\n",
      "53:\tlearn: 0.1810036\ttotal: 124ms\tremaining: 105ms\n",
      "54:\tlearn: 0.1786190\ttotal: 126ms\tremaining: 103ms\n",
      "55:\tlearn: 0.1764293\ttotal: 128ms\tremaining: 101ms\n",
      "56:\tlearn: 0.1750363\ttotal: 130ms\tremaining: 98.4ms\n",
      "57:\tlearn: 0.1728957\ttotal: 133ms\tremaining: 96.2ms\n",
      "58:\tlearn: 0.1711929\ttotal: 136ms\tremaining: 94.4ms\n",
      "59:\tlearn: 0.1694863\ttotal: 139ms\tremaining: 92.7ms\n",
      "60:\tlearn: 0.1677827\ttotal: 141ms\tremaining: 90.4ms\n",
      "61:\tlearn: 0.1655538\ttotal: 143ms\tremaining: 87.9ms\n",
      "62:\tlearn: 0.1637268\ttotal: 146ms\tremaining: 85.9ms\n",
      "63:\tlearn: 0.1621708\ttotal: 149ms\tremaining: 83.5ms\n",
      "64:\tlearn: 0.1602179\ttotal: 151ms\tremaining: 81.3ms\n",
      "65:\tlearn: 0.1582814\ttotal: 153ms\tremaining: 78.9ms\n",
      "66:\tlearn: 0.1570635\ttotal: 155ms\tremaining: 76.6ms\n",
      "67:\tlearn: 0.1553412\ttotal: 158ms\tremaining: 74.2ms\n",
      "68:\tlearn: 0.1538519\ttotal: 160ms\tremaining: 72.1ms\n",
      "69:\tlearn: 0.1520415\ttotal: 163ms\tremaining: 70ms\n",
      "70:\tlearn: 0.1503745\ttotal: 166ms\tremaining: 67.9ms\n",
      "71:\tlearn: 0.1489939\ttotal: 169ms\tremaining: 65.6ms\n",
      "72:\tlearn: 0.1475812\ttotal: 171ms\tremaining: 63.3ms\n",
      "73:\tlearn: 0.1464544\ttotal: 173ms\tremaining: 60.9ms\n",
      "74:\tlearn: 0.1452051\ttotal: 176ms\tremaining: 58.6ms\n",
      "75:\tlearn: 0.1443461\ttotal: 178ms\tremaining: 56.2ms\n",
      "76:\tlearn: 0.1429102\ttotal: 180ms\tremaining: 53.8ms\n",
      "77:\tlearn: 0.1419870\ttotal: 183ms\tremaining: 51.5ms\n",
      "78:\tlearn: 0.1404569\ttotal: 185ms\tremaining: 49.1ms\n",
      "79:\tlearn: 0.1387366\ttotal: 188ms\tremaining: 47ms\n",
      "80:\tlearn: 0.1377203\ttotal: 190ms\tremaining: 44.6ms\n",
      "81:\tlearn: 0.1363476\ttotal: 192ms\tremaining: 42.2ms\n",
      "82:\tlearn: 0.1352608\ttotal: 195ms\tremaining: 40ms\n",
      "83:\tlearn: 0.1339300\ttotal: 198ms\tremaining: 37.8ms\n",
      "84:\tlearn: 0.1333907\ttotal: 201ms\tremaining: 35.4ms\n",
      "85:\tlearn: 0.1324117\ttotal: 203ms\tremaining: 33ms\n",
      "86:\tlearn: 0.1317803\ttotal: 205ms\tremaining: 30.7ms\n",
      "87:\tlearn: 0.1312382\ttotal: 208ms\tremaining: 28.4ms\n",
      "88:\tlearn: 0.1303107\ttotal: 210ms\tremaining: 26ms\n",
      "89:\tlearn: 0.1291991\ttotal: 213ms\tremaining: 23.6ms\n",
      "90:\tlearn: 0.1282459\ttotal: 215ms\tremaining: 21.3ms\n",
      "91:\tlearn: 0.1274080\ttotal: 218ms\tremaining: 19ms\n",
      "92:\tlearn: 0.1263812\ttotal: 221ms\tremaining: 16.6ms\n",
      "93:\tlearn: 0.1257266\ttotal: 223ms\tremaining: 14.2ms\n",
      "94:\tlearn: 0.1246851\ttotal: 226ms\tremaining: 11.9ms\n",
      "95:\tlearn: 0.1236112\ttotal: 228ms\tremaining: 9.49ms\n",
      "96:\tlearn: 0.1227683\ttotal: 230ms\tremaining: 7.12ms\n",
      "97:\tlearn: 0.1222343\ttotal: 233ms\tremaining: 4.75ms\n",
      "98:\tlearn: 0.1214030\ttotal: 235ms\tremaining: 2.37ms\n",
      "99:\tlearn: 0.1203443\ttotal: 237ms\tremaining: 0us\n",
      "0:\tlearn: 0.6587585\ttotal: 2.36ms\tremaining: 234ms\n",
      "1:\tlearn: 0.6280080\ttotal: 4.92ms\tremaining: 241ms\n",
      "2:\tlearn: 0.6027066\ttotal: 7.53ms\tremaining: 244ms\n",
      "3:\tlearn: 0.5790613\ttotal: 9.93ms\tremaining: 238ms\n",
      "4:\tlearn: 0.5565316\ttotal: 12.2ms\tremaining: 231ms\n",
      "5:\tlearn: 0.5354625\ttotal: 15ms\tremaining: 235ms\n",
      "6:\tlearn: 0.5157042\ttotal: 17.4ms\tremaining: 231ms\n",
      "7:\tlearn: 0.4958100\ttotal: 19.7ms\tremaining: 226ms\n",
      "8:\tlearn: 0.4764543\ttotal: 22.2ms\tremaining: 225ms\n",
      "9:\tlearn: 0.4598402\ttotal: 25.1ms\tremaining: 226ms\n",
      "10:\tlearn: 0.4448855\ttotal: 26.4ms\tremaining: 214ms\n",
      "11:\tlearn: 0.4307588\ttotal: 28.6ms\tremaining: 210ms\n",
      "12:\tlearn: 0.4172202\ttotal: 30.9ms\tremaining: 207ms\n",
      "13:\tlearn: 0.4026939\ttotal: 33.3ms\tremaining: 204ms\n",
      "14:\tlearn: 0.3901896\ttotal: 35.5ms\tremaining: 201ms\n",
      "15:\tlearn: 0.3778814\ttotal: 37.8ms\tremaining: 198ms\n",
      "16:\tlearn: 0.3667769\ttotal: 40ms\tremaining: 195ms\n",
      "17:\tlearn: 0.3559213\ttotal: 42.1ms\tremaining: 192ms\n",
      "18:\tlearn: 0.3464933\ttotal: 44.4ms\tremaining: 189ms\n",
      "19:\tlearn: 0.3357407\ttotal: 46.7ms\tremaining: 187ms\n",
      "20:\tlearn: 0.3276080\ttotal: 48.9ms\tremaining: 184ms\n",
      "21:\tlearn: 0.3187401\ttotal: 51.1ms\tremaining: 181ms\n",
      "22:\tlearn: 0.3114792\ttotal: 53.5ms\tremaining: 179ms\n",
      "23:\tlearn: 0.3038816\ttotal: 57.1ms\tremaining: 181ms\n",
      "24:\tlearn: 0.2966029\ttotal: 59.5ms\tremaining: 179ms\n",
      "25:\tlearn: 0.2909022\ttotal: 61.9ms\tremaining: 176ms\n",
      "26:\tlearn: 0.2840729\ttotal: 64.3ms\tremaining: 174ms\n",
      "27:\tlearn: 0.2766774\ttotal: 66.5ms\tremaining: 171ms\n",
      "28:\tlearn: 0.2714162\ttotal: 69.3ms\tremaining: 170ms\n",
      "29:\tlearn: 0.2663837\ttotal: 71.7ms\tremaining: 167ms\n",
      "30:\tlearn: 0.2620768\ttotal: 74.2ms\tremaining: 165ms\n",
      "31:\tlearn: 0.2567518\ttotal: 76.7ms\tremaining: 163ms\n",
      "32:\tlearn: 0.2521032\ttotal: 78.9ms\tremaining: 160ms\n",
      "33:\tlearn: 0.2470670\ttotal: 81.3ms\tremaining: 158ms\n",
      "34:\tlearn: 0.2424098\ttotal: 83.6ms\tremaining: 155ms\n",
      "35:\tlearn: 0.2371652\ttotal: 85.9ms\tremaining: 153ms\n",
      "36:\tlearn: 0.2336595\ttotal: 88.3ms\tremaining: 150ms\n",
      "37:\tlearn: 0.2284589\ttotal: 90.6ms\tremaining: 148ms\n",
      "38:\tlearn: 0.2253314\ttotal: 92.9ms\tremaining: 145ms\n",
      "39:\tlearn: 0.2214486\ttotal: 95.1ms\tremaining: 143ms\n",
      "40:\tlearn: 0.2181124\ttotal: 97.3ms\tremaining: 140ms\n",
      "41:\tlearn: 0.2143048\ttotal: 99.8ms\tremaining: 138ms\n",
      "42:\tlearn: 0.2097484\ttotal: 103ms\tremaining: 136ms\n",
      "43:\tlearn: 0.2066050\ttotal: 105ms\tremaining: 134ms\n",
      "44:\tlearn: 0.2035410\ttotal: 108ms\tremaining: 132ms\n",
      "45:\tlearn: 0.2006039\ttotal: 110ms\tremaining: 130ms\n",
      "46:\tlearn: 0.1979171\ttotal: 113ms\tremaining: 127ms\n",
      "47:\tlearn: 0.1949509\ttotal: 115ms\tremaining: 124ms\n",
      "48:\tlearn: 0.1918820\ttotal: 117ms\tremaining: 122ms\n",
      "49:\tlearn: 0.1892070\ttotal: 119ms\tremaining: 119ms\n",
      "50:\tlearn: 0.1862518\ttotal: 122ms\tremaining: 117ms\n",
      "51:\tlearn: 0.1836235\ttotal: 124ms\tremaining: 114ms\n",
      "52:\tlearn: 0.1816967\ttotal: 126ms\tremaining: 112ms\n",
      "53:\tlearn: 0.1798589\ttotal: 128ms\tremaining: 109ms\n",
      "54:\tlearn: 0.1774722\ttotal: 131ms\tremaining: 107ms\n",
      "55:\tlearn: 0.1754973\ttotal: 133ms\tremaining: 105ms\n",
      "56:\tlearn: 0.1734997\ttotal: 136ms\tremaining: 102ms\n",
      "57:\tlearn: 0.1713698\ttotal: 138ms\tremaining: 99.8ms\n",
      "58:\tlearn: 0.1696858\ttotal: 140ms\tremaining: 97.3ms\n",
      "59:\tlearn: 0.1682317\ttotal: 143ms\tremaining: 95.1ms\n",
      "60:\tlearn: 0.1671878\ttotal: 145ms\tremaining: 92.5ms\n",
      "61:\tlearn: 0.1653712\ttotal: 147ms\tremaining: 90.1ms\n",
      "62:\tlearn: 0.1636940\ttotal: 149ms\tremaining: 87.7ms\n",
      "63:\tlearn: 0.1619227\ttotal: 152ms\tremaining: 85.3ms\n",
      "64:\tlearn: 0.1604476\ttotal: 155ms\tremaining: 83.3ms\n",
      "65:\tlearn: 0.1586673\ttotal: 157ms\tremaining: 80.9ms\n",
      "66:\tlearn: 0.1571285\ttotal: 159ms\tremaining: 78.4ms\n",
      "67:\tlearn: 0.1555903\ttotal: 162ms\tremaining: 76.1ms\n",
      "68:\tlearn: 0.1540445\ttotal: 165ms\tremaining: 74.1ms\n",
      "69:\tlearn: 0.1531565\ttotal: 167ms\tremaining: 71.6ms\n",
      "70:\tlearn: 0.1517460\ttotal: 169ms\tremaining: 69.2ms\n",
      "71:\tlearn: 0.1510416\ttotal: 172ms\tremaining: 67ms\n",
      "72:\tlearn: 0.1496555\ttotal: 176ms\tremaining: 65ms\n",
      "73:\tlearn: 0.1482819\ttotal: 178ms\tremaining: 62.6ms\n",
      "74:\tlearn: 0.1470814\ttotal: 180ms\tremaining: 60.1ms\n",
      "75:\tlearn: 0.1462626\ttotal: 183ms\tremaining: 57.7ms\n",
      "76:\tlearn: 0.1442399\ttotal: 185ms\tremaining: 55.2ms\n",
      "77:\tlearn: 0.1428778\ttotal: 187ms\tremaining: 52.7ms\n",
      "78:\tlearn: 0.1419315\ttotal: 189ms\tremaining: 50.3ms\n",
      "79:\tlearn: 0.1403553\ttotal: 192ms\tremaining: 47.9ms\n",
      "80:\tlearn: 0.1393527\ttotal: 194ms\tremaining: 45.5ms\n",
      "81:\tlearn: 0.1383087\ttotal: 196ms\tremaining: 43.1ms\n",
      "82:\tlearn: 0.1368450\ttotal: 199ms\tremaining: 40.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83:\tlearn: 0.1354215\ttotal: 201ms\tremaining: 38.3ms\n",
      "84:\tlearn: 0.1346336\ttotal: 204ms\tremaining: 35.9ms\n",
      "85:\tlearn: 0.1335414\ttotal: 206ms\tremaining: 33.5ms\n",
      "86:\tlearn: 0.1329925\ttotal: 209ms\tremaining: 31.3ms\n",
      "87:\tlearn: 0.1319896\ttotal: 211ms\tremaining: 28.8ms\n",
      "88:\tlearn: 0.1311388\ttotal: 214ms\tremaining: 26.4ms\n",
      "89:\tlearn: 0.1296158\ttotal: 217ms\tremaining: 24.1ms\n",
      "90:\tlearn: 0.1285307\ttotal: 219ms\tremaining: 21.7ms\n",
      "91:\tlearn: 0.1277427\ttotal: 222ms\tremaining: 19.3ms\n",
      "92:\tlearn: 0.1264455\ttotal: 224ms\tremaining: 16.9ms\n",
      "93:\tlearn: 0.1254810\ttotal: 227ms\tremaining: 14.5ms\n",
      "94:\tlearn: 0.1244253\ttotal: 229ms\tremaining: 12.1ms\n",
      "95:\tlearn: 0.1237696\ttotal: 232ms\tremaining: 9.64ms\n",
      "96:\tlearn: 0.1230051\ttotal: 234ms\tremaining: 7.23ms\n",
      "97:\tlearn: 0.1223677\ttotal: 236ms\tremaining: 4.82ms\n",
      "98:\tlearn: 0.1215037\ttotal: 238ms\tremaining: 2.41ms\n",
      "99:\tlearn: 0.1205982\ttotal: 241ms\tremaining: 0us\n",
      "0:\tlearn: 0.6271142\ttotal: 1.46ms\tremaining: 144ms\n",
      "1:\tlearn: 0.5776311\ttotal: 3.82ms\tremaining: 187ms\n",
      "2:\tlearn: 0.5315137\ttotal: 5.4ms\tremaining: 175ms\n",
      "3:\tlearn: 0.4924283\ttotal: 7.52ms\tremaining: 180ms\n",
      "4:\tlearn: 0.4626219\ttotal: 9.6ms\tremaining: 182ms\n",
      "5:\tlearn: 0.4332794\ttotal: 11.7ms\tremaining: 183ms\n",
      "6:\tlearn: 0.4075966\ttotal: 13.8ms\tremaining: 183ms\n",
      "7:\tlearn: 0.3812579\ttotal: 16.2ms\tremaining: 186ms\n",
      "8:\tlearn: 0.3623644\ttotal: 19.1ms\tremaining: 193ms\n",
      "9:\tlearn: 0.3428616\ttotal: 21.5ms\tremaining: 193ms\n",
      "10:\tlearn: 0.3248749\ttotal: 23.6ms\tremaining: 191ms\n",
      "11:\tlearn: 0.3085911\ttotal: 25.9ms\tremaining: 190ms\n",
      "12:\tlearn: 0.2952599\ttotal: 28ms\tremaining: 187ms\n",
      "13:\tlearn: 0.2819475\ttotal: 30.2ms\tremaining: 186ms\n",
      "14:\tlearn: 0.2698514\ttotal: 32.6ms\tremaining: 185ms\n",
      "15:\tlearn: 0.2577639\ttotal: 35ms\tremaining: 183ms\n",
      "16:\tlearn: 0.2477691\ttotal: 37.3ms\tremaining: 182ms\n",
      "17:\tlearn: 0.2368901\ttotal: 39.5ms\tremaining: 180ms\n",
      "18:\tlearn: 0.2313193\ttotal: 41.7ms\tremaining: 178ms\n",
      "19:\tlearn: 0.2238663\ttotal: 43.9ms\tremaining: 175ms\n",
      "20:\tlearn: 0.2163441\ttotal: 46.3ms\tremaining: 174ms\n",
      "21:\tlearn: 0.2092454\ttotal: 48.6ms\tremaining: 172ms\n",
      "22:\tlearn: 0.2016965\ttotal: 50.9ms\tremaining: 170ms\n",
      "23:\tlearn: 0.1969208\ttotal: 53.4ms\tremaining: 169ms\n",
      "24:\tlearn: 0.1928095\ttotal: 55.8ms\tremaining: 167ms\n",
      "25:\tlearn: 0.1859084\ttotal: 58ms\tremaining: 165ms\n",
      "26:\tlearn: 0.1809503\ttotal: 60.3ms\tremaining: 163ms\n",
      "27:\tlearn: 0.1766041\ttotal: 62.7ms\tremaining: 161ms\n",
      "28:\tlearn: 0.1728243\ttotal: 65.4ms\tremaining: 160ms\n",
      "29:\tlearn: 0.1668831\ttotal: 67.7ms\tremaining: 158ms\n",
      "30:\tlearn: 0.1618556\ttotal: 70ms\tremaining: 156ms\n",
      "31:\tlearn: 0.1579373\ttotal: 72.3ms\tremaining: 154ms\n",
      "32:\tlearn: 0.1546037\ttotal: 74.7ms\tremaining: 152ms\n",
      "33:\tlearn: 0.1520818\ttotal: 77.2ms\tremaining: 150ms\n",
      "34:\tlearn: 0.1490788\ttotal: 79.6ms\tremaining: 148ms\n",
      "35:\tlearn: 0.1457416\ttotal: 82ms\tremaining: 146ms\n",
      "36:\tlearn: 0.1441172\ttotal: 84.3ms\tremaining: 143ms\n",
      "37:\tlearn: 0.1408894\ttotal: 86.6ms\tremaining: 141ms\n",
      "38:\tlearn: 0.1392358\ttotal: 88.8ms\tremaining: 139ms\n",
      "39:\tlearn: 0.1367689\ttotal: 91.1ms\tremaining: 137ms\n",
      "40:\tlearn: 0.1346231\ttotal: 93.6ms\tremaining: 135ms\n",
      "41:\tlearn: 0.1328557\ttotal: 95.7ms\tremaining: 132ms\n",
      "42:\tlearn: 0.1310678\ttotal: 98.8ms\tremaining: 131ms\n",
      "43:\tlearn: 0.1291080\ttotal: 101ms\tremaining: 129ms\n",
      "44:\tlearn: 0.1272884\ttotal: 104ms\tremaining: 127ms\n",
      "45:\tlearn: 0.1261459\ttotal: 106ms\tremaining: 125ms\n",
      "46:\tlearn: 0.1243388\ttotal: 109ms\tremaining: 122ms\n",
      "47:\tlearn: 0.1220812\ttotal: 111ms\tremaining: 120ms\n",
      "48:\tlearn: 0.1205234\ttotal: 113ms\tremaining: 118ms\n",
      "49:\tlearn: 0.1187428\ttotal: 116ms\tremaining: 116ms\n",
      "50:\tlearn: 0.1174004\ttotal: 118ms\tremaining: 113ms\n",
      "51:\tlearn: 0.1156585\ttotal: 120ms\tremaining: 111ms\n",
      "52:\tlearn: 0.1146293\ttotal: 123ms\tremaining: 109ms\n",
      "53:\tlearn: 0.1132964\ttotal: 125ms\tremaining: 106ms\n",
      "54:\tlearn: 0.1120257\ttotal: 127ms\tremaining: 104ms\n",
      "55:\tlearn: 0.1110488\ttotal: 129ms\tremaining: 101ms\n",
      "56:\tlearn: 0.1094479\ttotal: 131ms\tremaining: 99.2ms\n",
      "57:\tlearn: 0.1082599\ttotal: 134ms\tremaining: 96.9ms\n",
      "58:\tlearn: 0.1075220\ttotal: 136ms\tremaining: 94.6ms\n",
      "59:\tlearn: 0.1063211\ttotal: 138ms\tremaining: 92.2ms\n",
      "60:\tlearn: 0.1050404\ttotal: 141ms\tremaining: 90ms\n",
      "61:\tlearn: 0.1038725\ttotal: 143ms\tremaining: 87.8ms\n",
      "62:\tlearn: 0.1032174\ttotal: 146ms\tremaining: 85.5ms\n",
      "63:\tlearn: 0.1021057\ttotal: 148ms\tremaining: 83.3ms\n",
      "64:\tlearn: 0.1009545\ttotal: 150ms\tremaining: 81ms\n",
      "65:\tlearn: 0.1000826\ttotal: 153ms\tremaining: 78.9ms\n",
      "66:\tlearn: 0.0992686\ttotal: 155ms\tremaining: 76.5ms\n",
      "67:\tlearn: 0.0988390\ttotal: 158ms\tremaining: 74.1ms\n",
      "68:\tlearn: 0.0979798\ttotal: 160ms\tremaining: 71.7ms\n",
      "69:\tlearn: 0.0972473\ttotal: 169ms\tremaining: 72.2ms\n",
      "70:\tlearn: 0.0964087\ttotal: 171ms\tremaining: 69.8ms\n",
      "71:\tlearn: 0.0954652\ttotal: 173ms\tremaining: 67.4ms\n",
      "72:\tlearn: 0.0949550\ttotal: 176ms\tremaining: 64.9ms\n",
      "73:\tlearn: 0.0942322\ttotal: 178ms\tremaining: 62.5ms\n",
      "74:\tlearn: 0.0934672\ttotal: 180ms\tremaining: 60ms\n",
      "75:\tlearn: 0.0927618\ttotal: 182ms\tremaining: 57.6ms\n",
      "76:\tlearn: 0.0920468\ttotal: 185ms\tremaining: 55.1ms\n",
      "77:\tlearn: 0.0912990\ttotal: 187ms\tremaining: 52.8ms\n",
      "78:\tlearn: 0.0906001\ttotal: 189ms\tremaining: 50.3ms\n",
      "79:\tlearn: 0.0901819\ttotal: 192ms\tremaining: 47.9ms\n",
      "80:\tlearn: 0.0887813\ttotal: 194ms\tremaining: 45.5ms\n",
      "81:\tlearn: 0.0880764\ttotal: 196ms\tremaining: 43.1ms\n",
      "82:\tlearn: 0.0869635\ttotal: 199ms\tremaining: 40.8ms\n",
      "83:\tlearn: 0.0864929\ttotal: 202ms\tremaining: 38.4ms\n",
      "84:\tlearn: 0.0857205\ttotal: 204ms\tremaining: 36ms\n",
      "85:\tlearn: 0.0851602\ttotal: 206ms\tremaining: 33.6ms\n",
      "86:\tlearn: 0.0845857\ttotal: 209ms\tremaining: 31.2ms\n",
      "87:\tlearn: 0.0842289\ttotal: 211ms\tremaining: 28.8ms\n",
      "88:\tlearn: 0.0837987\ttotal: 214ms\tremaining: 26.4ms\n",
      "89:\tlearn: 0.0831306\ttotal: 217ms\tremaining: 24.1ms\n",
      "90:\tlearn: 0.0825878\ttotal: 219ms\tremaining: 21.7ms\n",
      "91:\tlearn: 0.0820315\ttotal: 221ms\tremaining: 19.3ms\n",
      "92:\tlearn: 0.0811737\ttotal: 224ms\tremaining: 16.8ms\n",
      "93:\tlearn: 0.0808196\ttotal: 226ms\tremaining: 14.4ms\n",
      "94:\tlearn: 0.0801998\ttotal: 229ms\tremaining: 12ms\n",
      "95:\tlearn: 0.0795497\ttotal: 231ms\tremaining: 9.62ms\n",
      "96:\tlearn: 0.0793458\ttotal: 233ms\tremaining: 7.21ms\n",
      "97:\tlearn: 0.0787237\ttotal: 235ms\tremaining: 4.8ms\n",
      "98:\tlearn: 0.0780768\ttotal: 239ms\tremaining: 2.41ms\n",
      "99:\tlearn: 0.0773513\ttotal: 241ms\tremaining: 0us\n",
      "0:\tlearn: 0.6256143\ttotal: 2.4ms\tremaining: 238ms\n",
      "1:\tlearn: 0.5704489\ttotal: 4.58ms\tremaining: 224ms\n",
      "2:\tlearn: 0.5302243\ttotal: 6.86ms\tremaining: 222ms\n",
      "3:\tlearn: 0.4942758\ttotal: 8.95ms\tremaining: 215ms\n",
      "4:\tlearn: 0.4604304\ttotal: 11.3ms\tremaining: 216ms\n",
      "5:\tlearn: 0.4309161\ttotal: 13.9ms\tremaining: 218ms\n",
      "6:\tlearn: 0.4054040\ttotal: 16.1ms\tremaining: 214ms\n",
      "7:\tlearn: 0.3815432\ttotal: 18.4ms\tremaining: 212ms\n",
      "8:\tlearn: 0.3576101\ttotal: 20.7ms\tremaining: 210ms\n",
      "9:\tlearn: 0.3393478\ttotal: 23ms\tremaining: 207ms\n",
      "10:\tlearn: 0.3200697\ttotal: 25.2ms\tremaining: 204ms\n",
      "11:\tlearn: 0.3022505\ttotal: 27.3ms\tremaining: 200ms\n",
      "12:\tlearn: 0.2876923\ttotal: 30.1ms\tremaining: 201ms\n",
      "13:\tlearn: 0.2753845\ttotal: 32.5ms\tremaining: 199ms\n",
      "14:\tlearn: 0.2627363\ttotal: 34.8ms\tremaining: 197ms\n",
      "15:\tlearn: 0.2540804\ttotal: 37.1ms\tremaining: 195ms\n",
      "16:\tlearn: 0.2437959\ttotal: 39.4ms\tremaining: 192ms\n",
      "17:\tlearn: 0.2344740\ttotal: 41.6ms\tremaining: 189ms\n",
      "18:\tlearn: 0.2270679\ttotal: 43.9ms\tremaining: 187ms\n",
      "19:\tlearn: 0.2210634\ttotal: 46.2ms\tremaining: 185ms\n",
      "20:\tlearn: 0.2144580\ttotal: 48.8ms\tremaining: 184ms\n",
      "21:\tlearn: 0.2082488\ttotal: 51.3ms\tremaining: 182ms\n",
      "22:\tlearn: 0.2024804\ttotal: 53.7ms\tremaining: 180ms\n",
      "23:\tlearn: 0.1963387\ttotal: 55.9ms\tremaining: 177ms\n",
      "24:\tlearn: 0.1906472\ttotal: 58.2ms\tremaining: 174ms\n",
      "25:\tlearn: 0.1856819\ttotal: 60.7ms\tremaining: 173ms\n",
      "26:\tlearn: 0.1813116\ttotal: 62.8ms\tremaining: 170ms\n",
      "27:\tlearn: 0.1754721\ttotal: 65.3ms\tremaining: 168ms\n",
      "28:\tlearn: 0.1713243\ttotal: 67.6ms\tremaining: 166ms\n",
      "29:\tlearn: 0.1665220\ttotal: 70ms\tremaining: 163ms\n",
      "30:\tlearn: 0.1627580\ttotal: 72.4ms\tremaining: 161ms\n",
      "31:\tlearn: 0.1597594\ttotal: 74.7ms\tremaining: 159ms\n",
      "32:\tlearn: 0.1559158\ttotal: 76.8ms\tremaining: 156ms\n",
      "33:\tlearn: 0.1538269\ttotal: 79.1ms\tremaining: 154ms\n",
      "34:\tlearn: 0.1507994\ttotal: 81.4ms\tremaining: 151ms\n",
      "35:\tlearn: 0.1480769\ttotal: 83.6ms\tremaining: 149ms\n",
      "36:\tlearn: 0.1454253\ttotal: 85.9ms\tremaining: 146ms\n",
      "37:\tlearn: 0.1435197\ttotal: 88.2ms\tremaining: 144ms\n",
      "38:\tlearn: 0.1406557\ttotal: 90.7ms\tremaining: 142ms\n",
      "39:\tlearn: 0.1375213\ttotal: 93.1ms\tremaining: 140ms\n",
      "40:\tlearn: 0.1350927\ttotal: 95.3ms\tremaining: 137ms\n",
      "41:\tlearn: 0.1320323\ttotal: 97.4ms\tremaining: 135ms\n",
      "42:\tlearn: 0.1302738\ttotal: 99.8ms\tremaining: 132ms\n",
      "43:\tlearn: 0.1279907\ttotal: 102ms\tremaining: 130ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44:\tlearn: 0.1262496\ttotal: 105ms\tremaining: 128ms\n",
      "45:\tlearn: 0.1239598\ttotal: 107ms\tremaining: 126ms\n",
      "46:\tlearn: 0.1225089\ttotal: 109ms\tremaining: 123ms\n",
      "47:\tlearn: 0.1208122\ttotal: 112ms\tremaining: 122ms\n",
      "48:\tlearn: 0.1200406\ttotal: 115ms\tremaining: 120ms\n",
      "49:\tlearn: 0.1182186\ttotal: 117ms\tremaining: 117ms\n",
      "50:\tlearn: 0.1167131\ttotal: 120ms\tremaining: 115ms\n",
      "51:\tlearn: 0.1157214\ttotal: 123ms\tremaining: 113ms\n",
      "52:\tlearn: 0.1142802\ttotal: 125ms\tremaining: 111ms\n",
      "53:\tlearn: 0.1127230\ttotal: 127ms\tremaining: 108ms\n",
      "54:\tlearn: 0.1108103\ttotal: 130ms\tremaining: 106ms\n",
      "55:\tlearn: 0.1093772\ttotal: 132ms\tremaining: 104ms\n",
      "56:\tlearn: 0.1088903\ttotal: 135ms\tremaining: 102ms\n",
      "57:\tlearn: 0.1079069\ttotal: 138ms\tremaining: 99.6ms\n",
      "58:\tlearn: 0.1065365\ttotal: 140ms\tremaining: 97.3ms\n",
      "59:\tlearn: 0.1056323\ttotal: 142ms\tremaining: 94.9ms\n",
      "60:\tlearn: 0.1048654\ttotal: 145ms\tremaining: 92.5ms\n",
      "61:\tlearn: 0.1037395\ttotal: 148ms\tremaining: 90.7ms\n",
      "62:\tlearn: 0.1029573\ttotal: 150ms\tremaining: 88.2ms\n",
      "63:\tlearn: 0.1021623\ttotal: 152ms\tremaining: 85.7ms\n",
      "64:\tlearn: 0.1014830\ttotal: 155ms\tremaining: 83.2ms\n",
      "65:\tlearn: 0.1010995\ttotal: 157ms\tremaining: 80.8ms\n",
      "66:\tlearn: 0.1009240\ttotal: 158ms\tremaining: 77.9ms\n",
      "67:\tlearn: 0.0997266\ttotal: 161ms\tremaining: 75.5ms\n",
      "68:\tlearn: 0.0991941\ttotal: 163ms\tremaining: 73.2ms\n",
      "69:\tlearn: 0.0982238\ttotal: 165ms\tremaining: 70.8ms\n",
      "70:\tlearn: 0.0973892\ttotal: 168ms\tremaining: 68.5ms\n",
      "71:\tlearn: 0.0967639\ttotal: 170ms\tremaining: 66ms\n",
      "72:\tlearn: 0.0959353\ttotal: 172ms\tremaining: 63.8ms\n",
      "73:\tlearn: 0.0951946\ttotal: 175ms\tremaining: 61.4ms\n",
      "74:\tlearn: 0.0945118\ttotal: 177ms\tremaining: 59ms\n",
      "75:\tlearn: 0.0933980\ttotal: 179ms\tremaining: 56.6ms\n",
      "76:\tlearn: 0.0930186\ttotal: 182ms\tremaining: 54.3ms\n",
      "77:\tlearn: 0.0924660\ttotal: 184ms\tremaining: 51.8ms\n",
      "78:\tlearn: 0.0919318\ttotal: 186ms\tremaining: 49.5ms\n",
      "79:\tlearn: 0.0911733\ttotal: 188ms\tremaining: 47.1ms\n",
      "80:\tlearn: 0.0906917\ttotal: 191ms\tremaining: 44.8ms\n",
      "81:\tlearn: 0.0901725\ttotal: 193ms\tremaining: 42.4ms\n",
      "82:\tlearn: 0.0898130\ttotal: 195ms\tremaining: 40ms\n",
      "83:\tlearn: 0.0894060\ttotal: 198ms\tremaining: 37.7ms\n",
      "84:\tlearn: 0.0884729\ttotal: 200ms\tremaining: 35.4ms\n",
      "85:\tlearn: 0.0879899\ttotal: 203ms\tremaining: 33ms\n",
      "86:\tlearn: 0.0874538\ttotal: 205ms\tremaining: 30.6ms\n",
      "87:\tlearn: 0.0867178\ttotal: 207ms\tremaining: 28.3ms\n",
      "88:\tlearn: 0.0861704\ttotal: 210ms\tremaining: 25.9ms\n",
      "89:\tlearn: 0.0857613\ttotal: 212ms\tremaining: 23.6ms\n",
      "90:\tlearn: 0.0853673\ttotal: 214ms\tremaining: 21.2ms\n",
      "91:\tlearn: 0.0846850\ttotal: 217ms\tremaining: 18.8ms\n",
      "92:\tlearn: 0.0839706\ttotal: 219ms\tremaining: 16.5ms\n",
      "93:\tlearn: 0.0836730\ttotal: 222ms\tremaining: 14.2ms\n",
      "94:\tlearn: 0.0831209\ttotal: 224ms\tremaining: 11.8ms\n",
      "95:\tlearn: 0.0825924\ttotal: 227ms\tremaining: 9.45ms\n",
      "96:\tlearn: 0.0819345\ttotal: 229ms\tremaining: 7.08ms\n",
      "97:\tlearn: 0.0816283\ttotal: 231ms\tremaining: 4.72ms\n",
      "98:\tlearn: 0.0809243\ttotal: 234ms\tremaining: 2.36ms\n",
      "99:\tlearn: 0.0801354\ttotal: 236ms\tremaining: 0us\n",
      "0:\tlearn: 0.6260552\ttotal: 2.06ms\tremaining: 204ms\n",
      "1:\tlearn: 0.5712674\ttotal: 4.24ms\tremaining: 208ms\n",
      "2:\tlearn: 0.5295628\ttotal: 6.53ms\tremaining: 211ms\n",
      "3:\tlearn: 0.4930433\ttotal: 9.33ms\tremaining: 224ms\n",
      "4:\tlearn: 0.4603491\ttotal: 11.3ms\tremaining: 215ms\n",
      "5:\tlearn: 0.4312578\ttotal: 13.6ms\tremaining: 213ms\n",
      "6:\tlearn: 0.4054381\ttotal: 15.8ms\tremaining: 209ms\n",
      "7:\tlearn: 0.3807159\ttotal: 18.2ms\tremaining: 209ms\n",
      "8:\tlearn: 0.3563650\ttotal: 20.4ms\tremaining: 206ms\n",
      "9:\tlearn: 0.3365614\ttotal: 22.7ms\tremaining: 204ms\n",
      "10:\tlearn: 0.3182448\ttotal: 25.1ms\tremaining: 203ms\n",
      "11:\tlearn: 0.3021835\ttotal: 27.3ms\tremaining: 200ms\n",
      "12:\tlearn: 0.2879721\ttotal: 30.2ms\tremaining: 202ms\n",
      "13:\tlearn: 0.2764793\ttotal: 32.2ms\tremaining: 198ms\n",
      "14:\tlearn: 0.2653904\ttotal: 34.6ms\tremaining: 196ms\n",
      "15:\tlearn: 0.2555651\ttotal: 36.9ms\tremaining: 194ms\n",
      "16:\tlearn: 0.2447383\ttotal: 39.4ms\tremaining: 192ms\n",
      "17:\tlearn: 0.2356304\ttotal: 41.6ms\tremaining: 190ms\n",
      "18:\tlearn: 0.2272268\ttotal: 43.9ms\tremaining: 187ms\n",
      "19:\tlearn: 0.2204892\ttotal: 46.3ms\tremaining: 185ms\n",
      "20:\tlearn: 0.2123663\ttotal: 48.4ms\tremaining: 182ms\n",
      "21:\tlearn: 0.2079614\ttotal: 50.7ms\tremaining: 180ms\n",
      "22:\tlearn: 0.2027151\ttotal: 53ms\tremaining: 177ms\n",
      "23:\tlearn: 0.1968645\ttotal: 55.4ms\tremaining: 175ms\n",
      "24:\tlearn: 0.1912361\ttotal: 57.6ms\tremaining: 173ms\n",
      "25:\tlearn: 0.1861829\ttotal: 59.9ms\tremaining: 171ms\n",
      "26:\tlearn: 0.1818745\ttotal: 62.3ms\tremaining: 169ms\n",
      "27:\tlearn: 0.1770800\ttotal: 64.8ms\tremaining: 167ms\n",
      "28:\tlearn: 0.1731373\ttotal: 67.2ms\tremaining: 165ms\n",
      "29:\tlearn: 0.1682575\ttotal: 69.6ms\tremaining: 162ms\n",
      "30:\tlearn: 0.1638260\ttotal: 71.7ms\tremaining: 160ms\n",
      "31:\tlearn: 0.1611567\ttotal: 74.1ms\tremaining: 157ms\n",
      "32:\tlearn: 0.1569225\ttotal: 76.3ms\tremaining: 155ms\n",
      "33:\tlearn: 0.1548774\ttotal: 79.6ms\tremaining: 154ms\n",
      "34:\tlearn: 0.1522495\ttotal: 81.9ms\tremaining: 152ms\n",
      "35:\tlearn: 0.1494951\ttotal: 84.2ms\tremaining: 150ms\n",
      "36:\tlearn: 0.1466880\ttotal: 86.5ms\tremaining: 147ms\n",
      "37:\tlearn: 0.1429074\ttotal: 88.9ms\tremaining: 145ms\n",
      "38:\tlearn: 0.1400885\ttotal: 91.1ms\tremaining: 142ms\n",
      "39:\tlearn: 0.1377791\ttotal: 93.5ms\tremaining: 140ms\n",
      "40:\tlearn: 0.1359086\ttotal: 95.7ms\tremaining: 138ms\n",
      "41:\tlearn: 0.1346784\ttotal: 98.2ms\tremaining: 136ms\n",
      "42:\tlearn: 0.1319116\ttotal: 101ms\tremaining: 134ms\n",
      "43:\tlearn: 0.1294421\ttotal: 103ms\tremaining: 132ms\n",
      "44:\tlearn: 0.1279441\ttotal: 106ms\tremaining: 129ms\n",
      "45:\tlearn: 0.1264493\ttotal: 108ms\tremaining: 127ms\n",
      "46:\tlearn: 0.1253683\ttotal: 111ms\tremaining: 125ms\n",
      "47:\tlearn: 0.1238981\ttotal: 113ms\tremaining: 122ms\n",
      "48:\tlearn: 0.1231252\ttotal: 115ms\tremaining: 120ms\n",
      "49:\tlearn: 0.1217578\ttotal: 118ms\tremaining: 118ms\n",
      "50:\tlearn: 0.1209471\ttotal: 120ms\tremaining: 115ms\n",
      "51:\tlearn: 0.1194889\ttotal: 122ms\tremaining: 113ms\n",
      "52:\tlearn: 0.1178929\ttotal: 125ms\tremaining: 110ms\n",
      "53:\tlearn: 0.1164880\ttotal: 127ms\tremaining: 108ms\n",
      "54:\tlearn: 0.1150287\ttotal: 130ms\tremaining: 107ms\n",
      "55:\tlearn: 0.1133232\ttotal: 133ms\tremaining: 104ms\n",
      "56:\tlearn: 0.1126158\ttotal: 135ms\tremaining: 102ms\n",
      "57:\tlearn: 0.1114034\ttotal: 137ms\tremaining: 99.3ms\n",
      "58:\tlearn: 0.1104275\ttotal: 139ms\tremaining: 96.9ms\n",
      "59:\tlearn: 0.1097535\ttotal: 142ms\tremaining: 94.6ms\n",
      "60:\tlearn: 0.1079826\ttotal: 144ms\tremaining: 92.2ms\n",
      "61:\tlearn: 0.1070311\ttotal: 147ms\tremaining: 89.9ms\n",
      "62:\tlearn: 0.1060449\ttotal: 149ms\tremaining: 87.5ms\n",
      "63:\tlearn: 0.1055950\ttotal: 151ms\tremaining: 85ms\n",
      "64:\tlearn: 0.1047114\ttotal: 153ms\tremaining: 82.5ms\n",
      "65:\tlearn: 0.1037170\ttotal: 155ms\tremaining: 80.1ms\n",
      "66:\tlearn: 0.1030529\ttotal: 158ms\tremaining: 77.7ms\n",
      "67:\tlearn: 0.1019206\ttotal: 160ms\tremaining: 75.2ms\n",
      "68:\tlearn: 0.1009779\ttotal: 162ms\tremaining: 72.8ms\n",
      "69:\tlearn: 0.1000752\ttotal: 164ms\tremaining: 70.4ms\n",
      "70:\tlearn: 0.0993645\ttotal: 167ms\tremaining: 68.1ms\n",
      "71:\tlearn: 0.0982626\ttotal: 169ms\tremaining: 65.7ms\n",
      "72:\tlearn: 0.0972577\ttotal: 171ms\tremaining: 63.4ms\n",
      "73:\tlearn: 0.0969263\ttotal: 174ms\tremaining: 61ms\n",
      "74:\tlearn: 0.0964055\ttotal: 176ms\tremaining: 58.6ms\n",
      "75:\tlearn: 0.0958601\ttotal: 178ms\tremaining: 56.3ms\n",
      "76:\tlearn: 0.0949855\ttotal: 181ms\tremaining: 54ms\n",
      "77:\tlearn: 0.0944943\ttotal: 183ms\tremaining: 51.7ms\n",
      "78:\tlearn: 0.0938470\ttotal: 186ms\tremaining: 49.3ms\n",
      "79:\tlearn: 0.0933516\ttotal: 188ms\tremaining: 47ms\n",
      "80:\tlearn: 0.0929698\ttotal: 190ms\tremaining: 44.7ms\n",
      "81:\tlearn: 0.0927043\ttotal: 193ms\tremaining: 42.3ms\n",
      "82:\tlearn: 0.0918916\ttotal: 195ms\tremaining: 39.9ms\n",
      "83:\tlearn: 0.0915154\ttotal: 197ms\tremaining: 37.6ms\n",
      "84:\tlearn: 0.0909338\ttotal: 200ms\tremaining: 35.2ms\n",
      "85:\tlearn: 0.0902930\ttotal: 202ms\tremaining: 32.9ms\n",
      "86:\tlearn: 0.0893481\ttotal: 204ms\tremaining: 30.5ms\n",
      "87:\tlearn: 0.0884087\ttotal: 207ms\tremaining: 28.2ms\n",
      "88:\tlearn: 0.0877695\ttotal: 209ms\tremaining: 25.8ms\n",
      "89:\tlearn: 0.0874336\ttotal: 211ms\tremaining: 23.5ms\n",
      "90:\tlearn: 0.0871619\ttotal: 214ms\tremaining: 21.1ms\n",
      "91:\tlearn: 0.0866970\ttotal: 216ms\tremaining: 18.8ms\n",
      "92:\tlearn: 0.0860793\ttotal: 218ms\tremaining: 16.4ms\n",
      "93:\tlearn: 0.0850994\ttotal: 221ms\tremaining: 14.1ms\n",
      "94:\tlearn: 0.0845279\ttotal: 223ms\tremaining: 11.7ms\n",
      "95:\tlearn: 0.0840036\ttotal: 226ms\tremaining: 9.4ms\n",
      "96:\tlearn: 0.0835178\ttotal: 228ms\tremaining: 7.05ms\n",
      "97:\tlearn: 0.0829858\ttotal: 230ms\tremaining: 4.7ms\n",
      "98:\tlearn: 0.0821956\ttotal: 233ms\tremaining: 2.35ms\n",
      "99:\tlearn: 0.0818029\ttotal: 235ms\tremaining: 0us\n",
      "0:\tlearn: 0.6789596\ttotal: 4.44ms\tremaining: 884ms\n",
      "1:\tlearn: 0.6657176\ttotal: 9.73ms\tremaining: 964ms\n",
      "2:\tlearn: 0.6527105\ttotal: 14ms\tremaining: 922ms\n",
      "3:\tlearn: 0.6398125\ttotal: 18.7ms\tremaining: 915ms\n",
      "4:\tlearn: 0.6263492\ttotal: 23.5ms\tremaining: 915ms\n",
      "5:\tlearn: 0.6137607\ttotal: 28ms\tremaining: 907ms\n",
      "6:\tlearn: 0.6006198\ttotal: 32.5ms\tremaining: 897ms\n",
      "7:\tlearn: 0.5896705\ttotal: 37.5ms\tremaining: 901ms\n",
      "8:\tlearn: 0.5773030\ttotal: 42.1ms\tremaining: 892ms\n",
      "9:\tlearn: 0.5654840\ttotal: 47.7ms\tremaining: 906ms\n",
      "10:\tlearn: 0.5554938\ttotal: 52.2ms\tremaining: 897ms\n",
      "11:\tlearn: 0.5444740\ttotal: 57.2ms\tremaining: 896ms\n",
      "12:\tlearn: 0.5359102\ttotal: 63.1ms\tremaining: 908ms\n",
      "13:\tlearn: 0.5263479\ttotal: 68.4ms\tremaining: 909ms\n",
      "14:\tlearn: 0.5156922\ttotal: 73.3ms\tremaining: 904ms\n",
      "15:\tlearn: 0.5050730\ttotal: 78.7ms\tremaining: 905ms\n",
      "16:\tlearn: 0.4956860\ttotal: 83.4ms\tremaining: 898ms\n",
      "17:\tlearn: 0.4876695\ttotal: 89.4ms\tremaining: 904ms\n",
      "18:\tlearn: 0.4795349\ttotal: 93.5ms\tremaining: 890ms\n",
      "19:\tlearn: 0.4723162\ttotal: 98.8ms\tremaining: 889ms\n",
      "20:\tlearn: 0.4629714\ttotal: 103ms\tremaining: 880ms\n",
      "21:\tlearn: 0.4550405\ttotal: 109ms\tremaining: 886ms\n",
      "22:\tlearn: 0.4476038\ttotal: 114ms\tremaining: 880ms\n",
      "23:\tlearn: 0.4405581\ttotal: 118ms\tremaining: 863ms\n",
      "24:\tlearn: 0.4345278\ttotal: 121ms\tremaining: 850ms\n",
      "25:\tlearn: 0.4278080\ttotal: 127ms\tremaining: 849ms\n",
      "26:\tlearn: 0.4232945\ttotal: 129ms\tremaining: 828ms\n",
      "27:\tlearn: 0.4148237\ttotal: 134ms\tremaining: 822ms\n",
      "28:\tlearn: 0.4072407\ttotal: 139ms\tremaining: 822ms\n",
      "29:\tlearn: 0.4012801\ttotal: 144ms\tremaining: 817ms\n",
      "30:\tlearn: 0.3954186\ttotal: 149ms\tremaining: 812ms\n",
      "31:\tlearn: 0.3899129\ttotal: 153ms\tremaining: 806ms\n",
      "32:\tlearn: 0.3842632\ttotal: 159ms\tremaining: 806ms\n",
      "33:\tlearn: 0.3790495\ttotal: 163ms\tremaining: 798ms\n",
      "34:\tlearn: 0.3731436\ttotal: 169ms\tremaining: 799ms\n",
      "35:\tlearn: 0.3689224\ttotal: 174ms\tremaining: 793ms\n",
      "36:\tlearn: 0.3641905\ttotal: 180ms\tremaining: 791ms\n",
      "37:\tlearn: 0.3586625\ttotal: 184ms\tremaining: 786ms\n",
      "38:\tlearn: 0.3548382\ttotal: 188ms\tremaining: 776ms\n",
      "39:\tlearn: 0.3498115\ttotal: 193ms\tremaining: 771ms\n",
      "40:\tlearn: 0.3452183\ttotal: 199ms\tremaining: 772ms\n",
      "41:\tlearn: 0.3403768\ttotal: 204ms\tremaining: 768ms\n",
      "42:\tlearn: 0.3355705\ttotal: 209ms\tremaining: 763ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43:\tlearn: 0.3300096\ttotal: 214ms\tremaining: 760ms\n",
      "44:\tlearn: 0.3260254\ttotal: 219ms\tremaining: 756ms\n",
      "45:\tlearn: 0.3224942\ttotal: 224ms\tremaining: 748ms\n",
      "46:\tlearn: 0.3189218\ttotal: 229ms\tremaining: 746ms\n",
      "47:\tlearn: 0.3156911\ttotal: 234ms\tremaining: 741ms\n",
      "48:\tlearn: 0.3119741\ttotal: 239ms\tremaining: 738ms\n",
      "49:\tlearn: 0.3099523\ttotal: 244ms\tremaining: 732ms\n",
      "50:\tlearn: 0.3066200\ttotal: 249ms\tremaining: 728ms\n",
      "51:\tlearn: 0.3021852\ttotal: 254ms\tremaining: 723ms\n",
      "52:\tlearn: 0.2987805\ttotal: 260ms\tremaining: 720ms\n",
      "53:\tlearn: 0.2966290\ttotal: 265ms\tremaining: 715ms\n",
      "54:\tlearn: 0.2921505\ttotal: 270ms\tremaining: 712ms\n",
      "55:\tlearn: 0.2886345\ttotal: 275ms\tremaining: 706ms\n",
      "56:\tlearn: 0.2845569\ttotal: 280ms\tremaining: 702ms\n",
      "57:\tlearn: 0.2804654\ttotal: 285ms\tremaining: 697ms\n",
      "58:\tlearn: 0.2779109\ttotal: 290ms\tremaining: 693ms\n",
      "59:\tlearn: 0.2754570\ttotal: 295ms\tremaining: 688ms\n",
      "60:\tlearn: 0.2721825\ttotal: 300ms\tremaining: 684ms\n",
      "61:\tlearn: 0.2695474\ttotal: 305ms\tremaining: 679ms\n",
      "62:\tlearn: 0.2668168\ttotal: 310ms\tremaining: 674ms\n",
      "63:\tlearn: 0.2648196\ttotal: 315ms\tremaining: 669ms\n",
      "64:\tlearn: 0.2621198\ttotal: 320ms\tremaining: 665ms\n",
      "65:\tlearn: 0.2591726\ttotal: 325ms\tremaining: 660ms\n",
      "66:\tlearn: 0.2569513\ttotal: 331ms\tremaining: 656ms\n",
      "67:\tlearn: 0.2546730\ttotal: 336ms\tremaining: 653ms\n",
      "68:\tlearn: 0.2528826\ttotal: 342ms\tremaining: 649ms\n",
      "69:\tlearn: 0.2506350\ttotal: 346ms\tremaining: 643ms\n",
      "70:\tlearn: 0.2486128\ttotal: 352ms\tremaining: 640ms\n",
      "71:\tlearn: 0.2480043\ttotal: 354ms\tremaining: 630ms\n",
      "72:\tlearn: 0.2453570\ttotal: 359ms\tremaining: 624ms\n",
      "73:\tlearn: 0.2426375\ttotal: 364ms\tremaining: 620ms\n",
      "74:\tlearn: 0.2409106\ttotal: 369ms\tremaining: 614ms\n",
      "75:\tlearn: 0.2394367\ttotal: 374ms\tremaining: 611ms\n",
      "76:\tlearn: 0.2367738\ttotal: 379ms\tremaining: 605ms\n",
      "77:\tlearn: 0.2342571\ttotal: 384ms\tremaining: 601ms\n",
      "78:\tlearn: 0.2323603\ttotal: 389ms\tremaining: 596ms\n",
      "79:\tlearn: 0.2302596\ttotal: 394ms\tremaining: 592ms\n",
      "80:\tlearn: 0.2283012\ttotal: 399ms\tremaining: 586ms\n",
      "81:\tlearn: 0.2268760\ttotal: 405ms\tremaining: 583ms\n",
      "82:\tlearn: 0.2252479\ttotal: 409ms\tremaining: 577ms\n",
      "83:\tlearn: 0.2239383\ttotal: 414ms\tremaining: 572ms\n",
      "84:\tlearn: 0.2226049\ttotal: 419ms\tremaining: 567ms\n",
      "85:\tlearn: 0.2212506\ttotal: 425ms\tremaining: 563ms\n",
      "86:\tlearn: 0.2190761\ttotal: 430ms\tremaining: 558ms\n",
      "87:\tlearn: 0.2174779\ttotal: 435ms\tremaining: 553ms\n",
      "88:\tlearn: 0.2164599\ttotal: 439ms\tremaining: 548ms\n",
      "89:\tlearn: 0.2142514\ttotal: 444ms\tremaining: 543ms\n",
      "90:\tlearn: 0.2132164\ttotal: 449ms\tremaining: 537ms\n",
      "91:\tlearn: 0.2121156\ttotal: 454ms\tremaining: 533ms\n",
      "92:\tlearn: 0.2103581\ttotal: 458ms\tremaining: 527ms\n",
      "93:\tlearn: 0.2087964\ttotal: 463ms\tremaining: 522ms\n",
      "94:\tlearn: 0.2076542\ttotal: 467ms\tremaining: 517ms\n",
      "95:\tlearn: 0.2058609\ttotal: 473ms\tremaining: 512ms\n",
      "96:\tlearn: 0.2043737\ttotal: 478ms\tremaining: 507ms\n",
      "97:\tlearn: 0.2026708\ttotal: 483ms\tremaining: 503ms\n",
      "98:\tlearn: 0.2015104\ttotal: 488ms\tremaining: 497ms\n",
      "99:\tlearn: 0.2003775\ttotal: 493ms\tremaining: 493ms\n",
      "100:\tlearn: 0.1991507\ttotal: 498ms\tremaining: 488ms\n",
      "101:\tlearn: 0.1978957\ttotal: 504ms\tremaining: 484ms\n",
      "102:\tlearn: 0.1964418\ttotal: 509ms\tremaining: 479ms\n",
      "103:\tlearn: 0.1955499\ttotal: 514ms\tremaining: 475ms\n",
      "104:\tlearn: 0.1946221\ttotal: 519ms\tremaining: 470ms\n",
      "105:\tlearn: 0.1939696\ttotal: 524ms\tremaining: 465ms\n",
      "106:\tlearn: 0.1924352\ttotal: 529ms\tremaining: 460ms\n",
      "107:\tlearn: 0.1908436\ttotal: 534ms\tremaining: 455ms\n",
      "108:\tlearn: 0.1895047\ttotal: 539ms\tremaining: 450ms\n",
      "109:\tlearn: 0.1886535\ttotal: 544ms\tremaining: 445ms\n",
      "110:\tlearn: 0.1876650\ttotal: 550ms\tremaining: 441ms\n",
      "111:\tlearn: 0.1860991\ttotal: 555ms\tremaining: 436ms\n",
      "112:\tlearn: 0.1845841\ttotal: 560ms\tremaining: 431ms\n",
      "113:\tlearn: 0.1837291\ttotal: 565ms\tremaining: 426ms\n",
      "114:\tlearn: 0.1822868\ttotal: 570ms\tremaining: 422ms\n",
      "115:\tlearn: 0.1810970\ttotal: 576ms\tremaining: 417ms\n",
      "116:\tlearn: 0.1801890\ttotal: 580ms\tremaining: 412ms\n",
      "117:\tlearn: 0.1790306\ttotal: 586ms\tremaining: 407ms\n",
      "118:\tlearn: 0.1787545\ttotal: 589ms\tremaining: 401ms\n",
      "119:\tlearn: 0.1776340\ttotal: 595ms\tremaining: 397ms\n",
      "120:\tlearn: 0.1766439\ttotal: 600ms\tremaining: 392ms\n",
      "121:\tlearn: 0.1750950\ttotal: 607ms\tremaining: 388ms\n",
      "122:\tlearn: 0.1742328\ttotal: 611ms\tremaining: 383ms\n",
      "123:\tlearn: 0.1732513\ttotal: 617ms\tremaining: 378ms\n",
      "124:\tlearn: 0.1721113\ttotal: 621ms\tremaining: 373ms\n",
      "125:\tlearn: 0.1711746\ttotal: 626ms\tremaining: 368ms\n",
      "126:\tlearn: 0.1702055\ttotal: 631ms\tremaining: 363ms\n",
      "127:\tlearn: 0.1693742\ttotal: 637ms\tremaining: 358ms\n",
      "128:\tlearn: 0.1681768\ttotal: 641ms\tremaining: 353ms\n",
      "129:\tlearn: 0.1674011\ttotal: 647ms\tremaining: 348ms\n",
      "130:\tlearn: 0.1666572\ttotal: 652ms\tremaining: 343ms\n",
      "131:\tlearn: 0.1663115\ttotal: 656ms\tremaining: 338ms\n",
      "132:\tlearn: 0.1654257\ttotal: 661ms\tremaining: 333ms\n",
      "133:\tlearn: 0.1647304\ttotal: 666ms\tremaining: 328ms\n",
      "134:\tlearn: 0.1638796\ttotal: 671ms\tremaining: 323ms\n",
      "135:\tlearn: 0.1633685\ttotal: 676ms\tremaining: 318ms\n",
      "136:\tlearn: 0.1623013\ttotal: 681ms\tremaining: 313ms\n",
      "137:\tlearn: 0.1613812\ttotal: 687ms\tremaining: 309ms\n",
      "138:\tlearn: 0.1604537\ttotal: 692ms\tremaining: 304ms\n",
      "139:\tlearn: 0.1597706\ttotal: 698ms\tremaining: 299ms\n",
      "140:\tlearn: 0.1586217\ttotal: 702ms\tremaining: 294ms\n",
      "141:\tlearn: 0.1578182\ttotal: 709ms\tremaining: 290ms\n",
      "142:\tlearn: 0.1569315\ttotal: 713ms\tremaining: 284ms\n",
      "143:\tlearn: 0.1560960\ttotal: 718ms\tremaining: 279ms\n",
      "144:\tlearn: 0.1555803\ttotal: 723ms\tremaining: 274ms\n",
      "145:\tlearn: 0.1549817\ttotal: 728ms\tremaining: 269ms\n",
      "146:\tlearn: 0.1543324\ttotal: 733ms\tremaining: 264ms\n",
      "147:\tlearn: 0.1536453\ttotal: 739ms\tremaining: 259ms\n",
      "148:\tlearn: 0.1532074\ttotal: 743ms\tremaining: 254ms\n",
      "149:\tlearn: 0.1526101\ttotal: 749ms\tremaining: 250ms\n",
      "150:\tlearn: 0.1518454\ttotal: 753ms\tremaining: 244ms\n",
      "151:\tlearn: 0.1512206\ttotal: 759ms\tremaining: 240ms\n",
      "152:\tlearn: 0.1507124\ttotal: 764ms\tremaining: 235ms\n",
      "153:\tlearn: 0.1500709\ttotal: 770ms\tremaining: 230ms\n",
      "154:\tlearn: 0.1495404\ttotal: 775ms\tremaining: 225ms\n",
      "155:\tlearn: 0.1491053\ttotal: 780ms\tremaining: 220ms\n",
      "156:\tlearn: 0.1482609\ttotal: 785ms\tremaining: 215ms\n",
      "157:\tlearn: 0.1475552\ttotal: 789ms\tremaining: 210ms\n",
      "158:\tlearn: 0.1469242\ttotal: 794ms\tremaining: 205ms\n",
      "159:\tlearn: 0.1463628\ttotal: 799ms\tremaining: 200ms\n",
      "160:\tlearn: 0.1454009\ttotal: 804ms\tremaining: 195ms\n",
      "161:\tlearn: 0.1446308\ttotal: 809ms\tremaining: 190ms\n",
      "162:\tlearn: 0.1442174\ttotal: 814ms\tremaining: 185ms\n",
      "163:\tlearn: 0.1436739\ttotal: 820ms\tremaining: 180ms\n",
      "164:\tlearn: 0.1432163\ttotal: 824ms\tremaining: 175ms\n",
      "165:\tlearn: 0.1425722\ttotal: 830ms\tremaining: 170ms\n",
      "166:\tlearn: 0.1422285\ttotal: 835ms\tremaining: 165ms\n",
      "167:\tlearn: 0.1415677\ttotal: 840ms\tremaining: 160ms\n",
      "168:\tlearn: 0.1410783\ttotal: 845ms\tremaining: 155ms\n",
      "169:\tlearn: 0.1406359\ttotal: 851ms\tremaining: 150ms\n",
      "170:\tlearn: 0.1401016\ttotal: 856ms\tremaining: 145ms\n",
      "171:\tlearn: 0.1395305\ttotal: 862ms\tremaining: 140ms\n",
      "172:\tlearn: 0.1391299\ttotal: 866ms\tremaining: 135ms\n",
      "173:\tlearn: 0.1386049\ttotal: 872ms\tremaining: 130ms\n",
      "174:\tlearn: 0.1381208\ttotal: 876ms\tremaining: 125ms\n",
      "175:\tlearn: 0.1375490\ttotal: 881ms\tremaining: 120ms\n",
      "176:\tlearn: 0.1370895\ttotal: 886ms\tremaining: 115ms\n",
      "177:\tlearn: 0.1367184\ttotal: 892ms\tremaining: 110ms\n",
      "178:\tlearn: 0.1363115\ttotal: 896ms\tremaining: 105ms\n",
      "179:\tlearn: 0.1357532\ttotal: 902ms\tremaining: 100ms\n",
      "180:\tlearn: 0.1351896\ttotal: 906ms\tremaining: 95.1ms\n",
      "181:\tlearn: 0.1346425\ttotal: 912ms\tremaining: 90.2ms\n",
      "182:\tlearn: 0.1339978\ttotal: 916ms\tremaining: 85.1ms\n",
      "183:\tlearn: 0.1333376\ttotal: 923ms\tremaining: 80.2ms\n",
      "184:\tlearn: 0.1327669\ttotal: 928ms\tremaining: 75.2ms\n",
      "185:\tlearn: 0.1320533\ttotal: 933ms\tremaining: 70.2ms\n",
      "186:\tlearn: 0.1315959\ttotal: 938ms\tremaining: 65.2ms\n",
      "187:\tlearn: 0.1311575\ttotal: 944ms\tremaining: 60.2ms\n",
      "188:\tlearn: 0.1307469\ttotal: 948ms\tremaining: 55.2ms\n",
      "189:\tlearn: 0.1303787\ttotal: 954ms\tremaining: 50.2ms\n",
      "190:\tlearn: 0.1298685\ttotal: 959ms\tremaining: 45.2ms\n",
      "191:\tlearn: 0.1293749\ttotal: 964ms\tremaining: 40.2ms\n",
      "192:\tlearn: 0.1288313\ttotal: 969ms\tremaining: 35.1ms\n",
      "193:\tlearn: 0.1284061\ttotal: 976ms\tremaining: 30.2ms\n",
      "194:\tlearn: 0.1280068\ttotal: 981ms\tremaining: 25.2ms\n",
      "195:\tlearn: 0.1273787\ttotal: 986ms\tremaining: 20.1ms\n",
      "196:\tlearn: 0.1269505\ttotal: 991ms\tremaining: 15.1ms\n",
      "197:\tlearn: 0.1265536\ttotal: 996ms\tremaining: 10.1ms\n",
      "198:\tlearn: 0.1262039\ttotal: 1s\tremaining: 5.03ms\n",
      "199:\tlearn: 0.1259477\ttotal: 1.01s\tremaining: 0us\n",
      "0:\tlearn: 0.6802306\ttotal: 4.13ms\tremaining: 823ms\n",
      "1:\tlearn: 0.6661020\ttotal: 9.87ms\tremaining: 977ms\n",
      "2:\tlearn: 0.6532761\ttotal: 14.1ms\tremaining: 926ms\n",
      "3:\tlearn: 0.6404202\ttotal: 18.8ms\tremaining: 920ms\n",
      "4:\tlearn: 0.6273002\ttotal: 23.3ms\tremaining: 909ms\n",
      "5:\tlearn: 0.6150857\ttotal: 28.9ms\tremaining: 934ms\n",
      "6:\tlearn: 0.6036942\ttotal: 33.2ms\tremaining: 916ms\n",
      "7:\tlearn: 0.5918060\ttotal: 38.4ms\tremaining: 922ms\n",
      "8:\tlearn: 0.5796174\ttotal: 42.8ms\tremaining: 909ms\n",
      "9:\tlearn: 0.5676196\ttotal: 48.3ms\tremaining: 918ms\n",
      "10:\tlearn: 0.5579337\ttotal: 52.7ms\tremaining: 906ms\n",
      "11:\tlearn: 0.5497352\ttotal: 58.5ms\tremaining: 916ms\n",
      "12:\tlearn: 0.5403507\ttotal: 64.1ms\tremaining: 922ms\n",
      "13:\tlearn: 0.5298374\ttotal: 69.4ms\tremaining: 922ms\n",
      "14:\tlearn: 0.5203726\ttotal: 74ms\tremaining: 912ms\n",
      "15:\tlearn: 0.5089386\ttotal: 80ms\tremaining: 920ms\n",
      "16:\tlearn: 0.5004506\ttotal: 85ms\tremaining: 915ms\n",
      "17:\tlearn: 0.4931872\ttotal: 89.8ms\tremaining: 908ms\n",
      "18:\tlearn: 0.4850438\ttotal: 94.6ms\tremaining: 901ms\n",
      "19:\tlearn: 0.4760234\ttotal: 99.8ms\tremaining: 899ms\n",
      "20:\tlearn: 0.4701017\ttotal: 103ms\tremaining: 875ms\n",
      "21:\tlearn: 0.4630420\ttotal: 107ms\tremaining: 866ms\n",
      "22:\tlearn: 0.4552304\ttotal: 112ms\tremaining: 866ms\n",
      "23:\tlearn: 0.4478613\ttotal: 117ms\tremaining: 860ms\n",
      "24:\tlearn: 0.4404962\ttotal: 123ms\tremaining: 859ms\n",
      "25:\tlearn: 0.4314912\ttotal: 128ms\tremaining: 853ms\n",
      "26:\tlearn: 0.4240678\ttotal: 133ms\tremaining: 854ms\n",
      "27:\tlearn: 0.4155650\ttotal: 138ms\tremaining: 850ms\n",
      "28:\tlearn: 0.4084683\ttotal: 143ms\tremaining: 844ms\n",
      "29:\tlearn: 0.4033471\ttotal: 148ms\tremaining: 837ms\n",
      "30:\tlearn: 0.3964382\ttotal: 154ms\tremaining: 838ms\n",
      "31:\tlearn: 0.3892224\ttotal: 159ms\tremaining: 833ms\n",
      "32:\tlearn: 0.3843769\ttotal: 164ms\tremaining: 832ms\n",
      "33:\tlearn: 0.3788612\ttotal: 169ms\tremaining: 824ms\n",
      "34:\tlearn: 0.3728868\ttotal: 174ms\tremaining: 821ms\n",
      "35:\tlearn: 0.3680979\ttotal: 179ms\tremaining: 815ms\n",
      "36:\tlearn: 0.3632595\ttotal: 185ms\tremaining: 814ms\n",
      "37:\tlearn: 0.3580596\ttotal: 190ms\tremaining: 808ms\n",
      "38:\tlearn: 0.3534681\ttotal: 196ms\tremaining: 807ms\n",
      "39:\tlearn: 0.3482560\ttotal: 200ms\tremaining: 801ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40:\tlearn: 0.3437996\ttotal: 206ms\tremaining: 798ms\n",
      "41:\tlearn: 0.3393614\ttotal: 210ms\tremaining: 791ms\n",
      "42:\tlearn: 0.3350761\ttotal: 216ms\tremaining: 787ms\n",
      "43:\tlearn: 0.3293630\ttotal: 221ms\tremaining: 784ms\n",
      "44:\tlearn: 0.3252165\ttotal: 226ms\tremaining: 778ms\n",
      "45:\tlearn: 0.3217759\ttotal: 231ms\tremaining: 773ms\n",
      "46:\tlearn: 0.3182767\ttotal: 237ms\tremaining: 772ms\n",
      "47:\tlearn: 0.3146351\ttotal: 242ms\tremaining: 766ms\n",
      "48:\tlearn: 0.3111885\ttotal: 246ms\tremaining: 759ms\n",
      "49:\tlearn: 0.3075495\ttotal: 251ms\tremaining: 754ms\n",
      "50:\tlearn: 0.3047981\ttotal: 255ms\tremaining: 746ms\n",
      "51:\tlearn: 0.3001084\ttotal: 260ms\tremaining: 740ms\n",
      "52:\tlearn: 0.2959397\ttotal: 265ms\tremaining: 735ms\n",
      "53:\tlearn: 0.2925743\ttotal: 269ms\tremaining: 728ms\n",
      "54:\tlearn: 0.2884559\ttotal: 275ms\tremaining: 724ms\n",
      "55:\tlearn: 0.2852210\ttotal: 279ms\tremaining: 718ms\n",
      "56:\tlearn: 0.2808072\ttotal: 284ms\tremaining: 714ms\n",
      "57:\tlearn: 0.2771230\ttotal: 289ms\tremaining: 707ms\n",
      "58:\tlearn: 0.2731029\ttotal: 294ms\tremaining: 701ms\n",
      "59:\tlearn: 0.2700591\ttotal: 298ms\tremaining: 696ms\n",
      "60:\tlearn: 0.2678392\ttotal: 304ms\tremaining: 692ms\n",
      "61:\tlearn: 0.2656395\ttotal: 309ms\tremaining: 688ms\n",
      "62:\tlearn: 0.2630699\ttotal: 314ms\tremaining: 683ms\n",
      "63:\tlearn: 0.2607855\ttotal: 319ms\tremaining: 678ms\n",
      "64:\tlearn: 0.2586574\ttotal: 325ms\tremaining: 675ms\n",
      "65:\tlearn: 0.2562834\ttotal: 330ms\tremaining: 670ms\n",
      "66:\tlearn: 0.2541891\ttotal: 335ms\tremaining: 665ms\n",
      "67:\tlearn: 0.2535684\ttotal: 338ms\tremaining: 656ms\n",
      "68:\tlearn: 0.2500208\ttotal: 343ms\tremaining: 650ms\n",
      "69:\tlearn: 0.2474156\ttotal: 347ms\tremaining: 644ms\n",
      "70:\tlearn: 0.2451250\ttotal: 352ms\tremaining: 639ms\n",
      "71:\tlearn: 0.2428021\ttotal: 357ms\tremaining: 634ms\n",
      "72:\tlearn: 0.2411788\ttotal: 361ms\tremaining: 629ms\n",
      "73:\tlearn: 0.2383766\ttotal: 366ms\tremaining: 623ms\n",
      "74:\tlearn: 0.2357215\ttotal: 370ms\tremaining: 617ms\n",
      "75:\tlearn: 0.2335937\ttotal: 376ms\tremaining: 613ms\n",
      "76:\tlearn: 0.2330689\ttotal: 379ms\tremaining: 605ms\n",
      "77:\tlearn: 0.2307691\ttotal: 383ms\tremaining: 599ms\n",
      "78:\tlearn: 0.2294245\ttotal: 389ms\tremaining: 595ms\n",
      "79:\tlearn: 0.2273775\ttotal: 393ms\tremaining: 590ms\n",
      "80:\tlearn: 0.2251187\ttotal: 399ms\tremaining: 587ms\n",
      "81:\tlearn: 0.2230724\ttotal: 404ms\tremaining: 581ms\n",
      "82:\tlearn: 0.2215388\ttotal: 410ms\tremaining: 577ms\n",
      "83:\tlearn: 0.2197852\ttotal: 414ms\tremaining: 572ms\n",
      "84:\tlearn: 0.2188909\ttotal: 419ms\tremaining: 567ms\n",
      "85:\tlearn: 0.2173191\ttotal: 424ms\tremaining: 562ms\n",
      "86:\tlearn: 0.2152391\ttotal: 429ms\tremaining: 557ms\n",
      "87:\tlearn: 0.2138404\ttotal: 433ms\tremaining: 552ms\n",
      "88:\tlearn: 0.2122740\ttotal: 440ms\tremaining: 548ms\n",
      "89:\tlearn: 0.2109175\ttotal: 444ms\tremaining: 543ms\n",
      "90:\tlearn: 0.2089577\ttotal: 450ms\tremaining: 539ms\n",
      "91:\tlearn: 0.2074576\ttotal: 454ms\tremaining: 533ms\n",
      "92:\tlearn: 0.2063363\ttotal: 459ms\tremaining: 528ms\n",
      "93:\tlearn: 0.2059929\ttotal: 461ms\tremaining: 520ms\n",
      "94:\tlearn: 0.2047325\ttotal: 467ms\tremaining: 516ms\n",
      "95:\tlearn: 0.2033504\ttotal: 472ms\tremaining: 511ms\n",
      "96:\tlearn: 0.2013723\ttotal: 477ms\tremaining: 507ms\n",
      "97:\tlearn: 0.2003247\ttotal: 483ms\tremaining: 503ms\n",
      "98:\tlearn: 0.1992149\ttotal: 488ms\tremaining: 497ms\n",
      "99:\tlearn: 0.1981532\ttotal: 493ms\tremaining: 493ms\n",
      "100:\tlearn: 0.1963012\ttotal: 497ms\tremaining: 487ms\n",
      "101:\tlearn: 0.1952990\ttotal: 503ms\tremaining: 484ms\n",
      "102:\tlearn: 0.1937032\ttotal: 508ms\tremaining: 479ms\n",
      "103:\tlearn: 0.1919498\ttotal: 514ms\tremaining: 474ms\n",
      "104:\tlearn: 0.1908283\ttotal: 518ms\tremaining: 469ms\n",
      "105:\tlearn: 0.1893223\ttotal: 523ms\tremaining: 464ms\n",
      "106:\tlearn: 0.1881493\ttotal: 528ms\tremaining: 459ms\n",
      "107:\tlearn: 0.1872957\ttotal: 533ms\tremaining: 454ms\n",
      "108:\tlearn: 0.1863929\ttotal: 538ms\tremaining: 449ms\n",
      "109:\tlearn: 0.1849486\ttotal: 543ms\tremaining: 445ms\n",
      "110:\tlearn: 0.1834748\ttotal: 548ms\tremaining: 439ms\n",
      "111:\tlearn: 0.1819405\ttotal: 552ms\tremaining: 434ms\n",
      "112:\tlearn: 0.1801818\ttotal: 557ms\tremaining: 429ms\n",
      "113:\tlearn: 0.1791252\ttotal: 562ms\tremaining: 424ms\n",
      "114:\tlearn: 0.1783683\ttotal: 567ms\tremaining: 419ms\n",
      "115:\tlearn: 0.1775490\ttotal: 573ms\tremaining: 415ms\n",
      "116:\tlearn: 0.1759607\ttotal: 577ms\tremaining: 410ms\n",
      "117:\tlearn: 0.1752002\ttotal: 582ms\tremaining: 405ms\n",
      "118:\tlearn: 0.1744645\ttotal: 587ms\tremaining: 400ms\n",
      "119:\tlearn: 0.1738409\ttotal: 593ms\tremaining: 395ms\n",
      "120:\tlearn: 0.1725316\ttotal: 598ms\tremaining: 390ms\n",
      "121:\tlearn: 0.1714012\ttotal: 603ms\tremaining: 385ms\n",
      "122:\tlearn: 0.1703228\ttotal: 608ms\tremaining: 380ms\n",
      "123:\tlearn: 0.1691878\ttotal: 613ms\tremaining: 376ms\n",
      "124:\tlearn: 0.1685863\ttotal: 618ms\tremaining: 371ms\n",
      "125:\tlearn: 0.1672581\ttotal: 630ms\tremaining: 370ms\n",
      "126:\tlearn: 0.1661133\ttotal: 635ms\tremaining: 365ms\n",
      "127:\tlearn: 0.1652626\ttotal: 641ms\tremaining: 360ms\n",
      "128:\tlearn: 0.1647089\ttotal: 646ms\tremaining: 355ms\n",
      "129:\tlearn: 0.1640782\ttotal: 651ms\tremaining: 351ms\n",
      "130:\tlearn: 0.1634617\ttotal: 656ms\tremaining: 345ms\n",
      "131:\tlearn: 0.1623185\ttotal: 662ms\tremaining: 341ms\n",
      "132:\tlearn: 0.1612603\ttotal: 667ms\tremaining: 336ms\n",
      "133:\tlearn: 0.1604483\ttotal: 672ms\tremaining: 331ms\n",
      "134:\tlearn: 0.1594836\ttotal: 678ms\tremaining: 326ms\n",
      "135:\tlearn: 0.1586397\ttotal: 683ms\tremaining: 321ms\n",
      "136:\tlearn: 0.1580161\ttotal: 688ms\tremaining: 317ms\n",
      "137:\tlearn: 0.1574083\ttotal: 693ms\tremaining: 312ms\n",
      "138:\tlearn: 0.1568224\ttotal: 698ms\tremaining: 306ms\n",
      "139:\tlearn: 0.1562103\ttotal: 703ms\tremaining: 301ms\n",
      "140:\tlearn: 0.1553204\ttotal: 708ms\tremaining: 296ms\n",
      "141:\tlearn: 0.1548232\ttotal: 714ms\tremaining: 292ms\n",
      "142:\tlearn: 0.1542593\ttotal: 719ms\tremaining: 286ms\n",
      "143:\tlearn: 0.1533639\ttotal: 724ms\tremaining: 282ms\n",
      "144:\tlearn: 0.1526828\ttotal: 729ms\tremaining: 276ms\n",
      "145:\tlearn: 0.1519037\ttotal: 735ms\tremaining: 272ms\n",
      "146:\tlearn: 0.1513174\ttotal: 739ms\tremaining: 266ms\n",
      "147:\tlearn: 0.1508760\ttotal: 745ms\tremaining: 262ms\n",
      "148:\tlearn: 0.1503245\ttotal: 751ms\tremaining: 257ms\n",
      "149:\tlearn: 0.1498244\ttotal: 756ms\tremaining: 252ms\n",
      "150:\tlearn: 0.1493087\ttotal: 761ms\tremaining: 247ms\n",
      "151:\tlearn: 0.1487642\ttotal: 765ms\tremaining: 241ms\n",
      "152:\tlearn: 0.1482336\ttotal: 769ms\tremaining: 236ms\n",
      "153:\tlearn: 0.1475203\ttotal: 775ms\tremaining: 232ms\n",
      "154:\tlearn: 0.1470911\ttotal: 779ms\tremaining: 226ms\n",
      "155:\tlearn: 0.1465543\ttotal: 785ms\tremaining: 221ms\n",
      "156:\tlearn: 0.1458357\ttotal: 790ms\tremaining: 216ms\n",
      "157:\tlearn: 0.1450088\ttotal: 795ms\tremaining: 211ms\n",
      "158:\tlearn: 0.1443637\ttotal: 800ms\tremaining: 206ms\n",
      "159:\tlearn: 0.1439437\ttotal: 806ms\tremaining: 201ms\n",
      "160:\tlearn: 0.1434126\ttotal: 810ms\tremaining: 196ms\n",
      "161:\tlearn: 0.1425393\ttotal: 816ms\tremaining: 191ms\n",
      "162:\tlearn: 0.1420354\ttotal: 821ms\tremaining: 186ms\n",
      "163:\tlearn: 0.1414320\ttotal: 827ms\tremaining: 182ms\n",
      "164:\tlearn: 0.1406242\ttotal: 832ms\tremaining: 176ms\n",
      "165:\tlearn: 0.1405768\ttotal: 835ms\tremaining: 171ms\n",
      "166:\tlearn: 0.1399249\ttotal: 840ms\tremaining: 166ms\n",
      "167:\tlearn: 0.1391942\ttotal: 845ms\tremaining: 161ms\n",
      "168:\tlearn: 0.1387384\ttotal: 850ms\tremaining: 156ms\n",
      "169:\tlearn: 0.1383489\ttotal: 855ms\tremaining: 151ms\n",
      "170:\tlearn: 0.1378234\ttotal: 861ms\tremaining: 146ms\n",
      "171:\tlearn: 0.1373362\ttotal: 866ms\tremaining: 141ms\n",
      "172:\tlearn: 0.1368767\ttotal: 871ms\tremaining: 136ms\n",
      "173:\tlearn: 0.1363349\ttotal: 875ms\tremaining: 131ms\n",
      "174:\tlearn: 0.1360073\ttotal: 879ms\tremaining: 126ms\n",
      "175:\tlearn: 0.1356177\ttotal: 884ms\tremaining: 121ms\n",
      "176:\tlearn: 0.1352548\ttotal: 889ms\tremaining: 115ms\n",
      "177:\tlearn: 0.1346777\ttotal: 894ms\tremaining: 110ms\n",
      "178:\tlearn: 0.1340746\ttotal: 898ms\tremaining: 105ms\n",
      "179:\tlearn: 0.1335032\ttotal: 903ms\tremaining: 100ms\n",
      "180:\tlearn: 0.1329396\ttotal: 908ms\tremaining: 95.3ms\n",
      "181:\tlearn: 0.1325800\ttotal: 912ms\tremaining: 90.2ms\n",
      "182:\tlearn: 0.1322128\ttotal: 917ms\tremaining: 85.2ms\n",
      "183:\tlearn: 0.1318781\ttotal: 922ms\tremaining: 80.2ms\n",
      "184:\tlearn: 0.1314027\ttotal: 927ms\tremaining: 75.1ms\n",
      "185:\tlearn: 0.1310562\ttotal: 932ms\tremaining: 70.2ms\n",
      "186:\tlearn: 0.1304987\ttotal: 938ms\tremaining: 65.2ms\n",
      "187:\tlearn: 0.1300601\ttotal: 943ms\tremaining: 60.2ms\n",
      "188:\tlearn: 0.1295909\ttotal: 948ms\tremaining: 55.2ms\n",
      "189:\tlearn: 0.1291844\ttotal: 953ms\tremaining: 50.2ms\n",
      "190:\tlearn: 0.1287853\ttotal: 957ms\tremaining: 45.1ms\n",
      "191:\tlearn: 0.1284636\ttotal: 961ms\tremaining: 40ms\n",
      "192:\tlearn: 0.1282018\ttotal: 966ms\tremaining: 35ms\n",
      "193:\tlearn: 0.1276706\ttotal: 971ms\tremaining: 30ms\n",
      "194:\tlearn: 0.1273169\ttotal: 976ms\tremaining: 25ms\n",
      "195:\tlearn: 0.1270181\ttotal: 982ms\tremaining: 20ms\n",
      "196:\tlearn: 0.1268085\ttotal: 987ms\tremaining: 15ms\n",
      "197:\tlearn: 0.1262735\ttotal: 992ms\tremaining: 10ms\n",
      "198:\tlearn: 0.1258773\ttotal: 996ms\tremaining: 5.01ms\n",
      "199:\tlearn: 0.1254199\ttotal: 1s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6793961\ttotal: 4.04ms\tremaining: 804ms\n",
      "1:\tlearn: 0.6662346\ttotal: 8.99ms\tremaining: 891ms\n",
      "2:\tlearn: 0.6525627\ttotal: 13.2ms\tremaining: 867ms\n",
      "3:\tlearn: 0.6402018\ttotal: 18.2ms\tremaining: 892ms\n",
      "4:\tlearn: 0.6272833\ttotal: 22.7ms\tremaining: 884ms\n",
      "5:\tlearn: 0.6149989\ttotal: 27.9ms\tremaining: 902ms\n",
      "6:\tlearn: 0.6026186\ttotal: 32.5ms\tremaining: 895ms\n",
      "7:\tlearn: 0.5906781\ttotal: 36.7ms\tremaining: 880ms\n",
      "8:\tlearn: 0.5801847\ttotal: 41.5ms\tremaining: 880ms\n",
      "9:\tlearn: 0.5699095\ttotal: 46.6ms\tremaining: 886ms\n",
      "10:\tlearn: 0.5606133\ttotal: 51ms\tremaining: 876ms\n",
      "11:\tlearn: 0.5502047\ttotal: 55.5ms\tremaining: 870ms\n",
      "12:\tlearn: 0.5402383\ttotal: 60ms\tremaining: 863ms\n",
      "13:\tlearn: 0.5299129\ttotal: 65.6ms\tremaining: 872ms\n",
      "14:\tlearn: 0.5203711\ttotal: 70.6ms\tremaining: 871ms\n",
      "15:\tlearn: 0.5087655\ttotal: 75.5ms\tremaining: 869ms\n",
      "16:\tlearn: 0.4994306\ttotal: 80.3ms\tremaining: 864ms\n",
      "17:\tlearn: 0.4916544\ttotal: 86.2ms\tremaining: 871ms\n",
      "18:\tlearn: 0.4829044\ttotal: 91ms\tremaining: 867ms\n",
      "19:\tlearn: 0.4730832\ttotal: 96.2ms\tremaining: 865ms\n",
      "20:\tlearn: 0.4645104\ttotal: 101ms\tremaining: 859ms\n",
      "21:\tlearn: 0.4552211\ttotal: 106ms\tremaining: 859ms\n",
      "22:\tlearn: 0.4471946\ttotal: 111ms\tremaining: 852ms\n",
      "23:\tlearn: 0.4396360\ttotal: 116ms\tremaining: 852ms\n",
      "24:\tlearn: 0.4328201\ttotal: 121ms\tremaining: 846ms\n",
      "25:\tlearn: 0.4264169\ttotal: 126ms\tremaining: 840ms\n",
      "26:\tlearn: 0.4186298\ttotal: 130ms\tremaining: 834ms\n",
      "27:\tlearn: 0.4127212\ttotal: 135ms\tremaining: 832ms\n",
      "28:\tlearn: 0.4058854\ttotal: 140ms\tremaining: 825ms\n",
      "29:\tlearn: 0.3992605\ttotal: 145ms\tremaining: 823ms\n",
      "30:\tlearn: 0.3921401\ttotal: 151ms\tremaining: 823ms\n",
      "31:\tlearn: 0.3869264\ttotal: 156ms\tremaining: 817ms\n",
      "32:\tlearn: 0.3813580\ttotal: 160ms\tremaining: 811ms\n",
      "33:\tlearn: 0.3770421\ttotal: 166ms\tremaining: 809ms\n",
      "34:\tlearn: 0.3720740\ttotal: 171ms\tremaining: 804ms\n",
      "35:\tlearn: 0.3667750\ttotal: 176ms\tremaining: 801ms\n",
      "36:\tlearn: 0.3639197\ttotal: 180ms\tremaining: 792ms\n",
      "37:\tlearn: 0.3594905\ttotal: 185ms\tremaining: 789ms\n",
      "38:\tlearn: 0.3551419\ttotal: 190ms\tremaining: 784ms\n",
      "39:\tlearn: 0.3502572\ttotal: 196ms\tremaining: 782ms\n",
      "40:\tlearn: 0.3464353\ttotal: 201ms\tremaining: 779ms\n",
      "41:\tlearn: 0.3417799\ttotal: 207ms\tremaining: 778ms\n",
      "42:\tlearn: 0.3378560\ttotal: 212ms\tremaining: 773ms\n",
      "43:\tlearn: 0.3318973\ttotal: 218ms\tremaining: 772ms\n",
      "44:\tlearn: 0.3277203\ttotal: 223ms\tremaining: 767ms\n",
      "45:\tlearn: 0.3228241\ttotal: 228ms\tremaining: 762ms\n",
      "46:\tlearn: 0.3205612\ttotal: 232ms\tremaining: 756ms\n",
      "47:\tlearn: 0.3172023\ttotal: 238ms\tremaining: 754ms\n",
      "48:\tlearn: 0.3125236\ttotal: 243ms\tremaining: 749ms\n",
      "49:\tlearn: 0.3086880\ttotal: 248ms\tremaining: 745ms\n",
      "50:\tlearn: 0.3050008\ttotal: 253ms\tremaining: 740ms\n",
      "51:\tlearn: 0.3006019\ttotal: 259ms\tremaining: 737ms\n",
      "52:\tlearn: 0.2964880\ttotal: 263ms\tremaining: 729ms\n",
      "53:\tlearn: 0.2934379\ttotal: 268ms\tremaining: 724ms\n",
      "54:\tlearn: 0.2908472\ttotal: 273ms\tremaining: 720ms\n",
      "55:\tlearn: 0.2876930\ttotal: 279ms\tremaining: 718ms\n",
      "56:\tlearn: 0.2843959\ttotal: 284ms\tremaining: 712ms\n",
      "57:\tlearn: 0.2813914\ttotal: 289ms\tremaining: 708ms\n",
      "58:\tlearn: 0.2785801\ttotal: 294ms\tremaining: 703ms\n",
      "59:\tlearn: 0.2761924\ttotal: 299ms\tremaining: 697ms\n",
      "60:\tlearn: 0.2737007\ttotal: 304ms\tremaining: 692ms\n",
      "61:\tlearn: 0.2703728\ttotal: 309ms\tremaining: 689ms\n",
      "62:\tlearn: 0.2675595\ttotal: 314ms\tremaining: 683ms\n",
      "63:\tlearn: 0.2635612\ttotal: 319ms\tremaining: 678ms\n",
      "64:\tlearn: 0.2607090\ttotal: 324ms\tremaining: 673ms\n",
      "65:\tlearn: 0.2573378\ttotal: 329ms\tremaining: 667ms\n",
      "66:\tlearn: 0.2558504\ttotal: 333ms\tremaining: 662ms\n",
      "67:\tlearn: 0.2537842\ttotal: 339ms\tremaining: 657ms\n",
      "68:\tlearn: 0.2518117\ttotal: 343ms\tremaining: 652ms\n",
      "69:\tlearn: 0.2486377\ttotal: 349ms\tremaining: 648ms\n",
      "70:\tlearn: 0.2466293\ttotal: 354ms\tremaining: 642ms\n",
      "71:\tlearn: 0.2451280\ttotal: 359ms\tremaining: 638ms\n",
      "72:\tlearn: 0.2436533\ttotal: 364ms\tremaining: 633ms\n",
      "73:\tlearn: 0.2420182\ttotal: 369ms\tremaining: 629ms\n",
      "74:\tlearn: 0.2401689\ttotal: 374ms\tremaining: 624ms\n",
      "75:\tlearn: 0.2374096\ttotal: 380ms\tremaining: 620ms\n",
      "76:\tlearn: 0.2349675\ttotal: 385ms\tremaining: 615ms\n",
      "77:\tlearn: 0.2327538\ttotal: 390ms\tremaining: 610ms\n",
      "78:\tlearn: 0.2311748\ttotal: 395ms\tremaining: 605ms\n",
      "79:\tlearn: 0.2303260\ttotal: 399ms\tremaining: 598ms\n",
      "80:\tlearn: 0.2278584\ttotal: 403ms\tremaining: 593ms\n",
      "81:\tlearn: 0.2269575\ttotal: 406ms\tremaining: 585ms\n",
      "82:\tlearn: 0.2246760\ttotal: 411ms\tremaining: 579ms\n",
      "83:\tlearn: 0.2230745\ttotal: 417ms\tremaining: 576ms\n",
      "84:\tlearn: 0.2218190\ttotal: 422ms\tremaining: 571ms\n",
      "85:\tlearn: 0.2193132\ttotal: 427ms\tremaining: 566ms\n",
      "86:\tlearn: 0.2174892\ttotal: 432ms\tremaining: 561ms\n",
      "87:\tlearn: 0.2162541\ttotal: 437ms\tremaining: 556ms\n",
      "88:\tlearn: 0.2147913\ttotal: 442ms\tremaining: 551ms\n",
      "89:\tlearn: 0.2128313\ttotal: 447ms\tremaining: 547ms\n",
      "90:\tlearn: 0.2121094\ttotal: 452ms\tremaining: 542ms\n",
      "91:\tlearn: 0.2109777\ttotal: 457ms\tremaining: 537ms\n",
      "92:\tlearn: 0.2099673\ttotal: 462ms\tremaining: 531ms\n",
      "93:\tlearn: 0.2083490\ttotal: 466ms\tremaining: 526ms\n",
      "94:\tlearn: 0.2073270\ttotal: 472ms\tremaining: 522ms\n",
      "95:\tlearn: 0.2061666\ttotal: 477ms\tremaining: 517ms\n",
      "96:\tlearn: 0.2050146\ttotal: 482ms\tremaining: 512ms\n",
      "97:\tlearn: 0.2038973\ttotal: 487ms\tremaining: 507ms\n",
      "98:\tlearn: 0.2028299\ttotal: 492ms\tremaining: 502ms\n",
      "99:\tlearn: 0.2015336\ttotal: 498ms\tremaining: 498ms\n",
      "100:\tlearn: 0.1999805\ttotal: 502ms\tremaining: 492ms\n",
      "101:\tlearn: 0.1987551\ttotal: 508ms\tremaining: 488ms\n",
      "102:\tlearn: 0.1976203\ttotal: 512ms\tremaining: 482ms\n",
      "103:\tlearn: 0.1966296\ttotal: 518ms\tremaining: 478ms\n",
      "104:\tlearn: 0.1947919\ttotal: 522ms\tremaining: 473ms\n",
      "105:\tlearn: 0.1931485\ttotal: 528ms\tremaining: 468ms\n",
      "106:\tlearn: 0.1924178\ttotal: 533ms\tremaining: 463ms\n",
      "107:\tlearn: 0.1910545\ttotal: 539ms\tremaining: 459ms\n",
      "108:\tlearn: 0.1897339\ttotal: 543ms\tremaining: 454ms\n",
      "109:\tlearn: 0.1880887\ttotal: 549ms\tremaining: 449ms\n",
      "110:\tlearn: 0.1869468\ttotal: 553ms\tremaining: 444ms\n",
      "111:\tlearn: 0.1857154\ttotal: 558ms\tremaining: 438ms\n",
      "112:\tlearn: 0.1851077\ttotal: 563ms\tremaining: 433ms\n",
      "113:\tlearn: 0.1843689\ttotal: 567ms\tremaining: 428ms\n",
      "114:\tlearn: 0.1839613\ttotal: 571ms\tremaining: 422ms\n",
      "115:\tlearn: 0.1835316\ttotal: 574ms\tremaining: 416ms\n",
      "116:\tlearn: 0.1822476\ttotal: 578ms\tremaining: 410ms\n",
      "117:\tlearn: 0.1814914\ttotal: 583ms\tremaining: 405ms\n",
      "118:\tlearn: 0.1807116\ttotal: 588ms\tremaining: 400ms\n",
      "119:\tlearn: 0.1795947\ttotal: 593ms\tremaining: 395ms\n",
      "120:\tlearn: 0.1787029\ttotal: 598ms\tremaining: 390ms\n",
      "121:\tlearn: 0.1778527\ttotal: 603ms\tremaining: 385ms\n",
      "122:\tlearn: 0.1765790\ttotal: 608ms\tremaining: 380ms\n",
      "123:\tlearn: 0.1758395\ttotal: 613ms\tremaining: 376ms\n",
      "124:\tlearn: 0.1748033\ttotal: 618ms\tremaining: 371ms\n",
      "125:\tlearn: 0.1737065\ttotal: 623ms\tremaining: 366ms\n",
      "126:\tlearn: 0.1727844\ttotal: 627ms\tremaining: 361ms\n",
      "127:\tlearn: 0.1715500\ttotal: 633ms\tremaining: 356ms\n",
      "128:\tlearn: 0.1705123\ttotal: 637ms\tremaining: 351ms\n",
      "129:\tlearn: 0.1699247\ttotal: 643ms\tremaining: 346ms\n",
      "130:\tlearn: 0.1686654\ttotal: 648ms\tremaining: 341ms\n",
      "131:\tlearn: 0.1674184\ttotal: 654ms\tremaining: 337ms\n",
      "132:\tlearn: 0.1663659\ttotal: 658ms\tremaining: 332ms\n",
      "133:\tlearn: 0.1651920\ttotal: 664ms\tremaining: 327ms\n",
      "134:\tlearn: 0.1643149\ttotal: 669ms\tremaining: 322ms\n",
      "135:\tlearn: 0.1634933\ttotal: 674ms\tremaining: 317ms\n",
      "136:\tlearn: 0.1624090\ttotal: 679ms\tremaining: 312ms\n",
      "137:\tlearn: 0.1615309\ttotal: 684ms\tremaining: 307ms\n",
      "138:\tlearn: 0.1605065\ttotal: 689ms\tremaining: 303ms\n",
      "139:\tlearn: 0.1599883\ttotal: 695ms\tremaining: 298ms\n",
      "140:\tlearn: 0.1588024\ttotal: 699ms\tremaining: 293ms\n",
      "141:\tlearn: 0.1582436\ttotal: 705ms\tremaining: 288ms\n",
      "142:\tlearn: 0.1574146\ttotal: 709ms\tremaining: 283ms\n",
      "143:\tlearn: 0.1567414\ttotal: 714ms\tremaining: 278ms\n",
      "144:\tlearn: 0.1561497\ttotal: 719ms\tremaining: 273ms\n",
      "145:\tlearn: 0.1557449\ttotal: 724ms\tremaining: 268ms\n",
      "146:\tlearn: 0.1550383\ttotal: 729ms\tremaining: 263ms\n",
      "147:\tlearn: 0.1542182\ttotal: 734ms\tremaining: 258ms\n",
      "148:\tlearn: 0.1532443\ttotal: 739ms\tremaining: 253ms\n",
      "149:\tlearn: 0.1527661\ttotal: 745ms\tremaining: 248ms\n",
      "150:\tlearn: 0.1523262\ttotal: 750ms\tremaining: 243ms\n",
      "151:\tlearn: 0.1517968\ttotal: 755ms\tremaining: 239ms\n",
      "152:\tlearn: 0.1512109\ttotal: 760ms\tremaining: 234ms\n",
      "153:\tlearn: 0.1505562\ttotal: 765ms\tremaining: 229ms\n",
      "154:\tlearn: 0.1498268\ttotal: 770ms\tremaining: 224ms\n",
      "155:\tlearn: 0.1493706\ttotal: 775ms\tremaining: 219ms\n",
      "156:\tlearn: 0.1488622\ttotal: 780ms\tremaining: 214ms\n",
      "157:\tlearn: 0.1484930\ttotal: 785ms\tremaining: 209ms\n",
      "158:\tlearn: 0.1480376\ttotal: 790ms\tremaining: 204ms\n",
      "159:\tlearn: 0.1476466\ttotal: 795ms\tremaining: 199ms\n",
      "160:\tlearn: 0.1468891\ttotal: 801ms\tremaining: 194ms\n",
      "161:\tlearn: 0.1463283\ttotal: 805ms\tremaining: 189ms\n",
      "162:\tlearn: 0.1455577\ttotal: 810ms\tremaining: 184ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163:\tlearn: 0.1450634\ttotal: 815ms\tremaining: 179ms\n",
      "164:\tlearn: 0.1442950\ttotal: 820ms\tremaining: 174ms\n",
      "165:\tlearn: 0.1436467\ttotal: 826ms\tremaining: 169ms\n",
      "166:\tlearn: 0.1430075\ttotal: 830ms\tremaining: 164ms\n",
      "167:\tlearn: 0.1422872\ttotal: 836ms\tremaining: 159ms\n",
      "168:\tlearn: 0.1419054\ttotal: 841ms\tremaining: 154ms\n",
      "169:\tlearn: 0.1414598\ttotal: 846ms\tremaining: 149ms\n",
      "170:\tlearn: 0.1408550\ttotal: 851ms\tremaining: 144ms\n",
      "171:\tlearn: 0.1404817\ttotal: 857ms\tremaining: 139ms\n",
      "172:\tlearn: 0.1399947\ttotal: 862ms\tremaining: 135ms\n",
      "173:\tlearn: 0.1393403\ttotal: 868ms\tremaining: 130ms\n",
      "174:\tlearn: 0.1387502\ttotal: 872ms\tremaining: 125ms\n",
      "175:\tlearn: 0.1379535\ttotal: 878ms\tremaining: 120ms\n",
      "176:\tlearn: 0.1374893\ttotal: 882ms\tremaining: 115ms\n",
      "177:\tlearn: 0.1368322\ttotal: 887ms\tremaining: 110ms\n",
      "178:\tlearn: 0.1361965\ttotal: 893ms\tremaining: 105ms\n",
      "179:\tlearn: 0.1357426\ttotal: 898ms\tremaining: 99.7ms\n",
      "180:\tlearn: 0.1353827\ttotal: 902ms\tremaining: 94.7ms\n",
      "181:\tlearn: 0.1348580\ttotal: 908ms\tremaining: 89.8ms\n",
      "182:\tlearn: 0.1345759\ttotal: 912ms\tremaining: 84.8ms\n",
      "183:\tlearn: 0.1342848\ttotal: 918ms\tremaining: 79.8ms\n",
      "184:\tlearn: 0.1337755\ttotal: 923ms\tremaining: 74.8ms\n",
      "185:\tlearn: 0.1332722\ttotal: 928ms\tremaining: 69.9ms\n",
      "186:\tlearn: 0.1329645\ttotal: 933ms\tremaining: 64.9ms\n",
      "187:\tlearn: 0.1326703\ttotal: 938ms\tremaining: 59.9ms\n",
      "188:\tlearn: 0.1322238\ttotal: 943ms\tremaining: 54.9ms\n",
      "189:\tlearn: 0.1317731\ttotal: 948ms\tremaining: 49.9ms\n",
      "190:\tlearn: 0.1312888\ttotal: 953ms\tremaining: 44.9ms\n",
      "191:\tlearn: 0.1310310\ttotal: 959ms\tremaining: 39.9ms\n",
      "192:\tlearn: 0.1306710\ttotal: 963ms\tremaining: 34.9ms\n",
      "193:\tlearn: 0.1302740\ttotal: 969ms\tremaining: 30ms\n",
      "194:\tlearn: 0.1300151\ttotal: 974ms\tremaining: 25ms\n",
      "195:\tlearn: 0.1295868\ttotal: 979ms\tremaining: 20ms\n",
      "196:\tlearn: 0.1291579\ttotal: 984ms\tremaining: 15ms\n",
      "197:\tlearn: 0.1287243\ttotal: 989ms\tremaining: 9.99ms\n",
      "198:\tlearn: 0.1284241\ttotal: 995ms\tremaining: 5ms\n",
      "199:\tlearn: 0.1281745\ttotal: 1s\tremaining: 0us\n",
      "0:\tlearn: 0.6250705\ttotal: 4.43ms\tremaining: 882ms\n",
      "1:\tlearn: 0.5689746\ttotal: 9.79ms\tremaining: 969ms\n",
      "2:\tlearn: 0.5173111\ttotal: 14.3ms\tremaining: 937ms\n",
      "3:\tlearn: 0.4839438\ttotal: 17.6ms\tremaining: 863ms\n",
      "4:\tlearn: 0.4605108\ttotal: 20.8ms\tremaining: 811ms\n",
      "5:\tlearn: 0.4268715\ttotal: 25.1ms\tremaining: 810ms\n",
      "6:\tlearn: 0.3886061\ttotal: 29.4ms\tremaining: 810ms\n",
      "7:\tlearn: 0.3584622\ttotal: 34ms\tremaining: 816ms\n",
      "8:\tlearn: 0.3324899\ttotal: 40ms\tremaining: 848ms\n",
      "9:\tlearn: 0.3095059\ttotal: 44.5ms\tremaining: 845ms\n",
      "10:\tlearn: 0.2913028\ttotal: 50.4ms\tremaining: 865ms\n",
      "11:\tlearn: 0.2754278\ttotal: 55.2ms\tremaining: 864ms\n",
      "12:\tlearn: 0.2582373\ttotal: 60.5ms\tremaining: 871ms\n",
      "13:\tlearn: 0.2475525\ttotal: 64.9ms\tremaining: 863ms\n",
      "14:\tlearn: 0.2318810\ttotal: 71ms\tremaining: 876ms\n",
      "15:\tlearn: 0.2250340\ttotal: 76.1ms\tremaining: 875ms\n",
      "16:\tlearn: 0.2187825\ttotal: 81.9ms\tremaining: 881ms\n",
      "17:\tlearn: 0.2116678\ttotal: 87.2ms\tremaining: 881ms\n",
      "18:\tlearn: 0.2037600\ttotal: 92.1ms\tremaining: 877ms\n",
      "19:\tlearn: 0.1978205\ttotal: 97.1ms\tremaining: 874ms\n",
      "20:\tlearn: 0.1922061\ttotal: 103ms\tremaining: 875ms\n",
      "21:\tlearn: 0.1845653\ttotal: 108ms\tremaining: 871ms\n",
      "22:\tlearn: 0.1787151\ttotal: 113ms\tremaining: 871ms\n",
      "23:\tlearn: 0.1744279\ttotal: 118ms\tremaining: 865ms\n",
      "24:\tlearn: 0.1701208\ttotal: 122ms\tremaining: 857ms\n",
      "25:\tlearn: 0.1644283\ttotal: 127ms\tremaining: 852ms\n",
      "26:\tlearn: 0.1614765\ttotal: 133ms\tremaining: 851ms\n",
      "27:\tlearn: 0.1554386\ttotal: 138ms\tremaining: 848ms\n",
      "28:\tlearn: 0.1525875\ttotal: 143ms\tremaining: 846ms\n",
      "29:\tlearn: 0.1487044\ttotal: 148ms\tremaining: 840ms\n",
      "30:\tlearn: 0.1452860\ttotal: 154ms\tremaining: 838ms\n",
      "31:\tlearn: 0.1407154\ttotal: 158ms\tremaining: 831ms\n",
      "32:\tlearn: 0.1376776\ttotal: 164ms\tremaining: 829ms\n",
      "33:\tlearn: 0.1358360\ttotal: 169ms\tremaining: 824ms\n",
      "34:\tlearn: 0.1334955\ttotal: 174ms\tremaining: 822ms\n",
      "35:\tlearn: 0.1313568\ttotal: 179ms\tremaining: 814ms\n",
      "36:\tlearn: 0.1298975\ttotal: 184ms\tremaining: 812ms\n",
      "37:\tlearn: 0.1268370\ttotal: 189ms\tremaining: 807ms\n",
      "38:\tlearn: 0.1232321\ttotal: 195ms\tremaining: 803ms\n",
      "39:\tlearn: 0.1214674\ttotal: 199ms\tremaining: 796ms\n",
      "40:\tlearn: 0.1193121\ttotal: 205ms\tremaining: 794ms\n",
      "41:\tlearn: 0.1177703\ttotal: 209ms\tremaining: 787ms\n",
      "42:\tlearn: 0.1163841\ttotal: 214ms\tremaining: 782ms\n",
      "43:\tlearn: 0.1143108\ttotal: 219ms\tremaining: 775ms\n",
      "44:\tlearn: 0.1130692\ttotal: 225ms\tremaining: 774ms\n",
      "45:\tlearn: 0.1120311\ttotal: 229ms\tremaining: 768ms\n",
      "46:\tlearn: 0.1107091\ttotal: 234ms\tremaining: 763ms\n",
      "47:\tlearn: 0.1091328\ttotal: 239ms\tremaining: 758ms\n",
      "48:\tlearn: 0.1072516\ttotal: 244ms\tremaining: 753ms\n",
      "49:\tlearn: 0.1056400\ttotal: 249ms\tremaining: 748ms\n",
      "50:\tlearn: 0.1040969\ttotal: 255ms\tremaining: 745ms\n",
      "51:\tlearn: 0.1033505\ttotal: 260ms\tremaining: 739ms\n",
      "52:\tlearn: 0.1026228\ttotal: 265ms\tremaining: 736ms\n",
      "53:\tlearn: 0.1006046\ttotal: 271ms\tremaining: 732ms\n",
      "54:\tlearn: 0.0999598\ttotal: 276ms\tremaining: 726ms\n",
      "55:\tlearn: 0.0989345\ttotal: 281ms\tremaining: 722ms\n",
      "56:\tlearn: 0.0976337\ttotal: 286ms\tremaining: 717ms\n",
      "57:\tlearn: 0.0970657\ttotal: 290ms\tremaining: 709ms\n",
      "58:\tlearn: 0.0960780\ttotal: 295ms\tremaining: 704ms\n",
      "59:\tlearn: 0.0948821\ttotal: 300ms\tremaining: 700ms\n",
      "60:\tlearn: 0.0932768\ttotal: 304ms\tremaining: 694ms\n",
      "61:\tlearn: 0.0921403\ttotal: 309ms\tremaining: 688ms\n",
      "62:\tlearn: 0.0910191\ttotal: 314ms\tremaining: 683ms\n",
      "63:\tlearn: 0.0907704\ttotal: 318ms\tremaining: 675ms\n",
      "64:\tlearn: 0.0896708\ttotal: 322ms\tremaining: 669ms\n",
      "65:\tlearn: 0.0883877\ttotal: 327ms\tremaining: 665ms\n",
      "66:\tlearn: 0.0876779\ttotal: 332ms\tremaining: 659ms\n",
      "67:\tlearn: 0.0865162\ttotal: 337ms\tremaining: 654ms\n",
      "68:\tlearn: 0.0856801\ttotal: 342ms\tremaining: 649ms\n",
      "69:\tlearn: 0.0851300\ttotal: 347ms\tremaining: 645ms\n",
      "70:\tlearn: 0.0843909\ttotal: 352ms\tremaining: 640ms\n",
      "71:\tlearn: 0.0839179\ttotal: 358ms\tremaining: 636ms\n",
      "72:\tlearn: 0.0829470\ttotal: 363ms\tremaining: 631ms\n",
      "73:\tlearn: 0.0826416\ttotal: 368ms\tremaining: 626ms\n",
      "74:\tlearn: 0.0817356\ttotal: 372ms\tremaining: 621ms\n",
      "75:\tlearn: 0.0808218\ttotal: 377ms\tremaining: 616ms\n",
      "76:\tlearn: 0.0800702\ttotal: 382ms\tremaining: 611ms\n",
      "77:\tlearn: 0.0795866\ttotal: 388ms\tremaining: 606ms\n",
      "78:\tlearn: 0.0789167\ttotal: 392ms\tremaining: 600ms\n",
      "79:\tlearn: 0.0784852\ttotal: 397ms\tremaining: 596ms\n",
      "80:\tlearn: 0.0779945\ttotal: 402ms\tremaining: 590ms\n",
      "81:\tlearn: 0.0773606\ttotal: 408ms\tremaining: 586ms\n",
      "82:\tlearn: 0.0771859\ttotal: 411ms\tremaining: 579ms\n",
      "83:\tlearn: 0.0766287\ttotal: 416ms\tremaining: 575ms\n",
      "84:\tlearn: 0.0762653\ttotal: 422ms\tremaining: 571ms\n",
      "85:\tlearn: 0.0755328\ttotal: 427ms\tremaining: 565ms\n",
      "86:\tlearn: 0.0751481\ttotal: 429ms\tremaining: 557ms\n",
      "87:\tlearn: 0.0744002\ttotal: 434ms\tremaining: 552ms\n",
      "88:\tlearn: 0.0735664\ttotal: 439ms\tremaining: 548ms\n",
      "89:\tlearn: 0.0732193\ttotal: 444ms\tremaining: 543ms\n",
      "90:\tlearn: 0.0726189\ttotal: 449ms\tremaining: 538ms\n",
      "91:\tlearn: 0.0722429\ttotal: 454ms\tremaining: 533ms\n",
      "92:\tlearn: 0.0718995\ttotal: 459ms\tremaining: 528ms\n",
      "93:\tlearn: 0.0713130\ttotal: 464ms\tremaining: 523ms\n",
      "94:\tlearn: 0.0709403\ttotal: 469ms\tremaining: 518ms\n",
      "95:\tlearn: 0.0704218\ttotal: 474ms\tremaining: 514ms\n",
      "96:\tlearn: 0.0700367\ttotal: 479ms\tremaining: 509ms\n",
      "97:\tlearn: 0.0696744\ttotal: 485ms\tremaining: 504ms\n",
      "98:\tlearn: 0.0692616\ttotal: 490ms\tremaining: 500ms\n",
      "99:\tlearn: 0.0687798\ttotal: 494ms\tremaining: 494ms\n",
      "100:\tlearn: 0.0684254\ttotal: 499ms\tremaining: 489ms\n",
      "101:\tlearn: 0.0681535\ttotal: 504ms\tremaining: 484ms\n",
      "102:\tlearn: 0.0673227\ttotal: 509ms\tremaining: 479ms\n",
      "103:\tlearn: 0.0667994\ttotal: 514ms\tremaining: 474ms\n",
      "104:\tlearn: 0.0663635\ttotal: 518ms\tremaining: 469ms\n",
      "105:\tlearn: 0.0657720\ttotal: 522ms\tremaining: 463ms\n",
      "106:\tlearn: 0.0653795\ttotal: 526ms\tremaining: 457ms\n",
      "107:\tlearn: 0.0649439\ttotal: 531ms\tremaining: 452ms\n",
      "108:\tlearn: 0.0642857\ttotal: 537ms\tremaining: 448ms\n",
      "109:\tlearn: 0.0637027\ttotal: 541ms\tremaining: 443ms\n",
      "110:\tlearn: 0.0631553\ttotal: 547ms\tremaining: 438ms\n",
      "111:\tlearn: 0.0627585\ttotal: 552ms\tremaining: 433ms\n",
      "112:\tlearn: 0.0622044\ttotal: 557ms\tremaining: 429ms\n",
      "113:\tlearn: 0.0618694\ttotal: 562ms\tremaining: 424ms\n",
      "114:\tlearn: 0.0615443\ttotal: 566ms\tremaining: 419ms\n",
      "115:\tlearn: 0.0611741\ttotal: 571ms\tremaining: 413ms\n",
      "116:\tlearn: 0.0610094\ttotal: 575ms\tremaining: 408ms\n",
      "117:\tlearn: 0.0607693\ttotal: 581ms\tremaining: 404ms\n",
      "118:\tlearn: 0.0604489\ttotal: 586ms\tremaining: 399ms\n",
      "119:\tlearn: 0.0600328\ttotal: 591ms\tremaining: 394ms\n",
      "120:\tlearn: 0.0595879\ttotal: 596ms\tremaining: 389ms\n",
      "121:\tlearn: 0.0592566\ttotal: 601ms\tremaining: 384ms\n",
      "122:\tlearn: 0.0586662\ttotal: 606ms\tremaining: 380ms\n",
      "123:\tlearn: 0.0582889\ttotal: 611ms\tremaining: 374ms\n",
      "124:\tlearn: 0.0582288\ttotal: 614ms\tremaining: 369ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125:\tlearn: 0.0581390\ttotal: 618ms\tremaining: 363ms\n",
      "126:\tlearn: 0.0579214\ttotal: 624ms\tremaining: 359ms\n",
      "127:\tlearn: 0.0573475\ttotal: 629ms\tremaining: 354ms\n",
      "128:\tlearn: 0.0570319\ttotal: 634ms\tremaining: 349ms\n",
      "129:\tlearn: 0.0566564\ttotal: 638ms\tremaining: 344ms\n",
      "130:\tlearn: 0.0561228\ttotal: 643ms\tremaining: 339ms\n",
      "131:\tlearn: 0.0560898\ttotal: 646ms\tremaining: 333ms\n",
      "132:\tlearn: 0.0557988\ttotal: 651ms\tremaining: 328ms\n",
      "133:\tlearn: 0.0552307\ttotal: 656ms\tremaining: 323ms\n",
      "134:\tlearn: 0.0548710\ttotal: 660ms\tremaining: 318ms\n",
      "135:\tlearn: 0.0545801\ttotal: 665ms\tremaining: 313ms\n",
      "136:\tlearn: 0.0541278\ttotal: 670ms\tremaining: 308ms\n",
      "137:\tlearn: 0.0540036\ttotal: 676ms\tremaining: 304ms\n",
      "138:\tlearn: 0.0537057\ttotal: 680ms\tremaining: 298ms\n",
      "139:\tlearn: 0.0535005\ttotal: 685ms\tremaining: 293ms\n",
      "140:\tlearn: 0.0531684\ttotal: 690ms\tremaining: 289ms\n",
      "141:\tlearn: 0.0530360\ttotal: 695ms\tremaining: 284ms\n",
      "142:\tlearn: 0.0524755\ttotal: 700ms\tremaining: 279ms\n",
      "143:\tlearn: 0.0521032\ttotal: 706ms\tremaining: 274ms\n",
      "144:\tlearn: 0.0516413\ttotal: 711ms\tremaining: 270ms\n",
      "145:\tlearn: 0.0515515\ttotal: 717ms\tremaining: 265ms\n",
      "146:\tlearn: 0.0511741\ttotal: 721ms\tremaining: 260ms\n",
      "147:\tlearn: 0.0508055\ttotal: 727ms\tremaining: 255ms\n",
      "148:\tlearn: 0.0504804\ttotal: 731ms\tremaining: 250ms\n",
      "149:\tlearn: 0.0503735\ttotal: 737ms\tremaining: 246ms\n",
      "150:\tlearn: 0.0501637\ttotal: 741ms\tremaining: 241ms\n",
      "151:\tlearn: 0.0497522\ttotal: 746ms\tremaining: 236ms\n",
      "152:\tlearn: 0.0492598\ttotal: 751ms\tremaining: 231ms\n",
      "153:\tlearn: 0.0490336\ttotal: 757ms\tremaining: 226ms\n",
      "154:\tlearn: 0.0486303\ttotal: 761ms\tremaining: 221ms\n",
      "155:\tlearn: 0.0483024\ttotal: 767ms\tremaining: 216ms\n",
      "156:\tlearn: 0.0479818\ttotal: 772ms\tremaining: 211ms\n",
      "157:\tlearn: 0.0478199\ttotal: 777ms\tremaining: 206ms\n",
      "158:\tlearn: 0.0473925\ttotal: 781ms\tremaining: 201ms\n",
      "159:\tlearn: 0.0469538\ttotal: 787ms\tremaining: 197ms\n",
      "160:\tlearn: 0.0469233\ttotal: 790ms\tremaining: 191ms\n",
      "161:\tlearn: 0.0466986\ttotal: 794ms\tremaining: 186ms\n",
      "162:\tlearn: 0.0462645\ttotal: 799ms\tremaining: 181ms\n",
      "163:\tlearn: 0.0458573\ttotal: 804ms\tremaining: 176ms\n",
      "164:\tlearn: 0.0455534\ttotal: 809ms\tremaining: 172ms\n",
      "165:\tlearn: 0.0452782\ttotal: 814ms\tremaining: 167ms\n",
      "166:\tlearn: 0.0451080\ttotal: 819ms\tremaining: 162ms\n",
      "167:\tlearn: 0.0447537\ttotal: 824ms\tremaining: 157ms\n",
      "168:\tlearn: 0.0444292\ttotal: 829ms\tremaining: 152ms\n",
      "169:\tlearn: 0.0440131\ttotal: 834ms\tremaining: 147ms\n",
      "170:\tlearn: 0.0438847\ttotal: 839ms\tremaining: 142ms\n",
      "171:\tlearn: 0.0435423\ttotal: 845ms\tremaining: 138ms\n",
      "172:\tlearn: 0.0431490\ttotal: 850ms\tremaining: 133ms\n",
      "173:\tlearn: 0.0427654\ttotal: 855ms\tremaining: 128ms\n",
      "174:\tlearn: 0.0427056\ttotal: 860ms\tremaining: 123ms\n",
      "175:\tlearn: 0.0424554\ttotal: 864ms\tremaining: 118ms\n",
      "176:\tlearn: 0.0422409\ttotal: 869ms\tremaining: 113ms\n",
      "177:\tlearn: 0.0419703\ttotal: 873ms\tremaining: 108ms\n",
      "178:\tlearn: 0.0417477\ttotal: 880ms\tremaining: 103ms\n",
      "179:\tlearn: 0.0414977\ttotal: 885ms\tremaining: 98.3ms\n",
      "180:\tlearn: 0.0411119\ttotal: 892ms\tremaining: 93.6ms\n",
      "181:\tlearn: 0.0408642\ttotal: 896ms\tremaining: 88.6ms\n",
      "182:\tlearn: 0.0406324\ttotal: 902ms\tremaining: 83.7ms\n",
      "183:\tlearn: 0.0404178\ttotal: 906ms\tremaining: 78.8ms\n",
      "184:\tlearn: 0.0402365\ttotal: 911ms\tremaining: 73.9ms\n",
      "185:\tlearn: 0.0400463\ttotal: 916ms\tremaining: 68.9ms\n",
      "186:\tlearn: 0.0398316\ttotal: 920ms\tremaining: 64ms\n",
      "187:\tlearn: 0.0396865\ttotal: 926ms\tremaining: 59.1ms\n",
      "188:\tlearn: 0.0392886\ttotal: 931ms\tremaining: 54.2ms\n",
      "189:\tlearn: 0.0390135\ttotal: 936ms\tremaining: 49.3ms\n",
      "190:\tlearn: 0.0388584\ttotal: 942ms\tremaining: 44.4ms\n",
      "191:\tlearn: 0.0386869\ttotal: 947ms\tremaining: 39.5ms\n",
      "192:\tlearn: 0.0384492\ttotal: 953ms\tremaining: 34.6ms\n",
      "193:\tlearn: 0.0382358\ttotal: 958ms\tremaining: 29.6ms\n",
      "194:\tlearn: 0.0380850\ttotal: 963ms\tremaining: 24.7ms\n",
      "195:\tlearn: 0.0380462\ttotal: 968ms\tremaining: 19.7ms\n",
      "196:\tlearn: 0.0379441\ttotal: 973ms\tremaining: 14.8ms\n",
      "197:\tlearn: 0.0377000\ttotal: 978ms\tremaining: 9.88ms\n",
      "198:\tlearn: 0.0373924\ttotal: 984ms\tremaining: 4.94ms\n",
      "199:\tlearn: 0.0373160\ttotal: 989ms\tremaining: 0us\n",
      "0:\tlearn: 0.6309338\ttotal: 4.14ms\tremaining: 825ms\n",
      "1:\tlearn: 0.5741373\ttotal: 8.9ms\tremaining: 881ms\n",
      "2:\tlearn: 0.5224918\ttotal: 13ms\tremaining: 857ms\n",
      "3:\tlearn: 0.4810269\ttotal: 18.5ms\tremaining: 909ms\n",
      "4:\tlearn: 0.4402782\ttotal: 23.3ms\tremaining: 909ms\n",
      "5:\tlearn: 0.4111011\ttotal: 28ms\tremaining: 904ms\n",
      "6:\tlearn: 0.3758876\ttotal: 32.6ms\tremaining: 899ms\n",
      "7:\tlearn: 0.3441509\ttotal: 37.8ms\tremaining: 908ms\n",
      "8:\tlearn: 0.3204883\ttotal: 42.7ms\tremaining: 906ms\n",
      "9:\tlearn: 0.2960222\ttotal: 47.9ms\tremaining: 910ms\n",
      "10:\tlearn: 0.2778647\ttotal: 53.1ms\tremaining: 912ms\n",
      "11:\tlearn: 0.2593130\ttotal: 59ms\tremaining: 924ms\n",
      "12:\tlearn: 0.2469031\ttotal: 63.8ms\tremaining: 918ms\n",
      "13:\tlearn: 0.2382873\ttotal: 68.6ms\tremaining: 911ms\n",
      "14:\tlearn: 0.2302727\ttotal: 73.4ms\tremaining: 905ms\n",
      "15:\tlearn: 0.2219701\ttotal: 78.7ms\tremaining: 905ms\n",
      "16:\tlearn: 0.2135518\ttotal: 83.6ms\tremaining: 900ms\n",
      "17:\tlearn: 0.2072799\ttotal: 88.4ms\tremaining: 894ms\n",
      "18:\tlearn: 0.1976881\ttotal: 93.4ms\tremaining: 890ms\n",
      "19:\tlearn: 0.1896930\ttotal: 97.7ms\tremaining: 879ms\n",
      "20:\tlearn: 0.1847823\ttotal: 103ms\tremaining: 875ms\n",
      "21:\tlearn: 0.1796279\ttotal: 108ms\tremaining: 874ms\n",
      "22:\tlearn: 0.1732603\ttotal: 113ms\tremaining: 867ms\n",
      "23:\tlearn: 0.1696721\ttotal: 118ms\tremaining: 866ms\n",
      "24:\tlearn: 0.1662299\ttotal: 123ms\tremaining: 859ms\n",
      "25:\tlearn: 0.1631889\ttotal: 128ms\tremaining: 859ms\n",
      "26:\tlearn: 0.1586684\ttotal: 134ms\tremaining: 856ms\n",
      "27:\tlearn: 0.1547925\ttotal: 139ms\tremaining: 854ms\n",
      "28:\tlearn: 0.1530433\ttotal: 144ms\tremaining: 849ms\n",
      "29:\tlearn: 0.1506257\ttotal: 149ms\tremaining: 844ms\n",
      "30:\tlearn: 0.1459673\ttotal: 154ms\tremaining: 837ms\n",
      "31:\tlearn: 0.1437451\ttotal: 159ms\tremaining: 836ms\n",
      "32:\tlearn: 0.1412432\ttotal: 164ms\tremaining: 831ms\n",
      "33:\tlearn: 0.1372570\ttotal: 170ms\tremaining: 829ms\n",
      "34:\tlearn: 0.1341494\ttotal: 175ms\tremaining: 823ms\n",
      "35:\tlearn: 0.1324226\ttotal: 180ms\tremaining: 821ms\n",
      "36:\tlearn: 0.1299661\ttotal: 185ms\tremaining: 815ms\n",
      "37:\tlearn: 0.1282195\ttotal: 190ms\tremaining: 810ms\n",
      "38:\tlearn: 0.1255298\ttotal: 195ms\tremaining: 804ms\n",
      "39:\tlearn: 0.1237581\ttotal: 201ms\tremaining: 802ms\n",
      "40:\tlearn: 0.1224250\ttotal: 205ms\tremaining: 797ms\n",
      "41:\tlearn: 0.1199094\ttotal: 211ms\tremaining: 793ms\n",
      "42:\tlearn: 0.1191799\ttotal: 216ms\tremaining: 788ms\n",
      "43:\tlearn: 0.1171458\ttotal: 221ms\tremaining: 784ms\n",
      "44:\tlearn: 0.1149296\ttotal: 226ms\tremaining: 778ms\n",
      "45:\tlearn: 0.1135466\ttotal: 232ms\tremaining: 776ms\n",
      "46:\tlearn: 0.1119365\ttotal: 237ms\tremaining: 770ms\n",
      "47:\tlearn: 0.1104953\ttotal: 242ms\tremaining: 767ms\n",
      "48:\tlearn: 0.1090013\ttotal: 247ms\tremaining: 760ms\n",
      "49:\tlearn: 0.1084319\ttotal: 252ms\tremaining: 755ms\n",
      "50:\tlearn: 0.1069845\ttotal: 257ms\tremaining: 750ms\n",
      "51:\tlearn: 0.1055441\ttotal: 262ms\tremaining: 746ms\n",
      "52:\tlearn: 0.1041235\ttotal: 266ms\tremaining: 739ms\n",
      "53:\tlearn: 0.1033977\ttotal: 272ms\tremaining: 736ms\n",
      "54:\tlearn: 0.1023174\ttotal: 277ms\tremaining: 731ms\n",
      "55:\tlearn: 0.1008504\ttotal: 283ms\tremaining: 727ms\n",
      "56:\tlearn: 0.1000901\ttotal: 287ms\tremaining: 719ms\n",
      "57:\tlearn: 0.0988315\ttotal: 291ms\tremaining: 714ms\n",
      "58:\tlearn: 0.0975187\ttotal: 296ms\tremaining: 708ms\n",
      "59:\tlearn: 0.0966953\ttotal: 302ms\tremaining: 704ms\n",
      "60:\tlearn: 0.0962481\ttotal: 307ms\tremaining: 699ms\n",
      "61:\tlearn: 0.0955974\ttotal: 312ms\tremaining: 694ms\n",
      "62:\tlearn: 0.0951727\ttotal: 316ms\tremaining: 687ms\n",
      "63:\tlearn: 0.0941565\ttotal: 322ms\tremaining: 684ms\n",
      "64:\tlearn: 0.0936486\ttotal: 327ms\tremaining: 679ms\n",
      "65:\tlearn: 0.0933917\ttotal: 331ms\tremaining: 671ms\n",
      "66:\tlearn: 0.0933254\ttotal: 333ms\tremaining: 660ms\n",
      "67:\tlearn: 0.0922539\ttotal: 337ms\tremaining: 655ms\n",
      "68:\tlearn: 0.0911998\ttotal: 343ms\tremaining: 651ms\n",
      "69:\tlearn: 0.0902455\ttotal: 347ms\tremaining: 645ms\n",
      "70:\tlearn: 0.0891205\ttotal: 352ms\tremaining: 640ms\n",
      "71:\tlearn: 0.0891168\ttotal: 355ms\tremaining: 631ms\n",
      "72:\tlearn: 0.0882671\ttotal: 359ms\tremaining: 625ms\n",
      "73:\tlearn: 0.0880646\ttotal: 365ms\tremaining: 621ms\n",
      "74:\tlearn: 0.0867289\ttotal: 370ms\tremaining: 617ms\n",
      "75:\tlearn: 0.0861855\ttotal: 375ms\tremaining: 613ms\n",
      "76:\tlearn: 0.0856663\ttotal: 380ms\tremaining: 607ms\n",
      "77:\tlearn: 0.0849643\ttotal: 386ms\tremaining: 603ms\n",
      "78:\tlearn: 0.0847861\ttotal: 389ms\tremaining: 596ms\n",
      "79:\tlearn: 0.0837008\ttotal: 393ms\tremaining: 590ms\n",
      "80:\tlearn: 0.0827569\ttotal: 398ms\tremaining: 585ms\n",
      "81:\tlearn: 0.0820897\ttotal: 404ms\tremaining: 581ms\n",
      "82:\tlearn: 0.0813575\ttotal: 409ms\tremaining: 576ms\n",
      "83:\tlearn: 0.0804848\ttotal: 414ms\tremaining: 572ms\n",
      "84:\tlearn: 0.0798728\ttotal: 419ms\tremaining: 567ms\n",
      "85:\tlearn: 0.0791701\ttotal: 425ms\tremaining: 564ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86:\tlearn: 0.0785632\ttotal: 431ms\tremaining: 559ms\n",
      "87:\tlearn: 0.0779173\ttotal: 436ms\tremaining: 555ms\n",
      "88:\tlearn: 0.0773236\ttotal: 441ms\tremaining: 550ms\n",
      "89:\tlearn: 0.0773200\ttotal: 444ms\tremaining: 542ms\n",
      "90:\tlearn: 0.0765388\ttotal: 448ms\tremaining: 536ms\n",
      "91:\tlearn: 0.0760327\ttotal: 459ms\tremaining: 539ms\n",
      "92:\tlearn: 0.0760317\ttotal: 461ms\tremaining: 531ms\n",
      "93:\tlearn: 0.0753906\ttotal: 466ms\tremaining: 526ms\n",
      "94:\tlearn: 0.0746676\ttotal: 472ms\tremaining: 521ms\n",
      "95:\tlearn: 0.0746658\ttotal: 475ms\tremaining: 515ms\n",
      "96:\tlearn: 0.0741459\ttotal: 480ms\tremaining: 509ms\n",
      "97:\tlearn: 0.0740057\ttotal: 485ms\tremaining: 504ms\n",
      "98:\tlearn: 0.0735846\ttotal: 489ms\tremaining: 499ms\n",
      "99:\tlearn: 0.0735678\ttotal: 494ms\tremaining: 494ms\n",
      "100:\tlearn: 0.0734562\ttotal: 497ms\tremaining: 487ms\n",
      "101:\tlearn: 0.0733883\ttotal: 502ms\tremaining: 482ms\n",
      "102:\tlearn: 0.0731198\ttotal: 507ms\tremaining: 478ms\n",
      "103:\tlearn: 0.0728824\ttotal: 511ms\tremaining: 472ms\n",
      "104:\tlearn: 0.0728819\ttotal: 514ms\tremaining: 465ms\n",
      "105:\tlearn: 0.0723110\ttotal: 518ms\tremaining: 460ms\n",
      "106:\tlearn: 0.0720755\ttotal: 523ms\tremaining: 455ms\n",
      "107:\tlearn: 0.0720671\ttotal: 526ms\tremaining: 448ms\n",
      "108:\tlearn: 0.0713285\ttotal: 530ms\tremaining: 443ms\n",
      "109:\tlearn: 0.0705122\ttotal: 536ms\tremaining: 438ms\n",
      "110:\tlearn: 0.0699589\ttotal: 540ms\tremaining: 433ms\n",
      "111:\tlearn: 0.0699571\ttotal: 544ms\tremaining: 427ms\n",
      "112:\tlearn: 0.0694434\ttotal: 548ms\tremaining: 422ms\n",
      "113:\tlearn: 0.0689350\ttotal: 553ms\tremaining: 417ms\n",
      "114:\tlearn: 0.0686839\ttotal: 557ms\tremaining: 412ms\n",
      "115:\tlearn: 0.0683532\ttotal: 562ms\tremaining: 407ms\n",
      "116:\tlearn: 0.0676593\ttotal: 567ms\tremaining: 402ms\n",
      "117:\tlearn: 0.0673939\ttotal: 572ms\tremaining: 398ms\n",
      "118:\tlearn: 0.0667048\ttotal: 577ms\tremaining: 393ms\n",
      "119:\tlearn: 0.0666608\ttotal: 580ms\tremaining: 387ms\n",
      "120:\tlearn: 0.0666459\ttotal: 583ms\tremaining: 380ms\n",
      "121:\tlearn: 0.0659741\ttotal: 587ms\tremaining: 375ms\n",
      "122:\tlearn: 0.0657599\ttotal: 590ms\tremaining: 370ms\n",
      "123:\tlearn: 0.0657593\ttotal: 593ms\tremaining: 363ms\n",
      "124:\tlearn: 0.0655893\ttotal: 598ms\tremaining: 359ms\n",
      "125:\tlearn: 0.0648398\ttotal: 604ms\tremaining: 354ms\n",
      "126:\tlearn: 0.0643407\ttotal: 609ms\tremaining: 350ms\n",
      "127:\tlearn: 0.0643403\ttotal: 611ms\tremaining: 344ms\n",
      "128:\tlearn: 0.0638818\ttotal: 616ms\tremaining: 339ms\n",
      "129:\tlearn: 0.0634532\ttotal: 621ms\tremaining: 335ms\n",
      "130:\tlearn: 0.0631727\ttotal: 626ms\tremaining: 330ms\n",
      "131:\tlearn: 0.0624941\ttotal: 631ms\tremaining: 325ms\n",
      "132:\tlearn: 0.0622839\ttotal: 636ms\tremaining: 320ms\n",
      "133:\tlearn: 0.0622704\ttotal: 640ms\tremaining: 315ms\n",
      "134:\tlearn: 0.0621021\ttotal: 642ms\tremaining: 309ms\n",
      "135:\tlearn: 0.0619009\ttotal: 647ms\tremaining: 305ms\n",
      "136:\tlearn: 0.0615223\ttotal: 652ms\tremaining: 300ms\n",
      "137:\tlearn: 0.0609540\ttotal: 658ms\tremaining: 296ms\n",
      "138:\tlearn: 0.0607479\ttotal: 663ms\tremaining: 291ms\n",
      "139:\tlearn: 0.0602919\ttotal: 668ms\tremaining: 286ms\n",
      "140:\tlearn: 0.0597861\ttotal: 674ms\tremaining: 282ms\n",
      "141:\tlearn: 0.0597553\ttotal: 678ms\tremaining: 277ms\n",
      "142:\tlearn: 0.0595274\ttotal: 683ms\tremaining: 272ms\n",
      "143:\tlearn: 0.0591627\ttotal: 688ms\tremaining: 268ms\n",
      "144:\tlearn: 0.0588383\ttotal: 693ms\tremaining: 263ms\n",
      "145:\tlearn: 0.0588381\ttotal: 695ms\tremaining: 257ms\n",
      "146:\tlearn: 0.0584711\ttotal: 700ms\tremaining: 252ms\n",
      "147:\tlearn: 0.0580558\ttotal: 705ms\tremaining: 248ms\n",
      "148:\tlearn: 0.0578879\ttotal: 711ms\tremaining: 243ms\n",
      "149:\tlearn: 0.0576443\ttotal: 716ms\tremaining: 239ms\n",
      "150:\tlearn: 0.0572092\ttotal: 721ms\tremaining: 234ms\n",
      "151:\tlearn: 0.0572076\ttotal: 726ms\tremaining: 229ms\n",
      "152:\tlearn: 0.0572030\ttotal: 730ms\tremaining: 224ms\n",
      "153:\tlearn: 0.0567978\ttotal: 735ms\tremaining: 219ms\n",
      "154:\tlearn: 0.0564327\ttotal: 739ms\tremaining: 215ms\n",
      "155:\tlearn: 0.0561792\ttotal: 745ms\tremaining: 210ms\n",
      "156:\tlearn: 0.0558971\ttotal: 749ms\tremaining: 205ms\n",
      "157:\tlearn: 0.0553883\ttotal: 755ms\tremaining: 201ms\n",
      "158:\tlearn: 0.0552029\ttotal: 760ms\tremaining: 196ms\n",
      "159:\tlearn: 0.0549860\ttotal: 765ms\tremaining: 191ms\n",
      "160:\tlearn: 0.0547418\ttotal: 770ms\tremaining: 186ms\n",
      "161:\tlearn: 0.0544254\ttotal: 776ms\tremaining: 182ms\n",
      "162:\tlearn: 0.0541539\ttotal: 781ms\tremaining: 177ms\n",
      "163:\tlearn: 0.0538322\ttotal: 786ms\tremaining: 173ms\n",
      "164:\tlearn: 0.0534658\ttotal: 791ms\tremaining: 168ms\n",
      "165:\tlearn: 0.0533040\ttotal: 798ms\tremaining: 163ms\n",
      "166:\tlearn: 0.0530294\ttotal: 802ms\tremaining: 159ms\n",
      "167:\tlearn: 0.0527342\ttotal: 807ms\tremaining: 154ms\n",
      "168:\tlearn: 0.0527066\ttotal: 810ms\tremaining: 149ms\n",
      "169:\tlearn: 0.0524027\ttotal: 814ms\tremaining: 144ms\n",
      "170:\tlearn: 0.0521450\ttotal: 820ms\tremaining: 139ms\n",
      "171:\tlearn: 0.0518905\ttotal: 824ms\tremaining: 134ms\n",
      "172:\tlearn: 0.0516937\ttotal: 829ms\tremaining: 129ms\n",
      "173:\tlearn: 0.0512904\ttotal: 834ms\tremaining: 125ms\n",
      "174:\tlearn: 0.0509736\ttotal: 840ms\tremaining: 120ms\n",
      "175:\tlearn: 0.0507574\ttotal: 845ms\tremaining: 115ms\n",
      "176:\tlearn: 0.0504523\ttotal: 850ms\tremaining: 110ms\n",
      "177:\tlearn: 0.0501835\ttotal: 855ms\tremaining: 106ms\n",
      "178:\tlearn: 0.0499755\ttotal: 860ms\tremaining: 101ms\n",
      "179:\tlearn: 0.0496621\ttotal: 865ms\tremaining: 96.1ms\n",
      "180:\tlearn: 0.0495275\ttotal: 870ms\tremaining: 91.3ms\n",
      "181:\tlearn: 0.0489884\ttotal: 875ms\tremaining: 86.5ms\n",
      "182:\tlearn: 0.0486484\ttotal: 880ms\tremaining: 81.7ms\n",
      "183:\tlearn: 0.0482191\ttotal: 884ms\tremaining: 76.9ms\n",
      "184:\tlearn: 0.0481995\ttotal: 890ms\tremaining: 72.1ms\n",
      "185:\tlearn: 0.0481947\ttotal: 892ms\tremaining: 67.2ms\n",
      "186:\tlearn: 0.0480977\ttotal: 897ms\tremaining: 62.3ms\n",
      "187:\tlearn: 0.0476939\ttotal: 901ms\tremaining: 57.5ms\n",
      "188:\tlearn: 0.0473820\ttotal: 905ms\tremaining: 52.7ms\n",
      "189:\tlearn: 0.0470306\ttotal: 911ms\tremaining: 47.9ms\n",
      "190:\tlearn: 0.0466281\ttotal: 915ms\tremaining: 43.1ms\n",
      "191:\tlearn: 0.0466279\ttotal: 918ms\tremaining: 38.2ms\n",
      "192:\tlearn: 0.0465268\ttotal: 922ms\tremaining: 33.4ms\n",
      "193:\tlearn: 0.0462321\ttotal: 927ms\tremaining: 28.7ms\n",
      "194:\tlearn: 0.0461018\ttotal: 932ms\tremaining: 23.9ms\n",
      "195:\tlearn: 0.0457591\ttotal: 938ms\tremaining: 19.1ms\n",
      "196:\tlearn: 0.0455762\ttotal: 943ms\tremaining: 14.4ms\n",
      "197:\tlearn: 0.0454950\ttotal: 949ms\tremaining: 9.59ms\n",
      "198:\tlearn: 0.0451098\ttotal: 954ms\tremaining: 4.79ms\n",
      "199:\tlearn: 0.0447964\ttotal: 959ms\tremaining: 0us\n",
      "0:\tlearn: 0.6270642\ttotal: 4.2ms\tremaining: 836ms\n",
      "1:\tlearn: 0.5708485\ttotal: 9.26ms\tremaining: 916ms\n",
      "2:\tlearn: 0.5194128\ttotal: 13.6ms\tremaining: 892ms\n",
      "3:\tlearn: 0.4779223\ttotal: 19.3ms\tremaining: 946ms\n",
      "4:\tlearn: 0.4402619\ttotal: 23.8ms\tremaining: 927ms\n",
      "5:\tlearn: 0.4086418\ttotal: 28.8ms\tremaining: 931ms\n",
      "6:\tlearn: 0.3737086\ttotal: 33.3ms\tremaining: 919ms\n",
      "7:\tlearn: 0.3426834\ttotal: 38ms\tremaining: 911ms\n",
      "8:\tlearn: 0.3215684\ttotal: 43ms\tremaining: 912ms\n",
      "9:\tlearn: 0.2982598\ttotal: 48.5ms\tremaining: 921ms\n",
      "10:\tlearn: 0.2860368\ttotal: 53.2ms\tremaining: 915ms\n",
      "11:\tlearn: 0.2715455\ttotal: 57.9ms\tremaining: 907ms\n",
      "12:\tlearn: 0.2611370\ttotal: 63ms\tremaining: 906ms\n",
      "13:\tlearn: 0.2506002\ttotal: 69.1ms\tremaining: 919ms\n",
      "14:\tlearn: 0.2424901\ttotal: 73.9ms\tremaining: 911ms\n",
      "15:\tlearn: 0.2288665\ttotal: 79.2ms\tremaining: 911ms\n",
      "16:\tlearn: 0.2200666\ttotal: 84.3ms\tremaining: 908ms\n",
      "17:\tlearn: 0.2103349\ttotal: 90.8ms\tremaining: 918ms\n",
      "18:\tlearn: 0.1998230\ttotal: 95.7ms\tremaining: 912ms\n",
      "19:\tlearn: 0.1905817\ttotal: 100ms\tremaining: 903ms\n",
      "20:\tlearn: 0.1861239\ttotal: 105ms\tremaining: 899ms\n",
      "21:\tlearn: 0.1801236\ttotal: 111ms\tremaining: 899ms\n",
      "22:\tlearn: 0.1745040\ttotal: 116ms\tremaining: 889ms\n",
      "23:\tlearn: 0.1709646\ttotal: 120ms\tremaining: 883ms\n",
      "24:\tlearn: 0.1651451\ttotal: 125ms\tremaining: 874ms\n",
      "25:\tlearn: 0.1620257\ttotal: 131ms\tremaining: 875ms\n",
      "26:\tlearn: 0.1590059\ttotal: 135ms\tremaining: 868ms\n",
      "27:\tlearn: 0.1565899\ttotal: 142ms\tremaining: 871ms\n",
      "28:\tlearn: 0.1523939\ttotal: 147ms\tremaining: 868ms\n",
      "29:\tlearn: 0.1490144\ttotal: 153ms\tremaining: 868ms\n",
      "30:\tlearn: 0.1445173\ttotal: 158ms\tremaining: 861ms\n",
      "31:\tlearn: 0.1414270\ttotal: 163ms\tremaining: 855ms\n",
      "32:\tlearn: 0.1393117\ttotal: 168ms\tremaining: 852ms\n",
      "33:\tlearn: 0.1370675\ttotal: 173ms\tremaining: 846ms\n",
      "34:\tlearn: 0.1344987\ttotal: 178ms\tremaining: 840ms\n",
      "35:\tlearn: 0.1317512\ttotal: 183ms\tremaining: 836ms\n",
      "36:\tlearn: 0.1296143\ttotal: 188ms\tremaining: 829ms\n",
      "37:\tlearn: 0.1277991\ttotal: 193ms\tremaining: 821ms\n",
      "38:\tlearn: 0.1251621\ttotal: 197ms\tremaining: 813ms\n",
      "39:\tlearn: 0.1237188\ttotal: 202ms\tremaining: 810ms\n",
      "40:\tlearn: 0.1221637\ttotal: 208ms\tremaining: 805ms\n",
      "41:\tlearn: 0.1204626\ttotal: 213ms\tremaining: 800ms\n",
      "42:\tlearn: 0.1185625\ttotal: 217ms\tremaining: 793ms\n",
      "43:\tlearn: 0.1167789\ttotal: 223ms\tremaining: 789ms\n",
      "44:\tlearn: 0.1145954\ttotal: 227ms\tremaining: 783ms\n",
      "45:\tlearn: 0.1127776\ttotal: 233ms\tremaining: 779ms\n",
      "46:\tlearn: 0.1116986\ttotal: 236ms\tremaining: 770ms\n",
      "47:\tlearn: 0.1099572\ttotal: 242ms\tremaining: 766ms\n",
      "48:\tlearn: 0.1081498\ttotal: 247ms\tremaining: 760ms\n",
      "49:\tlearn: 0.1064652\ttotal: 252ms\tremaining: 757ms\n",
      "50:\tlearn: 0.1047800\ttotal: 257ms\tremaining: 751ms\n",
      "51:\tlearn: 0.1036076\ttotal: 262ms\tremaining: 747ms\n",
      "52:\tlearn: 0.1025466\ttotal: 267ms\tremaining: 740ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53:\tlearn: 0.1017131\ttotal: 272ms\tremaining: 735ms\n",
      "54:\tlearn: 0.1007542\ttotal: 276ms\tremaining: 729ms\n",
      "55:\tlearn: 0.1002477\ttotal: 282ms\tremaining: 725ms\n",
      "56:\tlearn: 0.0987470\ttotal: 287ms\tremaining: 719ms\n",
      "57:\tlearn: 0.0978472\ttotal: 292ms\tremaining: 715ms\n",
      "58:\tlearn: 0.0968733\ttotal: 297ms\tremaining: 710ms\n",
      "59:\tlearn: 0.0961848\ttotal: 303ms\tremaining: 707ms\n",
      "60:\tlearn: 0.0945034\ttotal: 308ms\tremaining: 702ms\n",
      "61:\tlearn: 0.0935133\ttotal: 313ms\tremaining: 697ms\n",
      "62:\tlearn: 0.0928596\ttotal: 319ms\tremaining: 693ms\n",
      "63:\tlearn: 0.0918609\ttotal: 324ms\tremaining: 689ms\n",
      "64:\tlearn: 0.0916653\ttotal: 327ms\tremaining: 680ms\n",
      "65:\tlearn: 0.0907559\ttotal: 332ms\tremaining: 673ms\n",
      "66:\tlearn: 0.0897698\ttotal: 337ms\tremaining: 668ms\n",
      "67:\tlearn: 0.0890414\ttotal: 341ms\tremaining: 663ms\n",
      "68:\tlearn: 0.0884973\ttotal: 347ms\tremaining: 659ms\n",
      "69:\tlearn: 0.0875471\ttotal: 352ms\tremaining: 653ms\n",
      "70:\tlearn: 0.0868474\ttotal: 358ms\tremaining: 650ms\n",
      "71:\tlearn: 0.0859999\ttotal: 362ms\tremaining: 644ms\n",
      "72:\tlearn: 0.0847293\ttotal: 367ms\tremaining: 639ms\n",
      "73:\tlearn: 0.0840901\ttotal: 372ms\tremaining: 634ms\n",
      "74:\tlearn: 0.0833692\ttotal: 378ms\tremaining: 630ms\n",
      "75:\tlearn: 0.0828729\ttotal: 383ms\tremaining: 624ms\n",
      "76:\tlearn: 0.0825122\ttotal: 386ms\tremaining: 617ms\n",
      "77:\tlearn: 0.0818995\ttotal: 391ms\tremaining: 612ms\n",
      "78:\tlearn: 0.0812489\ttotal: 397ms\tremaining: 608ms\n",
      "79:\tlearn: 0.0806276\ttotal: 402ms\tremaining: 603ms\n",
      "80:\tlearn: 0.0799435\ttotal: 407ms\tremaining: 598ms\n",
      "81:\tlearn: 0.0796374\ttotal: 413ms\tremaining: 594ms\n",
      "82:\tlearn: 0.0791651\ttotal: 418ms\tremaining: 589ms\n",
      "83:\tlearn: 0.0790186\ttotal: 421ms\tremaining: 581ms\n",
      "84:\tlearn: 0.0786022\ttotal: 425ms\tremaining: 576ms\n",
      "85:\tlearn: 0.0778183\ttotal: 431ms\tremaining: 571ms\n",
      "86:\tlearn: 0.0767976\ttotal: 436ms\tremaining: 566ms\n",
      "87:\tlearn: 0.0760898\ttotal: 441ms\tremaining: 561ms\n",
      "88:\tlearn: 0.0758407\ttotal: 446ms\tremaining: 557ms\n",
      "89:\tlearn: 0.0752989\ttotal: 452ms\tremaining: 552ms\n",
      "90:\tlearn: 0.0747254\ttotal: 456ms\tremaining: 547ms\n",
      "91:\tlearn: 0.0746270\ttotal: 462ms\tremaining: 542ms\n",
      "92:\tlearn: 0.0743160\ttotal: 466ms\tremaining: 536ms\n",
      "93:\tlearn: 0.0737098\ttotal: 471ms\tremaining: 531ms\n",
      "94:\tlearn: 0.0735678\ttotal: 475ms\tremaining: 524ms\n",
      "95:\tlearn: 0.0727511\ttotal: 480ms\tremaining: 520ms\n",
      "96:\tlearn: 0.0722545\ttotal: 485ms\tremaining: 515ms\n",
      "97:\tlearn: 0.0718788\ttotal: 490ms\tremaining: 510ms\n",
      "98:\tlearn: 0.0715565\ttotal: 494ms\tremaining: 504ms\n",
      "99:\tlearn: 0.0712265\ttotal: 501ms\tremaining: 501ms\n",
      "100:\tlearn: 0.0708846\ttotal: 506ms\tremaining: 496ms\n",
      "101:\tlearn: 0.0703937\ttotal: 511ms\tremaining: 491ms\n",
      "102:\tlearn: 0.0698689\ttotal: 516ms\tremaining: 486ms\n",
      "103:\tlearn: 0.0696319\ttotal: 520ms\tremaining: 480ms\n",
      "104:\tlearn: 0.0695830\ttotal: 523ms\tremaining: 474ms\n",
      "105:\tlearn: 0.0692251\ttotal: 528ms\tremaining: 468ms\n",
      "106:\tlearn: 0.0686658\ttotal: 533ms\tremaining: 464ms\n",
      "107:\tlearn: 0.0677769\ttotal: 538ms\tremaining: 458ms\n",
      "108:\tlearn: 0.0673551\ttotal: 543ms\tremaining: 453ms\n",
      "109:\tlearn: 0.0669956\ttotal: 548ms\tremaining: 448ms\n",
      "110:\tlearn: 0.0663517\ttotal: 553ms\tremaining: 444ms\n",
      "111:\tlearn: 0.0659956\ttotal: 558ms\tremaining: 438ms\n",
      "112:\tlearn: 0.0655464\ttotal: 563ms\tremaining: 434ms\n",
      "113:\tlearn: 0.0648665\ttotal: 568ms\tremaining: 428ms\n",
      "114:\tlearn: 0.0643671\ttotal: 573ms\tremaining: 423ms\n",
      "115:\tlearn: 0.0643522\ttotal: 575ms\tremaining: 416ms\n",
      "116:\tlearn: 0.0638381\ttotal: 580ms\tremaining: 411ms\n",
      "117:\tlearn: 0.0636156\ttotal: 585ms\tremaining: 407ms\n",
      "118:\tlearn: 0.0633019\ttotal: 590ms\tremaining: 401ms\n",
      "119:\tlearn: 0.0629826\ttotal: 595ms\tremaining: 397ms\n",
      "120:\tlearn: 0.0629383\ttotal: 597ms\tremaining: 390ms\n",
      "121:\tlearn: 0.0623853\ttotal: 601ms\tremaining: 385ms\n",
      "122:\tlearn: 0.0620001\ttotal: 607ms\tremaining: 380ms\n",
      "123:\tlearn: 0.0615425\ttotal: 612ms\tremaining: 375ms\n",
      "124:\tlearn: 0.0612861\ttotal: 617ms\tremaining: 370ms\n",
      "125:\tlearn: 0.0609204\ttotal: 621ms\tremaining: 365ms\n",
      "126:\tlearn: 0.0607497\ttotal: 627ms\tremaining: 360ms\n",
      "127:\tlearn: 0.0604668\ttotal: 632ms\tremaining: 355ms\n",
      "128:\tlearn: 0.0600969\ttotal: 637ms\tremaining: 350ms\n",
      "129:\tlearn: 0.0598837\ttotal: 641ms\tremaining: 345ms\n",
      "130:\tlearn: 0.0595534\ttotal: 647ms\tremaining: 341ms\n",
      "131:\tlearn: 0.0593691\ttotal: 652ms\tremaining: 336ms\n",
      "132:\tlearn: 0.0591250\ttotal: 657ms\tremaining: 331ms\n",
      "133:\tlearn: 0.0586385\ttotal: 662ms\tremaining: 326ms\n",
      "134:\tlearn: 0.0582777\ttotal: 669ms\tremaining: 322ms\n",
      "135:\tlearn: 0.0577950\ttotal: 674ms\tremaining: 317ms\n",
      "136:\tlearn: 0.0574335\ttotal: 679ms\tremaining: 312ms\n",
      "137:\tlearn: 0.0572296\ttotal: 684ms\tremaining: 307ms\n",
      "138:\tlearn: 0.0570239\ttotal: 688ms\tremaining: 302ms\n",
      "139:\tlearn: 0.0565982\ttotal: 694ms\tremaining: 297ms\n",
      "140:\tlearn: 0.0564326\ttotal: 698ms\tremaining: 292ms\n",
      "141:\tlearn: 0.0562559\ttotal: 704ms\tremaining: 287ms\n",
      "142:\tlearn: 0.0558996\ttotal: 708ms\tremaining: 282ms\n",
      "143:\tlearn: 0.0554803\ttotal: 713ms\tremaining: 277ms\n",
      "144:\tlearn: 0.0549694\ttotal: 718ms\tremaining: 272ms\n",
      "145:\tlearn: 0.0547767\ttotal: 723ms\tremaining: 267ms\n",
      "146:\tlearn: 0.0546160\ttotal: 728ms\tremaining: 262ms\n",
      "147:\tlearn: 0.0539971\ttotal: 732ms\tremaining: 257ms\n",
      "148:\tlearn: 0.0537656\ttotal: 737ms\tremaining: 252ms\n",
      "149:\tlearn: 0.0536716\ttotal: 742ms\tremaining: 247ms\n",
      "150:\tlearn: 0.0533541\ttotal: 746ms\tremaining: 242ms\n",
      "151:\tlearn: 0.0530302\ttotal: 752ms\tremaining: 237ms\n",
      "152:\tlearn: 0.0525757\ttotal: 758ms\tremaining: 233ms\n",
      "153:\tlearn: 0.0524552\ttotal: 762ms\tremaining: 228ms\n",
      "154:\tlearn: 0.0521988\ttotal: 767ms\tremaining: 223ms\n",
      "155:\tlearn: 0.0520570\ttotal: 772ms\tremaining: 218ms\n",
      "156:\tlearn: 0.0518243\ttotal: 777ms\tremaining: 213ms\n",
      "157:\tlearn: 0.0517961\ttotal: 780ms\tremaining: 207ms\n",
      "158:\tlearn: 0.0515232\ttotal: 784ms\tremaining: 202ms\n",
      "159:\tlearn: 0.0512931\ttotal: 789ms\tremaining: 197ms\n",
      "160:\tlearn: 0.0508172\ttotal: 794ms\tremaining: 192ms\n",
      "161:\tlearn: 0.0504636\ttotal: 800ms\tremaining: 188ms\n",
      "162:\tlearn: 0.0501669\ttotal: 805ms\tremaining: 183ms\n",
      "163:\tlearn: 0.0497560\ttotal: 810ms\tremaining: 178ms\n",
      "164:\tlearn: 0.0494014\ttotal: 815ms\tremaining: 173ms\n",
      "165:\tlearn: 0.0490142\ttotal: 820ms\tremaining: 168ms\n",
      "166:\tlearn: 0.0488390\ttotal: 825ms\tremaining: 163ms\n",
      "167:\tlearn: 0.0487876\ttotal: 831ms\tremaining: 158ms\n",
      "168:\tlearn: 0.0484507\ttotal: 835ms\tremaining: 153ms\n",
      "169:\tlearn: 0.0482897\ttotal: 840ms\tremaining: 148ms\n",
      "170:\tlearn: 0.0478527\ttotal: 845ms\tremaining: 143ms\n",
      "171:\tlearn: 0.0474048\ttotal: 850ms\tremaining: 138ms\n",
      "172:\tlearn: 0.0469910\ttotal: 855ms\tremaining: 133ms\n",
      "173:\tlearn: 0.0468121\ttotal: 860ms\tremaining: 129ms\n",
      "174:\tlearn: 0.0466312\ttotal: 864ms\tremaining: 123ms\n",
      "175:\tlearn: 0.0463910\ttotal: 870ms\tremaining: 119ms\n",
      "176:\tlearn: 0.0461695\ttotal: 875ms\tremaining: 114ms\n",
      "177:\tlearn: 0.0459790\ttotal: 880ms\tremaining: 109ms\n",
      "178:\tlearn: 0.0455742\ttotal: 885ms\tremaining: 104ms\n",
      "179:\tlearn: 0.0454072\ttotal: 891ms\tremaining: 99ms\n",
      "180:\tlearn: 0.0448625\ttotal: 896ms\tremaining: 94ms\n",
      "181:\tlearn: 0.0445695\ttotal: 901ms\tremaining: 89.1ms\n",
      "182:\tlearn: 0.0442585\ttotal: 906ms\tremaining: 84.2ms\n",
      "183:\tlearn: 0.0441426\ttotal: 911ms\tremaining: 79.3ms\n",
      "184:\tlearn: 0.0438549\ttotal: 917ms\tremaining: 74.3ms\n",
      "185:\tlearn: 0.0436809\ttotal: 922ms\tremaining: 69.4ms\n",
      "186:\tlearn: 0.0432511\ttotal: 927ms\tremaining: 64.5ms\n",
      "187:\tlearn: 0.0430552\ttotal: 933ms\tremaining: 59.5ms\n",
      "188:\tlearn: 0.0428922\ttotal: 938ms\tremaining: 54.6ms\n",
      "189:\tlearn: 0.0427995\ttotal: 943ms\tremaining: 49.7ms\n",
      "190:\tlearn: 0.0425737\ttotal: 948ms\tremaining: 44.7ms\n",
      "191:\tlearn: 0.0422459\ttotal: 953ms\tremaining: 39.7ms\n",
      "192:\tlearn: 0.0419983\ttotal: 959ms\tremaining: 34.8ms\n",
      "193:\tlearn: 0.0416426\ttotal: 964ms\tremaining: 29.8ms\n",
      "194:\tlearn: 0.0415189\ttotal: 969ms\tremaining: 24.8ms\n",
      "195:\tlearn: 0.0410817\ttotal: 974ms\tremaining: 19.9ms\n",
      "196:\tlearn: 0.0408729\ttotal: 978ms\tremaining: 14.9ms\n",
      "197:\tlearn: 0.0405963\ttotal: 984ms\tremaining: 9.94ms\n",
      "198:\tlearn: 0.0404095\ttotal: 989ms\tremaining: 4.97ms\n",
      "199:\tlearn: 0.0401635\ttotal: 993ms\tremaining: 0us\n",
      "0:\tlearn: 0.5640776\ttotal: 5.05ms\tremaining: 1s\n",
      "1:\tlearn: 0.4695336\ttotal: 10.8ms\tremaining: 1.07s\n",
      "2:\tlearn: 0.4004997\ttotal: 15.6ms\tremaining: 1.02s\n",
      "3:\tlearn: 0.3460859\ttotal: 21.3ms\tremaining: 1.04s\n",
      "4:\tlearn: 0.3085127\ttotal: 26ms\tremaining: 1.01s\n",
      "5:\tlearn: 0.2748831\ttotal: 30.9ms\tremaining: 1000ms\n",
      "6:\tlearn: 0.2446279\ttotal: 36.3ms\tremaining: 1s\n",
      "7:\tlearn: 0.2264189\ttotal: 41.7ms\tremaining: 1s\n",
      "8:\tlearn: 0.2142515\ttotal: 46.6ms\tremaining: 989ms\n",
      "9:\tlearn: 0.2053630\ttotal: 52.2ms\tremaining: 992ms\n",
      "10:\tlearn: 0.1894043\ttotal: 57.1ms\tremaining: 981ms\n",
      "11:\tlearn: 0.1796848\ttotal: 62.3ms\tremaining: 976ms\n",
      "12:\tlearn: 0.1660200\ttotal: 66.8ms\tremaining: 961ms\n",
      "13:\tlearn: 0.1575055\ttotal: 72.1ms\tremaining: 958ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:\tlearn: 0.1498265\ttotal: 77.8ms\tremaining: 959ms\n",
      "15:\tlearn: 0.1432593\ttotal: 82.9ms\tremaining: 954ms\n",
      "16:\tlearn: 0.1381365\ttotal: 87.9ms\tremaining: 946ms\n",
      "17:\tlearn: 0.1345212\ttotal: 93.8ms\tremaining: 948ms\n",
      "18:\tlearn: 0.1301162\ttotal: 98.3ms\tremaining: 936ms\n",
      "19:\tlearn: 0.1250322\ttotal: 103ms\tremaining: 929ms\n",
      "20:\tlearn: 0.1210224\ttotal: 108ms\tremaining: 920ms\n",
      "21:\tlearn: 0.1173501\ttotal: 112ms\tremaining: 910ms\n",
      "22:\tlearn: 0.1147104\ttotal: 118ms\tremaining: 907ms\n",
      "23:\tlearn: 0.1123362\ttotal: 123ms\tremaining: 900ms\n",
      "24:\tlearn: 0.1092919\ttotal: 128ms\tremaining: 899ms\n",
      "25:\tlearn: 0.1064714\ttotal: 134ms\tremaining: 897ms\n",
      "26:\tlearn: 0.1033503\ttotal: 139ms\tremaining: 889ms\n",
      "27:\tlearn: 0.1007534\ttotal: 144ms\tremaining: 886ms\n",
      "28:\tlearn: 0.0997301\ttotal: 150ms\tremaining: 882ms\n",
      "29:\tlearn: 0.0968347\ttotal: 155ms\tremaining: 877ms\n",
      "30:\tlearn: 0.0940664\ttotal: 160ms\tremaining: 870ms\n",
      "31:\tlearn: 0.0923796\ttotal: 166ms\tremaining: 871ms\n",
      "32:\tlearn: 0.0908276\ttotal: 171ms\tremaining: 864ms\n",
      "33:\tlearn: 0.0903848\ttotal: 176ms\tremaining: 860ms\n",
      "34:\tlearn: 0.0888206\ttotal: 181ms\tremaining: 852ms\n",
      "35:\tlearn: 0.0866415\ttotal: 186ms\tremaining: 849ms\n",
      "36:\tlearn: 0.0845515\ttotal: 191ms\tremaining: 841ms\n",
      "37:\tlearn: 0.0832101\ttotal: 196ms\tremaining: 836ms\n",
      "38:\tlearn: 0.0816624\ttotal: 201ms\tremaining: 829ms\n",
      "39:\tlearn: 0.0801204\ttotal: 207ms\tremaining: 826ms\n",
      "40:\tlearn: 0.0784499\ttotal: 211ms\tremaining: 819ms\n",
      "41:\tlearn: 0.0765099\ttotal: 216ms\tremaining: 813ms\n",
      "42:\tlearn: 0.0745651\ttotal: 221ms\tremaining: 805ms\n",
      "43:\tlearn: 0.0733531\ttotal: 226ms\tremaining: 800ms\n",
      "44:\tlearn: 0.0715078\ttotal: 230ms\tremaining: 793ms\n",
      "45:\tlearn: 0.0701123\ttotal: 237ms\tremaining: 792ms\n",
      "46:\tlearn: 0.0699349\ttotal: 239ms\tremaining: 779ms\n",
      "47:\tlearn: 0.0690564\ttotal: 244ms\tremaining: 773ms\n",
      "48:\tlearn: 0.0677398\ttotal: 249ms\tremaining: 768ms\n",
      "49:\tlearn: 0.0665142\ttotal: 254ms\tremaining: 761ms\n",
      "50:\tlearn: 0.0658762\ttotal: 259ms\tremaining: 757ms\n",
      "51:\tlearn: 0.0652287\ttotal: 264ms\tremaining: 751ms\n",
      "52:\tlearn: 0.0644227\ttotal: 269ms\tremaining: 745ms\n",
      "53:\tlearn: 0.0636019\ttotal: 273ms\tremaining: 739ms\n",
      "54:\tlearn: 0.0628837\ttotal: 279ms\tremaining: 735ms\n",
      "55:\tlearn: 0.0624257\ttotal: 284ms\tremaining: 729ms\n",
      "56:\tlearn: 0.0616024\ttotal: 288ms\tremaining: 723ms\n",
      "57:\tlearn: 0.0610818\ttotal: 293ms\tremaining: 717ms\n",
      "58:\tlearn: 0.0601753\ttotal: 298ms\tremaining: 712ms\n",
      "59:\tlearn: 0.0594360\ttotal: 303ms\tremaining: 706ms\n",
      "60:\tlearn: 0.0588243\ttotal: 308ms\tremaining: 701ms\n",
      "61:\tlearn: 0.0579726\ttotal: 312ms\tremaining: 695ms\n",
      "62:\tlearn: 0.0569059\ttotal: 317ms\tremaining: 690ms\n",
      "63:\tlearn: 0.0560807\ttotal: 323ms\tremaining: 686ms\n",
      "64:\tlearn: 0.0551647\ttotal: 327ms\tremaining: 680ms\n",
      "65:\tlearn: 0.0546805\ttotal: 333ms\tremaining: 675ms\n",
      "66:\tlearn: 0.0546444\ttotal: 337ms\tremaining: 668ms\n",
      "67:\tlearn: 0.0540567\ttotal: 341ms\tremaining: 662ms\n",
      "68:\tlearn: 0.0528809\ttotal: 346ms\tremaining: 657ms\n",
      "69:\tlearn: 0.0519740\ttotal: 350ms\tremaining: 651ms\n",
      "70:\tlearn: 0.0512114\ttotal: 356ms\tremaining: 647ms\n",
      "71:\tlearn: 0.0505420\ttotal: 361ms\tremaining: 641ms\n",
      "72:\tlearn: 0.0495003\ttotal: 365ms\tremaining: 636ms\n",
      "73:\tlearn: 0.0490598\ttotal: 370ms\tremaining: 630ms\n",
      "74:\tlearn: 0.0488702\ttotal: 376ms\tremaining: 626ms\n",
      "75:\tlearn: 0.0483437\ttotal: 380ms\tremaining: 620ms\n",
      "76:\tlearn: 0.0482388\ttotal: 385ms\tremaining: 615ms\n",
      "77:\tlearn: 0.0474708\ttotal: 389ms\tremaining: 609ms\n",
      "78:\tlearn: 0.0466447\ttotal: 395ms\tremaining: 605ms\n",
      "79:\tlearn: 0.0457645\ttotal: 400ms\tremaining: 599ms\n",
      "80:\tlearn: 0.0452129\ttotal: 404ms\tremaining: 594ms\n",
      "81:\tlearn: 0.0447129\ttotal: 409ms\tremaining: 589ms\n",
      "82:\tlearn: 0.0441454\ttotal: 415ms\tremaining: 585ms\n",
      "83:\tlearn: 0.0438981\ttotal: 420ms\tremaining: 580ms\n",
      "84:\tlearn: 0.0432631\ttotal: 426ms\tremaining: 576ms\n",
      "85:\tlearn: 0.0430730\ttotal: 430ms\tremaining: 570ms\n",
      "86:\tlearn: 0.0424915\ttotal: 436ms\tremaining: 566ms\n",
      "87:\tlearn: 0.0423151\ttotal: 440ms\tremaining: 560ms\n",
      "88:\tlearn: 0.0418727\ttotal: 446ms\tremaining: 556ms\n",
      "89:\tlearn: 0.0417618\ttotal: 450ms\tremaining: 551ms\n",
      "90:\tlearn: 0.0413192\ttotal: 456ms\tremaining: 546ms\n",
      "91:\tlearn: 0.0410124\ttotal: 461ms\tremaining: 541ms\n",
      "92:\tlearn: 0.0405663\ttotal: 466ms\tremaining: 536ms\n",
      "93:\tlearn: 0.0400473\ttotal: 471ms\tremaining: 531ms\n",
      "94:\tlearn: 0.0396905\ttotal: 476ms\tremaining: 527ms\n",
      "95:\tlearn: 0.0393114\ttotal: 481ms\tremaining: 521ms\n",
      "96:\tlearn: 0.0385685\ttotal: 487ms\tremaining: 517ms\n",
      "97:\tlearn: 0.0380767\ttotal: 493ms\tremaining: 513ms\n",
      "98:\tlearn: 0.0377542\ttotal: 498ms\tremaining: 508ms\n",
      "99:\tlearn: 0.0371979\ttotal: 503ms\tremaining: 503ms\n",
      "100:\tlearn: 0.0364819\ttotal: 508ms\tremaining: 498ms\n",
      "101:\tlearn: 0.0362943\ttotal: 513ms\tremaining: 493ms\n",
      "102:\tlearn: 0.0359215\ttotal: 518ms\tremaining: 488ms\n",
      "103:\tlearn: 0.0357782\ttotal: 522ms\tremaining: 482ms\n",
      "104:\tlearn: 0.0350520\ttotal: 528ms\tremaining: 478ms\n",
      "105:\tlearn: 0.0346002\ttotal: 533ms\tremaining: 472ms\n",
      "106:\tlearn: 0.0343219\ttotal: 539ms\tremaining: 469ms\n",
      "107:\tlearn: 0.0338926\ttotal: 544ms\tremaining: 464ms\n",
      "108:\tlearn: 0.0336840\ttotal: 550ms\tremaining: 459ms\n",
      "109:\tlearn: 0.0335612\ttotal: 554ms\tremaining: 453ms\n",
      "110:\tlearn: 0.0328169\ttotal: 559ms\tremaining: 448ms\n",
      "111:\tlearn: 0.0326242\ttotal: 564ms\tremaining: 443ms\n",
      "112:\tlearn: 0.0320489\ttotal: 569ms\tremaining: 438ms\n",
      "113:\tlearn: 0.0318243\ttotal: 575ms\tremaining: 433ms\n",
      "114:\tlearn: 0.0316617\ttotal: 579ms\tremaining: 428ms\n",
      "115:\tlearn: 0.0311326\ttotal: 584ms\tremaining: 423ms\n",
      "116:\tlearn: 0.0308335\ttotal: 589ms\tremaining: 418ms\n",
      "117:\tlearn: 0.0305430\ttotal: 594ms\tremaining: 413ms\n",
      "118:\tlearn: 0.0304869\ttotal: 600ms\tremaining: 409ms\n",
      "119:\tlearn: 0.0303917\ttotal: 605ms\tremaining: 403ms\n",
      "120:\tlearn: 0.0303343\ttotal: 611ms\tremaining: 399ms\n",
      "121:\tlearn: 0.0302668\ttotal: 615ms\tremaining: 393ms\n",
      "122:\tlearn: 0.0296325\ttotal: 620ms\tremaining: 388ms\n",
      "123:\tlearn: 0.0294179\ttotal: 626ms\tremaining: 383ms\n",
      "124:\tlearn: 0.0291321\ttotal: 631ms\tremaining: 379ms\n",
      "125:\tlearn: 0.0286605\ttotal: 636ms\tremaining: 373ms\n",
      "126:\tlearn: 0.0283798\ttotal: 640ms\tremaining: 368ms\n",
      "127:\tlearn: 0.0283008\ttotal: 645ms\tremaining: 363ms\n",
      "128:\tlearn: 0.0279854\ttotal: 650ms\tremaining: 358ms\n",
      "129:\tlearn: 0.0273278\ttotal: 655ms\tremaining: 353ms\n",
      "130:\tlearn: 0.0269967\ttotal: 660ms\tremaining: 348ms\n",
      "131:\tlearn: 0.0267134\ttotal: 664ms\tremaining: 342ms\n",
      "132:\tlearn: 0.0263384\ttotal: 669ms\tremaining: 337ms\n",
      "133:\tlearn: 0.0260742\ttotal: 674ms\tremaining: 332ms\n",
      "134:\tlearn: 0.0256961\ttotal: 680ms\tremaining: 327ms\n",
      "135:\tlearn: 0.0253649\ttotal: 684ms\tremaining: 322ms\n",
      "136:\tlearn: 0.0251383\ttotal: 690ms\tremaining: 317ms\n",
      "137:\tlearn: 0.0249285\ttotal: 695ms\tremaining: 312ms\n",
      "138:\tlearn: 0.0247366\ttotal: 700ms\tremaining: 307ms\n",
      "139:\tlearn: 0.0245819\ttotal: 705ms\tremaining: 302ms\n",
      "140:\tlearn: 0.0243749\ttotal: 710ms\tremaining: 297ms\n",
      "141:\tlearn: 0.0241608\ttotal: 715ms\tremaining: 292ms\n",
      "142:\tlearn: 0.0237719\ttotal: 719ms\tremaining: 287ms\n",
      "143:\tlearn: 0.0235617\ttotal: 724ms\tremaining: 282ms\n",
      "144:\tlearn: 0.0232743\ttotal: 729ms\tremaining: 277ms\n",
      "145:\tlearn: 0.0231755\ttotal: 734ms\tremaining: 271ms\n",
      "146:\tlearn: 0.0229900\ttotal: 741ms\tremaining: 267ms\n",
      "147:\tlearn: 0.0227172\ttotal: 746ms\tremaining: 262ms\n",
      "148:\tlearn: 0.0225493\ttotal: 750ms\tremaining: 257ms\n",
      "149:\tlearn: 0.0221797\ttotal: 755ms\tremaining: 252ms\n",
      "150:\tlearn: 0.0220246\ttotal: 761ms\tremaining: 247ms\n",
      "151:\tlearn: 0.0215951\ttotal: 765ms\tremaining: 241ms\n",
      "152:\tlearn: 0.0213782\ttotal: 770ms\tremaining: 237ms\n",
      "153:\tlearn: 0.0209943\ttotal: 775ms\tremaining: 231ms\n",
      "154:\tlearn: 0.0207908\ttotal: 779ms\tremaining: 226ms\n",
      "155:\tlearn: 0.0205704\ttotal: 785ms\tremaining: 221ms\n",
      "156:\tlearn: 0.0204343\ttotal: 790ms\tremaining: 216ms\n",
      "157:\tlearn: 0.0202352\ttotal: 795ms\tremaining: 211ms\n",
      "158:\tlearn: 0.0200819\ttotal: 800ms\tremaining: 206ms\n",
      "159:\tlearn: 0.0199476\ttotal: 805ms\tremaining: 201ms\n",
      "160:\tlearn: 0.0197234\ttotal: 810ms\tremaining: 196ms\n",
      "161:\tlearn: 0.0193861\ttotal: 815ms\tremaining: 191ms\n",
      "162:\tlearn: 0.0192362\ttotal: 820ms\tremaining: 186ms\n",
      "163:\tlearn: 0.0189518\ttotal: 826ms\tremaining: 181ms\n",
      "164:\tlearn: 0.0187253\ttotal: 830ms\tremaining: 176ms\n",
      "165:\tlearn: 0.0185765\ttotal: 836ms\tremaining: 171ms\n",
      "166:\tlearn: 0.0182955\ttotal: 841ms\tremaining: 166ms\n",
      "167:\tlearn: 0.0182013\ttotal: 846ms\tremaining: 161ms\n",
      "168:\tlearn: 0.0179992\ttotal: 851ms\tremaining: 156ms\n",
      "169:\tlearn: 0.0179324\ttotal: 856ms\tremaining: 151ms\n",
      "170:\tlearn: 0.0177609\ttotal: 860ms\tremaining: 146ms\n",
      "171:\tlearn: 0.0176000\ttotal: 866ms\tremaining: 141ms\n",
      "172:\tlearn: 0.0175168\ttotal: 871ms\tremaining: 136ms\n",
      "173:\tlearn: 0.0172624\ttotal: 876ms\tremaining: 131ms\n",
      "174:\tlearn: 0.0172099\ttotal: 880ms\tremaining: 126ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175:\tlearn: 0.0170847\ttotal: 885ms\tremaining: 121ms\n",
      "176:\tlearn: 0.0169545\ttotal: 890ms\tremaining: 116ms\n",
      "177:\tlearn: 0.0166518\ttotal: 895ms\tremaining: 111ms\n",
      "178:\tlearn: 0.0164676\ttotal: 900ms\tremaining: 106ms\n",
      "179:\tlearn: 0.0164168\ttotal: 905ms\tremaining: 101ms\n",
      "180:\tlearn: 0.0162707\ttotal: 910ms\tremaining: 95.5ms\n",
      "181:\tlearn: 0.0161588\ttotal: 915ms\tremaining: 90.5ms\n",
      "182:\tlearn: 0.0161153\ttotal: 920ms\tremaining: 85.5ms\n",
      "183:\tlearn: 0.0160373\ttotal: 925ms\tremaining: 80.5ms\n",
      "184:\tlearn: 0.0159823\ttotal: 931ms\tremaining: 75.5ms\n",
      "185:\tlearn: 0.0158266\ttotal: 936ms\tremaining: 70.4ms\n",
      "186:\tlearn: 0.0157688\ttotal: 941ms\tremaining: 65.4ms\n",
      "187:\tlearn: 0.0157239\ttotal: 945ms\tremaining: 60.3ms\n",
      "188:\tlearn: 0.0155507\ttotal: 950ms\tremaining: 55.3ms\n",
      "189:\tlearn: 0.0154199\ttotal: 955ms\tremaining: 50.3ms\n",
      "190:\tlearn: 0.0153396\ttotal: 960ms\tremaining: 45.3ms\n",
      "191:\tlearn: 0.0152346\ttotal: 965ms\tremaining: 40.2ms\n",
      "192:\tlearn: 0.0151593\ttotal: 971ms\tremaining: 35.2ms\n",
      "193:\tlearn: 0.0151115\ttotal: 975ms\tremaining: 30.2ms\n",
      "194:\tlearn: 0.0150222\ttotal: 983ms\tremaining: 25.2ms\n",
      "195:\tlearn: 0.0148846\ttotal: 988ms\tremaining: 20.2ms\n",
      "196:\tlearn: 0.0147838\ttotal: 994ms\tremaining: 15.1ms\n",
      "197:\tlearn: 0.0146683\ttotal: 999ms\tremaining: 10.1ms\n",
      "198:\tlearn: 0.0146487\ttotal: 1s\tremaining: 5.04ms\n",
      "199:\tlearn: 0.0145127\ttotal: 1.01s\tremaining: 0us\n",
      "0:\tlearn: 0.5746005\ttotal: 4.27ms\tremaining: 850ms\n",
      "1:\tlearn: 0.4723188\ttotal: 9.35ms\tremaining: 925ms\n",
      "2:\tlearn: 0.3977129\ttotal: 13.8ms\tremaining: 906ms\n",
      "3:\tlearn: 0.3416465\ttotal: 19.2ms\tremaining: 940ms\n",
      "4:\tlearn: 0.3023118\ttotal: 24.1ms\tremaining: 939ms\n",
      "5:\tlearn: 0.2605633\ttotal: 29.5ms\tremaining: 955ms\n",
      "6:\tlearn: 0.2412789\ttotal: 34.3ms\tremaining: 947ms\n",
      "7:\tlearn: 0.2239743\ttotal: 39.9ms\tremaining: 957ms\n",
      "8:\tlearn: 0.2095443\ttotal: 44.9ms\tremaining: 953ms\n",
      "9:\tlearn: 0.1931309\ttotal: 49.9ms\tremaining: 947ms\n",
      "10:\tlearn: 0.1832342\ttotal: 54.5ms\tremaining: 936ms\n",
      "11:\tlearn: 0.1743187\ttotal: 61ms\tremaining: 956ms\n",
      "12:\tlearn: 0.1653752\ttotal: 65.8ms\tremaining: 946ms\n",
      "13:\tlearn: 0.1554395\ttotal: 71.5ms\tremaining: 950ms\n",
      "14:\tlearn: 0.1510199\ttotal: 76ms\tremaining: 938ms\n",
      "15:\tlearn: 0.1423838\ttotal: 81.8ms\tremaining: 940ms\n",
      "16:\tlearn: 0.1392857\ttotal: 86.6ms\tremaining: 932ms\n",
      "17:\tlearn: 0.1360106\ttotal: 92.2ms\tremaining: 933ms\n",
      "18:\tlearn: 0.1307515\ttotal: 96.9ms\tremaining: 923ms\n",
      "19:\tlearn: 0.1251360\ttotal: 103ms\tremaining: 923ms\n",
      "20:\tlearn: 0.1213866\ttotal: 107ms\tremaining: 912ms\n",
      "21:\tlearn: 0.1172167\ttotal: 112ms\tremaining: 907ms\n",
      "22:\tlearn: 0.1134149\ttotal: 117ms\tremaining: 898ms\n",
      "23:\tlearn: 0.1104572\ttotal: 121ms\tremaining: 889ms\n",
      "24:\tlearn: 0.1081983\ttotal: 125ms\tremaining: 877ms\n",
      "25:\tlearn: 0.1050234\ttotal: 132ms\tremaining: 881ms\n",
      "26:\tlearn: 0.1030010\ttotal: 136ms\tremaining: 875ms\n",
      "27:\tlearn: 0.1002925\ttotal: 142ms\tremaining: 871ms\n",
      "28:\tlearn: 0.0979715\ttotal: 147ms\tremaining: 866ms\n",
      "29:\tlearn: 0.0963250\ttotal: 152ms\tremaining: 863ms\n",
      "30:\tlearn: 0.0942542\ttotal: 157ms\tremaining: 856ms\n",
      "31:\tlearn: 0.0925848\ttotal: 162ms\tremaining: 852ms\n",
      "32:\tlearn: 0.0913443\ttotal: 168ms\tremaining: 849ms\n",
      "33:\tlearn: 0.0903401\ttotal: 173ms\tremaining: 843ms\n",
      "34:\tlearn: 0.0890936\ttotal: 177ms\tremaining: 837ms\n",
      "35:\tlearn: 0.0881848\ttotal: 183ms\tremaining: 834ms\n",
      "36:\tlearn: 0.0854396\ttotal: 188ms\tremaining: 830ms\n",
      "37:\tlearn: 0.0844360\ttotal: 194ms\tremaining: 826ms\n",
      "38:\tlearn: 0.0830694\ttotal: 198ms\tremaining: 819ms\n",
      "39:\tlearn: 0.0819732\ttotal: 204ms\tremaining: 814ms\n",
      "40:\tlearn: 0.0810786\ttotal: 208ms\tremaining: 808ms\n",
      "41:\tlearn: 0.0807288\ttotal: 213ms\tremaining: 802ms\n",
      "42:\tlearn: 0.0790303\ttotal: 218ms\tremaining: 795ms\n",
      "43:\tlearn: 0.0775648\ttotal: 223ms\tremaining: 790ms\n",
      "44:\tlearn: 0.0772622\ttotal: 227ms\tremaining: 783ms\n",
      "45:\tlearn: 0.0764531\ttotal: 233ms\tremaining: 780ms\n",
      "46:\tlearn: 0.0758383\ttotal: 238ms\tremaining: 774ms\n",
      "47:\tlearn: 0.0752986\ttotal: 243ms\tremaining: 770ms\n",
      "48:\tlearn: 0.0741914\ttotal: 248ms\tremaining: 764ms\n",
      "49:\tlearn: 0.0729344\ttotal: 253ms\tremaining: 759ms\n",
      "50:\tlearn: 0.0715238\ttotal: 258ms\tremaining: 753ms\n",
      "51:\tlearn: 0.0711482\ttotal: 263ms\tremaining: 749ms\n",
      "52:\tlearn: 0.0698549\ttotal: 268ms\tremaining: 743ms\n",
      "53:\tlearn: 0.0690015\ttotal: 274ms\tremaining: 740ms\n",
      "54:\tlearn: 0.0689997\ttotal: 276ms\tremaining: 727ms\n",
      "55:\tlearn: 0.0689920\ttotal: 279ms\tremaining: 716ms\n",
      "56:\tlearn: 0.0676068\ttotal: 283ms\tremaining: 711ms\n",
      "57:\tlearn: 0.0667677\ttotal: 289ms\tremaining: 707ms\n",
      "58:\tlearn: 0.0656526\ttotal: 293ms\tremaining: 701ms\n",
      "59:\tlearn: 0.0656306\ttotal: 297ms\tremaining: 693ms\n",
      "60:\tlearn: 0.0647246\ttotal: 301ms\tremaining: 687ms\n",
      "61:\tlearn: 0.0638087\ttotal: 306ms\tremaining: 682ms\n",
      "62:\tlearn: 0.0625429\ttotal: 311ms\tremaining: 677ms\n",
      "63:\tlearn: 0.0618883\ttotal: 317ms\tremaining: 674ms\n",
      "64:\tlearn: 0.0612570\ttotal: 322ms\tremaining: 668ms\n",
      "65:\tlearn: 0.0608519\ttotal: 327ms\tremaining: 664ms\n",
      "66:\tlearn: 0.0599123\ttotal: 332ms\tremaining: 658ms\n",
      "67:\tlearn: 0.0597868\ttotal: 335ms\tremaining: 651ms\n",
      "68:\tlearn: 0.0590150\ttotal: 340ms\tremaining: 646ms\n",
      "69:\tlearn: 0.0581006\ttotal: 346ms\tremaining: 642ms\n",
      "70:\tlearn: 0.0576927\ttotal: 351ms\tremaining: 637ms\n",
      "71:\tlearn: 0.0570463\ttotal: 357ms\tremaining: 635ms\n",
      "72:\tlearn: 0.0570462\ttotal: 359ms\tremaining: 625ms\n",
      "73:\tlearn: 0.0570459\ttotal: 362ms\tremaining: 616ms\n",
      "74:\tlearn: 0.0570383\ttotal: 365ms\tremaining: 608ms\n",
      "75:\tlearn: 0.0566310\ttotal: 370ms\tremaining: 604ms\n",
      "76:\tlearn: 0.0564753\ttotal: 374ms\tremaining: 597ms\n",
      "77:\tlearn: 0.0559673\ttotal: 379ms\tremaining: 592ms\n",
      "78:\tlearn: 0.0559548\ttotal: 383ms\tremaining: 586ms\n",
      "79:\tlearn: 0.0559475\ttotal: 385ms\tremaining: 578ms\n",
      "80:\tlearn: 0.0549875\ttotal: 392ms\tremaining: 575ms\n",
      "81:\tlearn: 0.0542988\ttotal: 396ms\tremaining: 570ms\n",
      "82:\tlearn: 0.0542705\ttotal: 400ms\tremaining: 563ms\n",
      "83:\tlearn: 0.0537702\ttotal: 404ms\tremaining: 558ms\n",
      "84:\tlearn: 0.0533179\ttotal: 410ms\tremaining: 555ms\n",
      "85:\tlearn: 0.0526748\ttotal: 414ms\tremaining: 549ms\n",
      "86:\tlearn: 0.0520334\ttotal: 420ms\tremaining: 546ms\n",
      "87:\tlearn: 0.0520258\ttotal: 425ms\tremaining: 540ms\n",
      "88:\tlearn: 0.0509200\ttotal: 430ms\tremaining: 537ms\n",
      "89:\tlearn: 0.0509200\ttotal: 433ms\tremaining: 529ms\n",
      "90:\tlearn: 0.0500621\ttotal: 437ms\tremaining: 524ms\n",
      "91:\tlearn: 0.0500621\ttotal: 440ms\tremaining: 517ms\n",
      "92:\tlearn: 0.0500620\ttotal: 443ms\tremaining: 509ms\n",
      "93:\tlearn: 0.0495554\ttotal: 448ms\tremaining: 505ms\n",
      "94:\tlearn: 0.0492326\ttotal: 454ms\tremaining: 502ms\n",
      "95:\tlearn: 0.0489185\ttotal: 460ms\tremaining: 498ms\n",
      "96:\tlearn: 0.0489047\ttotal: 465ms\tremaining: 493ms\n",
      "97:\tlearn: 0.0481968\ttotal: 470ms\tremaining: 489ms\n",
      "98:\tlearn: 0.0473851\ttotal: 475ms\tremaining: 484ms\n",
      "99:\tlearn: 0.0468857\ttotal: 479ms\tremaining: 479ms\n",
      "100:\tlearn: 0.0468845\ttotal: 482ms\tremaining: 472ms\n",
      "101:\tlearn: 0.0460796\ttotal: 494ms\tremaining: 474ms\n",
      "102:\tlearn: 0.0453239\ttotal: 500ms\tremaining: 470ms\n",
      "103:\tlearn: 0.0452236\ttotal: 505ms\tremaining: 466ms\n",
      "104:\tlearn: 0.0448873\ttotal: 510ms\tremaining: 461ms\n",
      "105:\tlearn: 0.0441561\ttotal: 514ms\tremaining: 456ms\n",
      "106:\tlearn: 0.0441558\ttotal: 517ms\tremaining: 450ms\n",
      "107:\tlearn: 0.0435548\ttotal: 522ms\tremaining: 445ms\n",
      "108:\tlearn: 0.0431384\ttotal: 527ms\tremaining: 440ms\n",
      "109:\tlearn: 0.0426063\ttotal: 532ms\tremaining: 436ms\n",
      "110:\tlearn: 0.0418722\ttotal: 537ms\tremaining: 431ms\n",
      "111:\tlearn: 0.0412563\ttotal: 543ms\tremaining: 426ms\n",
      "112:\tlearn: 0.0410899\ttotal: 548ms\tremaining: 422ms\n",
      "113:\tlearn: 0.0406607\ttotal: 553ms\tremaining: 417ms\n",
      "114:\tlearn: 0.0402246\ttotal: 557ms\tremaining: 412ms\n",
      "115:\tlearn: 0.0398842\ttotal: 562ms\tremaining: 407ms\n",
      "116:\tlearn: 0.0398116\ttotal: 568ms\tremaining: 403ms\n",
      "117:\tlearn: 0.0396186\ttotal: 573ms\tremaining: 398ms\n",
      "118:\tlearn: 0.0390026\ttotal: 578ms\tremaining: 393ms\n",
      "119:\tlearn: 0.0389624\ttotal: 582ms\tremaining: 388ms\n",
      "120:\tlearn: 0.0386255\ttotal: 587ms\tremaining: 383ms\n",
      "121:\tlearn: 0.0381878\ttotal: 593ms\tremaining: 379ms\n",
      "122:\tlearn: 0.0378556\ttotal: 597ms\tremaining: 374ms\n",
      "123:\tlearn: 0.0376814\ttotal: 603ms\tremaining: 369ms\n",
      "124:\tlearn: 0.0376712\ttotal: 607ms\tremaining: 364ms\n",
      "125:\tlearn: 0.0375882\ttotal: 612ms\tremaining: 360ms\n",
      "126:\tlearn: 0.0373141\ttotal: 618ms\tremaining: 355ms\n",
      "127:\tlearn: 0.0368374\ttotal: 623ms\tremaining: 350ms\n",
      "128:\tlearn: 0.0368002\ttotal: 628ms\tremaining: 346ms\n",
      "129:\tlearn: 0.0359121\ttotal: 632ms\tremaining: 340ms\n",
      "130:\tlearn: 0.0356695\ttotal: 638ms\tremaining: 336ms\n",
      "131:\tlearn: 0.0354517\ttotal: 643ms\tremaining: 331ms\n",
      "132:\tlearn: 0.0354109\ttotal: 649ms\tremaining: 327ms\n",
      "133:\tlearn: 0.0351664\ttotal: 653ms\tremaining: 322ms\n",
      "134:\tlearn: 0.0346606\ttotal: 658ms\tremaining: 317ms\n",
      "135:\tlearn: 0.0344869\ttotal: 663ms\tremaining: 312ms\n",
      "136:\tlearn: 0.0338345\ttotal: 668ms\tremaining: 307ms\n",
      "137:\tlearn: 0.0334446\ttotal: 672ms\tremaining: 302ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138:\tlearn: 0.0328234\ttotal: 678ms\tremaining: 298ms\n",
      "139:\tlearn: 0.0327534\ttotal: 683ms\tremaining: 293ms\n",
      "140:\tlearn: 0.0327226\ttotal: 689ms\tremaining: 288ms\n",
      "141:\tlearn: 0.0323677\ttotal: 694ms\tremaining: 283ms\n",
      "142:\tlearn: 0.0319832\ttotal: 699ms\tremaining: 279ms\n",
      "143:\tlearn: 0.0313982\ttotal: 704ms\tremaining: 274ms\n",
      "144:\tlearn: 0.0312798\ttotal: 709ms\tremaining: 269ms\n",
      "145:\tlearn: 0.0307749\ttotal: 714ms\tremaining: 264ms\n",
      "146:\tlearn: 0.0304533\ttotal: 720ms\tremaining: 260ms\n",
      "147:\tlearn: 0.0301406\ttotal: 726ms\tremaining: 255ms\n",
      "148:\tlearn: 0.0298330\ttotal: 731ms\tremaining: 250ms\n",
      "149:\tlearn: 0.0296877\ttotal: 736ms\tremaining: 245ms\n",
      "150:\tlearn: 0.0294451\ttotal: 742ms\tremaining: 241ms\n",
      "151:\tlearn: 0.0292796\ttotal: 747ms\tremaining: 236ms\n",
      "152:\tlearn: 0.0290150\ttotal: 753ms\tremaining: 231ms\n",
      "153:\tlearn: 0.0287383\ttotal: 757ms\tremaining: 226ms\n",
      "154:\tlearn: 0.0284647\ttotal: 762ms\tremaining: 221ms\n",
      "155:\tlearn: 0.0282148\ttotal: 767ms\tremaining: 216ms\n",
      "156:\tlearn: 0.0280625\ttotal: 773ms\tremaining: 212ms\n",
      "157:\tlearn: 0.0279833\ttotal: 778ms\tremaining: 207ms\n",
      "158:\tlearn: 0.0276104\ttotal: 783ms\tremaining: 202ms\n",
      "159:\tlearn: 0.0272960\ttotal: 788ms\tremaining: 197ms\n",
      "160:\tlearn: 0.0270740\ttotal: 793ms\tremaining: 192ms\n",
      "161:\tlearn: 0.0267120\ttotal: 797ms\tremaining: 187ms\n",
      "162:\tlearn: 0.0265810\ttotal: 802ms\tremaining: 182ms\n",
      "163:\tlearn: 0.0261922\ttotal: 807ms\tremaining: 177ms\n",
      "164:\tlearn: 0.0260800\ttotal: 813ms\tremaining: 173ms\n",
      "165:\tlearn: 0.0260750\ttotal: 818ms\tremaining: 167ms\n",
      "166:\tlearn: 0.0258495\ttotal: 823ms\tremaining: 163ms\n",
      "167:\tlearn: 0.0257174\ttotal: 829ms\tremaining: 158ms\n",
      "168:\tlearn: 0.0255463\ttotal: 835ms\tremaining: 153ms\n",
      "169:\tlearn: 0.0252028\ttotal: 839ms\tremaining: 148ms\n",
      "170:\tlearn: 0.0248746\ttotal: 845ms\tremaining: 143ms\n",
      "171:\tlearn: 0.0245525\ttotal: 850ms\tremaining: 138ms\n",
      "172:\tlearn: 0.0244971\ttotal: 855ms\tremaining: 133ms\n",
      "173:\tlearn: 0.0241423\ttotal: 860ms\tremaining: 128ms\n",
      "174:\tlearn: 0.0241079\ttotal: 865ms\tremaining: 124ms\n",
      "175:\tlearn: 0.0239171\ttotal: 870ms\tremaining: 119ms\n",
      "176:\tlearn: 0.0237008\ttotal: 876ms\tremaining: 114ms\n",
      "177:\tlearn: 0.0235878\ttotal: 881ms\tremaining: 109ms\n",
      "178:\tlearn: 0.0233562\ttotal: 887ms\tremaining: 104ms\n",
      "179:\tlearn: 0.0230298\ttotal: 891ms\tremaining: 99ms\n",
      "180:\tlearn: 0.0230273\ttotal: 898ms\tremaining: 94.2ms\n",
      "181:\tlearn: 0.0227896\ttotal: 902ms\tremaining: 89.2ms\n",
      "182:\tlearn: 0.0227823\ttotal: 908ms\tremaining: 84.3ms\n",
      "183:\tlearn: 0.0226379\ttotal: 913ms\tremaining: 79.4ms\n",
      "184:\tlearn: 0.0225821\ttotal: 918ms\tremaining: 74.5ms\n",
      "185:\tlearn: 0.0224423\ttotal: 923ms\tremaining: 69.5ms\n",
      "186:\tlearn: 0.0222399\ttotal: 928ms\tremaining: 64.5ms\n",
      "187:\tlearn: 0.0220390\ttotal: 932ms\tremaining: 59.5ms\n",
      "188:\tlearn: 0.0219164\ttotal: 938ms\tremaining: 54.6ms\n",
      "189:\tlearn: 0.0218598\ttotal: 943ms\tremaining: 49.6ms\n",
      "190:\tlearn: 0.0217566\ttotal: 948ms\tremaining: 44.7ms\n",
      "191:\tlearn: 0.0216205\ttotal: 953ms\tremaining: 39.7ms\n",
      "192:\tlearn: 0.0214381\ttotal: 959ms\tremaining: 34.8ms\n",
      "193:\tlearn: 0.0213856\ttotal: 963ms\tremaining: 29.8ms\n",
      "194:\tlearn: 0.0212184\ttotal: 968ms\tremaining: 24.8ms\n",
      "195:\tlearn: 0.0209403\ttotal: 973ms\tremaining: 19.9ms\n",
      "196:\tlearn: 0.0207419\ttotal: 978ms\tremaining: 14.9ms\n",
      "197:\tlearn: 0.0205099\ttotal: 983ms\tremaining: 9.93ms\n",
      "198:\tlearn: 0.0204457\ttotal: 988ms\tremaining: 4.96ms\n",
      "199:\tlearn: 0.0201625\ttotal: 994ms\tremaining: 0us\n",
      "0:\tlearn: 0.5676032\ttotal: 3.98ms\tremaining: 792ms\n",
      "1:\tlearn: 0.4763876\ttotal: 10ms\tremaining: 994ms\n",
      "2:\tlearn: 0.3929843\ttotal: 14.6ms\tremaining: 960ms\n",
      "3:\tlearn: 0.3478979\ttotal: 20.2ms\tremaining: 988ms\n",
      "4:\tlearn: 0.3160845\ttotal: 24.8ms\tremaining: 969ms\n",
      "5:\tlearn: 0.2810723\ttotal: 29.3ms\tremaining: 948ms\n",
      "6:\tlearn: 0.2564100\ttotal: 34.5ms\tremaining: 951ms\n",
      "7:\tlearn: 0.2402107\ttotal: 39.6ms\tremaining: 950ms\n",
      "8:\tlearn: 0.2198079\ttotal: 44.1ms\tremaining: 935ms\n",
      "9:\tlearn: 0.2077976\ttotal: 50ms\tremaining: 951ms\n",
      "10:\tlearn: 0.1908969\ttotal: 54.8ms\tremaining: 942ms\n",
      "11:\tlearn: 0.1788050\ttotal: 60.1ms\tremaining: 942ms\n",
      "12:\tlearn: 0.1733917\ttotal: 64.7ms\tremaining: 931ms\n",
      "13:\tlearn: 0.1636534\ttotal: 70ms\tremaining: 929ms\n",
      "14:\tlearn: 0.1532883\ttotal: 75ms\tremaining: 926ms\n",
      "15:\tlearn: 0.1476422\ttotal: 80.5ms\tremaining: 926ms\n",
      "16:\tlearn: 0.1422163\ttotal: 85.4ms\tremaining: 919ms\n",
      "17:\tlearn: 0.1392681\ttotal: 91.6ms\tremaining: 926ms\n",
      "18:\tlearn: 0.1323312\ttotal: 96.4ms\tremaining: 919ms\n",
      "19:\tlearn: 0.1277137\ttotal: 102ms\tremaining: 921ms\n",
      "20:\tlearn: 0.1240388\ttotal: 108ms\tremaining: 919ms\n",
      "21:\tlearn: 0.1197691\ttotal: 113ms\tremaining: 914ms\n",
      "22:\tlearn: 0.1157508\ttotal: 118ms\tremaining: 908ms\n",
      "23:\tlearn: 0.1126711\ttotal: 123ms\tremaining: 900ms\n",
      "24:\tlearn: 0.1108903\ttotal: 128ms\tremaining: 893ms\n",
      "25:\tlearn: 0.1075825\ttotal: 133ms\tremaining: 890ms\n",
      "26:\tlearn: 0.1056647\ttotal: 137ms\tremaining: 875ms\n",
      "27:\tlearn: 0.1040631\ttotal: 142ms\tremaining: 870ms\n",
      "28:\tlearn: 0.1011299\ttotal: 147ms\tremaining: 865ms\n",
      "29:\tlearn: 0.0990570\ttotal: 152ms\tremaining: 864ms\n",
      "30:\tlearn: 0.0972383\ttotal: 157ms\tremaining: 858ms\n",
      "31:\tlearn: 0.0959165\ttotal: 163ms\tremaining: 855ms\n",
      "32:\tlearn: 0.0937261\ttotal: 167ms\tremaining: 848ms\n",
      "33:\tlearn: 0.0909861\ttotal: 173ms\tremaining: 845ms\n",
      "34:\tlearn: 0.0895836\ttotal: 177ms\tremaining: 836ms\n",
      "35:\tlearn: 0.0872362\ttotal: 183ms\tremaining: 833ms\n",
      "36:\tlearn: 0.0863191\ttotal: 187ms\tremaining: 825ms\n",
      "37:\tlearn: 0.0849073\ttotal: 191ms\tremaining: 815ms\n",
      "38:\tlearn: 0.0841260\ttotal: 197ms\tremaining: 811ms\n",
      "39:\tlearn: 0.0829488\ttotal: 201ms\tremaining: 805ms\n",
      "40:\tlearn: 0.0816616\ttotal: 206ms\tremaining: 797ms\n",
      "41:\tlearn: 0.0808236\ttotal: 211ms\tremaining: 794ms\n",
      "42:\tlearn: 0.0793441\ttotal: 216ms\tremaining: 790ms\n",
      "43:\tlearn: 0.0782968\ttotal: 222ms\tremaining: 788ms\n",
      "44:\tlearn: 0.0768045\ttotal: 227ms\tremaining: 781ms\n",
      "45:\tlearn: 0.0753156\ttotal: 232ms\tremaining: 776ms\n",
      "46:\tlearn: 0.0746294\ttotal: 234ms\tremaining: 763ms\n",
      "47:\tlearn: 0.0735874\ttotal: 239ms\tremaining: 758ms\n",
      "48:\tlearn: 0.0730727\ttotal: 245ms\tremaining: 755ms\n",
      "49:\tlearn: 0.0715821\ttotal: 250ms\tremaining: 749ms\n",
      "50:\tlearn: 0.0702569\ttotal: 254ms\tremaining: 743ms\n",
      "51:\tlearn: 0.0693003\ttotal: 259ms\tremaining: 738ms\n",
      "52:\tlearn: 0.0685501\ttotal: 265ms\tremaining: 735ms\n",
      "53:\tlearn: 0.0667787\ttotal: 270ms\tremaining: 729ms\n",
      "54:\tlearn: 0.0663345\ttotal: 275ms\tremaining: 725ms\n",
      "55:\tlearn: 0.0655487\ttotal: 280ms\tremaining: 721ms\n",
      "56:\tlearn: 0.0648106\ttotal: 286ms\tremaining: 717ms\n",
      "57:\tlearn: 0.0638930\ttotal: 290ms\tremaining: 711ms\n",
      "58:\tlearn: 0.0626947\ttotal: 296ms\tremaining: 707ms\n",
      "59:\tlearn: 0.0624485\ttotal: 301ms\tremaining: 702ms\n",
      "60:\tlearn: 0.0624136\ttotal: 304ms\tremaining: 692ms\n",
      "61:\tlearn: 0.0613084\ttotal: 308ms\tremaining: 686ms\n",
      "62:\tlearn: 0.0608431\ttotal: 313ms\tremaining: 680ms\n",
      "63:\tlearn: 0.0604203\ttotal: 318ms\tremaining: 676ms\n",
      "64:\tlearn: 0.0599083\ttotal: 323ms\tremaining: 671ms\n",
      "65:\tlearn: 0.0586245\ttotal: 328ms\tremaining: 666ms\n",
      "66:\tlearn: 0.0580600\ttotal: 333ms\tremaining: 662ms\n",
      "67:\tlearn: 0.0576517\ttotal: 338ms\tremaining: 656ms\n",
      "68:\tlearn: 0.0567743\ttotal: 343ms\tremaining: 651ms\n",
      "69:\tlearn: 0.0557408\ttotal: 348ms\tremaining: 646ms\n",
      "70:\tlearn: 0.0548143\ttotal: 353ms\tremaining: 641ms\n",
      "71:\tlearn: 0.0541467\ttotal: 357ms\tremaining: 635ms\n",
      "72:\tlearn: 0.0533484\ttotal: 363ms\tremaining: 631ms\n",
      "73:\tlearn: 0.0528523\ttotal: 368ms\tremaining: 627ms\n",
      "74:\tlearn: 0.0524215\ttotal: 373ms\tremaining: 622ms\n",
      "75:\tlearn: 0.0517513\ttotal: 378ms\tremaining: 616ms\n",
      "76:\tlearn: 0.0513384\ttotal: 383ms\tremaining: 612ms\n",
      "77:\tlearn: 0.0508951\ttotal: 388ms\tremaining: 607ms\n",
      "78:\tlearn: 0.0502874\ttotal: 393ms\tremaining: 602ms\n",
      "79:\tlearn: 0.0492335\ttotal: 398ms\tremaining: 597ms\n",
      "80:\tlearn: 0.0487026\ttotal: 403ms\tremaining: 593ms\n",
      "81:\tlearn: 0.0483448\ttotal: 408ms\tremaining: 587ms\n",
      "82:\tlearn: 0.0480940\ttotal: 414ms\tremaining: 584ms\n",
      "83:\tlearn: 0.0476894\ttotal: 418ms\tremaining: 578ms\n",
      "84:\tlearn: 0.0473236\ttotal: 424ms\tremaining: 574ms\n",
      "85:\tlearn: 0.0468390\ttotal: 429ms\tremaining: 569ms\n",
      "86:\tlearn: 0.0467597\ttotal: 434ms\tremaining: 563ms\n",
      "87:\tlearn: 0.0460157\ttotal: 439ms\tremaining: 558ms\n",
      "88:\tlearn: 0.0454724\ttotal: 444ms\tremaining: 554ms\n",
      "89:\tlearn: 0.0448255\ttotal: 449ms\tremaining: 549ms\n",
      "90:\tlearn: 0.0443894\ttotal: 455ms\tremaining: 545ms\n",
      "91:\tlearn: 0.0441705\ttotal: 460ms\tremaining: 539ms\n",
      "92:\tlearn: 0.0436211\ttotal: 465ms\tremaining: 536ms\n",
      "93:\tlearn: 0.0434298\ttotal: 470ms\tremaining: 530ms\n",
      "94:\tlearn: 0.0427485\ttotal: 476ms\tremaining: 526ms\n",
      "95:\tlearn: 0.0423475\ttotal: 480ms\tremaining: 520ms\n",
      "96:\tlearn: 0.0416827\ttotal: 485ms\tremaining: 515ms\n",
      "97:\tlearn: 0.0408684\ttotal: 489ms\tremaining: 509ms\n",
      "98:\tlearn: 0.0405402\ttotal: 494ms\tremaining: 504ms\n",
      "99:\tlearn: 0.0402844\ttotal: 500ms\tremaining: 500ms\n",
      "100:\tlearn: 0.0397979\ttotal: 505ms\tremaining: 495ms\n",
      "101:\tlearn: 0.0394761\ttotal: 510ms\tremaining: 490ms\n",
      "102:\tlearn: 0.0390409\ttotal: 515ms\tremaining: 485ms\n",
      "103:\tlearn: 0.0384325\ttotal: 520ms\tremaining: 480ms\n",
      "104:\tlearn: 0.0380533\ttotal: 525ms\tremaining: 475ms\n",
      "105:\tlearn: 0.0375945\ttotal: 530ms\tremaining: 470ms\n",
      "106:\tlearn: 0.0373801\ttotal: 535ms\tremaining: 465ms\n",
      "107:\tlearn: 0.0368279\ttotal: 540ms\tremaining: 460ms\n",
      "108:\tlearn: 0.0367406\ttotal: 546ms\tremaining: 456ms\n",
      "109:\tlearn: 0.0365068\ttotal: 551ms\tremaining: 451ms\n",
      "110:\tlearn: 0.0361151\ttotal: 556ms\tremaining: 446ms\n",
      "111:\tlearn: 0.0359673\ttotal: 561ms\tremaining: 441ms\n",
      "112:\tlearn: 0.0357404\ttotal: 567ms\tremaining: 437ms\n",
      "113:\tlearn: 0.0355461\ttotal: 572ms\tremaining: 431ms\n",
      "114:\tlearn: 0.0348284\ttotal: 577ms\tremaining: 426ms\n",
      "115:\tlearn: 0.0345366\ttotal: 582ms\tremaining: 421ms\n",
      "116:\tlearn: 0.0344097\ttotal: 587ms\tremaining: 416ms\n",
      "117:\tlearn: 0.0340008\ttotal: 592ms\tremaining: 411ms\n",
      "118:\tlearn: 0.0335944\ttotal: 596ms\tremaining: 406ms\n",
      "119:\tlearn: 0.0331703\ttotal: 602ms\tremaining: 401ms\n",
      "120:\tlearn: 0.0328212\ttotal: 607ms\tremaining: 396ms\n",
      "121:\tlearn: 0.0322309\ttotal: 612ms\tremaining: 391ms\n",
      "122:\tlearn: 0.0318301\ttotal: 617ms\tremaining: 386ms\n",
      "123:\tlearn: 0.0313851\ttotal: 622ms\tremaining: 381ms\n",
      "124:\tlearn: 0.0310733\ttotal: 627ms\tremaining: 376ms\n",
      "125:\tlearn: 0.0309242\ttotal: 632ms\tremaining: 371ms\n",
      "126:\tlearn: 0.0308219\ttotal: 637ms\tremaining: 366ms\n",
      "127:\tlearn: 0.0304362\ttotal: 642ms\tremaining: 361ms\n",
      "128:\tlearn: 0.0301064\ttotal: 649ms\tremaining: 357ms\n",
      "129:\tlearn: 0.0298747\ttotal: 653ms\tremaining: 352ms\n",
      "130:\tlearn: 0.0295287\ttotal: 658ms\tremaining: 346ms\n",
      "131:\tlearn: 0.0294158\ttotal: 663ms\tremaining: 341ms\n",
      "132:\tlearn: 0.0290795\ttotal: 668ms\tremaining: 336ms\n",
      "133:\tlearn: 0.0287460\ttotal: 673ms\tremaining: 332ms\n",
      "134:\tlearn: 0.0284306\ttotal: 679ms\tremaining: 327ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135:\tlearn: 0.0281474\ttotal: 683ms\tremaining: 322ms\n",
      "136:\tlearn: 0.0277375\ttotal: 689ms\tremaining: 317ms\n",
      "137:\tlearn: 0.0275806\ttotal: 694ms\tremaining: 312ms\n",
      "138:\tlearn: 0.0272315\ttotal: 699ms\tremaining: 307ms\n",
      "139:\tlearn: 0.0269619\ttotal: 704ms\tremaining: 302ms\n",
      "140:\tlearn: 0.0266043\ttotal: 709ms\tremaining: 297ms\n",
      "141:\tlearn: 0.0264239\ttotal: 714ms\tremaining: 291ms\n",
      "142:\tlearn: 0.0260476\ttotal: 718ms\tremaining: 286ms\n",
      "143:\tlearn: 0.0257963\ttotal: 723ms\tremaining: 281ms\n",
      "144:\tlearn: 0.0256380\ttotal: 727ms\tremaining: 276ms\n",
      "145:\tlearn: 0.0253765\ttotal: 732ms\tremaining: 271ms\n",
      "146:\tlearn: 0.0253248\ttotal: 737ms\tremaining: 266ms\n",
      "147:\tlearn: 0.0250103\ttotal: 742ms\tremaining: 261ms\n",
      "148:\tlearn: 0.0247996\ttotal: 748ms\tremaining: 256ms\n",
      "149:\tlearn: 0.0245623\ttotal: 752ms\tremaining: 251ms\n",
      "150:\tlearn: 0.0243107\ttotal: 757ms\tremaining: 246ms\n",
      "151:\tlearn: 0.0240235\ttotal: 762ms\tremaining: 241ms\n",
      "152:\tlearn: 0.0239686\ttotal: 767ms\tremaining: 236ms\n",
      "153:\tlearn: 0.0236893\ttotal: 772ms\tremaining: 231ms\n",
      "154:\tlearn: 0.0235051\ttotal: 777ms\tremaining: 226ms\n",
      "155:\tlearn: 0.0233071\ttotal: 782ms\tremaining: 220ms\n",
      "156:\tlearn: 0.0229933\ttotal: 787ms\tremaining: 216ms\n",
      "157:\tlearn: 0.0228884\ttotal: 791ms\tremaining: 210ms\n",
      "158:\tlearn: 0.0226838\ttotal: 796ms\tremaining: 205ms\n",
      "159:\tlearn: 0.0224830\ttotal: 801ms\tremaining: 200ms\n",
      "160:\tlearn: 0.0222571\ttotal: 806ms\tremaining: 195ms\n",
      "161:\tlearn: 0.0219967\ttotal: 812ms\tremaining: 190ms\n",
      "162:\tlearn: 0.0219044\ttotal: 818ms\tremaining: 186ms\n",
      "163:\tlearn: 0.0217621\ttotal: 823ms\tremaining: 181ms\n",
      "164:\tlearn: 0.0214310\ttotal: 828ms\tremaining: 176ms\n",
      "165:\tlearn: 0.0213115\ttotal: 833ms\tremaining: 171ms\n",
      "166:\tlearn: 0.0212766\ttotal: 838ms\tremaining: 165ms\n",
      "167:\tlearn: 0.0211936\ttotal: 842ms\tremaining: 160ms\n",
      "168:\tlearn: 0.0210905\ttotal: 847ms\tremaining: 155ms\n",
      "169:\tlearn: 0.0207928\ttotal: 852ms\tremaining: 150ms\n",
      "170:\tlearn: 0.0207030\ttotal: 857ms\tremaining: 145ms\n",
      "171:\tlearn: 0.0204957\ttotal: 862ms\tremaining: 140ms\n",
      "172:\tlearn: 0.0203413\ttotal: 867ms\tremaining: 135ms\n",
      "173:\tlearn: 0.0201021\ttotal: 872ms\tremaining: 130ms\n",
      "174:\tlearn: 0.0199827\ttotal: 877ms\tremaining: 125ms\n",
      "175:\tlearn: 0.0198505\ttotal: 882ms\tremaining: 120ms\n",
      "176:\tlearn: 0.0195813\ttotal: 887ms\tremaining: 115ms\n",
      "177:\tlearn: 0.0193888\ttotal: 892ms\tremaining: 110ms\n",
      "178:\tlearn: 0.0190913\ttotal: 898ms\tremaining: 105ms\n",
      "179:\tlearn: 0.0189424\ttotal: 903ms\tremaining: 100ms\n",
      "180:\tlearn: 0.0187595\ttotal: 908ms\tremaining: 95.4ms\n",
      "181:\tlearn: 0.0184826\ttotal: 913ms\tremaining: 90.3ms\n",
      "182:\tlearn: 0.0183251\ttotal: 919ms\tremaining: 85.3ms\n",
      "183:\tlearn: 0.0181625\ttotal: 923ms\tremaining: 80.3ms\n",
      "184:\tlearn: 0.0180256\ttotal: 929ms\tremaining: 75.3ms\n",
      "185:\tlearn: 0.0179295\ttotal: 934ms\tremaining: 70.3ms\n",
      "186:\tlearn: 0.0178079\ttotal: 939ms\tremaining: 65.3ms\n",
      "187:\tlearn: 0.0177023\ttotal: 944ms\tremaining: 60.2ms\n",
      "188:\tlearn: 0.0176499\ttotal: 949ms\tremaining: 55.2ms\n",
      "189:\tlearn: 0.0175250\ttotal: 953ms\tremaining: 50.2ms\n",
      "190:\tlearn: 0.0174019\ttotal: 958ms\tremaining: 45.1ms\n",
      "191:\tlearn: 0.0172803\ttotal: 963ms\tremaining: 40.1ms\n",
      "192:\tlearn: 0.0172279\ttotal: 968ms\tremaining: 35.1ms\n",
      "193:\tlearn: 0.0170397\ttotal: 973ms\tremaining: 30.1ms\n",
      "194:\tlearn: 0.0169395\ttotal: 979ms\tremaining: 25.1ms\n",
      "195:\tlearn: 0.0168614\ttotal: 983ms\tremaining: 20.1ms\n",
      "196:\tlearn: 0.0167606\ttotal: 989ms\tremaining: 15.1ms\n",
      "197:\tlearn: 0.0166601\ttotal: 994ms\tremaining: 10ms\n",
      "198:\tlearn: 0.0165596\ttotal: 999ms\tremaining: 5.02ms\n",
      "199:\tlearn: 0.0164763\ttotal: 1s\tremaining: 0us\n",
      "0:\tlearn: 0.5797768\ttotal: 3.28ms\tremaining: 653ms\n",
      "1:\tlearn: 0.4953808\ttotal: 6.39ms\tremaining: 632ms\n",
      "2:\tlearn: 0.4304256\ttotal: 9.59ms\tremaining: 630ms\n",
      "3:\tlearn: 0.3741064\ttotal: 13ms\tremaining: 639ms\n",
      "4:\tlearn: 0.3416712\ttotal: 16.5ms\tremaining: 645ms\n",
      "5:\tlearn: 0.3203208\ttotal: 19.9ms\tremaining: 645ms\n",
      "6:\tlearn: 0.3015507\ttotal: 23.4ms\tremaining: 646ms\n",
      "7:\tlearn: 0.2821341\ttotal: 26.9ms\tremaining: 646ms\n",
      "8:\tlearn: 0.2689275\ttotal: 30.8ms\tremaining: 653ms\n",
      "9:\tlearn: 0.2479917\ttotal: 34.5ms\tremaining: 655ms\n",
      "10:\tlearn: 0.2384000\ttotal: 38.2ms\tremaining: 656ms\n",
      "11:\tlearn: 0.2310278\ttotal: 41.9ms\tremaining: 657ms\n",
      "12:\tlearn: 0.2253454\ttotal: 45.5ms\tremaining: 655ms\n",
      "13:\tlearn: 0.2203254\ttotal: 49.5ms\tremaining: 658ms\n",
      "14:\tlearn: 0.2152816\ttotal: 53.1ms\tremaining: 655ms\n",
      "15:\tlearn: 0.2054597\ttotal: 56.8ms\tremaining: 654ms\n",
      "16:\tlearn: 0.2014208\ttotal: 60.4ms\tremaining: 650ms\n",
      "17:\tlearn: 0.1969901\ttotal: 65.1ms\tremaining: 658ms\n",
      "18:\tlearn: 0.1935699\ttotal: 69.9ms\tremaining: 666ms\n",
      "19:\tlearn: 0.1862380\ttotal: 73.6ms\tremaining: 662ms\n",
      "20:\tlearn: 0.1833933\ttotal: 77.4ms\tremaining: 659ms\n",
      "21:\tlearn: 0.1803048\ttotal: 80.7ms\tremaining: 653ms\n",
      "22:\tlearn: 0.1761457\ttotal: 85.4ms\tremaining: 657ms\n",
      "23:\tlearn: 0.1736113\ttotal: 88.8ms\tremaining: 651ms\n",
      "24:\tlearn: 0.1712636\ttotal: 92.7ms\tremaining: 649ms\n",
      "25:\tlearn: 0.1689765\ttotal: 96.2ms\tremaining: 644ms\n",
      "26:\tlearn: 0.1649962\ttotal: 99.8ms\tremaining: 639ms\n",
      "27:\tlearn: 0.1609437\ttotal: 103ms\tremaining: 633ms\n",
      "28:\tlearn: 0.1586259\ttotal: 107ms\tremaining: 632ms\n",
      "29:\tlearn: 0.1567235\ttotal: 110ms\tremaining: 625ms\n",
      "30:\tlearn: 0.1544590\ttotal: 114ms\tremaining: 620ms\n",
      "31:\tlearn: 0.1526506\ttotal: 117ms\tremaining: 616ms\n",
      "32:\tlearn: 0.1486504\ttotal: 121ms\tremaining: 611ms\n",
      "33:\tlearn: 0.1464015\ttotal: 124ms\tremaining: 607ms\n",
      "34:\tlearn: 0.1426946\ttotal: 128ms\tremaining: 603ms\n",
      "35:\tlearn: 0.1403433\ttotal: 131ms\tremaining: 599ms\n",
      "36:\tlearn: 0.1391853\ttotal: 136ms\tremaining: 597ms\n",
      "37:\tlearn: 0.1354377\ttotal: 139ms\tremaining: 592ms\n",
      "38:\tlearn: 0.1333434\ttotal: 142ms\tremaining: 588ms\n",
      "39:\tlearn: 0.1325295\ttotal: 146ms\tremaining: 584ms\n",
      "40:\tlearn: 0.1316127\ttotal: 150ms\tremaining: 581ms\n",
      "41:\tlearn: 0.1306640\ttotal: 153ms\tremaining: 576ms\n",
      "42:\tlearn: 0.1288010\ttotal: 156ms\tremaining: 571ms\n",
      "43:\tlearn: 0.1262782\ttotal: 160ms\tremaining: 567ms\n",
      "44:\tlearn: 0.1247118\ttotal: 164ms\tremaining: 563ms\n",
      "45:\tlearn: 0.1235447\ttotal: 168ms\tremaining: 561ms\n",
      "46:\tlearn: 0.1224222\ttotal: 171ms\tremaining: 558ms\n",
      "47:\tlearn: 0.1212236\ttotal: 175ms\tremaining: 553ms\n",
      "48:\tlearn: 0.1201060\ttotal: 178ms\tremaining: 550ms\n",
      "49:\tlearn: 0.1179524\ttotal: 182ms\tremaining: 546ms\n",
      "50:\tlearn: 0.1168147\ttotal: 186ms\tremaining: 543ms\n",
      "51:\tlearn: 0.1158114\ttotal: 189ms\tremaining: 538ms\n",
      "52:\tlearn: 0.1140936\ttotal: 193ms\tremaining: 535ms\n",
      "53:\tlearn: 0.1126827\ttotal: 196ms\tremaining: 531ms\n",
      "54:\tlearn: 0.1119491\ttotal: 201ms\tremaining: 529ms\n",
      "55:\tlearn: 0.1104694\ttotal: 204ms\tremaining: 524ms\n",
      "56:\tlearn: 0.1094630\ttotal: 207ms\tremaining: 520ms\n",
      "57:\tlearn: 0.1086001\ttotal: 211ms\tremaining: 516ms\n",
      "58:\tlearn: 0.1074460\ttotal: 214ms\tremaining: 512ms\n",
      "59:\tlearn: 0.1068297\ttotal: 218ms\tremaining: 509ms\n",
      "60:\tlearn: 0.1059344\ttotal: 221ms\tremaining: 504ms\n",
      "61:\tlearn: 0.1052734\ttotal: 225ms\tremaining: 500ms\n",
      "62:\tlearn: 0.1044242\ttotal: 228ms\tremaining: 497ms\n",
      "63:\tlearn: 0.1039233\ttotal: 232ms\tremaining: 493ms\n",
      "64:\tlearn: 0.1033272\ttotal: 236ms\tremaining: 490ms\n",
      "65:\tlearn: 0.1024630\ttotal: 239ms\tremaining: 486ms\n",
      "66:\tlearn: 0.1011339\ttotal: 243ms\tremaining: 482ms\n",
      "67:\tlearn: 0.1004494\ttotal: 247ms\tremaining: 479ms\n",
      "68:\tlearn: 0.0991570\ttotal: 250ms\tremaining: 475ms\n",
      "69:\tlearn: 0.0982790\ttotal: 254ms\tremaining: 471ms\n",
      "70:\tlearn: 0.0975193\ttotal: 257ms\tremaining: 467ms\n",
      "71:\tlearn: 0.0965748\ttotal: 261ms\tremaining: 463ms\n",
      "72:\tlearn: 0.0960493\ttotal: 264ms\tremaining: 460ms\n",
      "73:\tlearn: 0.0954828\ttotal: 268ms\tremaining: 456ms\n",
      "74:\tlearn: 0.0948987\ttotal: 272ms\tremaining: 453ms\n",
      "75:\tlearn: 0.0943315\ttotal: 275ms\tremaining: 449ms\n",
      "76:\tlearn: 0.0931834\ttotal: 278ms\tremaining: 444ms\n",
      "77:\tlearn: 0.0924712\ttotal: 282ms\tremaining: 441ms\n",
      "78:\tlearn: 0.0920192\ttotal: 285ms\tremaining: 437ms\n",
      "79:\tlearn: 0.0914866\ttotal: 289ms\tremaining: 433ms\n",
      "80:\tlearn: 0.0909057\ttotal: 292ms\tremaining: 429ms\n",
      "81:\tlearn: 0.0898312\ttotal: 296ms\tremaining: 425ms\n",
      "82:\tlearn: 0.0893833\ttotal: 299ms\tremaining: 422ms\n",
      "83:\tlearn: 0.0892303\ttotal: 303ms\tremaining: 419ms\n",
      "84:\tlearn: 0.0882770\ttotal: 307ms\tremaining: 416ms\n",
      "85:\tlearn: 0.0876895\ttotal: 311ms\tremaining: 412ms\n",
      "86:\tlearn: 0.0871950\ttotal: 315ms\tremaining: 409ms\n",
      "87:\tlearn: 0.0869228\ttotal: 318ms\tremaining: 405ms\n",
      "88:\tlearn: 0.0865546\ttotal: 322ms\tremaining: 401ms\n",
      "89:\tlearn: 0.0860325\ttotal: 325ms\tremaining: 397ms\n",
      "90:\tlearn: 0.0856687\ttotal: 329ms\tremaining: 394ms\n",
      "91:\tlearn: 0.0851844\ttotal: 334ms\tremaining: 392ms\n",
      "92:\tlearn: 0.0846488\ttotal: 338ms\tremaining: 389ms\n",
      "93:\tlearn: 0.0837259\ttotal: 342ms\tremaining: 385ms\n",
      "94:\tlearn: 0.0829767\ttotal: 345ms\tremaining: 382ms\n",
      "95:\tlearn: 0.0825378\ttotal: 349ms\tremaining: 378ms\n",
      "96:\tlearn: 0.0822534\ttotal: 353ms\tremaining: 375ms\n",
      "97:\tlearn: 0.0817259\ttotal: 357ms\tremaining: 371ms\n",
      "98:\tlearn: 0.0813538\ttotal: 360ms\tremaining: 368ms\n",
      "99:\tlearn: 0.0809611\ttotal: 364ms\tremaining: 364ms\n",
      "100:\tlearn: 0.0803888\ttotal: 368ms\tremaining: 361ms\n",
      "101:\tlearn: 0.0800852\ttotal: 372ms\tremaining: 357ms\n",
      "102:\tlearn: 0.0794766\ttotal: 375ms\tremaining: 353ms\n",
      "103:\tlearn: 0.0788533\ttotal: 379ms\tremaining: 350ms\n",
      "104:\tlearn: 0.0783304\ttotal: 383ms\tremaining: 346ms\n",
      "105:\tlearn: 0.0781014\ttotal: 386ms\tremaining: 342ms\n",
      "106:\tlearn: 0.0774467\ttotal: 390ms\tremaining: 339ms\n",
      "107:\tlearn: 0.0769284\ttotal: 394ms\tremaining: 335ms\n",
      "108:\tlearn: 0.0767333\ttotal: 397ms\tremaining: 332ms\n",
      "109:\tlearn: 0.0763950\ttotal: 401ms\tremaining: 328ms\n",
      "110:\tlearn: 0.0761450\ttotal: 405ms\tremaining: 325ms\n",
      "111:\tlearn: 0.0757637\ttotal: 408ms\tremaining: 321ms\n",
      "112:\tlearn: 0.0753579\ttotal: 412ms\tremaining: 317ms\n",
      "113:\tlearn: 0.0751080\ttotal: 415ms\tremaining: 313ms\n",
      "114:\tlearn: 0.0742112\ttotal: 420ms\tremaining: 310ms\n",
      "115:\tlearn: 0.0736220\ttotal: 423ms\tremaining: 307ms\n",
      "116:\tlearn: 0.0733882\ttotal: 427ms\tremaining: 303ms\n",
      "117:\tlearn: 0.0728573\ttotal: 431ms\tremaining: 299ms\n",
      "118:\tlearn: 0.0725230\ttotal: 434ms\tremaining: 296ms\n",
      "119:\tlearn: 0.0723497\ttotal: 438ms\tremaining: 292ms\n",
      "120:\tlearn: 0.0723482\ttotal: 443ms\tremaining: 289ms\n",
      "121:\tlearn: 0.0720000\ttotal: 447ms\tremaining: 286ms\n",
      "122:\tlearn: 0.0716845\ttotal: 450ms\tremaining: 282ms\n",
      "123:\tlearn: 0.0714697\ttotal: 454ms\tremaining: 278ms\n",
      "124:\tlearn: 0.0711495\ttotal: 457ms\tremaining: 274ms\n",
      "125:\tlearn: 0.0704367\ttotal: 461ms\tremaining: 271ms\n",
      "126:\tlearn: 0.0702420\ttotal: 464ms\tremaining: 267ms\n",
      "127:\tlearn: 0.0699636\ttotal: 468ms\tremaining: 263ms\n",
      "128:\tlearn: 0.0696307\ttotal: 471ms\tremaining: 259ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129:\tlearn: 0.0693053\ttotal: 475ms\tremaining: 256ms\n",
      "130:\tlearn: 0.0690550\ttotal: 478ms\tremaining: 252ms\n",
      "131:\tlearn: 0.0685984\ttotal: 482ms\tremaining: 248ms\n",
      "132:\tlearn: 0.0684182\ttotal: 485ms\tremaining: 245ms\n",
      "133:\tlearn: 0.0682335\ttotal: 489ms\tremaining: 241ms\n",
      "134:\tlearn: 0.0680519\ttotal: 493ms\tremaining: 237ms\n",
      "135:\tlearn: 0.0677669\ttotal: 497ms\tremaining: 234ms\n",
      "136:\tlearn: 0.0674847\ttotal: 500ms\tremaining: 230ms\n",
      "137:\tlearn: 0.0673411\ttotal: 504ms\tremaining: 226ms\n",
      "138:\tlearn: 0.0670158\ttotal: 507ms\tremaining: 223ms\n",
      "139:\tlearn: 0.0667821\ttotal: 511ms\tremaining: 219ms\n",
      "140:\tlearn: 0.0664906\ttotal: 514ms\tremaining: 215ms\n",
      "141:\tlearn: 0.0662290\ttotal: 518ms\tremaining: 212ms\n",
      "142:\tlearn: 0.0659928\ttotal: 521ms\tremaining: 208ms\n",
      "143:\tlearn: 0.0656658\ttotal: 525ms\tremaining: 204ms\n",
      "144:\tlearn: 0.0651090\ttotal: 529ms\tremaining: 201ms\n",
      "145:\tlearn: 0.0649723\ttotal: 533ms\tremaining: 197ms\n",
      "146:\tlearn: 0.0647896\ttotal: 537ms\tremaining: 194ms\n",
      "147:\tlearn: 0.0645355\ttotal: 540ms\tremaining: 190ms\n",
      "148:\tlearn: 0.0641741\ttotal: 544ms\tremaining: 186ms\n",
      "149:\tlearn: 0.0637909\ttotal: 547ms\tremaining: 182ms\n",
      "150:\tlearn: 0.0637909\ttotal: 550ms\tremaining: 178ms\n",
      "151:\tlearn: 0.0636693\ttotal: 553ms\tremaining: 175ms\n",
      "152:\tlearn: 0.0634228\ttotal: 556ms\tremaining: 171ms\n",
      "153:\tlearn: 0.0632366\ttotal: 560ms\tremaining: 167ms\n",
      "154:\tlearn: 0.0632344\ttotal: 563ms\tremaining: 164ms\n",
      "155:\tlearn: 0.0630150\ttotal: 567ms\tremaining: 160ms\n",
      "156:\tlearn: 0.0626968\ttotal: 571ms\tremaining: 156ms\n",
      "157:\tlearn: 0.0622522\ttotal: 575ms\tremaining: 153ms\n",
      "158:\tlearn: 0.0620940\ttotal: 579ms\tremaining: 149ms\n",
      "159:\tlearn: 0.0618875\ttotal: 583ms\tremaining: 146ms\n",
      "160:\tlearn: 0.0618141\ttotal: 586ms\tremaining: 142ms\n",
      "161:\tlearn: 0.0615646\ttotal: 590ms\tremaining: 138ms\n",
      "162:\tlearn: 0.0611178\ttotal: 593ms\tremaining: 135ms\n",
      "163:\tlearn: 0.0606665\ttotal: 597ms\tremaining: 131ms\n",
      "164:\tlearn: 0.0604395\ttotal: 600ms\tremaining: 127ms\n",
      "165:\tlearn: 0.0601890\ttotal: 605ms\tremaining: 124ms\n",
      "166:\tlearn: 0.0600942\ttotal: 609ms\tremaining: 120ms\n",
      "167:\tlearn: 0.0598555\ttotal: 613ms\tremaining: 117ms\n",
      "168:\tlearn: 0.0597652\ttotal: 616ms\tremaining: 113ms\n",
      "169:\tlearn: 0.0595741\ttotal: 620ms\tremaining: 109ms\n",
      "170:\tlearn: 0.0592036\ttotal: 623ms\tremaining: 106ms\n",
      "171:\tlearn: 0.0589430\ttotal: 627ms\tremaining: 102ms\n",
      "172:\tlearn: 0.0589306\ttotal: 631ms\tremaining: 98.5ms\n",
      "173:\tlearn: 0.0588223\ttotal: 635ms\tremaining: 94.9ms\n",
      "174:\tlearn: 0.0587092\ttotal: 639ms\tremaining: 91.2ms\n",
      "175:\tlearn: 0.0585003\ttotal: 643ms\tremaining: 87.6ms\n",
      "176:\tlearn: 0.0582466\ttotal: 647ms\tremaining: 84ms\n",
      "177:\tlearn: 0.0582062\ttotal: 651ms\tremaining: 80.4ms\n",
      "178:\tlearn: 0.0582020\ttotal: 654ms\tremaining: 76.7ms\n",
      "179:\tlearn: 0.0581448\ttotal: 658ms\tremaining: 73.1ms\n",
      "180:\tlearn: 0.0578269\ttotal: 662ms\tremaining: 69.5ms\n",
      "181:\tlearn: 0.0575627\ttotal: 665ms\tremaining: 65.8ms\n",
      "182:\tlearn: 0.0573948\ttotal: 669ms\tremaining: 62.1ms\n",
      "183:\tlearn: 0.0571807\ttotal: 673ms\tremaining: 58.5ms\n",
      "184:\tlearn: 0.0571506\ttotal: 678ms\tremaining: 54.9ms\n",
      "185:\tlearn: 0.0570986\ttotal: 683ms\tremaining: 51.4ms\n",
      "186:\tlearn: 0.0569670\ttotal: 687ms\tremaining: 47.7ms\n",
      "187:\tlearn: 0.0568498\ttotal: 690ms\tremaining: 44ms\n",
      "188:\tlearn: 0.0568277\ttotal: 693ms\tremaining: 40.4ms\n",
      "189:\tlearn: 0.0565142\ttotal: 697ms\tremaining: 36.7ms\n",
      "190:\tlearn: 0.0563593\ttotal: 701ms\tremaining: 33ms\n",
      "191:\tlearn: 0.0561832\ttotal: 704ms\tremaining: 29.3ms\n",
      "192:\tlearn: 0.0559811\ttotal: 708ms\tremaining: 25.7ms\n",
      "193:\tlearn: 0.0557643\ttotal: 712ms\tremaining: 22ms\n",
      "194:\tlearn: 0.0556819\ttotal: 715ms\tremaining: 18.3ms\n",
      "195:\tlearn: 0.0556278\ttotal: 718ms\tremaining: 14.7ms\n",
      "196:\tlearn: 0.0555956\ttotal: 722ms\tremaining: 11ms\n",
      "197:\tlearn: 0.0555257\ttotal: 725ms\tremaining: 7.33ms\n",
      "198:\tlearn: 0.0554976\ttotal: 729ms\tremaining: 3.66ms\n",
      "199:\tlearn: 0.0554207\ttotal: 733ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=&lt;catboost.core.CatBoostClassifier object at 0x177680990&gt;,\n",
       "             param_grid={&#x27;depth&#x27;: [4, 6, 8], &#x27;iterations&#x27;: [50, 100, 200],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=&lt;catboost.core.CatBoostClassifier object at 0x177680990&gt;,\n",
       "             param_grid={&#x27;depth&#x27;: [4, 6, 8], &#x27;iterations&#x27;: [50, 100, 200],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: CatBoostClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x177680990&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x177680990&gt;</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<catboost.core.CatBoostClassifier object at 0x177680990>,\n",
       "             param_grid={'depth': [4, 6, 8], 'iterations': [50, 100, 200],\n",
       "                         'learning_rate': [0.01, 0.05, 0.1]},\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the CatBoostClassifier\n",
    "cat = CatBoostClassifier()\n",
    "\n",
    "# Defining the parameter grid\n",
    "param_grid = {\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'iterations': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Setting up GridSearchCV with CatBoostClassifier\n",
    "grid_search = GridSearchCV(cat, param_grid=param_grid, scoring='recall', cv=3, verbose=1)\n",
    "\n",
    "# Fitting GridSearchCV with training data\n",
    "grid_search.fit(X_train, y_train, cat_features=categorical_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'depth': 4, 'iterations': 200, 'learning_rate': 0.1}\n",
      "Best Recall Score: 0.890937019969278\n"
     ]
    }
   ],
   "source": [
    "# Print best parameters and best recall score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Recall Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5797768\ttotal: 7.38ms\tremaining: 1.47s\n",
      "1:\tlearn: 0.4953808\ttotal: 12.7ms\tremaining: 1.26s\n",
      "2:\tlearn: 0.4304256\ttotal: 18.1ms\tremaining: 1.19s\n",
      "3:\tlearn: 0.3741064\ttotal: 24.7ms\tremaining: 1.21s\n",
      "4:\tlearn: 0.3416712\ttotal: 29.8ms\tremaining: 1.16s\n",
      "5:\tlearn: 0.3203208\ttotal: 35.9ms\tremaining: 1.16s\n",
      "6:\tlearn: 0.3015507\ttotal: 41.5ms\tremaining: 1.14s\n",
      "7:\tlearn: 0.2821341\ttotal: 45.6ms\tremaining: 1.09s\n",
      "8:\tlearn: 0.2689275\ttotal: 50ms\tremaining: 1.06s\n",
      "9:\tlearn: 0.2479917\ttotal: 55.2ms\tremaining: 1.05s\n",
      "10:\tlearn: 0.2384000\ttotal: 59.7ms\tremaining: 1.02s\n",
      "11:\tlearn: 0.2310278\ttotal: 64.5ms\tremaining: 1.01s\n",
      "12:\tlearn: 0.2253454\ttotal: 68.1ms\tremaining: 979ms\n",
      "13:\tlearn: 0.2203254\ttotal: 72.8ms\tremaining: 968ms\n",
      "14:\tlearn: 0.2152816\ttotal: 76.4ms\tremaining: 942ms\n",
      "15:\tlearn: 0.2054597\ttotal: 81ms\tremaining: 932ms\n",
      "16:\tlearn: 0.2014208\ttotal: 85.1ms\tremaining: 916ms\n",
      "17:\tlearn: 0.1969901\ttotal: 89.1ms\tremaining: 901ms\n",
      "18:\tlearn: 0.1935699\ttotal: 92.3ms\tremaining: 879ms\n",
      "19:\tlearn: 0.1862380\ttotal: 95.5ms\tremaining: 859ms\n",
      "20:\tlearn: 0.1833933\ttotal: 99ms\tremaining: 844ms\n",
      "21:\tlearn: 0.1803048\ttotal: 102ms\tremaining: 828ms\n",
      "22:\tlearn: 0.1761457\ttotal: 106ms\tremaining: 814ms\n",
      "23:\tlearn: 0.1736113\ttotal: 110ms\tremaining: 804ms\n",
      "24:\tlearn: 0.1712636\ttotal: 113ms\tremaining: 793ms\n",
      "25:\tlearn: 0.1689765\ttotal: 117ms\tremaining: 784ms\n",
      "26:\tlearn: 0.1649962\ttotal: 121ms\tremaining: 776ms\n",
      "27:\tlearn: 0.1609437\ttotal: 125ms\tremaining: 765ms\n",
      "28:\tlearn: 0.1586259\ttotal: 129ms\tremaining: 758ms\n",
      "29:\tlearn: 0.1567235\ttotal: 133ms\tremaining: 752ms\n",
      "30:\tlearn: 0.1544590\ttotal: 136ms\tremaining: 743ms\n",
      "31:\tlearn: 0.1526506\ttotal: 140ms\tremaining: 735ms\n",
      "32:\tlearn: 0.1486504\ttotal: 145ms\tremaining: 732ms\n",
      "33:\tlearn: 0.1464015\ttotal: 148ms\tremaining: 724ms\n",
      "34:\tlearn: 0.1426946\ttotal: 152ms\tremaining: 716ms\n",
      "35:\tlearn: 0.1403433\ttotal: 155ms\tremaining: 708ms\n",
      "36:\tlearn: 0.1391853\ttotal: 159ms\tremaining: 702ms\n",
      "37:\tlearn: 0.1354377\ttotal: 163ms\tremaining: 694ms\n",
      "38:\tlearn: 0.1333434\ttotal: 167ms\tremaining: 688ms\n",
      "39:\tlearn: 0.1325295\ttotal: 170ms\tremaining: 681ms\n",
      "40:\tlearn: 0.1316127\ttotal: 174ms\tremaining: 676ms\n",
      "41:\tlearn: 0.1306640\ttotal: 178ms\tremaining: 670ms\n",
      "42:\tlearn: 0.1288010\ttotal: 182ms\tremaining: 663ms\n",
      "43:\tlearn: 0.1262782\ttotal: 185ms\tremaining: 657ms\n",
      "44:\tlearn: 0.1247118\ttotal: 189ms\tremaining: 652ms\n",
      "45:\tlearn: 0.1235447\ttotal: 193ms\tremaining: 646ms\n",
      "46:\tlearn: 0.1224222\ttotal: 197ms\tremaining: 643ms\n",
      "47:\tlearn: 0.1212236\ttotal: 201ms\tremaining: 638ms\n",
      "48:\tlearn: 0.1201060\ttotal: 205ms\tremaining: 632ms\n",
      "49:\tlearn: 0.1179524\ttotal: 209ms\tremaining: 626ms\n",
      "50:\tlearn: 0.1168147\ttotal: 213ms\tremaining: 621ms\n",
      "51:\tlearn: 0.1158114\ttotal: 216ms\tremaining: 615ms\n",
      "52:\tlearn: 0.1140936\ttotal: 220ms\tremaining: 610ms\n",
      "53:\tlearn: 0.1126827\ttotal: 223ms\tremaining: 604ms\n",
      "54:\tlearn: 0.1119491\ttotal: 227ms\tremaining: 599ms\n",
      "55:\tlearn: 0.1104694\ttotal: 231ms\tremaining: 593ms\n",
      "56:\tlearn: 0.1094630\ttotal: 234ms\tremaining: 587ms\n",
      "57:\tlearn: 0.1086001\ttotal: 238ms\tremaining: 582ms\n",
      "58:\tlearn: 0.1074460\ttotal: 242ms\tremaining: 577ms\n",
      "59:\tlearn: 0.1068297\ttotal: 246ms\tremaining: 574ms\n",
      "60:\tlearn: 0.1059344\ttotal: 250ms\tremaining: 569ms\n",
      "61:\tlearn: 0.1052734\ttotal: 253ms\tremaining: 563ms\n",
      "62:\tlearn: 0.1044242\ttotal: 257ms\tremaining: 558ms\n",
      "63:\tlearn: 0.1039233\ttotal: 260ms\tremaining: 553ms\n",
      "64:\tlearn: 0.1033272\ttotal: 264ms\tremaining: 548ms\n",
      "65:\tlearn: 0.1024630\ttotal: 268ms\tremaining: 543ms\n",
      "66:\tlearn: 0.1011339\ttotal: 272ms\tremaining: 539ms\n",
      "67:\tlearn: 0.1004494\ttotal: 275ms\tremaining: 535ms\n",
      "68:\tlearn: 0.0991570\ttotal: 279ms\tremaining: 530ms\n",
      "69:\tlearn: 0.0982790\ttotal: 283ms\tremaining: 525ms\n",
      "70:\tlearn: 0.0975193\ttotal: 288ms\tremaining: 522ms\n",
      "71:\tlearn: 0.0965748\ttotal: 291ms\tremaining: 517ms\n",
      "72:\tlearn: 0.0960493\ttotal: 294ms\tremaining: 512ms\n",
      "73:\tlearn: 0.0954828\ttotal: 298ms\tremaining: 507ms\n",
      "74:\tlearn: 0.0948987\ttotal: 302ms\tremaining: 504ms\n",
      "75:\tlearn: 0.0943315\ttotal: 306ms\tremaining: 499ms\n",
      "76:\tlearn: 0.0931834\ttotal: 309ms\tremaining: 494ms\n",
      "77:\tlearn: 0.0924712\ttotal: 313ms\tremaining: 489ms\n",
      "78:\tlearn: 0.0920192\ttotal: 316ms\tremaining: 484ms\n",
      "79:\tlearn: 0.0914866\ttotal: 320ms\tremaining: 480ms\n",
      "80:\tlearn: 0.0909057\ttotal: 323ms\tremaining: 475ms\n",
      "81:\tlearn: 0.0898312\ttotal: 327ms\tremaining: 471ms\n",
      "82:\tlearn: 0.0893833\ttotal: 331ms\tremaining: 466ms\n",
      "83:\tlearn: 0.0892303\ttotal: 335ms\tremaining: 462ms\n",
      "84:\tlearn: 0.0882770\ttotal: 339ms\tremaining: 458ms\n",
      "85:\tlearn: 0.0876895\ttotal: 343ms\tremaining: 454ms\n",
      "86:\tlearn: 0.0871950\ttotal: 346ms\tremaining: 450ms\n",
      "87:\tlearn: 0.0869228\ttotal: 350ms\tremaining: 445ms\n",
      "88:\tlearn: 0.0865546\ttotal: 354ms\tremaining: 442ms\n",
      "89:\tlearn: 0.0860325\ttotal: 358ms\tremaining: 437ms\n",
      "90:\tlearn: 0.0856687\ttotal: 362ms\tremaining: 433ms\n",
      "91:\tlearn: 0.0851844\ttotal: 366ms\tremaining: 429ms\n",
      "92:\tlearn: 0.0846488\ttotal: 369ms\tremaining: 425ms\n",
      "93:\tlearn: 0.0837259\ttotal: 373ms\tremaining: 421ms\n",
      "94:\tlearn: 0.0829767\ttotal: 376ms\tremaining: 416ms\n",
      "95:\tlearn: 0.0825378\ttotal: 380ms\tremaining: 412ms\n",
      "96:\tlearn: 0.0822534\ttotal: 384ms\tremaining: 408ms\n",
      "97:\tlearn: 0.0817259\ttotal: 388ms\tremaining: 403ms\n",
      "98:\tlearn: 0.0813538\ttotal: 391ms\tremaining: 399ms\n",
      "99:\tlearn: 0.0809611\ttotal: 395ms\tremaining: 395ms\n",
      "100:\tlearn: 0.0803888\ttotal: 399ms\tremaining: 391ms\n",
      "101:\tlearn: 0.0800852\ttotal: 402ms\tremaining: 386ms\n",
      "102:\tlearn: 0.0794766\ttotal: 406ms\tremaining: 382ms\n",
      "103:\tlearn: 0.0788533\ttotal: 409ms\tremaining: 378ms\n",
      "104:\tlearn: 0.0783304\ttotal: 413ms\tremaining: 374ms\n",
      "105:\tlearn: 0.0781014\ttotal: 417ms\tremaining: 370ms\n",
      "106:\tlearn: 0.0774467\ttotal: 421ms\tremaining: 366ms\n",
      "107:\tlearn: 0.0769284\ttotal: 426ms\tremaining: 363ms\n",
      "108:\tlearn: 0.0767333\ttotal: 429ms\tremaining: 358ms\n",
      "109:\tlearn: 0.0763950\ttotal: 434ms\tremaining: 355ms\n",
      "110:\tlearn: 0.0761450\ttotal: 438ms\tremaining: 351ms\n",
      "111:\tlearn: 0.0757637\ttotal: 442ms\tremaining: 347ms\n",
      "112:\tlearn: 0.0753579\ttotal: 445ms\tremaining: 343ms\n",
      "113:\tlearn: 0.0751080\ttotal: 449ms\tremaining: 339ms\n",
      "114:\tlearn: 0.0742112\ttotal: 453ms\tremaining: 334ms\n",
      "115:\tlearn: 0.0736220\ttotal: 456ms\tremaining: 330ms\n",
      "116:\tlearn: 0.0733882\ttotal: 460ms\tremaining: 326ms\n",
      "117:\tlearn: 0.0728573\ttotal: 464ms\tremaining: 323ms\n",
      "118:\tlearn: 0.0725230\ttotal: 468ms\tremaining: 319ms\n",
      "119:\tlearn: 0.0723497\ttotal: 472ms\tremaining: 315ms\n",
      "120:\tlearn: 0.0723482\ttotal: 475ms\tremaining: 310ms\n",
      "121:\tlearn: 0.0720000\ttotal: 479ms\tremaining: 306ms\n",
      "122:\tlearn: 0.0716845\ttotal: 483ms\tremaining: 302ms\n",
      "123:\tlearn: 0.0714697\ttotal: 486ms\tremaining: 298ms\n",
      "124:\tlearn: 0.0711495\ttotal: 490ms\tremaining: 294ms\n",
      "125:\tlearn: 0.0704367\ttotal: 494ms\tremaining: 290ms\n",
      "126:\tlearn: 0.0702420\ttotal: 497ms\tremaining: 286ms\n",
      "127:\tlearn: 0.0699636\ttotal: 501ms\tremaining: 282ms\n",
      "128:\tlearn: 0.0696307\ttotal: 505ms\tremaining: 278ms\n",
      "129:\tlearn: 0.0693053\ttotal: 509ms\tremaining: 274ms\n",
      "130:\tlearn: 0.0690550\ttotal: 512ms\tremaining: 270ms\n",
      "131:\tlearn: 0.0685984\ttotal: 516ms\tremaining: 266ms\n",
      "132:\tlearn: 0.0684182\ttotal: 521ms\tremaining: 262ms\n",
      "133:\tlearn: 0.0682335\ttotal: 524ms\tremaining: 258ms\n",
      "134:\tlearn: 0.0680519\ttotal: 528ms\tremaining: 254ms\n",
      "135:\tlearn: 0.0677669\ttotal: 532ms\tremaining: 250ms\n",
      "136:\tlearn: 0.0674847\ttotal: 535ms\tremaining: 246ms\n",
      "137:\tlearn: 0.0673411\ttotal: 539ms\tremaining: 242ms\n",
      "138:\tlearn: 0.0670158\ttotal: 542ms\tremaining: 238ms\n",
      "139:\tlearn: 0.0667821\ttotal: 546ms\tremaining: 234ms\n",
      "140:\tlearn: 0.0664906\ttotal: 550ms\tremaining: 230ms\n",
      "141:\tlearn: 0.0662290\ttotal: 553ms\tremaining: 226ms\n",
      "142:\tlearn: 0.0659928\ttotal: 557ms\tremaining: 222ms\n",
      "143:\tlearn: 0.0656658\ttotal: 560ms\tremaining: 218ms\n",
      "144:\tlearn: 0.0651090\ttotal: 563ms\tremaining: 214ms\n",
      "145:\tlearn: 0.0649723\ttotal: 569ms\tremaining: 210ms\n",
      "146:\tlearn: 0.0647896\ttotal: 572ms\tremaining: 206ms\n",
      "147:\tlearn: 0.0645355\ttotal: 576ms\tremaining: 202ms\n",
      "148:\tlearn: 0.0641741\ttotal: 580ms\tremaining: 198ms\n",
      "149:\tlearn: 0.0637909\ttotal: 583ms\tremaining: 194ms\n",
      "150:\tlearn: 0.0637909\ttotal: 586ms\tremaining: 190ms\n",
      "151:\tlearn: 0.0636693\ttotal: 589ms\tremaining: 186ms\n",
      "152:\tlearn: 0.0634228\ttotal: 594ms\tremaining: 183ms\n",
      "153:\tlearn: 0.0632366\ttotal: 599ms\tremaining: 179ms\n",
      "154:\tlearn: 0.0632344\ttotal: 602ms\tremaining: 175ms\n",
      "155:\tlearn: 0.0630150\ttotal: 605ms\tremaining: 171ms\n",
      "156:\tlearn: 0.0626968\ttotal: 609ms\tremaining: 167ms\n",
      "157:\tlearn: 0.0622522\ttotal: 613ms\tremaining: 163ms\n",
      "158:\tlearn: 0.0620940\ttotal: 616ms\tremaining: 159ms\n",
      "159:\tlearn: 0.0618875\ttotal: 620ms\tremaining: 155ms\n",
      "160:\tlearn: 0.0618141\ttotal: 624ms\tremaining: 151ms\n",
      "161:\tlearn: 0.0615646\ttotal: 627ms\tremaining: 147ms\n",
      "162:\tlearn: 0.0611178\ttotal: 632ms\tremaining: 143ms\n",
      "163:\tlearn: 0.0606665\ttotal: 635ms\tremaining: 139ms\n",
      "164:\tlearn: 0.0604395\ttotal: 639ms\tremaining: 135ms\n",
      "165:\tlearn: 0.0601890\ttotal: 643ms\tremaining: 132ms\n",
      "166:\tlearn: 0.0600942\ttotal: 646ms\tremaining: 128ms\n",
      "167:\tlearn: 0.0598555\ttotal: 650ms\tremaining: 124ms\n",
      "168:\tlearn: 0.0597652\ttotal: 654ms\tremaining: 120ms\n",
      "169:\tlearn: 0.0595741\ttotal: 657ms\tremaining: 116ms\n",
      "170:\tlearn: 0.0592036\ttotal: 661ms\tremaining: 112ms\n",
      "171:\tlearn: 0.0589430\ttotal: 665ms\tremaining: 108ms\n",
      "172:\tlearn: 0.0589306\ttotal: 669ms\tremaining: 104ms\n",
      "173:\tlearn: 0.0588223\ttotal: 672ms\tremaining: 100ms\n",
      "174:\tlearn: 0.0587092\ttotal: 677ms\tremaining: 96.7ms\n",
      "175:\tlearn: 0.0585003\ttotal: 681ms\tremaining: 92.9ms\n",
      "176:\tlearn: 0.0582466\ttotal: 685ms\tremaining: 89ms\n",
      "177:\tlearn: 0.0582062\ttotal: 689ms\tremaining: 85.2ms\n",
      "178:\tlearn: 0.0582020\ttotal: 693ms\tremaining: 81.3ms\n",
      "179:\tlearn: 0.0581448\ttotal: 696ms\tremaining: 77.4ms\n",
      "180:\tlearn: 0.0578269\ttotal: 700ms\tremaining: 73.5ms\n",
      "181:\tlearn: 0.0575627\ttotal: 704ms\tremaining: 69.6ms\n",
      "182:\tlearn: 0.0573948\ttotal: 708ms\tremaining: 65.7ms\n",
      "183:\tlearn: 0.0571807\ttotal: 711ms\tremaining: 61.9ms\n",
      "184:\tlearn: 0.0571506\ttotal: 715ms\tremaining: 58ms\n",
      "185:\tlearn: 0.0570986\ttotal: 719ms\tremaining: 54.1ms\n",
      "186:\tlearn: 0.0569670\ttotal: 722ms\tremaining: 50.2ms\n",
      "187:\tlearn: 0.0568498\ttotal: 726ms\tremaining: 46.3ms\n",
      "188:\tlearn: 0.0568277\ttotal: 729ms\tremaining: 42.5ms\n",
      "189:\tlearn: 0.0565142\ttotal: 733ms\tremaining: 38.6ms\n",
      "190:\tlearn: 0.0563593\ttotal: 737ms\tremaining: 34.7ms\n",
      "191:\tlearn: 0.0561832\ttotal: 741ms\tremaining: 30.9ms\n",
      "192:\tlearn: 0.0559811\ttotal: 744ms\tremaining: 27ms\n",
      "193:\tlearn: 0.0557643\ttotal: 748ms\tremaining: 23.1ms\n",
      "194:\tlearn: 0.0556819\ttotal: 752ms\tremaining: 19.3ms\n",
      "195:\tlearn: 0.0556278\ttotal: 755ms\tremaining: 15.4ms\n",
      "196:\tlearn: 0.0555956\ttotal: 759ms\tremaining: 11.6ms\n",
      "197:\tlearn: 0.0555257\ttotal: 762ms\tremaining: 7.7ms\n",
      "198:\tlearn: 0.0554976\ttotal: 766ms\tremaining: 3.85ms\n",
      "199:\tlearn: 0.0554207\ttotal: 769ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Refit model with best parameters, specifying categorical features again\n",
    "best_cat = grid_search.best_estimator_\n",
    "best_cat.fit(X_train, y_train, cat_features=categorical_indices)\n",
    "\n",
    "# Make predictions on the validation set, specifying categorical features again\n",
    "y_pred = best_cat.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1701\n",
      "           1       0.97      0.86      0.91       325\n",
      "\n",
      "    accuracy                           0.97      2026\n",
      "   macro avg       0.97      0.93      0.95      2026\n",
      "weighted avg       0.97      0.97      0.97      2026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = best_cat.get_feature_importance(Pool(X_train, label=y_train, cat_features=categorical_indices))\n",
    "\n",
    "# Create a dataframe to store feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort features by importance (descending order)\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], align='center')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Client Churn Prediction Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Models\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>...</th>\n",
       "      <th>Income_Category_$120K +</th>\n",
       "      <th>Income_Category_$40K - $60K</th>\n",
       "      <th>Income_Category_$60K - $80K</th>\n",
       "      <th>Income_Category_$80K - $120K</th>\n",
       "      <th>Income_Category_Less than $40K</th>\n",
       "      <th>Income_Category_Unknown</th>\n",
       "      <th>Card_Category_Blue</th>\n",
       "      <th>Card_Category_Gold</th>\n",
       "      <th>Card_Category_Platinum</th>\n",
       "      <th>Card_Category_Silver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "0            45                3              39                         5   \n",
       "1            49                5              44                         6   \n",
       "2            51                3              36                         4   \n",
       "3            40                4              34                         3   \n",
       "4            40                3              21                         5   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                       1                      3       12691.0   \n",
       "1                       1                      2        8256.0   \n",
       "2                       1                      0        3418.0   \n",
       "3                       4                      1        3313.0   \n",
       "4                       1                      0        4716.0   \n",
       "\n",
       "   Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  ...  \\\n",
       "0                  777          11914.0                 1.335  ...   \n",
       "1                  864           7392.0                 1.541  ...   \n",
       "2                    0           3418.0                 2.594  ...   \n",
       "3                 2517            796.0                 1.405  ...   \n",
       "4                    0           4716.0                 2.175  ...   \n",
       "\n",
       "   Income_Category_$120K +  Income_Category_$40K - $60K  \\\n",
       "0                    False                        False   \n",
       "1                    False                        False   \n",
       "2                    False                        False   \n",
       "3                    False                        False   \n",
       "4                    False                        False   \n",
       "\n",
       "   Income_Category_$60K - $80K  Income_Category_$80K - $120K  \\\n",
       "0                         True                         False   \n",
       "1                        False                         False   \n",
       "2                        False                          True   \n",
       "3                        False                         False   \n",
       "4                         True                         False   \n",
       "\n",
       "   Income_Category_Less than $40K  Income_Category_Unknown  \\\n",
       "0                           False                    False   \n",
       "1                            True                    False   \n",
       "2                           False                    False   \n",
       "3                            True                    False   \n",
       "4                           False                    False   \n",
       "\n",
       "   Card_Category_Blue  Card_Category_Gold  Card_Category_Platinum  \\\n",
       "0                True               False                   False   \n",
       "1                True               False                   False   \n",
       "2                True               False                   False   \n",
       "3                True               False                   False   \n",
       "4                True               False                   False   \n",
       "\n",
       "   Card_Category_Silver  \n",
       "0                 False  \n",
       "1                 False  \n",
       "2                 False  \n",
       "3                 False  \n",
       "4                 False  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding categorical features (label encoding)\n",
    "for col in X.select_dtypes('category').columns:\n",
    "    dummies = pd.get_dummies(X[[col]])\n",
    "    X = pd.concat([X, dummies], axis=1)\n",
    "    X = X.drop([col], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 37 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Customer_Age                    10127 non-null  int64  \n",
      " 1   Dependent_count                 10127 non-null  int64  \n",
      " 2   Months_on_book                  10127 non-null  int64  \n",
      " 3   Total_Relationship_Count        10127 non-null  int64  \n",
      " 4   Months_Inactive_12_mon          10127 non-null  int64  \n",
      " 5   Contacts_Count_12_mon           10127 non-null  int64  \n",
      " 6   Credit_Limit                    10127 non-null  float64\n",
      " 7   Total_Revolving_Bal             10127 non-null  int64  \n",
      " 8   Avg_Open_To_Buy                 10127 non-null  float64\n",
      " 9   Total_Amt_Chng_Q4_Q1            10127 non-null  float64\n",
      " 10  Total_Trans_Amt                 10127 non-null  int64  \n",
      " 11  Total_Trans_Ct                  10127 non-null  int64  \n",
      " 12  Total_Ct_Chng_Q4_Q1             10127 non-null  float64\n",
      " 13  Avg_Utilization_Ratio           10127 non-null  float64\n",
      " 14  Gender_F                        10127 non-null  bool   \n",
      " 15  Gender_M                        10127 non-null  bool   \n",
      " 16  Education_Level_College         10127 non-null  bool   \n",
      " 17  Education_Level_Doctorate       10127 non-null  bool   \n",
      " 18  Education_Level_Graduate        10127 non-null  bool   \n",
      " 19  Education_Level_High School     10127 non-null  bool   \n",
      " 20  Education_Level_Post-Graduate   10127 non-null  bool   \n",
      " 21  Education_Level_Uneducated      10127 non-null  bool   \n",
      " 22  Education_Level_Unknown         10127 non-null  bool   \n",
      " 23  Marital_Status_Divorced         10127 non-null  bool   \n",
      " 24  Marital_Status_Married          10127 non-null  bool   \n",
      " 25  Marital_Status_Single           10127 non-null  bool   \n",
      " 26  Marital_Status_Unknown          10127 non-null  bool   \n",
      " 27  Income_Category_$120K +         10127 non-null  bool   \n",
      " 28  Income_Category_$40K - $60K     10127 non-null  bool   \n",
      " 29  Income_Category_$60K - $80K     10127 non-null  bool   \n",
      " 30  Income_Category_$80K - $120K    10127 non-null  bool   \n",
      " 31  Income_Category_Less than $40K  10127 non-null  bool   \n",
      " 32  Income_Category_Unknown         10127 non-null  bool   \n",
      " 33  Card_Category_Blue              10127 non-null  bool   \n",
      " 34  Card_Category_Gold              10127 non-null  bool   \n",
      " 35  Card_Category_Platinum          10127 non-null  bool   \n",
      " 36  Card_Category_Silver            10127 non-null  bool   \n",
      "dtypes: bool(23), float64(5), int64(9)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test Stratfied Split with stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Attrition_Flag\n",
       " 0    6799\n",
       " 1    1302\n",
       " Name: count, dtype: int64,\n",
       " Attrition_Flag\n",
       " 0    1701\n",
       " 1     325\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42,shuffle= True,stratify = y)\n",
    "y_train.value_counts(), y_val.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 40, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Recall Score: 0.8833867437687953\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search cross-validation\n",
    "\n",
    "# Define the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200, 250],\n",
    "    'max_depth': [20, 30, 40],\n",
    "    'min_samples_split': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "\n",
    "# Set up the GridSearchCV with recall as the scoring metric\n",
    "random_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cv, scoring='recall_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best Recall Score: {random_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on test set: 0.7661538461538462\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "best_rf = RandomForestClassifier(**random_search.best_params_)\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred = best_rf.predict(X_val)\n",
    "recall = recall_score(y_val, y_pred, average='binary')  \n",
    "print(f\"Recall on test set: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4532\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2065\n",
      "[LightGBM] [Info] Number of data points in the train set: 5400, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160741 -> initscore=-1.652727\n",
      "[LightGBM] [Info] Start training from score -1.652727\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2066\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 868, number of negative: 4533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160711 -> initscore=-1.652948\n",
      "[LightGBM] [Info] Start training from score -1.652948\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 1302, number of negative: 6799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2068\n",
      "[LightGBM] [Info] Number of data points in the train set: 8101, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160721 -> initscore=-1.652874\n",
      "[LightGBM] [Info] Start training from score -1.652874\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;bagging_fraction&#x27;: [0.8, 0.9, 1.0],\n",
       "                         &#x27;bagging_freq&#x27;: [5, 10, 15], &#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
       "                         &#x27;feature_fraction&#x27;: [0.8, 0.9, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
       "                         &#x27;num_leaves&#x27;: [20, 30, 40], &#x27;objective&#x27;: [&#x27;binary&#x27;]},\n",
       "             refit=&#x27;recall&#x27;,\n",
       "             scoring={&#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;)},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;bagging_fraction&#x27;: [0.8, 0.9, 1.0],\n",
       "                         &#x27;bagging_freq&#x27;: [5, 10, 15], &#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
       "                         &#x27;feature_fraction&#x27;: [0.8, 0.9, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
       "                         &#x27;num_leaves&#x27;: [20, 30, 40], &#x27;objective&#x27;: [&#x27;binary&#x27;]},\n",
       "             refit=&#x27;recall&#x27;,\n",
       "             scoring={&#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;)},\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={'bagging_fraction': [0.8, 0.9, 1.0],\n",
       "                         'bagging_freq': [5, 10, 15], 'boosting_type': ['gbdt'],\n",
       "                         'feature_fraction': [0.8, 0.9, 1.0],\n",
       "                         'learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'num_leaves': [20, 30, 40], 'objective': ['binary']},\n",
       "             refit='recall',\n",
       "             scoring={'recall': make_scorer(recall_score, response_method='predict')},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'objective': ['binary'],                # Binary classification\n",
    "    'num_leaves': [20, 30, 40],             # Maximum number of leaves in one tree\n",
    "    'learning_rate': [0.05, 0.1, 0.2],      # Learning rate (shrinkage)\n",
    "    'feature_fraction': [0.8, 0.9, 1.0],    # Percentage of features to consider\n",
    "    'bagging_fraction': [0.8, 0.9, 1.0],    # Percentage of data to use in each iteration (bagging)\n",
    "    'bagging_freq': [5, 10, 15],            # Frequency for bagging\n",
    "}\n",
    "\n",
    "scoring = {'recall': make_scorer(recall_score)}\n",
    "\n",
    "boost_search = GridSearchCV(clf, param_grid=param_grid, scoring=scoring, refit='recall',\n",
    "                           cv=3, verbose=1, n_jobs=-1)\n",
    "boost_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bagging_fraction': 0.8, 'bagging_freq': 15, 'boosting_type': 'gbdt', 'feature_fraction': 1.0, 'learning_rate': 0.2, 'num_leaves': 30, 'objective': 'binary'}\n"
     ]
    }
   ],
   "source": [
    "# Best parameters found during grid search\n",
    "print(f'Best parameters: {boost_search.best_params_}')\n",
    "best_params = boost_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 1302, number of negative: 6799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2068\n",
      "[LightGBM] [Info] Number of data points in the train set: 8101, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160721 -> initscore=-1.652874\n",
      "[LightGBM] [Info] Start training from score -1.652874\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Recall: 0.8523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1701\n",
      "           1       0.93      0.85      0.89       325\n",
      "\n",
      "    accuracy                           0.97      2026\n",
      "   macro avg       0.95      0.92      0.93      2026\n",
      "weighted avg       0.97      0.97      0.97      2026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the XGBoost model with the best hyperparameters\n",
    "best_model = lgb.LGBMClassifier(**best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set using the best model\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_val, y_pred)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Display classification report (precision, recall, F1-score, support)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the underlying LightGBM Booster object\n",
    "booster = best_model.booster_\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = booster.feature_importance(importance_type='gain')\n",
    "\n",
    "# Sort feature importance in descending order\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(8, 10))  # Adjust the figure size as needed\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), X_train.columns[sorted_idx])\n",
    "plt.xlabel('Feature Importance (Gain)')\n",
    "plt.ylabel('Features')\n",
    "plt.title('LightGBM Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to display most important features at the top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
